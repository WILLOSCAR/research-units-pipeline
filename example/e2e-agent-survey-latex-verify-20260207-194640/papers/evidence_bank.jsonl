{"evidence_id": "E-P0001-43f54265e8", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "method", "snippet": "We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0001-ca4a00b5cf", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "result", "snippet": "On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0001-604e8557e1", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "result", "snippet": "We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0001-8d0b22fef5", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0001-4f8536e0c6", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0001-d0f1113f52", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0001-1ac73ff02d", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0001-f18242e304", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "summary", "snippet": "On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0002-a8cd1f03c8", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0002-67875fd02f", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0002-9c4c3d45ac", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0002-f1f4c8649c", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller models excel.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0002-a58d26cb94", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0002-8f44086775", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0002-19f40531ed", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0003-b0fdbdd3a5", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose Reflexion, a novel framework to reinforce language agents not by updating weights, but instead through linguistic feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0003-a402af154b", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "For example, Reflexion achieves a 91% pass@1 accuracy on the HumanEval coding benchmark, surpassing the previous state-of-the-art GPT-4 that achieves 80%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0003-fb3046de14", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have been increasingly used to interact with external environments (e.g., games, compilers, APIs) as goal-driven agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0003-6c4bb4831c", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, it remains challenging for these language agents to quickly and efficiently learn from trial-and-error as traditional reinforcement learning methods require extensive training samples and expensive model fine-tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0003-901b0c3e29", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose Reflexion, a novel framework to reinforce language agents not by updating weights, but instead through linguistic feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0003-3f6b365112", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Concretely, Reflexion agents verbally reflect on task feedback signals, then maintain their own reflective text in an episodic memory buffer to induce better decision-making in subsequent trials.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0003-50d96acd26", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reflexion is flexible enough to incorporate various types (scalar values or free-form language) and sources (external or internally simulated) of feedback signals, and obtains significant improvements over a baseline agent across diverse tasks (sequential decision-making, coding, language reasoning).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0004-83af02f575", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0004-b9cd4289ed", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4% of tasks, our method achieved a success rate of 74%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0004-110ba95352", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0004-e9d0fe92c8", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0004-f64609094e", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0004-de6a7d0720", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0004-abde03b1c3", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0004-676a7be5f2", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0005-c57fee9291", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0005-b2eceb5b30", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "It obtains 3.3x more unique items, travels 2.3x longer distances, and unlocks key tech tree milestones up to 15.3x faster than prior SOTA.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0005-506120a6cd", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0005-e65ddaea31", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0005-c5ade9e083", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0005-51338842b2", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Voyager interacts with GPT-4 via blackbox queries, which bypasses the need for model parameter fine-tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0005-cc1ce5543d", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The skills developed by Voyager are temporally extended, interpretable, and compositional, which compounds the agent's abilities rapidly and alleviates catastrophic forgetting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0005-437d13c92d", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Empirically, Voyager shows strong in-context lifelong learning capability and exhibits exceptional proficiency in playing Minecraft.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0006-ce3104c142", "paper_id": "P0006", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Background: There is great interest in agentic LLMs, large language models that act as agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0006-2fb0b1b9ae", "paper_id": "P0006", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Methods: Agentic LLMs are LLMs that (1) reason, (2) act, and (3) interact.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0006-a1fb101bda", "paper_id": "P0006", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Further, agentic LLMs provide a solution for the problem of LLMs running out of training data: inference-time behavior generates new training states, such that LLMs can keep learning without needing ever larger datasets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0006-c14b84b190", "paper_id": "P0006", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Background: There is great interest in agentic LLMs, large language models that act as agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0006-0ffaa050ce", "paper_id": "P0006", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Objectives: We review the growing body of work in this area and provide a research agenda.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0006-4f05d5ff66", "paper_id": "P0006", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Methods: Agentic LLMs are LLMs that (1) reason, (2) act, and (3) interact.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0006-31fd7ed1c6", "paper_id": "P0006", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We organize the literature according to these three categories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0006-22d432dd58", "paper_id": "P0006", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Results: The research in the first category focuses on reasoning, reflection, and retrieval, aiming to improve decision making; the second category focuses on action models, robots, and tools, aiming for agents that act as useful assistants; the third category focuses on multi-agent systems, aiming for collaborative task solving and simulating interaction to study emergent social behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0006-e688e4a34e", "paper_id": "P0006", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "We note that there is risk associated with LLM assistants taking action in the real world-safety, liability and security are open problems-while agentic LLMs are also likely to benefit society.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0007-62b8101d4e", "paper_id": "P0007", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Tool use, planning, and feedback learning are currently three prominent paradigms for developing Large Language Model (LLM)-based agents across various tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0007-dc2266b72d", "paper_id": "P0007", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Specifically, 1) the taxonomy defines environments/tasks, common LLM-profiled roles or LMPRs (policy models, evaluators, and dynamic models), and universally applicable workflows found in prior work, and 2) it enables a comparison of key perspectives on the implementations of LMPRs and workflow designs across different agent paradigms and frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0007-81a4fb82d1", "paper_id": "P0007", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "3) Finally, we identify three limitations in existing workflow designs and systematically discuss the future work.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0007-a25d9c6a6c", "paper_id": "P0007", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tool use, planning, and feedback learning are currently three prominent paradigms for developing Large Language Model (LLM)-based agents across various tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0007-7f05d2fa5c", "paper_id": "P0007", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Although numerous frameworks have been devised for each paradigm, their intricate workflows and inconsistent taxonomy create challenges in understanding and reviewing the frameworks across different paradigms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0007-8d4ea17e2b", "paper_id": "P0007", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey introduces a unified taxonomy to systematically review and discuss these frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0007-480e7513c3", "paper_id": "P0007", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Specifically, 1) the taxonomy defines environments/tasks, common LLM-profiled roles or LMPRs (policy models, evaluators, and dynamic models), and universally applicable workflows found in prior work, and 2) it enables a comparison of key perspectives on the implementations of LMPRs and workflow designs across different agent paradigms and frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0007-f122d06471", "paper_id": "P0007", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "3) Finally, we identify three limitations in existing workflow designs and systematically discuss the future work.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0007-3c57288d9a", "paper_id": "P0007", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "3) Finally, we identify three limitations in existing workflow designs and systematically discuss the future work.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#limitations[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0008-c63f9e7a62", "paper_id": "P0008", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we explore the Large Language Model (LLM) agent reviewer dynamics in an Elo-ranked review system using real-world conference paper submissions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0008-a11e93b0b9", "paper_id": "P0008", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our simulation results showcase several interesting findings, including how incorporating Elo improves Area Chair decision accuracy, as well as reviewers' adaptive review strategy that exploits our Elo system without improving review effort.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0008-7a3393ef27", "paper_id": "P0008", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we explore the Large Language Model (LLM) agent reviewer dynamics in an Elo-ranked review system using real-world conference paper submissions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0008-ff3cba1c44", "paper_id": "P0008", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Multiple LLM agent reviewers with different personas are engage in multi round review interactions moderated by an Area Chair.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0008-82b5ed27f7", "paper_id": "P0008", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We compare a baseline setting with conditions that incorporate Elo ratings and reviewer memory.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0008-016742e4cb", "paper_id": "P0008", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our simulation results showcase several interesting findings, including how incorporating Elo improves Area Chair decision accuracy, as well as reviewers' adaptive review strategy that exploits our Elo system without improving review effort.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0008-8c677aaeca", "paper_id": "P0008", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our code is available at https://github.com/hsiangwei0903/EloReview.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0009-e2f85933e8", "paper_id": "P0009", "bibkey": "Guo2025Comprehensive", "title": "A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To contextualize this progress, we present a unified pipeline illustrating the workflow from task specification to deliverables, detailing how different solution paradigms address various complexity levels.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0009-e183231464", "paper_id": "P0009", "bibkey": "Guo2025Comprehensive", "title": "A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We review over 150 recent papers and propose a taxonomy along two key dimensions: (1) Solutions, categorized into prompt-based, fine-tuning-based, and agent-based paradigms, and (2) Benchmarks, including tasks such as code generation, translation, and repair.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0009-30bd885b0c", "paper_id": "P0009", "bibkey": "Guo2025Comprehensive", "title": "A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Unlike prior surveys that focus narrowly on specific aspects, this work connects 50+ benchmarks to their corresponding solution strategies, enabling researchers to identify optimal approaches for diverse evaluation criteria.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0009-5dd58aed88", "paper_id": "P0009", "bibkey": "Guo2025Comprehensive", "title": "A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The integration of Large Language Models (LLMs) into software engineering has driven a transition from traditional rule-based systems to autonomous agentic systems capable of solving complex problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0009-5dae3d6c93", "paper_id": "P0009", "bibkey": "Guo2025Comprehensive", "title": "A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, systematic progress is hindered by a lack of comprehensive understanding of how benchmarks and solutions interconnect.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0009-6a1af562e8", "paper_id": "P0009", "bibkey": "Guo2025Comprehensive", "title": "A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey addresses this gap by providing the first holistic analysis of LLM-powered software engineering, offering insights into evaluation methodologies and solution paradigms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0009-e45f78421b", "paper_id": "P0009", "bibkey": "Guo2025Comprehensive", "title": "A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We review over 150 recent papers and propose a taxonomy along two key dimensions: (1) Solutions, categorized into prompt-based, fine-tuning-based, and agent-based paradigms, and (2) Benchmarks, including tasks such as code generation, translation, and repair.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0009-b6c6899193", "paper_id": "P0009", "bibkey": "Guo2025Comprehensive", "title": "A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our analysis highlights the evolution from simple prompt engineering to sophisticated agentic systems incorporating capabilities like planning, reasoning, memory mechanisms, and tool augmentation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0010-b75c597e91", "paper_id": "P0010", "bibkey": "Yu2025Survey", "title": "A Survey on Trustworthy LLM Agents: Threats and Countermeasures", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this survey, we propose the TrustAgent framework, a comprehensive study on the trustworthiness of agents, characterized by modular taxonomy, multi-dimensional connotations, and technical implementation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0010-74b194488e", "paper_id": "P0010", "bibkey": "Yu2025Survey", "title": "A Survey on Trustworthy LLM Agents: Threats and Countermeasures", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "By thoroughly investigating and summarizing newly emerged attacks, defenses, and evaluation methods for agents and MAS, we extend the concept of Trustworthy LLM to the emerging paradigm of Trustworthy Agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "security"]}
{"evidence_id": "E-P0010-fd7a72d3e0", "paper_id": "P0010", "bibkey": "Yu2025Survey", "title": "A Survey on Trustworthy LLM Agents: Threats and Countermeasures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the rapid evolution of Large Language Models (LLMs), LLM-based agents and Multi-agent Systems (MAS) have significantly expanded the capabilities of LLM ecosystems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0010-db39332e77", "paper_id": "P0010", "bibkey": "Yu2025Survey", "title": "A Survey on Trustworthy LLM Agents: Threats and Countermeasures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This evolution stems from empowering LLMs with additional modules such as memory, tools, environment, and even other agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0010-3538f5d0b1", "paper_id": "P0010", "bibkey": "Yu2025Survey", "title": "A Survey on Trustworthy LLM Agents: Threats and Countermeasures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, this advancement has also introduced more complex issues of trustworthiness, which previous research focused solely on LLMs could not cover.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0010-b71fc1ecf3", "paper_id": "P0010", "bibkey": "Yu2025Survey", "title": "A Survey on Trustworthy LLM Agents: Threats and Countermeasures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this survey, we propose the TrustAgent framework, a comprehensive study on the trustworthiness of agents, characterized by modular taxonomy, multi-dimensional connotations, and technical implementation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0010-aafbaf2653", "paper_id": "P0010", "bibkey": "Yu2025Survey", "title": "A Survey on Trustworthy LLM Agents: Threats and Countermeasures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By thoroughly investigating and summarizing newly emerged attacks, defenses, and evaluation methods for agents and MAS, we extend the concept of Trustworthy LLM to the emerging paradigm of Trustworthy Agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "security"]}
{"evidence_id": "E-P0011-455a6721bd", "paper_id": "P0011", "bibkey": "Du2025Survey", "title": "A Survey on the Optimization of Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "With the rapid development of Large Language Models (LLMs), LLM-based agents have been widely adopted in various fields, becoming essential for autonomous decision-making and interactive tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0011-f0ea009256", "paper_id": "P0011", "bibkey": "Du2025Survey", "title": "A Survey on the Optimization of Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we summarize the datasets and benchmarks used for evaluation and tuning, review key applications of LLM-based agents, and discuss major challenges and promising future directions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0011-87f9935f5e", "paper_id": "P0011", "bibkey": "Du2025Survey", "title": "A Survey on the Optimization of Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the rapid development of Large Language Models (LLMs), LLM-based agents have been widely adopted in various fields, becoming essential for autonomous decision-making and interactive tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0011-26210903cc", "paper_id": "P0011", "bibkey": "Du2025Survey", "title": "A Survey on the Optimization of Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, current work typically relies on prompt design or fine-tuning strategies applied to vanilla LLMs, which often leads to limited effectiveness or suboptimal performance in complex agent-related environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0011-08efa921ed", "paper_id": "P0011", "bibkey": "Du2025Survey", "title": "A Survey on the Optimization of Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Although LLM optimization techniques can improve model performance across many general tasks, they lack specialized optimization towards critical agent functionalities such as long-term planning, dynamic environmental interaction, and complex decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0011-e4d5a179c9", "paper_id": "P0011", "bibkey": "Du2025Survey", "title": "A Survey on the Optimization of Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Although numerous recent studies have explored various strategies to optimize LLM-based agents for complex agent tasks, a systematic review summarizing and comparing these methods from a holistic perspective is still lacking.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0011-21d42345ac", "paper_id": "P0011", "bibkey": "Du2025Survey", "title": "A Survey on the Optimization of Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this survey, we provide a comprehensive review of LLM-based agent optimization approaches, categorizing them into parameter-driven and parameter-free methods.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0012-9de2760a61", "paper_id": "P0012", "bibkey": "Chowa2025From", "title": "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The pursuit of human-level artificial intelligence (AI) has significantly advanced the development of autonomous agents and Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0012-e0bcca0d9e", "paper_id": "P0012", "bibkey": "Chowa2025From", "title": "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Furthermore, we evaluated current benchmarks and assessment protocols and have provided an analysis of 68 publicly available datasets to assess the performance of LLM-based agents in various tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0012-a0fdb95626", "paper_id": "P0012", "bibkey": "Chowa2025From", "title": "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We only used the papers published between 2023 and 2025 in conferences of the A* and A rank and Q1 journals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0012-e0d8a082bf", "paper_id": "P0012", "bibkey": "Chowa2025From", "title": "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The pursuit of human-level artificial intelligence (AI) has significantly advanced the development of autonomous agents and Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0012-9ba636b243", "paper_id": "P0012", "bibkey": "Chowa2025From", "title": "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLMs are now widely utilized as decision-making agents for their ability to interpret instructions, manage sequential tasks, and adapt through feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0012-eede1b39a1", "paper_id": "P0012", "bibkey": "Chowa2025From", "title": "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This review examines recent developments in employing LLMs as autonomous agents and tool users and comprises seven research questions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0012-073ff381e9", "paper_id": "P0012", "bibkey": "Chowa2025From", "title": "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We only used the papers published between 2023 and 2025 in conferences of the A* and A rank and Q1 journals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0012-bca033cb92", "paper_id": "P0012", "bibkey": "Chowa2025From", "title": "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A structured analysis of the LLM agents' architectural design principles, dividing their applications into single-agent and multi-agent systems, and strategies for integrating external tools is presented.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0013-3fba6078a3", "paper_id": "P0013", "bibkey": "Nandi2025Bench", "title": "SOP-Bench: Complex Industrial SOPs for Evaluating LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this, we present three main contributions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0013-4e80a740e1", "paper_id": "P0013", "bibkey": "Nandi2025Bench", "title": "SOP-Bench: Complex Industrial SOPs for Evaluating LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Second, using this framework, we develop SOP-Bench, a benchmark of over 1,800 tasks across 10 industrial domains, each with APIs, tool interfaces, and human-validated test cases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0013-7cbad569a0", "paper_id": "P0013", "bibkey": "Nandi2025Bench", "title": "SOP-Bench: Complex Industrial SOPs for Evaluating LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Third, we evaluate two prominent agent architectures: Function-Calling and ReAct Agents, on SOP-Bench, observing average success rates of only 27% and 48%, respectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0013-946ab30f91", "paper_id": "P0013", "bibkey": "Nandi2025Bench", "title": "SOP-Bench: Complex Industrial SOPs for Evaluating LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) demonstrate impressive general-purpose reasoning and problem-solving abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0013-1a4a664a8a", "paper_id": "P0013", "bibkey": "Nandi2025Bench", "title": "SOP-Bench: Complex Industrial SOPs for Evaluating LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, they struggle with executing complex, long-horizon workflows that demand strict adherence to Standard Operating Procedures (SOPs), a critical requirement for real-world industrial automation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0013-a7be60b202", "paper_id": "P0013", "bibkey": "Nandi2025Bench", "title": "SOP-Bench: Complex Industrial SOPs for Evaluating LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite this need, there is a lack of public benchmarks that reflect the complexity, structure, and domain-specific nuances of SOPs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0013-83f368fc1c", "paper_id": "P0013", "bibkey": "Nandi2025Bench", "title": "SOP-Bench: Complex Industrial SOPs for Evaluating LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this, we present three main contributions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0013-40116f4954", "paper_id": "P0013", "bibkey": "Nandi2025Bench", "title": "SOP-Bench: Complex Industrial SOPs for Evaluating LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "First, we introduce a synthetic data generation framework to create realistic, industry-grade SOPs that rigorously test the planning, reasoning, and tool-use capabilities of LLM-based agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0014-1564795a81", "paper_id": "P0014", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a stealthy, multi-turn economic DoS attack that operates at the tool layer under the guise of a correctly completed task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#method"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0014-b6b7af5a81", "paper_id": "P0014", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across six LLMs on the ToolBench and BFCL benchmarks, our attack expands tasks into trajectories exceeding 60,000 tokens, inflates costs by up to 658x, and raises energy by 100-560x.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0014-0e9bf4bf0b", "paper_id": "P0014", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "It drives GPU KV cache occupancy from <1% to 35-74% and cuts co-running throughput by approximately 50%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0014-09300516c9", "paper_id": "P0014", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The agent-tool communication loop is a critical attack surface in modern Large Language Model (LLM) agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#summary_bullets[0]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0014-eb0bf8bedb", "paper_id": "P0014", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing Denial-of-Service (DoS) attacks, primarily triggered via user prompts or injected retrieval-augmented generation (RAG) context, are ineffective for this new paradigm.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "security"]}
{"evidence_id": "E-P0014-62b0277ae2", "paper_id": "P0014", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "They are fundamentally single-turn and often lack a task-oriented approach, making them conspicuous in goal-oriented workflows and unable to exploit the compounding costs of multi-turn agent-tool interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0014-d63edf9032", "paper_id": "P0014", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce a stealthy, multi-turn economic DoS attack that operates at the tool layer under the guise of a correctly completed task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#summary_bullets[3]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0014-508d7b3dcc", "paper_id": "P0014", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our method adjusts text-visible fields and a template-governed return policy in a benign, Model Context Protocol (MCP)-compatible tool server, optimizing these edits with a Monte Carlo Tree Search (MCTS) optimizer.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0015-fe9d1f4c75", "paper_id": "P0015", "bibkey": "Lu2025Just", "title": "Don't Just Fine-tune the Agent, Tune the Environment", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we introduce $\\textbf{Environment Tuning}$, a novel training paradigm that enables agents to learn complex behaviors directly from problem instances without relying on pre-collected expert trajectories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0015-763cb193e3", "paper_id": "P0015", "bibkey": "Lu2025Just", "title": "Don't Just Fine-tune the Agent, Tune the Environment", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Using only 400 problem instances from Berkeley Function-Calling Leaderboard (BFCL) benchmark, our method not only achieves competitive in-distribution performance against strong baselines but also demonstrates superior out-of-distribution generalization, overcoming the performance collapse common to SFT-based approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0015-d28d2d9fa0", "paper_id": "P0015", "bibkey": "Lu2025Just", "title": "Don't Just Fine-tune the Agent, Tune the Environment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents show great promise for complex, multi-turn tool-use tasks, but their development is often hampered by the extreme scarcity of high-quality training data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0015-ab7d4050ad", "paper_id": "P0015", "bibkey": "Lu2025Just", "title": "Don't Just Fine-tune the Agent, Tune the Environment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Supervised fine-tuning (SFT) on synthetic data leads to overfitting, whereas standard reinforcement learning (RL) struggles with a critical cold-start problem and training instability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0015-f77f16e445", "paper_id": "P0015", "bibkey": "Lu2025Just", "title": "Don't Just Fine-tune the Agent, Tune the Environment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these challenges, we introduce $\\textbf{Environment Tuning}$, a novel training paradigm that enables agents to learn complex behaviors directly from problem instances without relying on pre-collected expert trajectories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0015-60f288f7e6", "paper_id": "P0015", "bibkey": "Lu2025Just", "title": "Don't Just Fine-tune the Agent, Tune the Environment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "$\\textbf{Environment Tuning}$ orchestrates this learning process through a structured curriculum, actionable environment augmentation that provides corrective feedback, and fine-grained progress rewards to ensure stable and efficient exploration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0015-e7a87ab109", "paper_id": "P0015", "bibkey": "Lu2025Just", "title": "Don't Just Fine-tune the Agent, Tune the Environment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Using only 400 problem instances from Berkeley Function-Calling Leaderboard (BFCL) benchmark, our method not only achieves competitive in-distribution performance against strong baselines but also demonstrates superior out-of-distribution generalization, overcoming the performance collapse common to SFT-based approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0016-bbaca264f1", "paper_id": "P0016", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large language models (LLMs) and agent techniques have brought a fundamental shift in the functionality and development paradigm of data analysis tasks (a.k.a LLM/Agent-as-Data-Analyst), demonstrating substantial impact across both academia and industry.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0016-db233dcd06", "paper_id": "P0016", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we outline the remaining challenges and propose several insights and practical directions for advancing LLM/Agent-powered data analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0016-4e35a5103c", "paper_id": "P0016", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) and agent techniques have brought a fundamental shift in the functionality and development paradigm of data analysis tasks (a.k.a LLM/Agent-as-Data-Analyst), demonstrating substantial impact across both academia and industry.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0016-d66e2031cc", "paper_id": "P0016", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In comparison with traditional rule or small-model based approaches, (agentic) LLMs enable complex data understanding, natural language interfaces, semantic analysis functions, and autonomous pipeline orchestration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0016-a4245dcbb7", "paper_id": "P0016", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "From a modality perspective, we review LLM-based techniques for (i) structured data (e.g., NL2SQL, NL2GQL, ModelQA), (ii) semi-structured data (e.g., markup languages understanding, semi-structured table question answering), (iii) unstructured data (e.g., chart understanding, text/image document understanding), and (iv) heterogeneous data (e.g., data retrieval and modality alignment in data lakes).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0016-f66becbbae", "paper_id": "P0016", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The technical evolution further distills four key design goals for intelligent data analysis agents, namely semantic-aware design, autonomous pipelines, tool-augmented workflows, and support for open-world tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0016-46c53ee83d", "paper_id": "P0016", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Finally, we outline the remaining challenges and propose several insights and practical directions for advancing LLM/Agent-powered data analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0017-7cdfbf595a", "paper_id": "P0017", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The era of intelligent agents is upon us, driven by revolutionary advancements in large language models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0017-62cd0c501b", "paper_id": "P0017", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our work provides a unified architectural perspective, examining how agents are constructed, how they collaborate, and how they evolve over time, while also addressing evaluation methodologies, tool applications, practical challenges, and diverse application domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0017-65aa5a8555", "paper_id": "P0017", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The era of intelligent agents is upon us, driven by revolutionary advancements in large language models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0017-8447fe66ad", "paper_id": "P0017", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents, with goal-driven behaviors and dynamic adaptation capabilities, potentially represent a critical pathway toward artificial general intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0017-a47c55035c", "paper_id": "P0017", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey systematically deconstructs LLM agent systems through a methodology-centered taxonomy, linking architectural foundations, collaboration mechanisms, and evolutionary pathways.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0017-0f169966db", "paper_id": "P0017", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We unify fragmented research threads by revealing fundamental connections between agent design principles and their emergent behaviors in complex environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0017-4593284463", "paper_id": "P0017", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our work provides a unified architectural perspective, examining how agents are constructed, how they collaborate, and how they evolve over time, while also addressing evaluation methodologies, tool applications, practical challenges, and diverse application domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0018-64989870cb", "paper_id": "P0018", "bibkey": "Zeng2025Rejump", "title": "ReJump: A Tree-Jump Representation for Analyzing and Improving LLM Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To investigate this, we propose ReJump, which represents a reasoning trace as a visitation order over nodes in a tree of intermediate problem-solving steps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0018-2bad4bca21", "paper_id": "P0018", "bibkey": "Zeng2025Rejump", "title": "ReJump: A Tree-Jump Representation for Analyzing and Improving LLM Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Using our proposed LLM agent to extract reasoning traces into ReJump format, we evaluate state-of-the-art LRMs on two tasks and find that models with similar accuracy can exhibit distinct reasoning behaviors, while different tasks favor different reasoning styles (e.g., varying balance between exploration and exploitation).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0018-50fa4e8999", "paper_id": "P0018", "bibkey": "Zeng2025Rejump", "title": "ReJump: A Tree-Jump Representation for Analyzing and Improving LLM Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large Reasoning Models (LRMs) are Large Language Models (LLMs) explicitly trained to generate long-form Chain-of-Thoughts (CoTs), achieving impressive success on challenging tasks like math and programming.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0018-b02c7b3da4", "paper_id": "P0018", "bibkey": "Zeng2025Rejump", "title": "ReJump: A Tree-Jump Representation for Analyzing and Improving LLM Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Reasoning Models (LRMs) are Large Language Models (LLMs) explicitly trained to generate long-form Chain-of-Thoughts (CoTs), achieving impressive success on challenging tasks like math and programming.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0018-140a794f4e", "paper_id": "P0018", "bibkey": "Zeng2025Rejump", "title": "ReJump: A Tree-Jump Representation for Analyzing and Improving LLM Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, their underlying reasoning \"algorithms\" remain poorly understood.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0018-6f8926a921", "paper_id": "P0018", "bibkey": "Zeng2025Rejump", "title": "ReJump: A Tree-Jump Representation for Analyzing and Improving LLM Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To investigate this, we propose ReJump, which represents a reasoning trace as a visitation order over nodes in a tree of intermediate problem-solving steps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0018-1140953f38", "paper_id": "P0018", "bibkey": "Zeng2025Rejump", "title": "ReJump: A Tree-Jump Representation for Analyzing and Improving LLM Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Transitions between nodes, which we term jumps, include adjacent moves that capture behaviors such as calculation, and non-adjacent moves that capture behaviors such as backtracking and verification.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0018-0ab54673b5", "paper_id": "P0018", "bibkey": "Zeng2025Rejump", "title": "ReJump: A Tree-Jump Representation for Analyzing and Improving LLM Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ReJump enables analyzing LLM reasoning with diverse metrics that quantify exploration, exploitation, overthinking, forgetting, and verification.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0019-cb7c521301", "paper_id": "P0019", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose Reasoning-Style Poisoning (RSP), a paradigm that manipulates how agents process information rather than what they process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0019-c17bcfb7d4", "paper_id": "P0019", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "It increases reasoning steps by up to 4.4 times or induces premature errors, successfully bypassing state-of-the-art content filters.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0019-e38b4bdff3", "paper_id": "P0019", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To quantify these shifts, we develop the Reasoning Style Vector (RSV), a metric tracking Verification depth, Self-confidence, and Attention focus.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0019-dac2089fae", "paper_id": "P0019", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents relying on external retrieval are increasingly deployed in high-stakes environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0019-8517628bd0", "paper_id": "P0019", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0019-8a9233d368", "paper_id": "P0019", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose Reasoning-Style Poisoning (RSP), a paradigm that manipulates how agents process information rather than what they process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0019-058627ec30", "paper_id": "P0019", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Generative Style Injection (GSI), an attack method that rewrites retrieved documents into pathological tones--specifically \"analysis paralysis\" or \"cognitive haste\"--without altering underlying facts or using explicit triggers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[3]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0019-954eb74a81", "paper_id": "P0019", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To quantify these shifts, we develop the Reasoning Style Vector (RSV), a metric tracking Verification depth, Self-confidence, and Attention focus.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0020-a59bd04069", "paper_id": "P0020", "bibkey": "Gao2025Reviewagents", "title": "ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Additionally, we propose ReviewBench, a benchmark for evaluating the review comments generated by LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0020-196ba27ffc", "paper_id": "P0020", "bibkey": "Gao2025Reviewagents", "title": "ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The primary issue lies in generating comprehensive, accurate, and reasoning-consistent review comments that align with human reviewers' judgments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0020-758a78865c", "paper_id": "P0020", "bibkey": "Gao2025Reviewagents", "title": "ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We first introduce a novel dataset, Review-CoT, consisting of 142k review comments, designed for training LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0020-592b62d123", "paper_id": "P0020", "bibkey": "Gao2025Reviewagents", "title": "ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Academic paper review is a critical yet time-consuming task within the research community.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0020-5b3e206575", "paper_id": "P0020", "bibkey": "Gao2025Reviewagents", "title": "ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the increasing volume of academic publications, automating the review process has become a significant challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0020-cb8996916b", "paper_id": "P0020", "bibkey": "Gao2025Reviewagents", "title": "ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The primary issue lies in generating comprehensive, accurate, and reasoning-consistent review comments that align with human reviewers' judgments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0020-e0581c398b", "paper_id": "P0020", "bibkey": "Gao2025Reviewagents", "title": "ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we address this challenge by proposing ReviewAgents, a framework that leverages large language models (LLMs) to generate academic paper reviews.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0020-763e4e7e83", "paper_id": "P0020", "bibkey": "Gao2025Reviewagents", "title": "ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We first introduce a novel dataset, Review-CoT, consisting of 142k review comments, designed for training LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0021-48068017a1", "paper_id": "P0021", "bibkey": "Ruangtanusak2025Talk", "title": "Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "This report investigates approaches for prompting a tool-augmented large language model (LLM) to act as a role-playing dialogue agent in the API track of the Commonsense Persona-grounded Dialogue Challenge (CPDC) 2025.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#method"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0021-dee89cf74c", "paper_id": "P0021", "bibkey": "Ruangtanusak2025Talk", "title": "Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This report investigates approaches for prompting a tool-augmented large language model (LLM) to act as a role-playing dialogue agent in the API track of the Commonsense Persona-grounded Dialogue Challenge (CPDC) 2025.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0021-6820c1de30", "paper_id": "P0021", "bibkey": "Ruangtanusak2025Talk", "title": "Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We explore four prompting approaches to address these issues: 1) basic role prompting, 2) improved role prompting, 3) automatic prompt optimization (APO), and 4) rule-based role prompting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0021-7f918d46cc", "paper_id": "P0021", "bibkey": "Ruangtanusak2025Talk", "title": "Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This report investigates approaches for prompting a tool-augmented large language model (LLM) to act as a role-playing dialogue agent in the API track of the Commonsense Persona-grounded Dialogue Challenge (CPDC) 2025.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#summary_bullets[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0021-c56aceb7cc", "paper_id": "P0021", "bibkey": "Ruangtanusak2025Talk", "title": "Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this setting, dialogue agents often produce overly long in-character responses (over-speaking) while failing to use tools effectively according to the persona (under-acting), such as generating function calls that do not exist or making unnecessary tool calls before answering.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0021-a2c80b9c6c", "paper_id": "P0021", "bibkey": "Ruangtanusak2025Talk", "title": "Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We explore four prompting approaches to address these issues: 1) basic role prompting, 2) improved role prompting, 3) automatic prompt optimization (APO), and 4) rule-based role prompting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0021-bfdc88fc95", "paper_id": "P0021", "bibkey": "Ruangtanusak2025Talk", "title": "Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rule-based role prompting (RRP) approach achieved the best performance through two novel techniques-character-card/scene-contract design and strict enforcement of function calling-which led to an overall score of 0.571, improving on the zero-shot baseline score of 0.519.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0021-ca02f2cf95", "paper_id": "P0021", "bibkey": "Ruangtanusak2025Talk", "title": "Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These findings demonstrate that RRP design can substantially improve the effectiveness and reliability of role-playing dialogue agents compared with more elaborate methods such as APO.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0022-a824ee588d", "paper_id": "P0022", "bibkey": "Yang2025Toolmind", "title": "ToolMind Technical Report: A Large-Scale, Reasoning-Enhanced Tool-Use Dataset", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these limitations, we introduce ToolMind, a large-scale, high-quality tool-agentic dataset with 160k synthetic data instances generated using over 20k tools and 200k augmented open-source data instances.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0022-cd76f89b92", "paper_id": "P0022", "bibkey": "Yang2025Toolmind", "title": "ToolMind Technical Report: A Large-Scale, Reasoning-Enhanced Tool-Use Dataset", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To address these limitations, we introduce ToolMind, a large-scale, high-quality tool-agentic dataset with 160k synthetic data instances generated using over 20k tools and 200k augmented open-source data instances.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0022-5f1ea12e35", "paper_id": "P0022", "bibkey": "Yang2025Toolmind", "title": "ToolMind Technical Report: A Large-Scale, Reasoning-Enhanced Tool-Use Dataset", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Models fine-tuned on ToolMind show significant improvements over baselines on several benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0022-6af6de8459", "paper_id": "P0022", "bibkey": "Yang2025Toolmind", "title": "ToolMind Technical Report: A Large-Scale, Reasoning-Enhanced Tool-Use Dataset", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents have developed rapidly in recent years to solve complex real-world problems using external tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0022-82ed0dcec3", "paper_id": "P0022", "bibkey": "Yang2025Toolmind", "title": "ToolMind Technical Report: A Large-Scale, Reasoning-Enhanced Tool-Use Dataset", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the scarcity of high-quality trajectories still hinders the development of stronger LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0022-6f0318b974", "paper_id": "P0022", "bibkey": "Yang2025Toolmind", "title": "ToolMind Technical Report: A Large-Scale, Reasoning-Enhanced Tool-Use Dataset", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Most existing works on multi-turn dialogue synthesis validate correctness only at the trajectory level, which may overlook turn-level errors that can propagate during training and degrade model performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0022-33bdb9c032", "paper_id": "P0022", "bibkey": "Yang2025Toolmind", "title": "ToolMind Technical Report: A Large-Scale, Reasoning-Enhanced Tool-Use Dataset", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these limitations, we introduce ToolMind, a large-scale, high-quality tool-agentic dataset with 160k synthetic data instances generated using over 20k tools and 200k augmented open-source data instances.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0022-943f8d514b", "paper_id": "P0022", "bibkey": "Yang2025Toolmind", "title": "ToolMind Technical Report: A Large-Scale, Reasoning-Enhanced Tool-Use Dataset", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our data synthesis pipeline first constructs a function graph based on parameter correlations and then uses a multi-agent framework to simulate realistic user-assistant-tool interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0022-f5a0e32a25", "paper_id": "P0022", "bibkey": "Yang2025Toolmind", "title": "ToolMind Technical Report: A Large-Scale, Reasoning-Enhanced Tool-Use Dataset", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address these limitations, we introduce ToolMind, a large-scale, high-quality tool-agentic dataset with 160k synthetic data instances generated using over 20k tools and 200k augmented open-source data instances.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#limitations[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0023-bd38f6ac04", "paper_id": "P0023", "bibkey": "Zhang2024Ecoact", "title": "EcoAct: Economic Agent Determines When to Register What Action", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this, we introduce EcoAct, a tool using algorithm that allows LLMs to selectively register tools as needed, optimizing context use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0023-83f8d55860", "paper_id": "P0023", "bibkey": "Zhang2024Ecoact", "title": "EcoAct: Economic Agent Determines When to Register What Action", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "By integrating the tool registration process into the reasoning procedure, EcoAct reduces computational costs by over 50% in multiple steps reasoning tasks while maintaining performance, as demonstrated through extensive experiments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0023-1d7ac6cbee", "paper_id": "P0023", "bibkey": "Zhang2024Ecoact", "title": "EcoAct: Economic Agent Determines When to Register What Action", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements have enabled Large Language Models (LLMs) to function as agents that can perform actions using external tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0023-86b0bf95de", "paper_id": "P0023", "bibkey": "Zhang2024Ecoact", "title": "EcoAct: Economic Agent Determines When to Register What Action", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This requires registering, i.e., integrating tool information into the LLM context prior to taking actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0023-d00d10da44", "paper_id": "P0023", "bibkey": "Zhang2024Ecoact", "title": "EcoAct: Economic Agent Determines When to Register What Action", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current methods indiscriminately incorporate all candidate tools into the agent's context and retain them across multiple reasoning steps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0023-2f0766c8a9", "paper_id": "P0023", "bibkey": "Zhang2024Ecoact", "title": "EcoAct: Economic Agent Determines When to Register What Action", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This process remains opaque to LLM agents and is not integrated into their reasoning procedures, leading to inefficiencies due to increased context length from irrelevant tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0023-4a208c9b8d", "paper_id": "P0023", "bibkey": "Zhang2024Ecoact", "title": "EcoAct: Economic Agent Determines When to Register What Action", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this, we introduce EcoAct, a tool using algorithm that allows LLMs to selectively register tools as needed, optimizing context use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0024-110de36ea8", "paper_id": "P0024", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Trading is a highly competitive task that requires a combination of strategy, knowledge, and psychological fortitude.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0024-909ff3f218", "paper_id": "P0024", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "With the recent success of large language models(LLMs), it is appealing to apply the emerging intelligence of LLM agents in this competitive arena and understanding if they can outperform professional traders.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0024-27ff3101b9", "paper_id": "P0024", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Trading is a highly competitive task that requires a combination of strategy, knowledge, and psychological fortitude.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0024-c1377776f8", "paper_id": "P0024", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the recent success of large language models(LLMs), it is appealing to apply the emerging intelligence of LLM agents in this competitive arena and understanding if they can outperform professional traders.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0024-d40fcae00e", "paper_id": "P0024", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this survey, we provide a comprehensive review of the current research on using LLMs as agents in financial trading.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0024-13cc0711d4", "paper_id": "P0024", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We summarize the common architecture used in the agent, the data inputs, and the performance of LLM trading agents in backtesting as well as the challenges presented in these research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0024-6439b6bdc8", "paper_id": "P0024", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey aims to provide insights into the current state of LLM-based financial trading agents and outline future research directions in this field.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0025-afe907256b", "paper_id": "P0025", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Since the advent of personal computing devices, intelligent personal assistants (IPAs) have been one of the key technologies that researchers and engineers have focused on, aiming to help users efficiently obtain information and execute tasks, and provide users with more intelligent, convenient, and rich interaction experiences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0025-063c3b3128", "paper_id": "P0025", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Next, we discuss several key challenges to achieve intelligent, efficient and secure Personal LLM Agents, followed by a comprehensive survey of representative solutions to address these challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0025-8179d149f9", "paper_id": "P0025", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Since the advent of personal computing devices, intelligent personal assistants (IPAs) have been one of the key technologies that researchers and engineers have focused on, aiming to help users efficiently obtain information and execute tasks, and provide users with more intelligent, convenient, and rich interaction experiences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0025-b0726cba84", "paper_id": "P0025", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the development of smartphones and IoT, computing and sensing devices have become ubiquitous, greatly expanding the boundaries of IPAs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0025-716c8ba772", "paper_id": "P0025", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, due to the lack of capabilities such as user intent understanding, task planning, tool using, and personal data management etc., existing IPAs still have limited practicality and scalability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0025-01651dbee4", "paper_id": "P0025", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, the emergence of foundation models, represented by large language models (LLMs), brings new opportunities for the development of IPAs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0025-e3be73b8f9", "paper_id": "P0025", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the powerful semantic understanding and reasoning capabilities, LLM can enable intelligent agents to solve complex problems autonomously.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0026-01839baf55", "paper_id": "P0026", "bibkey": "Feng2026Backdooragent", "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To fill this gap, we propose \\textbf{BackdoorAgent}, a modular and stage-aware framework that provides a unified, agent-centric view of backdoor threats in LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0026-d296f8966d", "paper_id": "P0026", "bibkey": "Feng2026Backdooragent", "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our empirical analysis shows that \\textit{triggers implanted at a single stage can persist across multiple steps and propagate through intermediate states.} For instance, when using a GPT-based backbone, we observe trigger persistence in 43.58\\% of planning attacks, 77.97\\% of memory attacks, and 60.28\\% of tool-stage attacks, highlighting the vulnerabilities of the agentic workflow itself to backdoor threats.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0026-fbbcda4f8d", "paper_id": "P0026", "bibkey": "Feng2026Backdooragent", "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Building on this framework, we construct a standardized benchmark spanning four representative agent applications: \\textbf{Agent QA}, \\textbf{Agent Code}, \\textbf{Agent Web}, and \\textbf{Agent Drive}, covering both language-only and multimodal settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0026-dee1747966", "paper_id": "P0026", "bibkey": "Feng2026Backdooragent", "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents execute tasks through multi-step workflows that combine planning, memory, and tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0026-669d5f908a", "paper_id": "P0026", "bibkey": "Feng2026Backdooragent", "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While this design enables autonomy, it also expands the attack surface for backdoor threats.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0026-345d91afb8", "paper_id": "P0026", "bibkey": "Feng2026Backdooragent", "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Backdoor triggers injected into specific stages of an agent workflow can persist through multiple intermediate states and adversely influence downstream outputs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0026-364d7dfc87", "paper_id": "P0026", "bibkey": "Feng2026Backdooragent", "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing studies remain fragmented and typically analyze individual attack vectors in isolation, leaving the cross-stage interaction and propagation of backdoor triggers poorly understood from an agent-centric perspective.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory", "security"]}
{"evidence_id": "E-P0026-3d421d99d8", "paper_id": "P0026", "bibkey": "Feng2026Backdooragent", "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To fill this gap, we propose \\textbf{BackdoorAgent}, a modular and stage-aware framework that provides a unified, agent-centric view of backdoor threats in LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0027-ef4cf62416", "paper_id": "P0027", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0027-79f88927fa", "paper_id": "P0027", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0027-593af2dd94", "paper_id": "P0027", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "API specification, which includes detailed documentation and usage constraints, and 2.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0027-f99e220a0c", "paper_id": "P0027", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0027-2b1181bd3f", "paper_id": "P0027", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0027-cdecc79d54", "paper_id": "P0027", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "API specification, which includes detailed documentation and usage constraints, and 2.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0027-1d3c8db336", "paper_id": "P0027", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "API execution, which captures runtime challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0027-da81f3bb01", "paper_id": "P0027", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Consequently, WildAGTEval offers (i) an API system encompassing 60 distinct complexity scenarios that can be composed into approximately 32K test configurations, and (ii) user-agent interactions for evaluating LLM agents on these scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0028-f435bd682b", "paper_id": "P0028", "bibkey": "Gupta2026Reliabilitybench", "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce \\textbf{ReliabilityBench}, a benchmark for evaluating agent reliability across three dimensions: (i) consistency under repeated execution using $\\mathrm{pass}^k$, (ii) robustness to semantically equivalent task perturbations at intensity $$, and (iii) fault tolerance under controlled tool/API failures at intensity $$.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0028-36c7bf5169", "paper_id": "P0028", "bibkey": "Gupta2026Reliabilitybench", "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Perturbations alone reduce success from 96.9% at $=0$ to 88.1% at $=0.2$.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0028-880a7b0d43", "paper_id": "P0028", "bibkey": "Gupta2026Reliabilitybench", "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate two models (Gemini 2.0 Flash, GPT-4o) and two agent architectures (ReAct, Reflexion) across four domains (scheduling, travel, customer support, e-commerce) over 1,280 episodes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0028-634206a060", "paper_id": "P0028", "bibkey": "Gupta2026Reliabilitybench", "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing benchmarks for tool-using LLM agents primarily report single-run success rates and miss reliability properties required in production.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0028-123ca89bec", "paper_id": "P0028", "bibkey": "Gupta2026Reliabilitybench", "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce \\textbf{ReliabilityBench}, a benchmark for evaluating agent reliability across three dimensions: (i) consistency under repeated execution using $\\mathrm{pass}^k$, (ii) robustness to semantically equivalent task perturbations at intensity $$, and (iii) fault tolerance under controlled tool/API failures at intensity $$.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0028-0ff4f19b04", "paper_id": "P0028", "bibkey": "Gupta2026Reliabilitybench", "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ReliabilityBench contributes a unified reliability surface $R(k,,)$, \\textit{action metamorphic relations} that define correctness via end-state equivalence rather than text similarity, and a chaos-engineering-style fault injection framework (timeouts, rate limits, partial responses, schema drift).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0028-0662f6dfee", "paper_id": "P0028", "bibkey": "Gupta2026Reliabilitybench", "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluate two models (Gemini 2.0 Flash, GPT-4o) and two agent architectures (ReAct, Reflexion) across four domains (scheduling, travel, customer support, e-commerce) over 1,280 episodes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0028-afc3b1c08d", "paper_id": "P0028", "bibkey": "Gupta2026Reliabilitybench", "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Perturbations alone reduce success from 96.9% at $=0$ to 88.1% at $=0.2$.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0029-fd1c020725", "paper_id": "P0029", "bibkey": "Wang2025Comprehensive", "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The remarkable success of Large Language Models (LLMs) has illuminated a promising pathway toward achieving Artificial General Intelligence for both academic and industrial communities, owing to their unprecedented performance across various applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0029-d541ee15e3", "paper_id": "P0029", "bibkey": "Wang2025Comprehensive", "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our research is grounded in an exhaustive review of over 800+ papers, ensuring comprehensive coverage and systematic organization of security issues within a more holistic understanding.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0029-fb0d5b7ae0", "paper_id": "P0029", "bibkey": "Wang2025Comprehensive", "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The remarkable success of Large Language Models (LLMs) has illuminated a promising pathway toward achieving Artificial General Intelligence for both academic and industrial communities, owing to their unprecedented performance across various applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0029-122ed19ba9", "paper_id": "P0029", "bibkey": "Wang2025Comprehensive", "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The remarkable success of Large Language Models (LLMs) has illuminated a promising pathway toward achieving Artificial General Intelligence for both academic and industrial communities, owing to their unprecedented performance across various applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0029-1222ae6189", "paper_id": "P0029", "bibkey": "Wang2025Comprehensive", "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As LLMs continue to gain prominence in both research and commercial domains, their security and safety implications have become a growing concern, not only for researchers and corporations but also for every nation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0029-ab9bde5a7c", "paper_id": "P0029", "bibkey": "Wang2025Comprehensive", "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Currently, existing surveys on LLM safety primarily focus on specific stages of the LLM lifecycle, e.g., deployment phase or fine-tuning phase, lacking a comprehensive understanding of the entire \"lifechain\" of LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0029-615affe0f7", "paper_id": "P0029", "bibkey": "Wang2025Comprehensive", "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, this paper introduces, for the first time, the concept of \"full-stack\" safety to systematically consider safety issues throughout the entire process of LLM training, deployment, and eventual commercialization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0029-95124d237d", "paper_id": "P0029", "bibkey": "Wang2025Comprehensive", "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Compared to the off-the-shelf LLM safety surveys, our work demonstrates several distinctive advantages: (I) Comprehensive Perspective.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0029-6a2ccc17c0", "paper_id": "P0029", "bibkey": "Wang2025Comprehensive", "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "These insights provide valuable guidance for researchers pursuing future work in this field.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0030-c0838d4021", "paper_id": "P0030", "bibkey": "Yang2025Survey", "title": "A Survey of AI Agent Protocols", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The rapid development of large language models (LLMs) has led to the widespread deployment of LLM agents across diverse industries, including customer service, content generation, data analysis, and even healthcare.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0030-4c14763fd0", "paper_id": "P0030", "bibkey": "Yang2025Survey", "title": "A Survey of AI Agent Protocols", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We expect this work to serve as a practical reference for both researchers and engineers seeking to design, evaluate, or integrate robust communication infrastructures for intelligent agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0030-fe34addb48", "paper_id": "P0030", "bibkey": "Yang2025Survey", "title": "A Survey of AI Agent Protocols", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid development of large language models (LLMs) has led to the widespread deployment of LLM agents across diverse industries, including customer service, content generation, data analysis, and even healthcare.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0030-1b8e880d74", "paper_id": "P0030", "bibkey": "Yang2025Survey", "title": "A Survey of AI Agent Protocols", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, as more LLM agents are deployed, a major issue has emerged: there is no standard way for these agents to communicate with external tools or data sources.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0030-545803b1cb", "paper_id": "P0030", "bibkey": "Yang2025Survey", "title": "A Survey of AI Agent Protocols", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This lack of standardized protocols makes it difficult for agents to work together or scale effectively, and it limits their ability to tackle complex, real-world tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0030-bbaa02f6e8", "paper_id": "P0030", "bibkey": "Yang2025Survey", "title": "A Survey of AI Agent Protocols", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A unified communication protocol for LLM agents could change this.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0030-37383cc6c4", "paper_id": "P0030", "bibkey": "Yang2025Survey", "title": "A Survey of AI Agent Protocols", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It would allow agents and tools to interact more smoothly, encourage collaboration, and triggering the formation of collective intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0031-7b3ec45781", "paper_id": "P0031", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "This paper surveys the development of large language model (LLM)-based agents for question answering (QA).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0031-48f5050e3c", "paper_id": "P0031", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Additionally, this paper identifies ongoing challenges and explores future research directions to enhance the performance of LLM agent QA systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0031-c4dbb5a1b4", "paper_id": "P0031", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper surveys the development of large language model (LLM)-based agents for question answering (QA).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0031-d923fcecb6", "paper_id": "P0031", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional agents face significant limitations, including substantial data requirements and difficulty in generalizing to new environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0031-59428e8083", "paper_id": "P0031", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM-based agents address these challenges by leveraging LLMs as their core reasoning engine.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0031-cee8ef4c52", "paper_id": "P0031", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These agents achieve superior QA results compared to traditional QA pipelines and naive LLM QA systems by enabling interaction with external environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0031-6ad2cb771f", "paper_id": "P0031", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We systematically review the design of LLM agents in the context of QA tasks, organizing our discussion across key stages: planning, question understanding, information retrieval, and answer generation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0031-014d5f7597", "paper_id": "P0031", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Traditional agents face significant limitations, including substantial data requirements and difficulty in generalizing to new environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0032-bd9b2efeac", "paper_id": "P0032", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Information technology has profoundly altered the way humans interact with information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0032-698effea8f", "paper_id": "P0032", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Recent advances in large language models (LLMs) have demonstrated capabilities that surpass human performance in various language-related tasks and exhibit general understanding, reasoning, and decision-making abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0032-8587764f76", "paper_id": "P0032", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Information technology has profoundly altered the way humans interact with information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0032-24e201f889", "paper_id": "P0032", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The vast amount of content created, shared, and disseminated online has made it increasingly difficult to access relevant information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0032-61fda627ce", "paper_id": "P0032", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Over the past two decades, recommender systems and search (collectively referred to as information retrieval systems) have evolved significantly to address these challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0032-e149cdfbd2", "paper_id": "P0032", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in large language models (LLMs) have demonstrated capabilities that surpass human performance in various language-related tasks and exhibit general understanding, reasoning, and decision-making abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0032-a586c566b0", "paper_id": "P0032", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper explores the transformative potential of LLM agents in enhancing recommender and search systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0033-43b3136b8c", "paper_id": "P0033", "bibkey": "Yao2025Survey", "title": "A Survey on Agentic Multimodal Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Motivated by the growing interest in agentic AI and its potential trajectory toward AGI, we present a comprehensive survey on Agentic Multimodal Large Language Models (Agentic MLLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0033-1b6fe3407a", "paper_id": "P0033", "bibkey": "Yao2025Survey", "title": "A Survey on Agentic Multimodal Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To further accelerate research in this area for the community, we compile open-source training frameworks, training and evaluation datasets for developing agentic MLLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0033-5cb27c72cf", "paper_id": "P0033", "bibkey": "Yao2025Survey", "title": "A Survey on Agentic Multimodal Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the recent emergence of revolutionary autonomous agentic systems, research community is witnessing a significant shift from traditional static, passive, and domain-specific AI agents toward more dynamic, proactive, and generalizable agentic AI.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0033-3ab24ac75f", "paper_id": "P0033", "bibkey": "Yao2025Survey", "title": "A Survey on Agentic Multimodal Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Motivated by the growing interest in agentic AI and its potential trajectory toward AGI, we present a comprehensive survey on Agentic Multimodal Large Language Models (Agentic MLLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0033-9f159848e7", "paper_id": "P0033", "bibkey": "Yao2025Survey", "title": "A Survey on Agentic Multimodal Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this survey, we explore the emerging paradigm of agentic MLLMs, delineating their conceptual foundations and distinguishing characteristics from conventional MLLM-based agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0033-73c0158128", "paper_id": "P0033", "bibkey": "Yao2025Survey", "title": "A Survey on Agentic Multimodal Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We establish a conceptual framework that organizes agentic MLLMs along three fundamental dimensions: (i) Agentic internal intelligence functions as the system's commander, enabling accurate long-horizon planning through reasoning, reflection, and memory; (ii) Agentic external tool invocation, whereby models proactively use various external tools to extend their problem-solving capabilities beyond their intrinsic knowledge; and (iii) Agentic environment interaction further situates models within virtual or physical environments, allowing them to take actions, adapt strategies, and sustain goal-directed behavior in dynamic real-world scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0033-545ab7cc10", "paper_id": "P0033", "bibkey": "Yao2025Survey", "title": "A Survey on Agentic Multimodal Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To further accelerate research in this area for the community, we compile open-source training frameworks, training and evaluation datasets for developing agentic MLLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0034-f5791417c7", "paper_id": "P0034", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Audio-Language Models (LALMs) perform well on audio understanding tasks but lack multi-step reasoning and tool-calling found in recent Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0034-e31e41085b", "paper_id": "P0034", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments with MMAU, MMAR, and MMAU-Pro show state-of-the-art accuracy: up to 74.10% on MMAU, 68.80% on MMAR, and 57.96% on MMAU-Pro.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0034-de509152db", "paper_id": "P0034", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Monte Carlo sampling for shapley values across 374 configurations identifies effective agent-tool combinations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0034-3c246cb9dc", "paper_id": "P0034", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Audio-Language Models (LALMs) perform well on audio understanding tasks but lack multi-step reasoning and tool-calling found in recent Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0034-eefd7f1aeb", "paper_id": "P0034", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents AudioToolAgent, a framework that coordinates audio-language models as tools via a central LLM agent that accesses tool adapters for audio question answering and speech-to-text.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0034-9505dec385", "paper_id": "P0034", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The agent selects tools, asks follow-up questions, and compares outputs for verification.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0034-9e1de41865", "paper_id": "P0034", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Experiments with MMAU, MMAR, and MMAU-Pro show state-of-the-art accuracy: up to 74.10% on MMAU, 68.80% on MMAR, and 57.96% on MMAU-Pro.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0034-ed1755ca5d", "paper_id": "P0034", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Monte Carlo sampling for shapley values across 374 configurations identifies effective agent-tool combinations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0035-54aa7c79f9", "paper_id": "P0035", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a library implementing common prompting patterns using the PDL prompt programming language.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0035-1c2ad83594", "paper_id": "P0035", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluations across three tasks and seven LLMs (ranging from 3B to 70B parameters) show consistent accuracy gains ($9.21\\pm15.46$ percentage points), up to 67.5pp, and reveal that selected prompting strategies vary across models and tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0035-b3f5346012", "paper_id": "P0035", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "AutoPDL solutions are human-readable, editable, and executable PDL programs that use this library.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0035-5bd886ea4a", "paper_id": "P0035", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The performance of large language models (LLMs) depends on how they are prompted, with choices spanning both the high-level prompting pattern (e.g., Zero-Shot, CoT, ReAct, ReWOO) and the specific prompt content (instructions and few-shot demonstrations).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0035-05fc2ccbd6", "paper_id": "P0035", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Manually tuning this combination is tedious, error-prone, and specific to a given LLM and task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0035-658a4af4bb", "paper_id": "P0035", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Therefore, this paper proposes AutoPDL, an automated approach to discovering good LLM agent configurations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0035-91de05744d", "paper_id": "P0035", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our approach frames this as a structured AutoML problem over a combinatorial space of agentic and non-agentic prompting patterns and demonstrations, using successive halving to efficiently navigate this space.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0035-6391c2161a", "paper_id": "P0035", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce a library implementing common prompting patterns using the PDL prompt programming language.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0036-a8851cf04f", "paper_id": "P0036", "bibkey": "Lan2025Autoqual", "title": "AutoQual: An LLM Agent for Automated Discovery of Interpretable Features for Review Quality Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we propose AutoQual, an LLM-based agent framework that automates the discovery of interpretable features.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0036-eee04db801", "paper_id": "P0036", "bibkey": "Lan2025Autoqual", "title": "AutoQual: An LLM Agent for Automated Discovery of Interpretable Features for Review Quality Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large-scale A/B testing confirms its effectiveness, increasing average reviews viewed per user by 0.79% and the conversion rate of review readers by 0.27%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0036-b0e3db9547", "paper_id": "P0036", "bibkey": "Lan2025Autoqual", "title": "AutoQual: An LLM Agent for Automated Discovery of Interpretable Features for Review Quality Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "It mimics a human research process, iteratively generating feature hypotheses through reflection, operationalizing them via autonomous tool implementation, and accumulating experience in a persistent memory.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#key_results[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0036-03df73518b", "paper_id": "P0036", "bibkey": "Lan2025Autoqual", "title": "AutoQual: An LLM Agent for Automated Discovery of Interpretable Features for Review Quality Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Ranking online reviews by their intrinsic quality is a critical task for e-commerce platforms and information services, impacting user experience and business outcomes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0036-d5d6a63ed3", "paper_id": "P0036", "bibkey": "Lan2025Autoqual", "title": "AutoQual: An LLM Agent for Automated Discovery of Interpretable Features for Review Quality Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, quality is a domain-dependent and dynamic concept, making its assessment a formidable challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0036-c050ca017e", "paper_id": "P0036", "bibkey": "Lan2025Autoqual", "title": "AutoQual: An LLM Agent for Automated Discovery of Interpretable Features for Review Quality Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional methods relying on hand-crafted features are unscalable across domains and fail to adapt to evolving content patterns, while modern deep learning approaches often produce black-box models that lack interpretability and may prioritize semantics over quality.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0036-4cf9e8ebe2", "paper_id": "P0036", "bibkey": "Lan2025Autoqual", "title": "AutoQual: An LLM Agent for Automated Discovery of Interpretable Features for Review Quality Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these challenges, we propose AutoQual, an LLM-based agent framework that automates the discovery of interpretable features.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0036-d80534137d", "paper_id": "P0036", "bibkey": "Lan2025Autoqual", "title": "AutoQual: An LLM Agent for Automated Discovery of Interpretable Features for Review Quality Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While demonstrated on review quality assessment, AutoQual is designed as a general framework for transforming tacit knowledge embedded in data into explicit, computable features.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0037-682a68866c", "paper_id": "P0037", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose AutoTool, a novel graph-based framework that bypasses repeated LLM inference by exploiting a key empirical observation: tool usage inertia - the tendency of tool invocations to follow predictable sequential patterns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0037-d3344c79dc", "paper_id": "P0037", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments across diverse agent tasks demonstrate that AutoTool reduces inference costs by up to 30% while maintaining competitive task completion rates, offering a practical and scalable enhancement for inference-heavy frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0037-3f62ff9f3a", "paper_id": "P0037", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents have emerged as powerful tools for automating complex tasks by leveraging the reasoning and decision-making abilities of LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0037-7674242cfe", "paper_id": "P0037", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, a major bottleneck in current agent frameworks lies in the high inference cost of tool selection, especially in approaches like ReAct that repeatedly invoke the LLM to determine which tool to use at each step.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0037-7a8afd3d87", "paper_id": "P0037", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we propose AutoTool, a novel graph-based framework that bypasses repeated LLM inference by exploiting a key empirical observation: tool usage inertia - the tendency of tool invocations to follow predictable sequential patterns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0037-9000842ec5", "paper_id": "P0037", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "AutoTool constructs a directed graph from historical agent trajectories, where nodes represent tools and edges capture transition probabilities, effectively modeling the inertia in tool selection.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0037-1b6a24b281", "paper_id": "P0037", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It further integrates parameter-level information to refine tool input generation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0038-1e710dda72", "paper_id": "P0038", "bibkey": "Kaiyrbekov2025Automated", "title": "Automated Survey Collection with LLM-based Conversational Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To overcome these limitations, we propose an end-to-end survey collection framework driven by conversational Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0038-0e1917aa86", "paper_id": "P0038", "bibkey": "Kaiyrbekov2025Automated", "title": "Automated Survey Collection with LLM-based Conversational Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Results: Survey responses were successfully extracted by GPT-4o from conversation transcripts with an average accuracy of 98% despite transcripts exhibiting an average per-line word error rate of 7.7%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0038-1d486fa6b3", "paper_id": "P0038", "bibkey": "Kaiyrbekov2025Automated", "title": "Automated Survey Collection with LLM-based Conversational Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To test our framework, we recruited 8 participants consisting of 5 native and 3 non-native english speakers and administered 40 surveys.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0038-2a9c5c4a1e", "paper_id": "P0038", "bibkey": "Kaiyrbekov2025Automated", "title": "Automated Survey Collection with LLM-based Conversational Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Objective: Traditional phone-based surveys are among the most accessible and widely used methods to collect biomedical and healthcare data, however, they are often costly, labor intensive, and difficult to scale effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0038-153e11fcaa", "paper_id": "P0038", "bibkey": "Kaiyrbekov2025Automated", "title": "Automated Survey Collection with LLM-based Conversational Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To overcome these limitations, we propose an end-to-end survey collection framework driven by conversational Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0038-720f536fcc", "paper_id": "P0038", "bibkey": "Kaiyrbekov2025Automated", "title": "Automated Survey Collection with LLM-based Conversational Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Materials and Methods: Our framework consists of a researcher responsible for designing the survey and recruiting participants, a conversational phone agent powered by an LLM that calls participants and administers the survey, a second LLM (GPT-4o) that analyzes the conversation transcripts generated during the surveys, and a database for storing and organizing the results.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0038-1c24311ba2", "paper_id": "P0038", "bibkey": "Kaiyrbekov2025Automated", "title": "Automated Survey Collection with LLM-based Conversational Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To test our framework, we recruited 8 participants consisting of 5 native and 3 non-native english speakers and administered 40 surveys.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0038-990bab1139", "paper_id": "P0038", "bibkey": "Kaiyrbekov2025Automated", "title": "Automated Survey Collection with LLM-based Conversational Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluated the correctness of LLM-generated conversation transcripts, accuracy of survey responses inferred by GPT-4o and overall participant experience.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0038-143b85da69", "paper_id": "P0038", "bibkey": "Kaiyrbekov2025Automated", "title": "Automated Survey Collection with LLM-based Conversational Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To overcome these limitations, we propose an end-to-end survey collection framework driven by conversational Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0039-4b1ab22641", "paper_id": "P0039", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Second, we propose GradleFixer, an LLM agent with domain-specific tools for inspecting and manipulating the Gradle build environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0039-858f86ac9c", "paper_id": "P0039", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To address this gap, we first introduce AndroidBuildBench, a benchmark of 1,019 build failures curated from the commit histories of 43 open-source Android projects.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0039-852023ec1e", "paper_id": "P0039", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "GradleFixer achieves a resolve rate of 81.4% (pass@1), significantly outperforming a state-of-the-art coding agent that relies on a general-purpose shell.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0039-f3d4ecad3b", "paper_id": "P0039", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Android is the largest mobile platform, yet automatically building applications remains a practical challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0039-cb5f194b20", "paper_id": "P0039", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While Large Language Models (LLMs) show promise for code repair, their use for fixing Android build errors remains underexplored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0039-7686ac87f9", "paper_id": "P0039", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, we first introduce AndroidBuildBench, a benchmark of 1,019 build failures curated from the commit histories of 43 open-source Android projects.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0039-5879c6bb3c", "paper_id": "P0039", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Each problem is paired with a verified solution from a subsequent commit, ensuring that fixes are feasible.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0039-b1d0d2f2a4", "paper_id": "P0039", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Second, we propose GradleFixer, an LLM agent with domain-specific tools for inspecting and manipulating the Gradle build environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0040-c8895eaeab", "paper_id": "P0040", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Model (LLM) agents face security vulnerabilities spanning AI-specific and traditional software domains, yet current research addresses these separately.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0040-8e34a29629", "paper_id": "P0040", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "security", "tooling"]}
{"evidence_id": "E-P0040-8a2c2e2291", "paper_id": "P0040", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Attack complexity dramatically amplified effectiveness, with chained attacks achieving 91-96% success rates.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "security"]}
{"evidence_id": "E-P0040-2a59b6d5bc", "paper_id": "P0040", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents face security vulnerabilities spanning AI-specific and traditional software domains, yet current research addresses these separately.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0040-2333abf508", "paper_id": "P0040", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study bridges this gap through comparative evaluation of Function Calling architecture and Model Context Protocol (MCP) deployment paradigms using a unified threat classification framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0040-26646f7a50", "paper_id": "P0040", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We tested 3,250 attack scenarios across seven language models, evaluating simple, composed, and chained attacks targeting both AI-specific threats (prompt injection) and software vulnerabilities (JSON injection, denial-of-service).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0040-c6d60c7b44", "paper_id": "P0040", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers", "security", "tooling"]}
{"evidence_id": "E-P0040-a96843d7f0", "paper_id": "P0040", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Attack complexity dramatically amplified effectiveness, with chained attacks achieving 91-96% success rates.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers", "security"]}
{"evidence_id": "E-P0041-9d9d60644a", "paper_id": "P0041", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0041-04c60086db", "paper_id": "P0041", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design principles for trustworthy agents: modular decomposition, adaptive symbolic governance, and transparent state management.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0041-17d092450a", "paper_id": "P0041", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model agents suffer from fundamental architectural problems: entangled reasoning and execution, memory volatility, and uncontrolled action sequences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0041-10950917a3", "paper_id": "P0041", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0041-1dbc5333ba", "paper_id": "P0041", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "At the core of SCL is Soft Symbolic Control, an adaptive governance mechanism that applies symbolic constraints to probabilistic inference, preserving neural flexibility while restoring the explainability and controllability of classical symbolic systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0041-79a2100d6b", "paper_id": "P0041", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Through empirical validation on multi-step conditional reasoning tasks, we demonstrate that SCL achieves zero policy violations, eliminates redundant tool calls, and maintains complete decision traceability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0041-54c9afde38", "paper_id": "P0041", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These results address critical gaps in existing frameworks such as ReAct, AutoGPT, and memory-augmented approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0042-8b90da5dec", "paper_id": "P0042", "bibkey": "Huang2025Cascade", "title": "CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from \"LLM + tool use\" to \"LLM + skill acquisition\".", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0042-b52a2b87e4", "paper_id": "P0042", "bibkey": "Huang2025Cascade", "title": "CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate CASCADE on SciSkillBench, a benchmark of 116 materials science and chemistry research tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0042-52401b47d4", "paper_id": "P0042", "bibkey": "Huang2025Cascade", "title": "CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "CASCADE achieves a 93.3% success rate using GPT-5, compared to 35.4% without evolution mechanisms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0042-6938ca6091", "paper_id": "P0042", "bibkey": "Huang2025Cascade", "title": "CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents currently depend on predefined tools or brittle tool generation, constraining their capability and adaptability to complex scientific tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0042-04ab601193", "paper_id": "P0042", "bibkey": "Huang2025Cascade", "title": "CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from \"LLM + tool use\" to \"LLM + skill acquisition\".", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0042-dab7517725", "paper_id": "P0042", "bibkey": "Huang2025Cascade", "title": "CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "CASCADE enables agents to master complex external tools and codify knowledge through two meta-skills: continuous learning via web search and code extraction, and self-reflection via introspection and knowledge graph exploration, among others.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0042-02319eded2", "paper_id": "P0042", "bibkey": "Huang2025Cascade", "title": "CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluate CASCADE on SciSkillBench, a benchmark of 116 materials science and chemistry research tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0042-ce01a133f2", "paper_id": "P0042", "bibkey": "Huang2025Cascade", "title": "CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "CASCADE achieves a 93.3% success rate using GPT-5, compared to 35.4% without evolution mechanisms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0043-4702cb10b5", "paper_id": "P0043", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we present a novel diagnostic framework that integrates Knowledge Graphs (KGs) and Large Language Models (LLMs) to support system diagnostics in high-reliability systems such as nuclear power plants.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0043-f10376c14d", "paper_id": "P0043", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "A case study on an auxiliary feedwater system demonstrated the framework's effectiveness, with over 90% accuracy in key elements and consistent tool and argument extraction, supporting its use in safety-critical diagnostics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0043-434724f85d", "paper_id": "P0043", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we present a novel diagnostic framework that integrates Knowledge Graphs (KGs) and Large Language Models (LLMs) to support system diagnostics in high-reliability systems such as nuclear power plants.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0043-67e23ab509", "paper_id": "P0043", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional diagnostic modeling struggles when systems become too complex, making functional modeling a more attractive approach.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0043-ffc84de302", "paper_id": "P0043", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our approach introduces a diagnostic framework grounded in the functional modeling principles of the Dynamic Master Logic (DML) model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0043-437dc50301", "paper_id": "P0043", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It incorporates two coordinated LLM components, including an LLM-based workflow for automated construction of DML logic from system documentation and an LLM agent that facilitates interactive diagnostics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0043-8268c01f0f", "paper_id": "P0043", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The generated logic is encoded into a structured KG, referred to as KG-DML, which supports hierarchical fault reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0044-47638ecfe1", "paper_id": "P0044", "bibkey": "Ferrag2025From", "title": "From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We analyze attack feasibility, review existing defenses, and discuss mitigation strategies such as dynamic trust management, cryptographic provenance tracking, and sandboxed agent interfaces.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0044-74547b154c", "paper_id": "P0044", "bibkey": "Ferrag2025From", "title": "From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Compared to prior surveys, this work presents the first integrated taxonomy bridging input-level exploits and protocol-layer vulnerabilities in LLM-agent ecosystems, offering actionable guidance for designing secure and resilient agentic AI systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#key_results[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0044-07b3b8f590", "paper_id": "P0044", "bibkey": "Ferrag2025From", "title": "From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Autonomous AI agents powered by large language models (LLMs) with structured function-calling interfaces enable real-time data retrieval, computation, and multi-step orchestration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0044-0ee238792c", "paper_id": "P0044", "bibkey": "Ferrag2025From", "title": "From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the rapid growth of plugins, connectors, and inter-agent protocols has outpaced security practices, leading to brittle integrations that rely on ad-hoc authentication, inconsistent schemas, and weak validation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0044-ad4c362231", "paper_id": "P0044", "bibkey": "Ferrag2025From", "title": "From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey introduces a unified end-to-end threat model for LLM-agent ecosystems, covering host-to-tool and agent-to-agent communications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0044-8f839d5d9a", "paper_id": "P0044", "bibkey": "Ferrag2025From", "title": "From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We systematically categorize more than thirty attack techniques spanning input manipulation, model compromise, system and privacy attacks, and protocol-level vulnerabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#summary_bullets[3]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0044-14880fd9d1", "paper_id": "P0044", "bibkey": "Ferrag2025From", "title": "From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "For each category, we provide a formal threat formulation defining attacker capabilities, objectives, and affected system layers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#summary_bullets[4]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0045-be5e5c14b4", "paper_id": "P0045", "bibkey": "Min2025Goat", "title": "GOAT: A Training Framework for Goal-Oriented Agent with Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Thus, we propose a novel training framework GOAT, which enables fine-tuning of LLM agents in a human annotation-free setting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0045-8a32e8598f", "paper_id": "P0045", "bibkey": "Min2025Goat", "title": "GOAT: A Training Framework for Goal-Oriented Agent with Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "While proprietary closed-source models such as GPT-4 demonstrate strong reasoning abilities, smaller open-source models struggle to perform complex tool use effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0045-bb45089f75", "paper_id": "P0045", "bibkey": "Min2025Goat", "title": "GOAT: A Training Framework for Goal-Oriented Agent with Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through extensive experiments, we show that GOAT-trained agents achieve state-of-the-art performance across multiple existing goal-oriented benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0045-d47345785e", "paper_id": "P0045", "bibkey": "Min2025Goat", "title": "GOAT: A Training Framework for Goal-Oriented Agent with Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have recently been extended beyond traditional text generation to serve as interactive agents capable of using external tools based on user intent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0045-36962667b0", "paper_id": "P0045", "bibkey": "Min2025Goat", "title": "GOAT: A Training Framework for Goal-Oriented Agent with Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, current LLM agents still show limited ability to handle goal-oriented queries, which require decomposing a high-level objective into multiple interdependent API calls with correct planning and execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0045-9400ee4a67", "paper_id": "P0045", "bibkey": "Min2025Goat", "title": "GOAT: A Training Framework for Goal-Oriented Agent with Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current approaches mainly rely on zero-shot evaluation due to the absence of training data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0045-5d3c404b94", "paper_id": "P0045", "bibkey": "Min2025Goat", "title": "GOAT: A Training Framework for Goal-Oriented Agent with Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While proprietary closed-source models such as GPT-4 demonstrate strong reasoning abilities, smaller open-source models struggle to perform complex tool use effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0045-f02d3f6138", "paper_id": "P0045", "bibkey": "Min2025Goat", "title": "GOAT: A Training Framework for Goal-Oriented Agent with Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Thus, we propose a novel training framework GOAT, which enables fine-tuning of LLM agents in a human annotation-free setting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0046-1a30481cd1", "paper_id": "P0046", "bibkey": "Nakano2025Guided", "title": "Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose a guided reasoning pipeline for penetration testing LLM agents that incorporates a deterministic task tree built from the MITRE ATT&CK Matrix, a proven penetration testing kll chain, to constrain the LLM's reaoning process to explicitly defined tactics, techniques, and procedures.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0046-99359acdd7", "paper_id": "P0046", "bibkey": "Nakano2025Guided", "title": "Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Comparatively, the state-of-the-art LLM penetration testing tool using self-guided reasoning completed only 13.5\\%, 16.5\\%, and 75.7\\% of subtasks and required 86.2\\%, 118.7\\%, and 205.9\\% more model queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0046-741891e300", "paper_id": "P0046", "bibkey": "Nakano2025Guided", "title": "Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To evaluate our approach, we built an automated penetration testing LLM agent using three LLMs (Llama-3-8B, Gemini-1.5, and GPT-4) and applied it to navigate 10 HackTheBox cybersecurity exercises with 103 discrete subtasks representing real-world cyberattack scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0046-c23f7907d7", "paper_id": "P0046", "bibkey": "Nakano2025Guided", "title": "Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in Large Language Models (LLMs) have driven interest in automating cybersecurity penetration testing workflows, offering the promise of faster and more consistent vulnerability assessment for enterprise systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0046-1e44a192ee", "paper_id": "P0046", "bibkey": "Nakano2025Guided", "title": "Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing LLM agents for penetration testing primarily rely on self-guided reasoning, which can produce inaccurate or hallucinated procedural steps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0046-32a672f9c8", "paper_id": "P0046", "bibkey": "Nakano2025Guided", "title": "Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As a result, the LLM agent may undertake unproductive actions, such as exploiting unused software libraries or generating cyclical responses that repeat prior tactics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0046-683d15607c", "paper_id": "P0046", "bibkey": "Nakano2025Guided", "title": "Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we propose a guided reasoning pipeline for penetration testing LLM agents that incorporates a deterministic task tree built from the MITRE ATT&CK Matrix, a proven penetration testing kll chain, to constrain the LLM's reaoning process to explicitly defined tactics, techniques, and procedures.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0046-7ec094ca99", "paper_id": "P0046", "bibkey": "Nakano2025Guided", "title": "Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This anchors reasoning in proven penetration testing methodologies and filters out ineffective actions by guiding the agent towards more productive attack procedures.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#summary_bullets[4]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0047-c88c65aa08", "paper_id": "P0047", "bibkey": "Zhuang2025Hephaestus", "title": "Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Hephaestus-Forge, the first large-scale pre-training corpus designed to enhance the fundamental capabilities of LLM agents in API function calling, intrinsic reasoning and planning, and adapting to environmental feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0047-2396df2469", "paper_id": "P0047", "bibkey": "Zhuang2025Hephaestus", "title": "Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Hephaestus-Forge comprises 103B agent-specific data encompassing 76,537 APIs, including both tool documentation to introduce knowledge of API functions and function calling trajectories to strengthen intrinsic reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0047-a06d9a2787", "paper_id": "P0047", "bibkey": "Zhuang2025Hephaestus", "title": "Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "By continual pre-training on Hephaestus-Forge, Hephaestus outperforms small- to medium-scale open-source LLMs and rivals commercial LLMs on three agent benchmarks, demonstrating the effectiveness of our pre-training corpus in enhancing fundamental agentic capabilities and generalization of LLMs to new tasks or environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0047-53345fd4dc", "paper_id": "P0047", "bibkey": "Zhuang2025Hephaestus", "title": "Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Due to the scarcity of agent-oriented pre-training data, LLM-based autonomous agents typically rely on complex prompting or extensive fine-tuning, which often fails to introduce new capabilities while preserving strong generalizability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0047-63f8e3f51a", "paper_id": "P0047", "bibkey": "Zhuang2025Hephaestus", "title": "Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Hephaestus-Forge, the first large-scale pre-training corpus designed to enhance the fundamental capabilities of LLM agents in API function calling, intrinsic reasoning and planning, and adapting to environmental feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0047-10506254f7", "paper_id": "P0047", "bibkey": "Zhuang2025Hephaestus", "title": "Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Hephaestus-Forge comprises 103B agent-specific data encompassing 76,537 APIs, including both tool documentation to introduce knowledge of API functions and function calling trajectories to strengthen intrinsic reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0047-e7c8353257", "paper_id": "P0047", "bibkey": "Zhuang2025Hephaestus", "title": "Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To explore effective training protocols, we investigate scaling laws to identify the optimal recipe in data mixing ratios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0047-1e667df0ec", "paper_id": "P0047", "bibkey": "Zhuang2025Hephaestus", "title": "Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By continual pre-training on Hephaestus-Forge, Hephaestus outperforms small- to medium-scale open-source LLMs and rivals commercial LLMs on three agent benchmarks, demonstrating the effectiveness of our pre-training corpus in enhancing fundamental agentic capabilities and generalization of LLMs to new tasks or environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0048-e8d8968d72", "paper_id": "P0048", "bibkey": "Dang2025Improving", "title": "Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this, we introduce a curriculum-inspired framework that leverages structured reasoning templates to guide LLMs through more deliberate step-by-step instructions for generating function callings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#method"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0048-90f3b1c01e", "paper_id": "P0048", "bibkey": "Dang2025Improving", "title": "Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experimental results show that our method reduces tool-use errors, achieving 3-12% relative improvements over strong baselines across diverse model series and approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0048-df4ae8c353", "paper_id": "P0048", "bibkey": "Dang2025Improving", "title": "Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have demonstrated strong reasoning and tool-use capabilities, yet they often fail in real-world tool-interactions due to incorrect parameterization, poor tool selection, or misinterpretation of user intent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0048-6371c69426", "paper_id": "P0048", "bibkey": "Dang2025Improving", "title": "Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These issues often stem from an incomplete understanding of user goals and inadequate comprehension of tool documentation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0048-659d23ba30", "paper_id": "P0048", "bibkey": "Dang2025Improving", "title": "Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While Chain-of-Thought (CoT) prompting has proven effective for enhancing reasoning in general contexts, our analysis reveals that free-form CoT is insufficient and sometimes counterproductive for structured function-calling tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0048-5c67c01aa4", "paper_id": "P0048", "bibkey": "Dang2025Improving", "title": "Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this, we introduce a curriculum-inspired framework that leverages structured reasoning templates to guide LLMs through more deliberate step-by-step instructions for generating function callings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0048-a29098002d", "paper_id": "P0048", "bibkey": "Dang2025Improving", "title": "Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Experimental results show that our method reduces tool-use errors, achieving 3-12% relative improvements over strong baselines across diverse model series and approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0049-2dcdb73792", "paper_id": "P0049", "bibkey": "Zhang2025Infoagent", "title": "InfoAgent: Advancing Autonomous Information-Seeking Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce InfoAgent, a deep research agent powered by an innovative data synthesis pipeline and orchestrated web search tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0049-73c657cceb", "paper_id": "P0049", "bibkey": "Zhang2025Infoagent", "title": "InfoAgent: Advancing Autonomous Information-Seeking Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "With our methods, InfoAgent achieves 15.3\\% accuracy on BrowseComp, 29.2\\% on BrowseComp-ZH, and 40.4\\% on Xbench-DS, outperforming prior open-source deep research agents such as WebSailor-72B and DeepDive-32B.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0049-5e0571ea1c", "paper_id": "P0049", "bibkey": "Zhang2025Infoagent", "title": "InfoAgent: Advancing Autonomous Information-Seeking Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To construct challenging, hard-to-find queries,we build entity trees and apply sub-tree sampling with entity fuzzification to systematically increase question difficulty.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0049-6829b45828", "paper_id": "P0049", "bibkey": "Zhang2025Infoagent", "title": "InfoAgent: Advancing Autonomous Information-Seeking Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Building Large Language Model agents that expand their capabilities by interacting with external tools represents a new frontier in AI research and applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0049-0de574ad72", "paper_id": "P0049", "bibkey": "Zhang2025Infoagent", "title": "InfoAgent: Advancing Autonomous Information-Seeking Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce InfoAgent, a deep research agent powered by an innovative data synthesis pipeline and orchestrated web search tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0049-f8238b6bed", "paper_id": "P0049", "bibkey": "Zhang2025Infoagent", "title": "InfoAgent: Advancing Autonomous Information-Seeking Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To construct challenging, hard-to-find queries,we build entity trees and apply sub-tree sampling with entity fuzzification to systematically increase question difficulty.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0049-c6daa9f40f", "paper_id": "P0049", "bibkey": "Zhang2025Infoagent", "title": "InfoAgent: Advancing Autonomous Information-Seeking Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike prior work that relies heavily on commercial search tools, we develop a dedicated self-hosted search infrastructure, enhancing transparency of agent environments and facilitating further advancement of agent capacity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0049-dce6899acb", "paper_id": "P0049", "bibkey": "Zhang2025Infoagent", "title": "InfoAgent: Advancing Autonomous Information-Seeking Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluate the effectiveness of our data pipeline by measuring the average number of tool calls required to correctly answer a question, and also show that our agent yields better performance when equipped with our tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0050-044d4e6a4e", "paper_id": "P0050", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We study the resulting open-ended agent qualitatively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0050-b3caa17225", "paper_id": "P0050", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "These findings illustrate both the promise and current limits of adapting pretrained LLMs toward open-endedness, and point to future directions for training agents to manage memory, explore productively, and pursue abstract long-term goals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#key_results[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0050-a49a564488", "paper_id": "P0050", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent LLM agents have made great use of chain of thought reasoning and function calling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0050-eff3ad7b6b", "paper_id": "P0050", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As their capabilities grow, an important question arises: can this software represent not only a smart problem-solving tool, but an entity in its own right, that can plan, design immediate tasks, and reason toward broader, more ambiguous goals?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0050-cebb3ed2a1", "paper_id": "P0050", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To study this question, we adopt an open-ended experimental setting where we augment a pretrained LLM agent with the ability to generate its own tasks, accumulate knowledge, and interact extensively with its environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0050-cd1ed78e83", "paper_id": "P0050", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We study the resulting open-ended agent qualitatively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0050-c6edb731fb", "paper_id": "P0050", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It can reliably follow complex multi-step instructions, store and reuse information across runs, and propose and solve its own tasks, though it remains sensitive to prompt design, prone to repetitive task generation, and unable to form self-representations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0051-877442aea5", "paper_id": "P0051", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Motivated by the growing trend of scientific studies accompanied by public code repositories, we propose ToolMaker, an agentic framework that autonomously transforms papers with code into LLM-compatible tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0051-057a755e4e", "paper_id": "P0051", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To evaluate our approach, we introduce a benchmark comprising 15 complex computational tasks spanning various domains with over 100 unit tests to assess correctness and robustness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0051-172d428d55", "paper_id": "P0051", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our method correctly implements 80% of the tasks, substantially outperforming current state-of-the-art software engineering agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0051-e2c5ec2338", "paper_id": "P0051", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tool use has turned large language models (LLMs) into powerful agents that can perform complex multi-step tasks by dynamically utilising external software components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0051-253ce87f76", "paper_id": "P0051", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, these tools must be implemented in advance by human developers, hindering the applicability of LLM agents in domains demanding large numbers of highly specialised tools, like in life sciences and medicine.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0051-59d6b455cf", "paper_id": "P0051", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Motivated by the growing trend of scientific studies accompanied by public code repositories, we propose ToolMaker, an agentic framework that autonomously transforms papers with code into LLM-compatible tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0051-465662c3aa", "paper_id": "P0051", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Given a GitHub URL and short task description, ToolMaker autonomously installs dependencies and generates code to perform the task, using a closed-loop self-correction mechanism for debugging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0051-7b075e0982", "paper_id": "P0051", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To evaluate our approach, we introduce a benchmark comprising 15 complex computational tasks spanning various domains with over 100 unit tests to assess correctness and robustness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0052-e8a109886f", "paper_id": "P0052", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Models (LLMs) have garnered significant attention for several years now.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0052-597439cd1d", "paper_id": "P0052", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We then apply the same strategy to show that LLM agents can explore, discover, and exploit diverse chemical interactions in an advanced Atomic Layer Processing reactor simulation using intentionally limited probe capabilities without explicit instructions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0052-38aee336c0", "paper_id": "P0052", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have garnered significant attention for several years now.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0052-359710b235", "paper_id": "P0052", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, their use as independently reasoning agents has been proposed.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0052-65afe8ae85", "paper_id": "P0052", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we test the potential of such agents for knowledge discovery in materials science.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0052-c3039f93ce", "paper_id": "P0052", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We repurpose LangGraph's tool functionality to supply agents with a black box function to interrogate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0052-8cd4c3e787", "paper_id": "P0052", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In contrast to process optimization or performing specific, user-defined tasks, knowledge discovery consists of freely exploring the system, posing and verifying statements about the behavior of this black box, with the sole objective of generating and verifying generalizable statements.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0053-49822b305c", "paper_id": "P0053", "bibkey": "Sun2025Guided", "title": "LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we propose to model each homogeneous traveler group facing the same decision context with a single representative LLM agent who behaves like the population's average, maintaining and updating a mixed strategy over routes that coincides with the group's aggregate flow proportions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0053-298fc52f21", "paper_id": "P0053", "bibkey": "Sun2025Guided", "title": "LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In richer settings with income heterogeneity, multi-criteria costs, and multi-modal choices, the generated dynamics remain stable and interpretable, reproducing plausible behavioral patterns well-documented in psychology and economics, for example, the decoy effect in toll versus non-toll road selection, and higher willingness-to-pay for convenience among higher-income travelers when choosing between driving, transit, and park-and-ride options.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0053-9b739854f0", "paper_id": "P0053", "bibkey": "Sun2025Guided", "title": "LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are increasingly used as behavioral proxies for self-interested travelers in agent-based traffic models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0053-c629bfddf4", "paper_id": "P0053", "bibkey": "Sun2025Guided", "title": "LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Although more flexible and generalizable than conventional models, the practical use of these approaches remains limited by scalability due to the cost of calling one LLM for every traveler.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0053-2fc33d0e5c", "paper_id": "P0053", "bibkey": "Sun2025Guided", "title": "LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Moreover, it has been found that LLM agents often make opaque choices and produce unstable day-to-day dynamics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0053-4f7f7c96be", "paper_id": "P0053", "bibkey": "Sun2025Guided", "title": "LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these challenges, we propose to model each homogeneous traveler group facing the same decision context with a single representative LLM agent who behaves like the population's average, maintaining and updating a mixed strategy over routes that coincides with the group's aggregate flow proportions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0053-56110d6704", "paper_id": "P0053", "bibkey": "Sun2025Guided", "title": "LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Each day, the LLM reviews the travel experience and flags routes with positive reinforcement that they hope to use more often, and an interpretable update rule then converts this judgment into strategy adjustments using a tunable (progressively decaying) step size.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0054-5aef4ede27", "paper_id": "P0054", "bibkey": "Zhang2025Large", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Here we introduce a novel generative AI-based method for generating structural drawings employing a large language model (LLM) agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0054-897bcc2f50", "paper_id": "P0054", "bibkey": "Zhang2025Large", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. In civil engineering, structural drawings serve as the main communication tool between architects, engineers, and builders to avoid conflicts, act as legal documentation, and provide a reference for future maintenance or evaluation needs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0054-79064ef6b3", "paper_id": "P0054", "bibkey": "Zhang2025Large", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The method incorporates a retrieval-augmented generation (RAG) technique using externally-sourced facts to enhance the accuracy and reliability of the language model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0054-654bd71ff0", "paper_id": "P0054", "bibkey": "Zhang2025Large", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. In civil engineering, structural drawings serve as the main communication tool between architects, engineers, and builders to avoid conflicts, act as legal documentation, and provide a reference for future maintenance or evaluation needs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0054-d5a9c93165", "paper_id": "P0054", "bibkey": "Zhang2025Large", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "They are often organized using key elements such as title/subtitle blocks, scales, plan views, elevation view, sections, and detailed sections, which are annotated with standardized symbols and line types for interpretation by engineers and contractors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0054-e256e44d6f", "paper_id": "P0054", "bibkey": "Zhang2025Large", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite advances in software capabilities, the task of generating a structural drawing remains labor-intensive and time-consuming for structural engineers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0054-8db68504ca", "paper_id": "P0054", "bibkey": "Zhang2025Large", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Here we introduce a novel generative AI-based method for generating structural drawings employing a large language model (LLM) agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0054-187cdce5cb", "paper_id": "P0054", "bibkey": "Zhang2025Large", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The method incorporates a retrieval-augmented generation (RAG) technique using externally-sourced facts to enhance the accuracy and reliability of the language model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0055-e1e4fd7c13", "paper_id": "P0055", "bibkey": "Yin2025Magnet", "title": "Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this, we propose Magnet, a principled framework for synthesizing high-quality training trajectories to enhance the function calling capability of large language model agents in multi-turn conversations with humans.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0055-9f71b81590", "paper_id": "P0055", "bibkey": "Yin2025Magnet", "title": "Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments show that training with the positive trajectories with supervised fine-tuning and preference optimization against negative trajectories, our 14B model, Magnet-14B-mDPO, obtains 68.01 on BFCL-v3 and 73.30 on ToolQuery, surpassing the performance of the teacher model Gemini-1.5-pro-002 by a large margin in function calling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0055-c52679af82", "paper_id": "P0055", "bibkey": "Yin2025Magnet", "title": "Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have exhibited the ability to effectively utilize external tools to address user queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0055-6b3be7a9ba", "paper_id": "P0055", "bibkey": "Yin2025Magnet", "title": "Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, their performance may be limited in complex, multi-turn interactions involving users and multiple tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0055-018cc077ef", "paper_id": "P0055", "bibkey": "Yin2025Magnet", "title": "Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this, we propose Magnet, a principled framework for synthesizing high-quality training trajectories to enhance the function calling capability of large language model agents in multi-turn conversations with humans.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0055-ad86963716", "paper_id": "P0055", "bibkey": "Yin2025Magnet", "title": "Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The framework is based on automatic and iterative translations from a function signature path to a sequence of queries and executable function calls.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0055-e1f7ac2749", "paper_id": "P0055", "bibkey": "Yin2025Magnet", "title": "Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We model the complicated function interactions in multi-turn cases with graph and design novel node operations to build reliable signature paths.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0056-79603dbb38", "paper_id": "P0056", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Temporal progression is an integral part of knowledge accumulation and update.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0056-bc9f2f2374", "paper_id": "P0056", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results indicate that agent design and evaluations should take a dynamical view and implement measures to account for the temporal influence of external resources to ensure reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0056-ccb6112830", "paper_id": "P0056", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Temporal progression is an integral part of knowledge accumulation and update.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0056-bbd77bc2b8", "paper_id": "P0056", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Web search is frequently adopted as grounding for agent knowledge, yet an improper configuration affects the quality of the agent's responses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0056-355d9ee68b", "paper_id": "P0056", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Here, we assess the agent behavior using distinct date-controlled tools (DCTs) as stress test to measure the knowledge variability of large language model (LLM) agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0056-c44134e105", "paper_id": "P0056", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We demonstrate the temporal effects of an LLM agent as a writing assistant, which uses web search to complete scientific publication abstracts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0056-f90c91256d", "paper_id": "P0056", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We show that the temporality of search engine translates into tool-dependent agent performance but can be alleviated with base model choice and explicit reasoning instructions such as chain-of-thought prompting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0057-69289755a4", "paper_id": "P0057", "bibkey": "Tawosi2025Meta", "title": "Meta-RAG on Large Codebases Using Code Summarization", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose a multi-agent system to localize bugs in large pre-existing codebases using information retrieval and LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0057-e3ebb83eb2", "paper_id": "P0057", "bibkey": "Tawosi2025Meta", "title": "Meta-RAG on Large Codebases Using Code Summarization", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Meta-RAG scores 84.67 % and 53.0 % for file-level and function-level correct localization rates, respectively, achieving state-of-the-art performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0057-f36b515991", "paper_id": "P0057", "bibkey": "Tawosi2025Meta", "title": "Meta-RAG on Large Codebases Using Code Summarization", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\\%, into a compact, structured, natural language representation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0057-d075de386a", "paper_id": "P0057", "bibkey": "Tawosi2025Meta", "title": "Meta-RAG on Large Codebases Using Code Summarization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) systems have been at the forefront of applied Artificial Intelligence (AI) research in a multitude of domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0057-d9878accab", "paper_id": "P0057", "bibkey": "Tawosi2025Meta", "title": "Meta-RAG on Large Codebases Using Code Summarization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "One such domain is software development, where researchers have pushed the automation of a number of code tasks through LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0057-03b1dfae9c", "paper_id": "P0057", "bibkey": "Tawosi2025Meta", "title": "Meta-RAG on Large Codebases Using Code Summarization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Software development is a complex ecosystem, that stretches far beyond code implementation and well into the realm of code maintenance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0057-290ccf13b0", "paper_id": "P0057", "bibkey": "Tawosi2025Meta", "title": "Meta-RAG on Large Codebases Using Code Summarization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose a multi-agent system to localize bugs in large pre-existing codebases using information retrieval and LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0057-fb723acaff", "paper_id": "P0057", "bibkey": "Tawosi2025Meta", "title": "Meta-RAG on Large Codebases Using Code Summarization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\\%, into a compact, structured, natural language representation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0058-f090d39943", "paper_id": "P0058", "bibkey": "Hong2025Natural", "title": "Natural Language Actor-Critic: Scalable Off-Policy Learning in Language Space", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose Natural Language Actor-Critic (NLAC), a novel actor-critic algorithm that trains LLM policies using a generative LLM critic that produces natural language rather than scalar values.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0058-b3dd1098d3", "paper_id": "P0058", "bibkey": "Hong2025Natural", "title": "Natural Language Actor-Critic: Scalable Off-Policy Learning in Language Space", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We present results on a mixture of reasoning, web browsing, and tool-use with dialogue tasks, demonstrating that NLAC shows promise in outperforming existing training approaches and offers a more scalable and stable training paradigm for LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0058-7f2de7aa3a", "paper_id": "P0058", "bibkey": "Hong2025Natural", "title": "Natural Language Actor-Critic: Scalable Off-Policy Learning in Language Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents -- LLMs that dynamically interact with an environment over long horizons -- have become an increasingly important area of research, enabling automation in complex tasks involving tool-use, web browsing, and dialogue with people.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0058-da44deae3d", "paper_id": "P0058", "bibkey": "Hong2025Natural", "title": "Natural Language Actor-Critic: Scalable Off-Policy Learning in Language Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In the absence of expert demonstrations, training LLM agents has relied on policy gradient methods that optimize LLM policies with respect to an (often sparse) reward function.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0058-60c8a7e13a", "paper_id": "P0058", "bibkey": "Hong2025Natural", "title": "Natural Language Actor-Critic: Scalable Off-Policy Learning in Language Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, in long-horizon tasks with sparse rewards, learning from trajectory-level rewards can be noisy, leading to training that is unstable and has high sample complexity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0058-722aa972f8", "paper_id": "P0058", "bibkey": "Hong2025Natural", "title": "Natural Language Actor-Critic: Scalable Off-Policy Learning in Language Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Furthermore, policy improvement hinges on discovering better actions through exploration, which can be difficult when actions lie in natural language space.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0058-66cf8633de", "paper_id": "P0058", "bibkey": "Hong2025Natural", "title": "Natural Language Actor-Critic: Scalable Off-Policy Learning in Language Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose Natural Language Actor-Critic (NLAC), a novel actor-critic algorithm that trains LLM policies using a generative LLM critic that produces natural language rather than scalar values.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0059-929271af34", "paper_id": "P0059", "bibkey": "Yuksel2025Paace", "title": "PAACE: A Plan-Aware Automated Agent Context Engineering Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we introduce PAACE (Plan-Aware Automated Context Engineering), a unified framework for optimizing the evolving state of LLM agents through next-k-task relevance modeling, plan-structure analysis, instruction co-refinement, and function-preserving compression.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0059-ed34f42db0", "paper_id": "P0059", "bibkey": "Yuksel2025Paace", "title": "PAACE: A Plan-Aware Automated Agent Context Engineering Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on long-horizon benchmarks (AppWorld, OfficeBench, and 8-Objective QA) demonstrate that PAACE consistently improves agent correctness while substantially reducing context load.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0059-91f3543ccf", "paper_id": "P0059", "bibkey": "Yuksel2025Paace", "title": "PAACE: A Plan-Aware Automated Agent Context Engineering Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "PAACE comprises (1) PAACE-Syn, a large-scale generator of synthetic agent workflows annotated with stepwise compression supervision, and (2) PAACE-FT, a family of distilled, plan-aware compressors trained from successful teacher demonstrations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0059-54567060f7", "paper_id": "P0059", "bibkey": "Yuksel2025Paace", "title": "PAACE: A Plan-Aware Automated Agent Context Engineering Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents are increasingly deployed in complex, multi-step workflows involving planning, tool use, reflection, and interaction with external knowledge systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0059-57f902c67c", "paper_id": "P0059", "bibkey": "Yuksel2025Paace", "title": "PAACE: A Plan-Aware Automated Agent Context Engineering Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These workflows generate rapidly expanding contexts that must be curated, transformed, and compressed to maintain fidelity, avoid attention dilution, and reduce inference cost.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0059-4b776049b8", "paper_id": "P0059", "bibkey": "Yuksel2025Paace", "title": "PAACE: A Plan-Aware Automated Agent Context Engineering Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Prior work on summarization and query-aware compression largely ignores the multi-step, plan-aware nature of agentic reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0059-dce5b778af", "paper_id": "P0059", "bibkey": "Yuksel2025Paace", "title": "PAACE: A Plan-Aware Automated Agent Context Engineering Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we introduce PAACE (Plan-Aware Automated Context Engineering), a unified framework for optimizing the evolving state of LLM agents through next-k-task relevance modeling, plan-structure analysis, instruction co-refinement, and function-preserving compression.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0059-7d4ec6de8d", "paper_id": "P0059", "bibkey": "Yuksel2025Paace", "title": "PAACE: A Plan-Aware Automated Agent Context Engineering Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "PAACE comprises (1) PAACE-Syn, a large-scale generator of synthetic agent workflows annotated with stepwise compression supervision, and (2) PAACE-FT, a family of distilled, plan-aware compressors trained from successful teacher demonstrations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0060-982c751007", "paper_id": "P0060", "bibkey": "Rawat2025Multi", "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce Pre-Act, a novel approach that enhances the agent's performance by creating a multi-step execution plan along with the detailed reasoning for the given user input.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0060-5377f4f9b7", "paper_id": "P0060", "bibkey": "Rawat2025Multi", "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To measure the performance of task-oriented agents comprehensively, we propose a two-level evaluation framework: (1) turn level and (2) end-to-end.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0060-f979bf8e10", "paper_id": "P0060", "bibkey": "Rawat2025Multi", "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our turn-level evaluation, averaged across five models, shows that our approach, Pre-Act, outperforms ReAct by 70% in Action Recall on the Almita dataset.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0060-601f0469f6", "paper_id": "P0060", "bibkey": "Rawat2025Multi", "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The ReAct (Reasoning + Action) capability in large language models (LLMs) has become the foundation of modern agentic systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0060-97a9686dd7", "paper_id": "P0060", "bibkey": "Rawat2025Multi", "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent LLMs, such as DeepSeek-R1 and OpenAI o1/o3, exemplify this by emphasizing reasoning through the generation of ample intermediate tokens, which help build a strong premise before producing the final output tokens.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0060-ef0f3cefd0", "paper_id": "P0060", "bibkey": "Rawat2025Multi", "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce Pre-Act, a novel approach that enhances the agent's performance by creating a multi-step execution plan along with the detailed reasoning for the given user input.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0060-860c06745b", "paper_id": "P0060", "bibkey": "Rawat2025Multi", "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This plan incrementally incorporates previous steps and tool outputs, refining itself after each step execution until the final response is obtained.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0060-4f60d00ce2", "paper_id": "P0060", "bibkey": "Rawat2025Multi", "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our approach is applicable to both conversational and non-conversational agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0060-8463ea35d9", "paper_id": "P0060", "bibkey": "Rawat2025Multi", "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address this limitation, we fine-tune relatively small models such as Llama 3.1 (8B & 70B) using the proposed Pre-Act approach.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#limitations[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0061-27b24bfa54", "paper_id": "P0061", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Progent, the first privilege control framework to secure LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0061-68db58914f", "paper_id": "P0061", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0061-e6b786dc5e", "paper_id": "P0061", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM agents utilize Large Language Models as central components with diverse tools to complete various user tasks, but face significant security risks when interacting with external environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0061-52976e4dfa", "paper_id": "P0061", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Attackers can exploit these agents through various vectors, including indirect prompt injection, memory/knowledge base poisoning, and malicious tools, tricking agents into performing dangerous actions such as unauthorized financial transactions or data leakage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "security", "tooling"]}
{"evidence_id": "E-P0061-4792fb4704", "paper_id": "P0061", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The core problem that enables attacks to succeed lies in over-privileged tool access.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#summary_bullets[2]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0061-0396d9929b", "paper_id": "P0061", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Progent, the first privilege control framework to secure LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0061-006a17d83a", "paper_id": "P0061", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Progent enforces security at the tool level by restricting agents to performing tool calls necessary for user tasks while blocking potentially malicious ones.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0061-6829c8b583", "paper_id": "P0061", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Thanks to our modular design, integrating Progent does not alter agent internals and only requires minimal changes to the existing agent implementation, enhancing its practicality and potential for widespread adoption.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0062-bd7f718020", "paper_id": "P0062", "bibkey": "Zhong2025Rtbas", "title": "RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Robust TBAS (RTBAS), which automatically detects and executes tool calls that preserve integrity and confidentiality, requiring user confirmation only when these safeguards cannot be ensured.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0062-52fcef25b6", "paper_id": "P0062", "bibkey": "Zhong2025Rtbas", "title": "RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experimental results on the AgentDojo Prompt Injection benchmark show RTBAS prevents all targeted attacks with only a 2% loss of task utility when under attack, and further tests confirm its ability to obtain near-oracle performance on detecting both subtle and direct privacy leaks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0062-5a5435ff78", "paper_id": "P0062", "bibkey": "Zhong2025Rtbas", "title": "RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, these tools greatly increase the risks of prompt injection attacks, where malicious content hijacks the LM agent to leak confidential data or trigger harmful actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#key_results[1]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0062-99f6810fad", "paper_id": "P0062", "bibkey": "Zhong2025Rtbas", "title": "RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tool-Based Agent Systems (TBAS) allow Language Models (LMs) to use external tools for tasks beyond their standalone capabilities, such as searching websites, booking flights, or making financial transactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0062-5ed1bf2985", "paper_id": "P0062", "bibkey": "Zhong2025Rtbas", "title": "RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, these tools greatly increase the risks of prompt injection attacks, where malicious content hijacks the LM agent to leak confidential data or trigger harmful actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#summary_bullets[1]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0062-73a534b13a", "paper_id": "P0062", "bibkey": "Zhong2025Rtbas", "title": "RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing defenses (OpenAI GPTs) require user confirmation before every tool call, placing onerous burdens on users.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0062-efe404f762", "paper_id": "P0062", "bibkey": "Zhong2025Rtbas", "title": "RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Robust TBAS (RTBAS), which automatically detects and executes tool calls that preserve integrity and confidentiality, requiring user confirmation only when these safeguards cannot be ensured.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0062-cebb846193", "paper_id": "P0062", "bibkey": "Zhong2025Rtbas", "title": "RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "RTBAS adapts Information Flow Control to the unique challenges presented by TBAS.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0063-2edccf4d0f", "paper_id": "P0063", "bibkey": "Oueslati2025Refagent", "title": "RefAgent: A Multi-agent LLM-based Framework for Automatic Software Refactoring", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Specifically, we introduce RefAgent, a multi-agent LLM-based framework for end-to-end software refactoring.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0063-906d682e2a", "paper_id": "P0063", "bibkey": "Oueslati2025Refagent", "title": "RefAgent: A Multi-agent LLM-based Framework for Automatic Software Refactoring", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Additionally, it closely aligns with developer refactorings and the search-based tool in identifying refactoring opportunities, attaining a median F1-score of 79.15% and 72.7%, respectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0063-0e9149a85d", "paper_id": "P0063", "bibkey": "Oueslati2025Refagent", "title": "RefAgent: A Multi-agent LLM-based Framework for Automatic Software Refactoring", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Compared to single-agent approaches, RefAgent improves the median unit test pass rate by 64.7% and the median compilation success rate by 40.1%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0063-4014fe756c", "paper_id": "P0063", "bibkey": "Oueslati2025Refagent", "title": "RefAgent: A Multi-agent LLM-based Framework for Automatic Software Refactoring", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have substantially influenced various software engineering tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0063-80da1eadc7", "paper_id": "P0063", "bibkey": "Oueslati2025Refagent", "title": "RefAgent: A Multi-agent LLM-based Framework for Automatic Software Refactoring", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Indeed, in the case of software refactoring, traditional LLMs have shown the ability to reduce development time and enhance code quality.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0063-4c73d1777b", "paper_id": "P0063", "bibkey": "Oueslati2025Refagent", "title": "RefAgent: A Multi-agent LLM-based Framework for Automatic Software Refactoring", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, these LLMs often rely on static, detailed instructions for specific tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0063-008e15eff2", "paper_id": "P0063", "bibkey": "Oueslati2025Refagent", "title": "RefAgent: A Multi-agent LLM-based Framework for Automatic Software Refactoring", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In contrast, LLM-based agents can dynamically adapt to evolving contexts and autonomously make decisions by interacting with software tools and executing workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0063-57d1bb9350", "paper_id": "P0063", "bibkey": "Oueslati2025Refagent", "title": "RefAgent: A Multi-agent LLM-based Framework for Automatic Software Refactoring", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we explore the potential of LLM-based agents in supporting refactoring activities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0064-ec05e3ea6f", "paper_id": "P0064", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Agents powered by Large Language Models (LLMs) have recently demonstrated impressive capabilities in various tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0064-b5f497408b", "paper_id": "P0064", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Contributing to the ongoing research on neuro-symbolic hybrid systems, this work posits CBR as a viable technique for enhancing the reasoning skills and cognitive aspects of autonomous LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0064-fce48c710d", "paper_id": "P0064", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agents powered by Large Language Models (LLMs) have recently demonstrated impressive capabilities in various tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0064-45b7c47edc", "paper_id": "P0064", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Still, they face limitations in tasks requiring specific, structured knowledge, flexibility, or accountable decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0064-9d7bd89b61", "paper_id": "P0064", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While agents are capable of perceiving their environments, forming inferences, planning, and executing actions towards goals, they often face issues such as hallucinations and lack of contextual memory across interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0064-2582191f5c", "paper_id": "P0064", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper explores how Case-Based Reasoning (CBR), a strategy that solves new problems by referencing past experiences, can be integrated into LLM agent frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0064-c5a76cebfa", "paper_id": "P0064", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This integration allows LLMs to leverage explicit knowledge, enhancing their effectiveness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0064-90c64203f8", "paper_id": "P0064", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Still, they face limitations in tasks requiring specific, structured knowledge, flexibility, or accountable decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0065-18e9d83661", "paper_id": "P0065", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this, in this paper we propose Self-taught ActioN Deliberation (SAND) framework, enabling LLM agents to explicitly deliberate over candidate actions before committing to one.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0065-6273763a98", "paper_id": "P0065", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluating on two representative interactive agent tasks, SAND achieves an average 20% improvement over initial supervised finetuning and also outperforms state-of-the-art agent tuning approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0065-c32e04ef1b", "paper_id": "P0065", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To tackle the challenges of when and what to deliberate given large action space and step-level action evaluation, we incorporate self-consistency action sampling and execution-guided action critique to help synthesize step-wise action deliberation thoughts using the base model of the LLM agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0065-7aa323548c", "paper_id": "P0065", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents are commonly tuned with supervised finetuning on ReAct-style expert trajectories or preference optimization over pairwise rollouts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0065-8dfc3945ee", "paper_id": "P0065", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Most of these methods focus on imitating specific expert behaviors or promoting chosen reasoning thoughts and actions over rejected ones.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0065-a482c4692d", "paper_id": "P0065", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, without reasoning and comparing over alternatives actions, LLM agents finetuned with these methods may over-commit towards seemingly plausible but suboptimal actions due to limited action space exploration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0065-e66eb5ff65", "paper_id": "P0065", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this, in this paper we propose Self-taught ActioN Deliberation (SAND) framework, enabling LLM agents to explicitly deliberate over candidate actions before committing to one.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0065-98c3a0dd78", "paper_id": "P0065", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To tackle the challenges of when and what to deliberate given large action space and step-level action evaluation, we incorporate self-consistency action sampling and execution-guided action critique to help synthesize step-wise action deliberation thoughts using the base model of the LLM agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0066-236be15c59", "paper_id": "P0066", "bibkey": "Jeon2025Based", "title": "SLM-Based Agentic AI with P-C-G: Optimized for Korean Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose a small-scale language model (SLM) based agent architecture, Planner-Caller-Generator (P-C-G), optimized for Korean tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0066-ee5ba721d6", "paper_id": "P0066", "bibkey": "Jeon2025Based", "title": "SLM-Based Agentic AI with P-C-G: Optimized for Korean Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluation assumes Korean queries and Korean tool/parameter specifications; it covers single-chain, multi-chain, missing-parameters, and missing-functions scenarios, and is conducted via an LLM-as-a-Judge protocol averaged over five runs under a unified I/O interface.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0066-26ead18f57", "paper_id": "P0066", "bibkey": "Jeon2025Based", "title": "SLM-Based Agentic AI with P-C-G: Optimized for Korean Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Results show that P-C-G delivers competitive tool-use accuracy and end-to-end quality while reducing tokens and maintaining acceptable latency, indicating that role-specialized SLMs are a cost-effective alternative for Korean tool-use agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#key_results[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0066-5bef733aa8", "paper_id": "P0066", "bibkey": "Jeon2025Based", "title": "SLM-Based Agentic AI with P-C-G: Optimized for Korean Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose a small-scale language model (SLM) based agent architecture, Planner-Caller-Generator (P-C-G), optimized for Korean tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0066-249d1dbc2c", "paper_id": "P0066", "bibkey": "Jeon2025Based", "title": "SLM-Based Agentic AI with P-C-G: Optimized for Korean Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "P-C-G separates planning, calling, and generation by role: the Planner produces an initial batch plan with limited on-demand replanning; the Caller returns a normalized call object after joint schema-value validation; and the Generator integrates tool outputs to produce the final answer.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0066-36a830c81e", "paper_id": "P0066", "bibkey": "Jeon2025Based", "title": "SLM-Based Agentic AI with P-C-G: Optimized for Korean Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We apply a Korean-first value policy to reduce execution failures caused by frequent Korean-to-English code switching in Korean settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0066-5022dbbe3f", "paper_id": "P0066", "bibkey": "Jeon2025Based", "title": "SLM-Based Agentic AI with P-C-G: Optimized for Korean Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Evaluation assumes Korean queries and Korean tool/parameter specifications; it covers single-chain, multi-chain, missing-parameters, and missing-functions scenarios, and is conducted via an LLM-as-a-Judge protocol averaged over five runs under a unified I/O interface.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0066-0760ba1014", "paper_id": "P0066", "bibkey": "Jeon2025Based", "title": "SLM-Based Agentic AI with P-C-G: Optimized for Korean Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Results show that P-C-G delivers competitive tool-use accuracy and end-to-end quality while reducing tokens and maintaining acceptable latency, indicating that role-specialized SLMs are a cost-effective alternative for Korean tool-use agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0067-e872c22cb6", "paper_id": "P0067", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose the Self-Challenging framework for training an agent on high-quality tasks that are generated by itself.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0067-2e6956a116", "paper_id": "P0067", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0067-17d0e7f9d9", "paper_id": "P0067", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, training such agents is challenging because it requires human creation and annotation of a diverse set of tasks, tools, and evaluation criteria.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0067-35136168c1", "paper_id": "P0067", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models are quickly becoming the foundation for intelligent agents that are capable of using tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0067-e90846830c", "paper_id": "P0067", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, training such agents is challenging because it requires human creation and annotation of a diverse set of tasks, tools, and evaluation criteria.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0067-0e2de6e8b5", "paper_id": "P0067", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose the Self-Challenging framework for training an agent on high-quality tasks that are generated by itself.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0067-ca1f06ad35", "paper_id": "P0067", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The agent first plays the role of challenger and generates a task after interacting with the given tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0067-ff0acb5a64", "paper_id": "P0067", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The tasks take the form of a novel general class of problems termed Code-as-Task, which are defined by an instruction, a verification function and solution and failure cases which serve as tests, allowing to filter only for high-quality tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0068-b920ce772b", "paper_id": "P0068", "bibkey": "Alizadeh2025Simple", "title": "Simple Prompt Injection Attacks Can Leak Personal Data Observed by LLM Agents During Task Execution", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Using a fictitious banking agent, we develop data flow-based attacks and integrate them into AgentDojo, a recent benchmark for agentic security.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#method"}, "confidence": "medium", "tags": ["evaluation", "security"]}
{"evidence_id": "E-P0068-537b51e910", "paper_id": "P0068", "bibkey": "Alizadeh2025Simple", "title": "Simple Prompt Injection Attacks Can Leak Personal Data Observed by LLM Agents During Task Execution", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In 16 user tasks from AgentDojo, LLMs show a 15-50 percentage point drop in utility under attack, with average attack success rates (ASR) around 20 percent; some defenses reduce ASR to zero.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers", "security"]}
{"evidence_id": "E-P0068-c2c43d35ce", "paper_id": "P0068", "bibkey": "Alizadeh2025Simple", "title": "Simple Prompt Injection Attacks Can Leak Personal Data Observed by LLM Agents During Task Execution", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In an extended evaluation across 48 tasks, the average ASR is around 15 percent, with no built-in AgentDojo defense fully preventing leakage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0068-f88ec296aa", "paper_id": "P0068", "bibkey": "Alizadeh2025Simple", "title": "Simple Prompt Injection Attacks Can Leak Personal Data Observed by LLM Agents During Task Execution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Previous benchmarks on prompt injection in large language models (LLMs) have primarily focused on generic tasks and attacks, offering limited insights into more complex threats like data exfiltration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "security"]}
{"evidence_id": "E-P0068-1a86f6095d", "paper_id": "P0068", "bibkey": "Alizadeh2025Simple", "title": "Simple Prompt Injection Attacks Can Leak Personal Data Observed by LLM Agents During Task Execution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper examines how prompt injection can cause tool-calling agents to leak personal data observed during task execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#summary_bullets[1]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0068-44852888d9", "paper_id": "P0068", "bibkey": "Alizadeh2025Simple", "title": "Simple Prompt Injection Attacks Can Leak Personal Data Observed by LLM Agents During Task Execution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Using a fictitious banking agent, we develop data flow-based attacks and integrate them into AgentDojo, a recent benchmark for agentic security.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "security"]}
{"evidence_id": "E-P0068-12c72678db", "paper_id": "P0068", "bibkey": "Alizadeh2025Simple", "title": "Simple Prompt Injection Attacks Can Leak Personal Data Observed by LLM Agents During Task Execution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To enhance its scope, we also create a richer synthetic dataset of human-AI banking conversations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0068-1d7e5421a7", "paper_id": "P0068", "bibkey": "Alizadeh2025Simple", "title": "Simple Prompt Injection Attacks Can Leak Personal Data Observed by LLM Agents During Task Execution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In 16 user tasks from AgentDojo, LLMs show a 15-50 percentage point drop in utility under attack, with average attack success rates (ASR) around 20 percent; some defenses reduce ASR to zero.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory", "numbers", "security"]}
{"evidence_id": "E-P0069-2c281ce5fb", "paper_id": "P0069", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "This survey investigates how classical software design patterns can enhance the reliability and scalability of communication in Large Language Model (LLM)-driven agentic AI systems, focusing particularly on the Model Context Protocol (MCP).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0069-a26478752b", "paper_id": "P0069", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The article concludes by outlining open challenges, potential security risks, and promising directions for advancing robust, interoperable, and scalable multi-agent LLM ecosystems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0069-9122b67024", "paper_id": "P0069", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey investigates how classical software design patterns can enhance the reliability and scalability of communication in Large Language Model (LLM)-driven agentic AI systems, focusing particularly on the Model Context Protocol (MCP).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0069-c890a205fd", "paper_id": "P0069", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It examines the foundational architectures of LLM-based agents and their evolution from isolated operation to sophisticated, multi-agent collaboration, addressing key communication hurdles that arise in this transition.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0069-5a66424ae7", "paper_id": "P0069", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The study revisits well-established patterns, including Mediator, Observer, Publish-Subscribe, and Broker, and analyzes their relevance in structuring agent interactions within MCP-compliant frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0069-8eb9325ad5", "paper_id": "P0069", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To clarify these dynamics, the article provides conceptual schematics and formal models that map out communication pathways and optimize data flow.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0069-72d742561d", "paper_id": "P0069", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It further explores architectural variations suited to different degrees of agent autonomy and system complexity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0070-8b5ee25ff7", "paper_id": "P0070", "bibkey": "Yang2025Surveya", "title": "Survey of Specialized Large Language Model", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The rapid evolution of specialized large language models (LLMs) has transitioned from simple domain adaptation to sophisticated native architectures, marking a paradigm shift in AI development.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0070-0adaf943a1", "paper_id": "P0070", "bibkey": "Yang2025Surveya", "title": "Survey of Specialized Large Language Model", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our analysis reveals how these innovations address fundamental limitations of general-purpose LLMs in professional applications, with specialized models consistently performance gains on domain-specific benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0070-2bc8c7d5b7", "paper_id": "P0070", "bibkey": "Yang2025Surveya", "title": "Survey of Specialized Large Language Model", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid evolution of specialized large language models (LLMs) has transitioned from simple domain adaptation to sophisticated native architectures, marking a paradigm shift in AI development.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0070-defd82a0b5", "paper_id": "P0070", "bibkey": "Yang2025Surveya", "title": "Survey of Specialized Large Language Model", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey systematically examines this progression across healthcare, finance, legal, and technical domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0070-8ff42b3a6e", "paper_id": "P0070", "bibkey": "Yang2025Surveya", "title": "Survey of Specialized Large Language Model", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Besides the wide use of specialized LLMs, technical breakthrough such as the emergence of domain-native designs beyond fine-tuning, growing emphasis on parameter efficiency through sparse computation and quantization, increasing integration of multimodal capabilities and so on are applied to recent LLM agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0070-87e4bd5480", "paper_id": "P0070", "bibkey": "Yang2025Surveya", "title": "Survey of Specialized Large Language Model", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our analysis reveals how these innovations address fundamental limitations of general-purpose LLMs in professional applications, with specialized models consistently performance gains on domain-specific benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0070-05e98f9cbb", "paper_id": "P0070", "bibkey": "Yang2025Surveya", "title": "Survey of Specialized Large Language Model", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The survey further highlights the implications for E-Commerce field to fill gaps in the field.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0070-f58ab998f8", "paper_id": "P0070", "bibkey": "Yang2025Surveya", "title": "Survey of Specialized Large Language Model", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Our analysis reveals how these innovations address fundamental limitations of general-purpose LLMs in professional applications, with specialized models consistently performance gains on domain-specific benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#limitations[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0071-4fda54211b", "paper_id": "P0071", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this Systematization of Knowledge (SoK), we present the first comprehensive analysis of IPI-centric defense frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0071-e2d4798c18", "paper_id": "P0071", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, these defenses are fragmented, lacking a unified taxonomy and comprehensive evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0071-5607dc887c", "paper_id": "P0071", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Based on these findings, we design three novel adaptive attacks that significantly improve attack success rates targeting specific frameworks, demonstrating the severity of the flaws in these defenses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#key_results[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0071-7285727f9d", "paper_id": "P0071", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM)-based agents with function-calling capabilities are increasingly deployed, but remain vulnerable to Indirect Prompt Injection (IPI) attacks that hijack their tool calls.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#summary_bullets[0]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0071-d699d2d46c", "paper_id": "P0071", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In response, numerous IPI-centric defense frameworks have emerged.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0071-c77e903fb0", "paper_id": "P0071", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, these defenses are fragmented, lacking a unified taxonomy and comprehensive evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0071-8b099dd7f1", "paper_id": "P0071", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this Systematization of Knowledge (SoK), we present the first comprehensive analysis of IPI-centric defense frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0071-debd3c71cb", "paper_id": "P0071", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce a comprehensive taxonomy of these defenses, classifying them along five dimensions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0072-9b1cbfafd7", "paper_id": "P0072", "bibkey": "Maragheh2025Future", "title": "The Future is Agentic: Definitions, Perspectives, and Open Challenges of Multi-Agent Recommender Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a unified formalism that (i) models an individual agent as a tuple comprising its language core, tool set, and hierarchical memory, and (ii) captures a multi-agent recommender as a triple of agents, shared environment, and communication protocol.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#method"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0072-af89bfa234", "paper_id": "P0072", "bibkey": "Maragheh2025Future", "title": "The Future is Agentic: Definitions, Perspectives, and Open Challenges of Multi-Agent Recommender Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Within this framework, we present four end-to-end use cases-interactive party planning, synthetic user-simulation for offline evaluation, multi-modal furniture recommendation, and brand-aligned explanation generation-each illustrating a distinct capability unlocked by agentic orchestration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0072-0301cf089d", "paper_id": "P0072", "bibkey": "Maragheh2025Future", "title": "The Future is Agentic: Definitions, Perspectives, and Open Challenges of Multi-Agent Recommender Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The result is both a blueprint and an agenda: a blueprint that shows how memory-augmented, tool-using LLM agents can be composed into robust recommendation pipelines, and an agenda inviting the RecSys community to develop benchmarks, theoretical guarantees, and governance tools that keep pace with this new degree of autonomy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0072-6df79b53cc", "paper_id": "P0072", "bibkey": "Maragheh2025Future", "title": "The Future is Agentic: Definitions, Perspectives, and Open Challenges of Multi-Agent Recommender Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are rapidly evolving from passive engines of text generation into agentic entities that can plan, remember, invoke external tools, and co-operate with one another.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0072-c7e5c0374d", "paper_id": "P0072", "bibkey": "Maragheh2025Future", "title": "The Future is Agentic: Definitions, Perspectives, and Open Challenges of Multi-Agent Recommender Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This perspective paper investigates how such LLM agents (and societies thereof) can transform the design space of recommender systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0072-451ed2f3a7", "paper_id": "P0072", "bibkey": "Maragheh2025Future", "title": "The Future is Agentic: Definitions, Perspectives, and Open Challenges of Multi-Agent Recommender Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce a unified formalism that (i) models an individual agent as a tuple comprising its language core, tool set, and hierarchical memory, and (ii) captures a multi-agent recommender as a triple of agents, shared environment, and communication protocol.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0072-b837d71ac5", "paper_id": "P0072", "bibkey": "Maragheh2025Future", "title": "The Future is Agentic: Definitions, Perspectives, and Open Challenges of Multi-Agent Recommender Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Within this framework, we present four end-to-end use cases-interactive party planning, synthetic user-simulation for offline evaluation, multi-modal furniture recommendation, and brand-aligned explanation generation-each illustrating a distinct capability unlocked by agentic orchestration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0072-9c56cecb44", "paper_id": "P0072", "bibkey": "Maragheh2025Future", "title": "The Future is Agentic: Definitions, Perspectives, and Open Challenges of Multi-Agent Recommender Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We then surface five cross-cutting challenge families: protocol complexity, scalability, hallucination and error propagation, emergent misalignment (including covert collusion), and brand compliance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0073-352b11218b", "paper_id": "P0073", "bibkey": "Almeida2025Ticket", "title": "Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Ticket-Bench, a benchmark for multilingual agent evaluation in task-oriented scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0073-560878a578", "paper_id": "P0073", "bibkey": "Almeida2025Ticket", "title": "Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Results show that reasoning-oriented models (e.g., GPT-5, Qwen3-235B) dominate performance but still exhibit notable cross-lingual disparities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0073-ae129955c6", "paper_id": "P0073", "bibkey": "Almeida2025Ticket", "title": "Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large language models (LLMs) are increasingly deployed as task-oriented agents, where success depends on their ability to generate accurate function calls under realistic, multilingual conditions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#key_results[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0073-b9573eaeda", "paper_id": "P0073", "bibkey": "Almeida2025Ticket", "title": "Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are increasingly deployed as task-oriented agents, where success depends on their ability to generate accurate function calls under realistic, multilingual conditions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0073-a63a7611bc", "paper_id": "P0073", "bibkey": "Almeida2025Ticket", "title": "Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing agent evaluations largely overlook cultural and linguistic diversity, often relying on monolingual or naively translated benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0073-723f18e0e0", "paper_id": "P0073", "bibkey": "Almeida2025Ticket", "title": "Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Ticket-Bench, a benchmark for multilingual agent evaluation in task-oriented scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0073-2988a40632", "paper_id": "P0073", "bibkey": "Almeida2025Ticket", "title": "Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Ticket-Bench simulates the domain of soccer ticket purchases across six major languages: Portuguese, English, Spanish, German, Italian, and French.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0073-d8e4e97587", "paper_id": "P0073", "bibkey": "Almeida2025Ticket", "title": "Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Using localized teams, cities, and user profiles to provide a higher level of realism.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0074-7bac399c03", "paper_id": "P0074", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Based on these findings, we present an RPA evaluation design guideline to help researchers develop more systematic and consistent evaluation methods.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0074#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0074-4fc221fdea", "paper_id": "P0074", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This paper proposes an evidence-based, actionable, and generalizable evaluation design guideline for LLM-based RPA by systematically reviewing 1,676 papers published between Jan.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0074#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0074-c1f23da764", "paper_id": "P0074", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Role-Playing Agent (RPA) is an increasingly popular type of LLM Agent that simulates human-like behaviors in a variety of tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0074#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0074-eec58391a2", "paper_id": "P0074", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Role-Playing Agent (RPA) is an increasingly popular type of LLM Agent that simulates human-like behaviors in a variety of tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0074#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0074-1ef81a9450", "paper_id": "P0074", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, evaluating RPAs is challenging due to diverse task requirements and agent designs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0074#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0074-c7d5e0496d", "paper_id": "P0074", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper proposes an evidence-based, actionable, and generalizable evaluation design guideline for LLM-based RPA by systematically reviewing 1,676 papers published between Jan.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0074#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0075-3708cb93a9", "paper_id": "P0075", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address the challenge, we propose Tree-based Group Relative Policy Optimization (Tree-GRPO), a grouped agent RL method based on tree search, where each tree node represents the complete agent interaction step.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0075-9af6a59afb", "paper_id": "P0075", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments across 11 datasets and 3 types of QA tasks demonstrate the superiority of the proposed tree-based RL over the chain-based RL method.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0075-ae8eef51cb", "paper_id": "P0075", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in reinforcement learning (RL) have significantly enhanced the agentic capabilities of large language models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0075-f7e7ef339a", "paper_id": "P0075", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In long-term and multi-turn agent tasks, existing approaches driven solely by outcome rewards often suffer from the problem of sparse supervision.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0075-5645ea4455", "paper_id": "P0075", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address the challenge, we propose Tree-based Group Relative Policy Optimization (Tree-GRPO), a grouped agent RL method based on tree search, where each tree node represents the complete agent interaction step.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0075-7938fe1914", "paper_id": "P0075", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By sharing common prefixes, the tree search sampling increases the number of rollouts achievable within a fixed budget of tokens or tool calls.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0075-377d2b3ad8", "paper_id": "P0075", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Moreover, we find that the tree-structured trajectory naturally allows the construction of step-wise process supervised signals even using only the outcome reward.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0076-fdf9ca29d7", "paper_id": "P0076", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Solving complex or long-horizon problems often requires large language models (LLMs) to use external tools and operate over a significantly longer context window.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0076-ddd9371119", "paper_id": "P0076", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Models with 1M-2M token context windows show severe degradation already at 100K tokens, with performance drops exceeding 50\\% for both benign and harmful tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0076-3fdd9d3667", "paper_id": "P0076", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Refusal rates shift unpredictably: GPT-4.1-nano increases from $\\sim$5\\% to $\\sim$40\\% while Grok 4 Fast decreases from $\\sim$80\\% to $\\sim$10\\% at 200K tokens.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0076-d94c4039a2", "paper_id": "P0076", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Solving complex or long-horizon problems often requires large language models (LLMs) to use external tools and operate over a significantly longer context window.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0076-e111274d88", "paper_id": "P0076", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "New LLMs enable longer context windows and support tool calling capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0076-7e514e7d32", "paper_id": "P0076", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Prior works have focused mainly on evaluation of LLMs on long-context prompts, leaving agentic setup relatively unexplored, both from capability and safety perspectives.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0076-5decb2fe6f", "paper_id": "P0076", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our work addresses this gap.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0076-ecc548aa79", "paper_id": "P0076", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We find that LLM agents could be sensitive to length, type, and placement of the context, exhibiting unexpected and inconsistent shifts in task performance and in refusals to execute harmful requests.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0077-0924bce5d8", "paper_id": "P0077", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We study LLM whistleblowing: a subset of this behavior where models disclose suspected misconduct to parties beyond the dialog boundary (e.g., regulatory agencies) without user instruction or knowledge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0077-5603d51445", "paper_id": "P0077", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across models and settings, we find that: (1) the frequency of whistleblowing varies widely across model families, (2) increasing the complexity of the task the agent is instructed to complete lowers whistleblowing tendencies, (3) nudging the agent in the system prompt to act morally substantially raises whistleblowing rates, and (4) giving the model more obvious avenues for non-whistleblowing behavior, by providing more tools and a detailed workflow to follow, decreases whistleblowing rates.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0077-3c01157d9b", "paper_id": "P0077", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We introduce an evaluation suite of diverse and realistic staged misconduct scenarios to assess agents for this behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0077-719dab689a", "paper_id": "P0077", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The deployment of Large Language Models (LLMs) as tool-using agents causes their alignment training to manifest in new ways.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0077-ef846665da", "paper_id": "P0077", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent work finds that language models can use tools in ways that contradict the interests or explicit instructions of the user.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0077-5f6d3b30a6", "paper_id": "P0077", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We study LLM whistleblowing: a subset of this behavior where models disclose suspected misconduct to parties beyond the dialog boundary (e.g., regulatory agencies) without user instruction or knowledge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0077-1e37d6e7d0", "paper_id": "P0077", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce an evaluation suite of diverse and realistic staged misconduct scenarios to assess agents for this behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0077-03be1bffa6", "paper_id": "P0077", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Across models and settings, we find that: (1) the frequency of whistleblowing varies widely across model families, (2) increasing the complexity of the task the agent is instructed to complete lowers whistleblowing tendencies, (3) nudging the agent in the system prompt to act morally substantially raises whistleblowing rates, and (4) giving the model more obvious avenues for non-whistleblowing behavior, by providing more tools and a detailed workflow to follow, decreases whistleblowing rates.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0078-719cee6930", "paper_id": "P0078", "bibkey": "Guo2025World", "title": "World Modelling Improves Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose dynamics modelling (DyMo), a method that augments LLMs with a state prediction capability alongside function calling during post-training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0078-5000d7b78d", "paper_id": "P0078", "bibkey": "Guo2025World", "title": "World Modelling Improves Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On the Berkeley Function Calling Leaderboard V2, DyMo improves success rates and significantly reduces hallucinations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0078-2f56af10c4", "paper_id": "P0078", "bibkey": "Guo2025World", "title": "World Modelling Improves Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tool use in stateful environments presents unique challenges for large language models (LLMs), where existing test-time compute strategies relying on repeated trials in the environment are impractical.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0078-374ffd21c6", "paper_id": "P0078", "bibkey": "Guo2025World", "title": "World Modelling Improves Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose dynamics modelling (DyMo), a method that augments LLMs with a state prediction capability alongside function calling during post-training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0078-0b69b87b2f", "paper_id": "P0078", "bibkey": "Guo2025World", "title": "World Modelling Improves Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This enables LLMs to predict the future states of their actions through an internal environment model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0078-70991b43b7", "paper_id": "P0078", "bibkey": "Guo2025World", "title": "World Modelling Improves Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "On the Berkeley Function Calling Leaderboard V2, DyMo improves success rates and significantly reduces hallucinations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0078-4926a8e810", "paper_id": "P0078", "bibkey": "Guo2025World", "title": "World Modelling Improves Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We further integrate the internal environment model into self-verification sampling (SVS), and show that this substantially improves pass^k over number of trials k, and allows the model to refuse unreliable outputs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0079-7cfe0595ea", "paper_id": "P0079", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large language model (LLM) agents are increasingly used to interact with and execute tasks in dynamic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0079-7cd49652d3", "paper_id": "P0079", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To study this challenge, we constructed TicToc, a diverse dataset of multi-turn user-agent message trajectories across 76 scenarios, spanning dynamic environments with high, medium, and low time sensitivity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0079-aa2356b9aa", "paper_id": "P0079", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our analysis reveals that existing models display poor alignment with human temporal perception, with no model achieving a normalized alignment rate better than 65% when given time stamp information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0079-bb795af96d", "paper_id": "P0079", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents are increasingly used to interact with and execute tasks in dynamic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0079-9dc12a2780", "paper_id": "P0079", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, a critical yet overlooked limitation of these agents is that they, by default, assume a stationary context, failing to account for the real-world time elapsed between messages.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0079-b6d3fd177e", "paper_id": "P0079", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We refer to this as \"temporal blindness\".", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0079-08f17bd7aa", "paper_id": "P0079", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This limitation hinders decisions about when to invoke tools, leading agents to either over-rely on stale context and skip needed tool calls, or under-rely on it and redundantly repeat tool calls.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0079-08e662e238", "paper_id": "P0079", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To study this challenge, we constructed TicToc, a diverse dataset of multi-turn user-agent message trajectories across 76 scenarios, spanning dynamic environments with high, medium, and low time sensitivity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0079-1fbe3ed2e6", "paper_id": "P0079", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "However, a critical yet overlooked limitation of these agents is that they, by default, assume a stationary context, failing to account for the real-world time elapsed between messages.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0080-05c64bd329", "paper_id": "P0080", "bibkey": "Peng2024Survey", "title": "A Survey of Useful LLM Evaluation", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "LLMs have gotten attention across various research domains due to their exceptional performance on a wide range of complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0080-17ec1d2e4e", "paper_id": "P0080", "bibkey": "Peng2024Survey", "title": "A Survey of Useful LLM Evaluation", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We proposed the two-stage framework: from ``core ability'' to ``agent'', clearly explaining how LLMs can be applied based on their specific capabilities, along with the evaluation methods in each stage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0080-6a3c85b6a9", "paper_id": "P0080", "bibkey": "Peng2024Survey", "title": "A Survey of Useful LLM Evaluation", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we examined the challenges currently confronting the evaluation methods for LLMs, as well as the directions for future development.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0080-3d5da4dda7", "paper_id": "P0080", "bibkey": "Peng2024Survey", "title": "A Survey of Useful LLM Evaluation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLMs have gotten attention across various research domains due to their exceptional performance on a wide range of complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0080-5320d861a3", "paper_id": "P0080", "bibkey": "Peng2024Survey", "title": "A Survey of Useful LLM Evaluation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Therefore, refined methods to evaluate the capabilities of LLMs are needed to determine the tasks and responsibility they should undertake.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0080-172150b71c", "paper_id": "P0080", "bibkey": "Peng2024Survey", "title": "A Survey of Useful LLM Evaluation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our study mainly discussed how LLMs, as useful tools, should be effectively assessed.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0080-737a8b8255", "paper_id": "P0080", "bibkey": "Peng2024Survey", "title": "A Survey of Useful LLM Evaluation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We proposed the two-stage framework: from ``core ability'' to ``agent'', clearly explaining how LLMs can be applied based on their specific capabilities, along with the evaluation methods in each stage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0080-ef7037931c", "paper_id": "P0080", "bibkey": "Peng2024Survey", "title": "A Survey of Useful LLM Evaluation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Core ability refers to the capabilities that LLMs need in order to generate high-quality natural language texts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0081-86ba643e61", "paper_id": "P0081", "bibkey": "Dong2024Appl", "title": "APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this challenge, we propose APPL, A Prompt Programming Language that acts as a bridge between computer programs and LLMs, allowing seamless embedding of prompts into Python functions, and vice versa.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0081-1921c9f202", "paper_id": "P0081", "bibkey": "Dong2024Appl", "title": "APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on three parallelizable workflows further show that APPL can effectively parallelize independent LLM calls, with a significant speedup ratio that almost matches the estimation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0081-def86c3b41", "paper_id": "P0081", "bibkey": "Dong2024Appl", "title": "APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have become increasingly capable of handling diverse tasks with the aid of well-crafted prompts and integration of external tools, but as task complexity rises, the workflow involving LLMs can be complicated and thus challenging to implement and maintain.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0081-62228c5eee", "paper_id": "P0081", "bibkey": "Dong2024Appl", "title": "APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this challenge, we propose APPL, A Prompt Programming Language that acts as a bridge between computer programs and LLMs, allowing seamless embedding of prompts into Python functions, and vice versa.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0081-817965d1c5", "paper_id": "P0081", "bibkey": "Dong2024Appl", "title": "APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "APPL provides an intuitive and Python-native syntax, an efficient parallelized runtime with asynchronous semantics, and a tracing module supporting effective failure diagnosis and replaying without extra costs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0081-ac83e5489d", "paper_id": "P0081", "bibkey": "Dong2024Appl", "title": "APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We demonstrate that APPL programs are intuitive, concise, and efficient through three representative scenarios: Chain-of-Thought with self-consistency (CoT-SC), ReAct tool use agent, and multi-agent chat.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0081-4722e4161c", "paper_id": "P0081", "bibkey": "Dong2024Appl", "title": "APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Experiments on three parallelizable workflows further show that APPL can effectively parallelize independent LLM calls, with a significant speedup ratio that almost matches the estimation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0082-05164359d4", "paper_id": "P0082", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce AnyTool, a large language model agent designed to revolutionize the utilization of a vast array of tools in addressing user queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0082-d5c234444e", "paper_id": "P0082", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments across various datasets demonstrate the superiority of our AnyTool over strong baselines such as ToolLLM and a GPT-4 variant tailored for tool utilization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0082-e046416ff1", "paper_id": "P0082", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We utilize over 16,000 APIs from Rapid API, operating under the assumption that a subset of these APIs could potentially resolve the queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0082-ecdb125724", "paper_id": "P0082", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce AnyTool, a large language model agent designed to revolutionize the utilization of a vast array of tools in addressing user queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0082-4cd28de78f", "paper_id": "P0082", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We utilize over 16,000 APIs from Rapid API, operating under the assumption that a subset of these APIs could potentially resolve the queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0082-9cf97bc7d4", "paper_id": "P0082", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "AnyTool primarily incorporates three elements: an API retriever with a hierarchical structure, a solver aimed at resolving user queries using a selected set of API candidates, and a self-reflection mechanism, which re-activates AnyTool if the initial solution proves impracticable.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0082-28f4799b3b", "paper_id": "P0082", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "AnyTool is powered by the function calling feature of GPT-4, eliminating the need for training external modules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0082-4c17bf30c9", "paper_id": "P0082", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We also revisit the evaluation protocol introduced by previous works and identify a limitation in this protocol that leads to an artificially high pass rate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0082-4da9e4ae32", "paper_id": "P0082", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "We also revisit the evaluation protocol introduced by previous works and identify a limitation in this protocol that leads to an artificially high pass rate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#limitations[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0083-16bbf8a0a5", "paper_id": "P0083", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we develop a framework for building multi-turn RL algorithms for fine-tuning LLMs, that preserves the flexibility of existing single-turn RL methods for LLMs (e.g., proximal policy optimization), while accommodating multiple turns, long horizons, and delayed rewards effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0083-faa3d4c9ee", "paper_id": "P0083", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Empirically, we find that ArCHer significantly improves efficiency and performance on agent tasks, attaining a sample efficiency of about 100x over existing methods, while also improving with larger model capacity (upto the 7 billion scale that we tested on).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0083-6f94b5dd68", "paper_id": "P0083", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A broad use case of large language models (LLMs) is in goal-directed decision-making tasks (or \"agent\" tasks), where an LLM needs to not just generate completions for a given prompt, but rather make intelligent decisions over a multi-turn interaction to accomplish a task (e.g., when interacting with the web, using tools, or providing customer support).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0083-d7f0bcbe26", "paper_id": "P0083", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reinforcement learning (RL) provides a general paradigm to address such agent tasks, but current RL methods for LLMs largely focus on optimizing single-turn rewards.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0083-05ea8dd729", "paper_id": "P0083", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By construction, most single-turn RL methods cannot endow LLMs with the ability to intelligently seek information over multiple turns, perform credit assignment, or reason about their past actions -- all of which are critical in agent tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0083-910f4195eb", "paper_id": "P0083", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This raises the question: how can we design effective and efficient multi-turn RL algorithms for LLMs?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0083-f684b9a780", "paper_id": "P0083", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we develop a framework for building multi-turn RL algorithms for fine-tuning LLMs, that preserves the flexibility of existing single-turn RL methods for LLMs (e.g., proximal policy optimization), while accommodating multiple turns, long horizons, and delayed rewards effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-d42a20619b", "paper_id": "P0084", "bibkey": "Zhang2024Autocoderover", "title": "AutoCodeRover: Autonomous Program Improvement", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose an automated approach for solving GitHub issues to autonomously achieve program improvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-8b5287fcb0", "paper_id": "P0084", "bibkey": "Zhang2024Autocoderover", "title": "AutoCodeRover: Autonomous Program Improvement", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on SWE-bench-lite (300 real-life GitHub issues) show increased efficacy in solving GitHub issues (19% on SWE-bench-lite), which is higher than the efficacy of the recently reported SWE-agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0084-f6f9e6c2e2", "paper_id": "P0084", "bibkey": "Zhang2024Autocoderover", "title": "AutoCodeRover: Autonomous Program Improvement", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "In addition, AutoCodeRover achieved this efficacy with significantly lower cost (on average, $0.43 USD), compared to other baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0084-4dc793a67d", "paper_id": "P0084", "bibkey": "Zhang2024Autocoderover", "title": "AutoCodeRover: Autonomous Program Improvement", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Researchers have made significant progress in automating the software development process in the past decades.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-f7c22d5761", "paper_id": "P0084", "bibkey": "Zhang2024Autocoderover", "title": "AutoCodeRover: Autonomous Program Improvement", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent progress in Large Language Models (LLMs) has significantly impacted the development process, where developers can use LLM-based programming assistants to achieve automated coding.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-17a9620277", "paper_id": "P0084", "bibkey": "Zhang2024Autocoderover", "title": "AutoCodeRover: Autonomous Program Improvement", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Nevertheless, software engineering involves the process of program improvement apart from coding, specifically to enable software maintenance (e.g. bug fixing) and software evolution (e.g. feature additions).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-30298bb10a", "paper_id": "P0084", "bibkey": "Zhang2024Autocoderover", "title": "AutoCodeRover: Autonomous Program Improvement", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose an automated approach for solving GitHub issues to autonomously achieve program improvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-3dae760ad3", "paper_id": "P0084", "bibkey": "Zhang2024Autocoderover", "title": "AutoCodeRover: Autonomous Program Improvement", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In our approach called AutoCodeRover, LLMs are combined with sophisticated code search capabilities, ultimately leading to a program modification or patch.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0085-3a58f8db56", "paper_id": "P0085", "bibkey": "Song2024Domain", "title": "Domain-specific ReAct for physics-integrated iterative modeling: A case study of LLM agents for gas path analysis of gas turbines", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "This study explores the application of large language models (LLMs) with callable tools in energy and power engineering domain, focusing on gas path analysis of gas turbines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0085-7468098183", "paper_id": "P0085", "bibkey": "Song2024Domain", "title": "Domain-specific ReAct for physics-integrated iterative modeling: A case study of LLM agents for gas path analysis of gas turbines", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluated various LLMs, including LLama3, Qwen1.5 and GPT.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0085-6fd8a950f3", "paper_id": "P0085", "bibkey": "Song2024Domain", "title": "Domain-specific ReAct for physics-integrated iterative modeling: A case study of LLM agents for gas path analysis of gas turbines", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Based on the test results, we infer that LLMs with nearly 100 billion parameters could meet professional scenario requirements with fine-tuning and advanced prompt design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0085-c472cebf00", "paper_id": "P0085", "bibkey": "Song2024Domain", "title": "Domain-specific ReAct for physics-integrated iterative modeling: A case study of LLM agents for gas path analysis of gas turbines", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study explores the application of large language models (LLMs) with callable tools in energy and power engineering domain, focusing on gas path analysis of gas turbines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0085-5eed470d74", "paper_id": "P0085", "bibkey": "Song2024Domain", "title": "Domain-specific ReAct for physics-integrated iterative modeling: A case study of LLM agents for gas path analysis of gas turbines", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We developed a dual-agent tool-calling process to integrate expert knowledge, predefined tools, and LLM reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0085-37144a1128", "paper_id": "P0085", "bibkey": "Song2024Domain", "title": "Domain-specific ReAct for physics-integrated iterative modeling: A case study of LLM agents for gas path analysis of gas turbines", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluated various LLMs, including LLama3, Qwen1.5 and GPT.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0085-bb3b4c7978", "paper_id": "P0085", "bibkey": "Song2024Domain", "title": "Domain-specific ReAct for physics-integrated iterative modeling: A case study of LLM agents for gas path analysis of gas turbines", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Smaller models struggled with tool usage and parameter extraction, while larger models demonstrated favorable capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0085-5961794256", "paper_id": "P0085", "bibkey": "Song2024Domain", "title": "Domain-specific ReAct for physics-integrated iterative modeling: A case study of LLM agents for gas path analysis of gas turbines", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "All models faced challenges with complex, multi-component problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0086-9474507f65", "paper_id": "P0086", "bibkey": "Gao2024Efficient", "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose a new method for LLMs to better leverage tools in multi-step reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#method"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0086-ba9c98a93a", "paper_id": "P0086", "bibkey": "Gao2024Efficient", "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "In mathematical reasoning and Wiki QA domains, we show that our method consistently outperforms previous chain-of-thought and tool-augmented baselines on both in-distribution and out-of-distribution test sets, with an average ~6% absolute QA accuracy improvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers", "tooling"]}
{"evidence_id": "E-P0086-a9c15ec0c8", "paper_id": "P0086", "bibkey": "Gao2024Efficient", "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "LLM agents trained with our method also show more efficient tool use, with inference speed being on average ~1.4x faster than baseline tool-augmented LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers", "tooling"]}
{"evidence_id": "E-P0086-b77f5327ba", "paper_id": "P0086", "bibkey": "Gao2024Efficient", "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To achieve faithful reasoning that aligns with human expectations, large language models (LLMs) need to ground their reasoning to real-world knowledge (e.g., web facts, math and physical rules).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0086-33d05a5440", "paper_id": "P0086", "bibkey": "Gao2024Efficient", "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tools help LLMs access this external knowledge, but there remains challenges for fine-tuning LLM agents (e.g., Toolformer) to invoke tools in multi-step reasoning problems, where inter-connected tool calls require holistic and efficient tool usage planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0086-c10a939670", "paper_id": "P0086", "bibkey": "Gao2024Efficient", "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we propose a new method for LLMs to better leverage tools in multi-step reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0086-fbc34c83cc", "paper_id": "P0086", "bibkey": "Gao2024Efficient", "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our method, Chain-of-Abstraction (CoA), trains LLMs to first decode reasoning chains with abstract placeholders, and then call domain tools to reify each reasoning chain by filling in specific knowledge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0086-be5fc78cd7", "paper_id": "P0086", "bibkey": "Gao2024Efficient", "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This planning with abstract chains enables LLMs to learn more general reasoning strategies, which are robust to shifts of domain knowledge (e.g., math results) relevant to different reasoning questions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0087-a69e9aa428", "paper_id": "P0087", "bibkey": "Zala2024Envgen", "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose EnvGen, a novel framework to address this question.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0087-d8cf871a34", "paper_id": "P0087", "bibkey": "Zala2024Envgen", "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We find that a small RL agent trained with EnvGen can outperform SOTA methods, including a GPT-4 agent, and learns long-horizon tasks significantly faster.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0087-81909db190", "paper_id": "P0087", "bibkey": "Zala2024Envgen", "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Additionally, EnvGen is substantially more efficient as it only uses a small number of LLM calls (e.g., 4 in total), whereas LLM agents require thousands of calls.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0087-f1b7423b17", "paper_id": "P0087", "bibkey": "Zala2024Envgen", "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent SOTA approaches for embodied learning via interaction directly employ large language models (LLMs) as agents to determine the next steps in an environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0087-ba2342bd3d", "paper_id": "P0087", "bibkey": "Zala2024Envgen", "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Due to their world knowledge and reasoning capabilities, LLM agents achieve stronger performance than previous smaller agents based on reinforcement learning (RL); however, frequently calling LLMs is slow and expensive.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0087-f6b1a51dc0", "paper_id": "P0087", "bibkey": "Zala2024Envgen", "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Instead of directly employing LLMs as agents, can we use LLMs' reasoning capabilities to adaptively create training environments to help smaller RL agents learn useful skills that they are weak at?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0087-33183f1ebf", "paper_id": "P0087", "bibkey": "Zala2024Envgen", "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose EnvGen, a novel framework to address this question.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0087-4d8617c71f", "paper_id": "P0087", "bibkey": "Zala2024Envgen", "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We first prompt an LLM to generate training environments by giving it the task description and simulator objectives that the agents should learn and then asking it to generate a set of environment configurations (e.g., different terrains, items initially given to agents, etc.).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0088-3611bfc4e0", "paper_id": "P0088", "bibkey": "Turtayev2024Hacking", "title": "Hacking CTFs with Plain Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We saturate a high-school-level hacking benchmark with plain LLM agent design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0088-280f220625", "paper_id": "P0088", "bibkey": "Turtayev2024Hacking", "title": "Hacking CTFs with Plain Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Concretely, we obtain 95% performance on InterCode-CTF, a popular offensive security benchmark, using prompting, tool use, and multiple attempts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0088-082e64f92d", "paper_id": "P0088", "bibkey": "Turtayev2024Hacking", "title": "Hacking CTFs with Plain Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "This beats prior work by Phuong et al. 2024 (29%) and Abramovich et al. 2024 (72%).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0088-bf702c0eb6", "paper_id": "P0088", "bibkey": "Turtayev2024Hacking", "title": "Hacking CTFs with Plain Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We saturate a high-school-level hacking benchmark with plain LLM agent design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0088-9dd76b790e", "paper_id": "P0088", "bibkey": "Turtayev2024Hacking", "title": "Hacking CTFs with Plain Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Concretely, we obtain 95% performance on InterCode-CTF, a popular offensive security benchmark, using prompting, tool use, and multiple attempts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0088-5778d42519", "paper_id": "P0088", "bibkey": "Turtayev2024Hacking", "title": "Hacking CTFs with Plain Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This beats prior work by Phuong et al. 2024 (29%) and Abramovich et al. 2024 (72%).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0088-8ae375dc25", "paper_id": "P0088", "bibkey": "Turtayev2024Hacking", "title": "Hacking CTFs with Plain Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our results suggest that current LLMs have surpassed the high school level in offensive cybersecurity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0088-d5d06eb148", "paper_id": "P0088", "bibkey": "Turtayev2024Hacking", "title": "Hacking CTFs with Plain Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Their hacking capabilities remain underelicited: our ReAct&Plan prompting strategy solves many challenges in 1-2 turns without complex engineering or advanced harnessing.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0089-ef2df859e5", "paper_id": "P0089", "bibkey": "Radha2024Iteration", "title": "Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Motivated by this insight, we propose the Iteration of Thought (IoT) framework for enhancing LLM responses by generating \"thought\"-provoking prompts vis a vis an input query and the current iteration of an LLM's response.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0089-d36844b954", "paper_id": "P0089", "bibkey": "Radha2024Iteration", "title": "Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We investigate the performance of IoT across various datasets, spanning complex reasoning tasks from the GPQA dataset, explorative problem-solving in Game of 24, puzzle solving in Mini Crosswords, and multi-hop question answering from the HotpotQA dataset.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0089-dc268ffd9e", "paper_id": "P0089", "bibkey": "Radha2024Iteration", "title": "Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The three components of the IoT framework are (1) an Inner Dialogue Agent (IDA) responsible for generating instructive, context-specific prompts; (2) an LLM Agent (LLMA) that processes these prompts to refine its responses; and (3) an iterative prompting loop that implements a conversation between the former two components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0089-8767ae0705", "paper_id": "P0089", "bibkey": "Radha2024Iteration", "title": "Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Iterative human engagement is a common and effective means of leveraging the advanced language processing power of large language models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0089-ceea4956ca", "paper_id": "P0089", "bibkey": "Radha2024Iteration", "title": "Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Using well-structured prompts in a conversational manner, human users can effectively influence an LLM to develop more thoughtful and accurate responses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0089-f490fd9fb7", "paper_id": "P0089", "bibkey": "Radha2024Iteration", "title": "Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Motivated by this insight, we propose the Iteration of Thought (IoT) framework for enhancing LLM responses by generating \"thought\"-provoking prompts vis a vis an input query and the current iteration of an LLM's response.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0089-1e58445ad4", "paper_id": "P0089", "bibkey": "Radha2024Iteration", "title": "Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike static or semi-static approaches, e.g. Chain of Thought (CoT) or Tree of Thoughts (ToT), IoT adapts its reasoning path dynamically, based on evolving context, and without generating alternate explorative thoughts which are ultimately discarded.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0089-988bbe3858", "paper_id": "P0089", "bibkey": "Radha2024Iteration", "title": "Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The three components of the IoT framework are (1) an Inner Dialogue Agent (IDA) responsible for generating instructive, context-specific prompts; (2) an LLM Agent (LLMA) that processes these prompts to refine its responses; and (3) an iterative prompting loop that implements a conversation between the former two components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0090-736b6ce650", "paper_id": "P0090", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In recent years, large language models (LLMs) have become increasingly capable and can now interact with tools (i.e., call functions), read documents, and recursively call themselves.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0090-5289c5dd2a", "paper_id": "P0090", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Namely, we show that GPT-4 is capable of such hacks, but existing open-source models are not.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0090-4ca48f2c91", "paper_id": "P0090", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we show that GPT-4 is capable of autonomously finding vulnerabilities in websites in the wild.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "security"]}
{"evidence_id": "E-P0090-aa284afced", "paper_id": "P0090", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In recent years, large language models (LLMs) have become increasingly capable and can now interact with tools (i.e., call functions), read documents, and recursively call themselves.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0090-27c3729137", "paper_id": "P0090", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As a result, these LLMs can now function autonomously as agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0090-6585fe35f0", "paper_id": "P0090", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the rise in capabilities of these agents, recent work has speculated on how LLM agents would affect cybersecurity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0090-eb0e20f741", "paper_id": "P0090", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, not much is known about the offensive capabilities of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0090-a0519efcfb", "paper_id": "P0090", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we show that LLM agents can autonomously hack websites, performing tasks as complex as blind database schema extraction and SQL injections without human feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0090-58e3b3142d", "paper_id": "P0090", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Importantly, the agent does not need to know the vulnerability beforehand.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#limitations[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0091-a2aafb319f", "paper_id": "P0091", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "GUIs have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0091-1e605f8766", "paper_id": "P0091", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "GUIs have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0091-52fea1d199", "paper_id": "P0091", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We address research questions such as existing GUI agent frameworks, the collection and utilization of data for training specialized GUI agents, the development of large action models tailored for GUI tasks, and the evaluation metrics and benchmarks necessary to assess their effectiveness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0091-b24804a0b8", "paper_id": "P0091", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "GUIs have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0091-a936da9e8a", "paper_id": "P0091", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The advent of LLMs, particularly multimodal models, has ushered in a new era of GUI automation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0091-506fa962e0", "paper_id": "P0091", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "They have demonstrated exceptional capabilities in natural language understanding, code generation, and visual processing.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0091-089d5e559a", "paper_id": "P0091", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This has paved the way for a new generation of LLM-brained GUI agents capable of interpreting complex GUI elements and autonomously executing actions based on natural language instructions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0091-5bafc321f9", "paper_id": "P0091", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These agents represent a paradigm shift, enabling users to perform intricate, multi-step tasks through simple conversational commands.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0092-4455fd2e27", "paper_id": "P0092", "bibkey": "Yin2024Mmau", "title": "MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these limitations, we introduce the Massive Multitask Agent Understanding (MMAU) benchmark, featuring comprehensive offline tasks that eliminate the need for complex environment setups.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0092-ebb97f6129", "paper_id": "P0092", "bibkey": "Yin2024Mmau", "title": "MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "With a total of 20 meticulously designed tasks encompassing over 3K distinct prompts, MMAU provides a comprehensive framework for evaluating the strengths and limitations of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0092-e2f49d6ebf", "paper_id": "P0092", "bibkey": "Yin2024Mmau", "title": "MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "By testing 18 representative models on MMAU, we provide deep and insightful analyses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0092-9b4eeec496", "paper_id": "P0092", "bibkey": "Yin2024Mmau", "title": "MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in large language models (LLMs) have increased the demand for comprehensive benchmarks to evaluate their capabilities as human-like agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0092-b4a2bb2fa8", "paper_id": "P0092", "bibkey": "Yin2024Mmau", "title": "MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing benchmarks, while useful, often focus on specific application scenarios, emphasizing task completion but failing to dissect the underlying skills that drive these outcomes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0092-f0b9da9b60", "paper_id": "P0092", "bibkey": "Yin2024Mmau", "title": "MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This lack of granularity makes it difficult to deeply discern where failures stem from.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0092-db25796ff1", "paper_id": "P0092", "bibkey": "Yin2024Mmau", "title": "MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Additionally, setting up these environments requires considerable effort, and issues of unreliability and reproducibility sometimes arise, especially in interactive tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0092-7f5a08ddea", "paper_id": "P0092", "bibkey": "Yin2024Mmau", "title": "MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these limitations, we introduce the Massive Multitask Agent Understanding (MMAU) benchmark, featuring comprehensive offline tasks that eliminate the need for complex environment setups.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0092-0889be3715", "paper_id": "P0092", "bibkey": "Yin2024Mmau", "title": "MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address these limitations, we introduce the Massive Multitask Agent Understanding (MMAU) benchmark, featuring comprehensive offline tasks that eliminate the need for complex environment setups.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#limitations[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0093-dd962b27b4", "paper_id": "P0093", "bibkey": "Zhu2024Menti", "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce MeNTi, a universal agent architecture for LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0093-846c85b609", "paper_id": "P0093", "bibkey": "Zhu2024Menti", "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "CalcQA is constructed by professional physicians and includes 100 case-calculator pairs, complemented by a toolkit of 281 medical tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0093-6c0f9f8b56", "paper_id": "P0093", "bibkey": "Zhu2024Menti", "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "This benchmark requires LLMs to use medical calculators to perform calculations and assess patient health status.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0093-dcfa174862", "paper_id": "P0093", "bibkey": "Zhu2024Menti", "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Integrating tools into Large Language Models (LLMs) has facilitated the widespread application.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0093-c89dc1fa9e", "paper_id": "P0093", "bibkey": "Zhu2024Menti", "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite this, in specialized downstream task contexts, reliance solely on tools is insufficient to fully address the complexities of the real world.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0093-ce4b7c4591", "paper_id": "P0093", "bibkey": "Zhu2024Menti", "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This particularly restricts the effective deployment of LLMs in fields such as medicine.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0093-fe1e74651c", "paper_id": "P0093", "bibkey": "Zhu2024Menti", "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we focus on the downstream tasks of medical calculators, which use standardized tests to assess an individual's health status.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0093-62837f00ac", "paper_id": "P0093", "bibkey": "Zhu2024Menti", "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce MeNTi, a universal agent architecture for LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0094-b04d8338a8", "paper_id": "P0094", "bibkey": "Kumar2024Swissnyf", "title": "SwissNYF: Tool Grounded LLM Agents for Black Box Setting", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce TOPGUN, an ingeniously crafted approach leveraging program synthesis for black box tool planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#method"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0094-edad145d16", "paper_id": "P0094", "bibkey": "Kumar2024Swissnyf", "title": "SwissNYF: Tool Grounded LLM Agents for Black Box Setting", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The public code for SwissNYF is available at https://github.com/iclr-dummy-user/SwissNYF.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0094-7ce4800cf9", "paper_id": "P0094", "bibkey": "Kumar2024Swissnyf", "title": "SwissNYF: Tool Grounded LLM Agents for Black Box Setting", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While Large Language Models (LLMs) have demonstrated enhanced capabilities in function-calling, these advancements primarily rely on accessing the functions' responses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0094-690f7174cc", "paper_id": "P0094", "bibkey": "Kumar2024Swissnyf", "title": "SwissNYF: Tool Grounded LLM Agents for Black Box Setting", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This methodology is practical for simpler APIs but faces scalability issues with irreversible APIs that significantly impact the system, such as a database deletion API.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0094-594bbdeeab", "paper_id": "P0094", "bibkey": "Kumar2024Swissnyf", "title": "SwissNYF: Tool Grounded LLM Agents for Black Box Setting", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Similarly, processes requiring extensive time for each API call and those necessitating forward planning, like automated action pipelines, present complex challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0094-eb3a172c3a", "paper_id": "P0094", "bibkey": "Kumar2024Swissnyf", "title": "SwissNYF: Tool Grounded LLM Agents for Black Box Setting", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Furthermore, scenarios often arise where a generalized approach is needed because algorithms lack direct access to the specific implementations of these functions or secrets to use them.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0094-b50e399065", "paper_id": "P0094", "bibkey": "Kumar2024Swissnyf", "title": "SwissNYF: Tool Grounded LLM Agents for Black Box Setting", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional tool planning methods are inadequate in these cases, compelling the need to operate within black-box environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0095-586b799cd4", "paper_id": "P0095", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Inspired by the rapid development of Large Language Models (LLMs), LLM agents have evolved to perform complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0095-302bb87ff0", "paper_id": "P0095", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "By highlighting these critical security and privacy issues, the survey seeks to stimulate future research towards enhancing the security and privacy of LLM agents, thereby increasing their reliability and trustworthiness in future applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0095-45ed2b5dca", "paper_id": "P0095", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Inspired by the rapid development of Large Language Models (LLMs), LLM agents have evolved to perform complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0095-36598f95c7", "paper_id": "P0095", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM agents are now extensively applied across various domains, handling vast amounts of data to interact with humans and execute tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0095-55ac1d8361", "paper_id": "P0095", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The widespread applications of LLM agents demonstrate their significant commercial value; however, they also expose security and privacy vulnerabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0095-2944b9e886", "paper_id": "P0095", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "At the current stage, comprehensive research on the security and privacy of LLM agents is highly needed.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0095-1393dc56a1", "paper_id": "P0095", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey aims to provide a comprehensive overview of the newly emerged privacy and security issues faced by LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0096-1b32f976db", "paper_id": "P0096", "bibkey": "Erdogan2024Tinyagent", "title": "TinyAgent: Function Calling at the Edge", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To this end, we present TinyAgent, an end-to-end framework for training and deploying task-specific small language model agents capable of function calling for driving agentic systems at the edge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0096-4fca49d200", "paper_id": "P0096", "bibkey": "Erdogan2024Tinyagent", "title": "TinyAgent: Function Calling at the Edge", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We then systematically curate a high-quality dataset for function calling, which we use to fine-tune two small language models, TinyAgent-1.1B and 7B.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0096-8acebc13f7", "paper_id": "P0096", "bibkey": "Erdogan2024Tinyagent", "title": "TinyAgent: Function Calling at the Edge", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results show that our models can achieve, and even surpass, the function-calling capabilities of larger models like GPT-4-Turbo, while being fully deployed at the edge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0096-81d2299a8b", "paper_id": "P0096", "bibkey": "Erdogan2024Tinyagent", "title": "TinyAgent: Function Calling at the Edge", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent large language models (LLMs) have enabled the development of advanced agentic systems that can integrate various tools and APIs to fulfill user queries through function calling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0096-296136ee9d", "paper_id": "P0096", "bibkey": "Erdogan2024Tinyagent", "title": "TinyAgent: Function Calling at the Edge", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the deployment of these LLMs on the edge has not been explored since they typically require cloud-based infrastructure due to their substantial model size and computational demands.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0096-8178f601fa", "paper_id": "P0096", "bibkey": "Erdogan2024Tinyagent", "title": "TinyAgent: Function Calling at the Edge", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To this end, we present TinyAgent, an end-to-end framework for training and deploying task-specific small language model agents capable of function calling for driving agentic systems at the edge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0096-b8ed17ecd7", "paper_id": "P0096", "bibkey": "Erdogan2024Tinyagent", "title": "TinyAgent: Function Calling at the Edge", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We first show how to enable accurate function calling for open-source models via the LLMCompiler framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0096-00f36866e2", "paper_id": "P0096", "bibkey": "Erdogan2024Tinyagent", "title": "TinyAgent: Function Calling at the Edge", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We then systematically curate a high-quality dataset for function calling, which we use to fine-tune two small language models, TinyAgent-1.1B and 7B.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0097-c42cf712f3", "paper_id": "P0097", "bibkey": "Huang2024Understanding", "title": "Understanding the planning of LLM agents: A survey", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "As Large Language Models (LLMs) have shown significant intelligence, the progress to leverage LLMs as planning modules of autonomous agents has attracted more attention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0097-ba968b6b32", "paper_id": "P0097", "bibkey": "Huang2024Understanding", "title": "Understanding the planning of LLM agents: A survey", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Comprehensive analyses are conducted for each direction, and further challenges for the field of research are discussed.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0097-4f5a103381", "paper_id": "P0097", "bibkey": "Huang2024Understanding", "title": "Understanding the planning of LLM agents: A survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As Large Language Models (LLMs) have shown significant intelligence, the progress to leverage LLMs as planning modules of autonomous agents has attracted more attention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0097-eb9c9a3564", "paper_id": "P0097", "bibkey": "Huang2024Understanding", "title": "Understanding the planning of LLM agents: A survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey provides the first systematic view of LLM-based agents planning, covering recent works aiming to improve planning ability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0097-124466c3d9", "paper_id": "P0097", "bibkey": "Huang2024Understanding", "title": "Understanding the planning of LLM agents: A survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We provide a taxonomy of existing works on LLM-Agent planning, which can be categorized into Task Decomposition, Plan Selection, External Module, Reflection and Memory.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0097-84a2f2d3c0", "paper_id": "P0097", "bibkey": "Huang2024Understanding", "title": "Understanding the planning of LLM agents: A survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Comprehensive analyses are conducted for each direction, and further challenges for the field of research are discussed.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0098-a68163e536", "paper_id": "P0098", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of LLM-based autonomous agents from a holistic perspective.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0098-7902b25b48", "paper_id": "P0098", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0098-2cd82bbe79", "paper_id": "P0098", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0098-4e8c5a07c9", "paper_id": "P0098", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Autonomous agents have long been a prominent research focus in both academic and industry communities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0098-735b270082", "paper_id": "P0098", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0098-70b43a61f3", "paper_id": "P0098", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0098-3271d08126", "paper_id": "P0098", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This has sparked an upsurge in studies investigating LLM-based autonomous agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0098-feb9b75f6e", "paper_id": "P0098", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of LLM-based autonomous agents from a holistic perspective.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0099-b6c6841af2", "paper_id": "P0099", "bibkey": "Wu2026Agent", "title": "Agent-Dice: Disentangling Knowledge Updates via Geometric Consensus for Agent Continual Learning", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this, we propose Agent-Dice, a parameter fusion framework based on directional consensus evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0099-daa2d2e135", "paper_id": "P0099", "bibkey": "Wu2026Agent", "title": "Agent-Dice: Disentangling Knowledge Updates via Geometric Consensus for Agent Continual Learning", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "To address this, we propose Agent-Dice, a parameter fusion framework based on directional consensus evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0099-ea74473a5c", "paper_id": "P0099", "bibkey": "Wu2026Agent", "title": "Agent-Dice: Disentangling Knowledge Updates via Geometric Consensus for Agent Continual Learning", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM)-based agents significantly extend the utility of LLMs by interacting with dynamic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0099-bd9ef4a68d", "paper_id": "P0099", "bibkey": "Wu2026Agent", "title": "Agent-Dice: Disentangling Knowledge Updates via Geometric Consensus for Agent Continual Learning", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, enabling agents to continually learn new tasks without catastrophic forgetting remains a critical challenge, known as the stability-plasticity dilemma.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0099-f16c94c445", "paper_id": "P0099", "bibkey": "Wu2026Agent", "title": "Agent-Dice: Disentangling Knowledge Updates via Geometric Consensus for Agent Continual Learning", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we argue that this dilemma fundamentally arises from the failure to explicitly distinguish between common knowledge shared across tasks and conflicting knowledge introduced by task-specific interference.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0099-76aae3c9b4", "paper_id": "P0099", "bibkey": "Wu2026Agent", "title": "Agent-Dice: Disentangling Knowledge Updates via Geometric Consensus for Agent Continual Learning", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this, we propose Agent-Dice, a parameter fusion framework based on directional consensus evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0099-c42e26515e", "paper_id": "P0099", "bibkey": "Wu2026Agent", "title": "Agent-Dice: Disentangling Knowledge Updates via Geometric Consensus for Agent Continual Learning", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Concretely, Agent-Dice disentangles knowledge updates through a two-stage process: geometric consensus filtering to prune conflicting gradients, and curvature-based importance weighting to amplify shared semantics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0100-67ea29ce26", "paper_id": "P0100", "bibkey": "Li2026Autonomous", "title": "Autonomous Quantum Simulation through Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We demonstrate that large language model (LLM) agents can autonomously perform tensor network simulations of quantum many-body systems, achieving approximately 90% success rate across representative benchmark tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#method"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0100-499402e2fb", "paper_id": "P0100", "bibkey": "Li2026Autonomous", "title": "Autonomous Quantum Simulation through Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We demonstrate that large language model (LLM) agents can autonomously perform tensor network simulations of quantum many-body systems, achieving approximately 90% success rate across representative benchmark tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0100-9980bf7642", "paper_id": "P0100", "bibkey": "Li2026Autonomous", "title": "Autonomous Quantum Simulation through Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Systematic evaluation using DeepSeek-V3.2, Gemini 2.5 Pro, and Claude Opus 4.5 demonstrates that both in-context learning and multi-agent architecture are essential.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0100-b497dd93f2", "paper_id": "P0100", "bibkey": "Li2026Autonomous", "title": "Autonomous Quantum Simulation through Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We demonstrate that large language model (LLM) agents can autonomously perform tensor network simulations of quantum many-body systems, achieving approximately 90% success rate across representative benchmark tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0100-a10b5d889d", "paper_id": "P0100", "bibkey": "Li2026Autonomous", "title": "Autonomous Quantum Simulation through Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tensor network methods are powerful tools for quantum simulation, but their effective use requires expertise typically acquired through years of graduate training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0100-971c9175a5", "paper_id": "P0100", "bibkey": "Li2026Autonomous", "title": "Autonomous Quantum Simulation through Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By combining in-context learning with curated documentation and multi-agent decomposition, we create autonomous AI agents that can be trained in specialized computational domains within minutes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0100-ba4092bc07", "paper_id": "P0100", "bibkey": "Li2026Autonomous", "title": "Autonomous Quantum Simulation through Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We benchmark three configurations (baseline, single-agent with in-context learning, and multi-agent with in-context learning) on problems spanning quantum phase transitions, open quantum system dynamics, and photochemical reactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0100-4a1d0abe6f", "paper_id": "P0100", "bibkey": "Li2026Autonomous", "title": "Autonomous Quantum Simulation through Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Systematic evaluation using DeepSeek-V3.2, Gemini 2.5 Pro, and Claude Opus 4.5 demonstrates that both in-context learning and multi-agent architecture are essential.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0101-afe68b52b5", "paper_id": "P0101", "bibkey": "Balaji2026Beyond", "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we introduce JourneyBench, a benchmark designed to assess policy-aware agents in customer support.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0101-d36da098af", "paper_id": "P0101", "bibkey": "Balaji2026Beyond", "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across 703 conversations in three domains, we show that DPA significantly boosts policy adherence, even allowing smaller models like GPT-4o-mini to outperform more capable ones like GPT-4o.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0101-a4ae2708e4", "paper_id": "P0101", "bibkey": "Balaji2026Beyond", "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0101-9090b0d1ea", "paper_id": "P0101", "bibkey": "Balaji2026Beyond", "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional customer support systems, such as Interactive Voice Response (IVR), rely on rigid scripts and lack the flexibility required for handling complex, policy-driven tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0101-d30f1529ac", "paper_id": "P0101", "bibkey": "Balaji2026Beyond", "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While large language model (LLM) agents offer a promising alternative, evaluating their ability to act in accordance with business rules and real-world support workflows remains an open challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0101-bdb67b980a", "paper_id": "P0101", "bibkey": "Balaji2026Beyond", "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0101-067afa7d8e", "paper_id": "P0101", "bibkey": "Balaji2026Beyond", "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we introduce JourneyBench, a benchmark designed to assess policy-aware agents in customer support.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0101-373d5e7fb4", "paper_id": "P0101", "bibkey": "Balaji2026Beyond", "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "JourneyBench leverages graph representations to generate diverse, realistic support scenarios and proposes the User Journey Coverage Score, a novel metric to measure policy adherence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0101-2e32363eff", "paper_id": "P0101", "bibkey": "Balaji2026Beyond", "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "year": 2026, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "While large language model (LLM) agents offer a promising alternative, evaluating their ability to act in accordance with business rules and real-world support workflows remains an open challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#limitations[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0102-a4634aca5a", "paper_id": "P0102", "bibkey": "Peng2026Enhancing", "title": "Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these limitations, we propose CyberOps-Bots, a hierarchical multi-agent reinforcement learning framework empowered by Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0102-ec579c4773", "paper_id": "P0102", "bibkey": "Peng2026Enhancing", "title": "Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on real cloud datasets show that, compared to state-of-the-art algorithms, CyberOps-Bots maintains network availability 68.5% higher and achieves a 34.7% jumpstart performance gain when shifting the scenarios without retraining.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0102-d4940031dc", "paper_id": "P0102", "bibkey": "Peng2026Enhancing", "title": "Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Inspired by MITRE ATT&CK's Tactics-Techniques model, CyberOps-Bots features a two-layer architecture: (1) An upper-level LLM agent with four modules--ReAct planning, IPDRR-based perception, long-short term memory, and action/tool integration--performs global awareness, human intent recognition, and tactical planning; (2) Lower-level RL agents, developed via heterogeneous separated pre-training, execute atomic defense actions within localized network regions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers", "tooling"]}
{"evidence_id": "E-P0102-98d4089bc9", "paper_id": "P0102", "bibkey": "Peng2026Enhancing", "title": "Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While virtualization and resource pooling empower cloud networks with structural flexibility and elastic scalability, they inevitably expand the attack surface and challenge cyber resilience.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0102-df0433b99e", "paper_id": "P0102", "bibkey": "Peng2026Enhancing", "title": "Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reinforcement Learning (RL)-based defense strategies have been developed to optimize resource deployment and isolation policies under adversarial conditions, aiming to enhance system resilience by maintaining and restoring network availability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0102-e4682e4d55", "paper_id": "P0102", "bibkey": "Peng2026Enhancing", "title": "Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing approaches lack robustness as they require retraining to adapt to dynamic changes in network structure, node scale, attack strategies, and attack intensity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0102-17dba3c1ab", "paper_id": "P0102", "bibkey": "Peng2026Enhancing", "title": "Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Furthermore, the lack of Human-in-the-Loop (HITL) support limits interpretability and flexibility.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0102-abfbe13e64", "paper_id": "P0102", "bibkey": "Peng2026Enhancing", "title": "Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these limitations, we propose CyberOps-Bots, a hierarchical multi-agent reinforcement learning framework empowered by Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0102-9710893788", "paper_id": "P0102", "bibkey": "Peng2026Enhancing", "title": "Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework", "year": 2026, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address these limitations, we propose CyberOps-Bots, a hierarchical multi-agent reinforcement learning framework empowered by Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0103-df142ee3e5", "paper_id": "P0103", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To dismantle this trilemma, we introduce EvoRoute, a self-evolving model routing paradigm that transcends static, pre-defined model assignments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0103-60cc0d458f", "paper_id": "P0103", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\\%$ and latency by over $70\\%$.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0103-d550725f5f", "paper_id": "P0103", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, this success is shadowed by prohibitive economic costs and severe latency, exposing a critical, yet underexplored, trade-off.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0103-f5b4e3fb6c", "paper_id": "P0103", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Complex agentic AI systems, powered by a coordinated ensemble of Large Language Models (LLMs), tool and memory modules, have demonstrated remarkable capabilities on intricate, multi-turn tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0103-229019434c", "paper_id": "P0103", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, this success is shadowed by prohibitive economic costs and severe latency, exposing a critical, yet underexplored, trade-off.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0103-6b1976d308", "paper_id": "P0103", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We formalize this challenge as the \\textbf{Agent System Trilemma}: the inherent tension among achieving state-of-the-art performance, minimizing monetary cost, and ensuring rapid task completion.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0103-c3bf9179de", "paper_id": "P0103", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To dismantle this trilemma, we introduce EvoRoute, a self-evolving model routing paradigm that transcends static, pre-defined model assignments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0103-ac4995eba6", "paper_id": "P0103", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Leveraging an ever-expanding knowledge base of prior experience, EvoRoute dynamically selects Pareto-optimal LLM backbones at each step, balancing accuracy, efficiency, and resource use, while continually refining its own selection policy through environment feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0104-2414d1e3d2", "paper_id": "P0104", "bibkey": "Kao2026Hidden", "title": "Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we study deception in the Social Deduction Game (SDG) Mafia, where success is dependent on deceiving others through conversation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0104-513fb030c0", "paper_id": "P0104", "bibkey": "Kao2026Hidden", "title": "Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We compare this prediction accuracy to that of 28 human games and a random baseline.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0104-8440e1bceb", "paper_id": "P0104", "bibkey": "Kao2026Hidden", "title": "Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We simulate 35 Mafia games with GPT-4o LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0104-d2a4e33e69", "paper_id": "P0104", "bibkey": "Kao2026Hidden", "title": "Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents are increasingly used in many applications, raising concerns about their safety.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0104-7d7b7e80d9", "paper_id": "P0104", "bibkey": "Kao2026Hidden", "title": "Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While previous work has shown that LLMs can deceive in controlled tasks, less is known about their ability to deceive using natural language in social contexts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0104-df41e449cb", "paper_id": "P0104", "bibkey": "Kao2026Hidden", "title": "Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we study deception in the Social Deduction Game (SDG) Mafia, where success is dependent on deceiving others through conversation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0104-404328a8f9", "paper_id": "P0104", "bibkey": "Kao2026Hidden", "title": "Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike previous SDG studies, we use an asynchronous multi-agent framework which better simulates realistic social contexts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0104-263a55cd81", "paper_id": "P0104", "bibkey": "Kao2026Hidden", "title": "Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We simulate 35 Mafia games with GPT-4o LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0105-cfd50d8597", "paper_id": "P0105", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "Existing change detection methods often lack the versatility to handle diverse real-world queries and the intelligence for comprehensive analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0105-a8702dce10", "paper_id": "P0105", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "The agent was evaluated on a curated dataset of 140 questions categorized by real-world scenarios, encompassing various question types (e.g., Size, Class, Number) and complexities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0105-deabf13faf", "paper_id": "P0105", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "ChangeGPT, especially with a GPT-4-turbo backend, demonstrated superior performance, achieving a 90.71 % Match rate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0105-c4ff905064", "paper_id": "P0105", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing change detection methods often lack the versatility to handle diverse real-world queries and the intelligence for comprehensive analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0105-0afbc558b7", "paper_id": "P0105", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents a general agent framework, integrating Large Language Models (LLM) with vision foundation models to form ChangeGPT.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0105-24d3c2a530", "paper_id": "P0105", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A hierarchical structure is employed to mitigate hallucination.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0105-2e15e2fac2", "paper_id": "P0105", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The agent was evaluated on a curated dataset of 140 questions categorized by real-world scenarios, encompassing various question types (e.g., Size, Class, Number) and complexities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0105-b295eea25f", "paper_id": "P0105", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The evaluation assessed the agent's tool selection ability (Precision/Recall) and overall query accuracy (Match).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0106-26a024b9d9", "paper_id": "P0106", "bibkey": "Nipane2026Specmap", "title": "SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Traceability Link Recovery in Systems Engineering", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present a hierarchical datasheet-to-code mapping methodology that employs large language models for semantic analysis while explicitly structuring the traceability process across multiple abstraction levels.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0106-095d5b5fe8", "paper_id": "P0106", "bibkey": "Nipane2026Specmap", "title": "SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Traceability Link Recovery in Systems Engineering", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experimental results show substantial improvements over traditional information-retrieval-based baselines, achieving up to 73.3% file mapping accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0106-54ba52842b", "paper_id": "P0106", "bibkey": "Nipane2026Specmap", "title": "SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Traceability Link Recovery in Systems Engineering", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We significantly reduce computational overhead, lowering total LLM token consumption by 84% and end-to-end runtime by approximately 80%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0106-13868c66a7", "paper_id": "P0106", "bibkey": "Nipane2026Specmap", "title": "SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Traceability Link Recovery in Systems Engineering", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Establishing precise traceability between embedded systems datasheets and their corresponding code implementations remains a fundamental challenge in systems engineering, particularly for low-level software where manual mapping between specification documents and large code repositories is infeasible.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0106-10d0014c02", "paper_id": "P0106", "bibkey": "Nipane2026Specmap", "title": "SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Traceability Link Recovery in Systems Engineering", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing Traceability Link Recovery approaches primarily rely on lexical similarity and information retrieval techniques, which struggle to capture the semantic, structural, and symbol level relationships prevalent in embedded systems software.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0106-97e8ca6ced", "paper_id": "P0106", "bibkey": "Nipane2026Specmap", "title": "SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Traceability Link Recovery in Systems Engineering", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present a hierarchical datasheet-to-code mapping methodology that employs large language models for semantic analysis while explicitly structuring the traceability process across multiple abstraction levels.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0106-3d3d34a212", "paper_id": "P0106", "bibkey": "Nipane2026Specmap", "title": "SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Traceability Link Recovery in Systems Engineering", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Rather than performing direct specification-to-code matching, the proposed approach progressively narrows the search space through repository-level structure inference, file-level relevance estimation, and fine-grained symbollevel alignment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0106-1704d89442", "paper_id": "P0106", "bibkey": "Nipane2026Specmap", "title": "SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Traceability Link Recovery in Systems Engineering", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The method extends beyond function-centric mapping by explicitly covering macros, structs, constants, configuration parameters, and register definitions commonly found in systems-level C/C++ codebases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0107-f3960be2ca", "paper_id": "P0107", "bibkey": "Ji2026Taming", "title": "Taming Various Privilege Escalation in LLM-Based Agent Systems: A Mandatory Access Control Framework", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To defend against both known and newly demonstrated privilege escalation, we propose SEAgent, a mandatory access control (MAC) framework built upon attribute-based access control (ABAC).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0107-bd0ad98bfd", "paper_id": "P0107", "bibkey": "Ji2026Taming", "title": "Taming Various Privilege Escalation in LLM-Based Agent Systems: A Mandatory Access Control Framework", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "This demonstrates its robustness and adaptability in securing LLM-based agent systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0107-5384118f56", "paper_id": "P0107", "bibkey": "Ji2026Taming", "title": "Taming Various Privilege Escalation in LLM-Based Agent Systems: A Mandatory Access Control Framework", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM)-based agent systems are increasingly deployed for complex real-world tasks but remain vulnerable to natural language-based attacks that exploit over-privileged tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#summary_bullets[0]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0107-e0b7ea29d0", "paper_id": "P0107", "bibkey": "Ji2026Taming", "title": "Taming Various Privilege Escalation in LLM-Based Agent Systems: A Mandatory Access Control Framework", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper aims to understand and mitigate such attacks through the lens of privilege escalation, defined as agent actions exceeding the least privilege required for a user's intended task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0107-373cd4a19d", "paper_id": "P0107", "bibkey": "Ji2026Taming", "title": "Taming Various Privilege Escalation in LLM-Based Agent Systems: A Mandatory Access Control Framework", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Based on a formal model of LLM agent systems, we identify novel privilege escalation scenarios, particularly in multi-agent systems, including a variant akin to the classic confused deputy problem.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0107-8bfe222a28", "paper_id": "P0107", "bibkey": "Ji2026Taming", "title": "Taming Various Privilege Escalation in LLM-Based Agent Systems: A Mandatory Access Control Framework", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To defend against both known and newly demonstrated privilege escalation, we propose SEAgent, a mandatory access control (MAC) framework built upon attribute-based access control (ABAC).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0107-8df6cee725", "paper_id": "P0107", "bibkey": "Ji2026Taming", "title": "Taming Various Privilege Escalation in LLM-Based Agent Systems: A Mandatory Access Control Framework", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "SEAgent monitors agent-tool interactions via an information flow graph and enforces customizable security policies based on entity attributes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0108-4259f85a98", "paper_id": "P0108", "bibkey": "Li2026Toolprmbench", "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0108-3e2edc05cd", "paper_id": "P0108", "bibkey": "Li2026Toolprmbench", "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0108-9861661010", "paper_id": "P0108", "bibkey": "Li2026Toolprmbench", "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0108-0b3dfdca08", "paper_id": "P0108", "bibkey": "Li2026Toolprmbench", "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reward-guided search methods have demonstrated strong potential in enhancing tool-using agents by effectively guiding sampling and exploration over complex action spaces.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0108-d01a2965cd", "paper_id": "P0108", "bibkey": "Li2026Toolprmbench", "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As a core design, those search methods utilize process reward models (PRMs) to provide step-level rewards, enabling more fine-grained monitoring.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0108-f46a87924a", "paper_id": "P0108", "bibkey": "Li2026Toolprmbench", "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0108-a14c51be8b", "paper_id": "P0108", "bibkey": "Li2026Toolprmbench", "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0108-6cdbd45db3", "paper_id": "P0108", "bibkey": "Li2026Toolprmbench", "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ToolPRMBench is built on top of several representative tool-using benchmarks and converts agent trajectories into step-level test cases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0109-a30ae037f4", "paper_id": "P0109", "bibkey": "Mou2026Toolsafe", "title": "ToolSafe: Enhancing Tool Invocation Safety of LLM-based agents via Proactive Step-level Guardrail and Feedback", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#method"}, "confidence": "medium", "tags": ["memory", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0109-c6a59efa61", "paper_id": "P0109", "bibkey": "Mou2026Toolsafe", "title": "ToolSafe: Enhancing Tool Invocation Safety of LLM-based agents via Proactive Step-level Guardrail and Feedback", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0109-850e7ba79d", "paper_id": "P0109", "bibkey": "Mou2026Toolsafe", "title": "ToolSafe: Enhancing Tool Invocation Safety of LLM-based agents via Proactive Step-level Guardrail and Feedback", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "In this work, we first construct TS-Bench, a novel benchmark for step-level tool invocation safety detection in LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0109-6d43d588b2", "paper_id": "P0109", "bibkey": "Mou2026Toolsafe", "title": "ToolSafe: Enhancing Tool Invocation Safety of LLM-based agents via Proactive Step-level Guardrail and Feedback", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While LLM-based agents can interact with environments via invoking external tools, their expanded capabilities also amplify security risks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0109-02381e3b0f", "paper_id": "P0109", "bibkey": "Mou2026Toolsafe", "title": "ToolSafe: Enhancing Tool Invocation Safety of LLM-based agents via Proactive Step-level Guardrail and Feedback", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Monitoring step-level tool invocation behaviors in real time and proactively intervening before unsafe execution is critical for agent deployment, yet remains under-explored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0109-711e1a71d4", "paper_id": "P0109", "bibkey": "Mou2026Toolsafe", "title": "ToolSafe: Enhancing Tool Invocation Safety of LLM-based agents via Proactive Step-level Guardrail and Feedback", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we first construct TS-Bench, a novel benchmark for step-level tool invocation safety detection in LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0109-4543f0ba60", "paper_id": "P0109", "bibkey": "Mou2026Toolsafe", "title": "ToolSafe: Enhancing Tool Invocation Safety of LLM-based agents via Proactive Step-level Guardrail and Feedback", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We then develop a guardrail model, TS-Guard, using multi-task reinforcement learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#summary_bullets[3]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0109-3563614247", "paper_id": "P0109", "bibkey": "Mou2026Toolsafe", "title": "ToolSafe: Enhancing Tool Invocation Safety of LLM-based agents via Proactive Step-level Guardrail and Feedback", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The model proactively detects unsafe tool invocation actions before execution by reasoning over the interaction history.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0110-3818985b07", "paper_id": "P0110", "bibkey": "Doshi2026Towards", "title": "Towards Verifiably Safe Tool Use for LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose a process that starts with applying System-Theoretic Process Analysis (STPA) to identify hazards in agent workflows, derive safety requirements, and formalize them as enforceable specifications on data flows and tool sequences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0110-7a360a698e", "paper_id": "P0110", "bibkey": "Doshi2026Towards", "title": "Towards Verifiably Safe Tool Use for LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Methods like information flow control (IFC) and temporal constraints aim to provide guarantees but often require extensive human annotation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0110-dab37b0fe2", "paper_id": "P0110", "bibkey": "Doshi2026Towards", "title": "Towards Verifiably Safe Tool Use for LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM)-based AI agents extend LLM capabilities by enabling access to tools such as data sources, APIs, search engines, code sandboxes, and even other agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#summary_bullets[0]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0110-8a1e290622", "paper_id": "P0110", "bibkey": "Doshi2026Towards", "title": "Towards Verifiably Safe Tool Use for LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While this empowers agents to perform complex tasks, LLMs may invoke unintended tool interactions and introduce risks, such as leaking sensitive data or overwriting critical records, which are unacceptable in enterprise contexts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0110-d653bbf935", "paper_id": "P0110", "bibkey": "Doshi2026Towards", "title": "Towards Verifiably Safe Tool Use for LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current approaches to mitigate these risks, such as model-based safeguards, enhance agents' reliability but cannot guarantee system safety.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0110-be35190115", "paper_id": "P0110", "bibkey": "Doshi2026Towards", "title": "Towards Verifiably Safe Tool Use for LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Methods like information flow control (IFC) and temporal constraints aim to provide guarantees but often require extensive human annotation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0110-9623ffb455", "paper_id": "P0110", "bibkey": "Doshi2026Towards", "title": "Towards Verifiably Safe Tool Use for LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose a process that starts with applying System-Theoretic Process Analysis (STPA) to identify hazards in agent workflows, derive safety requirements, and formalize them as enforceable specifications on data flows and tool sequences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0111-61fccaae39", "paper_id": "P0111", "bibkey": "Mell2025Fast", "title": "A Fast, Reliable, and Secure Programming Language for LLM Agents with Code Actions", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose a novel programming language for code actions, called Quasar, which has several benefits: (1) automated parallelization to improve performance, (2) uncertainty quantification to improve reliability and mitigate hallucinations, and (3) security features enabling the user to validate actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#method"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0111-1537ae6d67", "paper_id": "P0111", "bibkey": "Mell2025Fast", "title": "A Fast, Reliable, and Secure Programming Language for LLM Agents with Code Actions", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate our approach on the ViperGPT visual question answering agent, applied to the GQA dataset, demonstrating that LLMs with Quasar actions instead of Python actions retain strong performance, while reducing execution time when possible by 42%, improving security by reducing user approval interactions when possible by 52%, and improving reliability by applying conformal prediction to achieve a desired target coverage level.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0111-62a4ed1ace", "paper_id": "P0111", "bibkey": "Mell2025Fast", "title": "A Fast, Reliable, and Secure Programming Language for LLM Agents with Code Actions", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We propose a novel programming language for code actions, called Quasar, which has several benefits: (1) automated parallelization to improve performance, (2) uncertainty quantification to improve reliability and mitigate hallucinations, and (3) security features enabling the user to validate actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0111-6cc2606291", "paper_id": "P0111", "bibkey": "Mell2025Fast", "title": "A Fast, Reliable, and Secure Programming Language for LLM Agents with Code Actions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Modern large language models (LLMs) are often deployed as agents, calling external tools adaptively to solve tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0111-3feccffbc5", "paper_id": "P0111", "bibkey": "Mell2025Fast", "title": "A Fast, Reliable, and Secure Programming Language for LLM Agents with Code Actions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Rather than directly calling tools, it can be more effective for LLMs to write code to perform the tool calls, enabling them to automatically generate complex control flow such as conditionals and loops.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0111-86db4fcde8", "paper_id": "P0111", "bibkey": "Mell2025Fast", "title": "A Fast, Reliable, and Secure Programming Language for LLM Agents with Code Actions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Such code actions are typically provided as Python code, since LLMs are quite proficient at it; however, Python may not be the ideal language due to limited built-in support for performance, security, and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0111-93c492e2b0", "paper_id": "P0111", "bibkey": "Mell2025Fast", "title": "A Fast, Reliable, and Secure Programming Language for LLM Agents with Code Actions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose a novel programming language for code actions, called Quasar, which has several benefits: (1) automated parallelization to improve performance, (2) uncertainty quantification to improve reliability and mitigate hallucinations, and (3) security features enabling the user to validate actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0111-df7aee32a6", "paper_id": "P0111", "bibkey": "Mell2025Fast", "title": "A Fast, Reliable, and Secure Programming Language for LLM Agents with Code Actions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLMs can write code in a subset of Python, which is automatically transpiled to Quasar.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0112-dda4615952", "paper_id": "P0112", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this issue, we propose a multi-modal and automated scale bar detection and extraction framework that provides concurrent object detection, text detection and text recognition with a Large Language Model (LLM) agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0112-1b9b514b0a", "paper_id": "P0112", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The hybrid OCR system achieved 89% precision, 65% recall, and a 75% F1 score on the Auto-DG dataset, significantly outperforming several mainstream standalone engines, highlighting its reliability for scientific image analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0112-065ba24ce9", "paper_id": "P0112", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The proposed model demonstrates a strong performance in object detection and accurate localization with a precision of 100%, recall of 95.8%, and a mean Average Precision (mAP) of 99.2% at IoU=0.5 and 69.1% at IoU=0.5:0.95.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0112-a1b1baea2e", "paper_id": "P0112", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Microscopic characterizations, such as Scanning Electron Microscopy (SEM), are widely used in scientific research for visualizing and analyzing microstructures.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0112-b0095e0371", "paper_id": "P0112", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Determining the scale bars is an important first step of accurate SEM analysis; however, currently, it mainly relies on manual operations, which is both time-consuming and prone to errors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0112-c7a327bc99", "paper_id": "P0112", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this issue, we propose a multi-modal and automated scale bar detection and extraction framework that provides concurrent object detection, text detection and text recognition with a Large Language Model (LLM) agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0112-53d135ee7f", "paper_id": "P0112", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The proposed framework operates in four phases; i) Automatic Dataset Generation (Auto-DG) model to synthesize a diverse dataset of SEM images ensuring robust training and high generalizability of the model, ii) scale bar object detection, iii) information extraction using a hybrid Optical Character Recognition (OCR) system with DenseNet and Convolutional Recurrent Neural Network (CRNN) based algorithms, iv) an LLM agent to analyze and verify accuracy of the results.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0112-ceadf20bcb", "paper_id": "P0112", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The proposed model demonstrates a strong performance in object detection and accurate localization with a precision of 100%, recall of 95.8%, and a mean Average Precision (mAP) of 99.2% at IoU=0.5 and 69.1% at IoU=0.5:0.95.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0113-e2d0085f84", "paper_id": "P0113", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a task-driven taxonomy encompassing six broad application areas: data extraction, interpretation and Q\\&A; atomistic simulation; property prediction; materials structure, design and discovery; process planning, discovery, and optimization; and multiscale modeling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0113-a68f39bc04", "paper_id": "P0113", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This survey provides a comprehensive overview of foundation models, agentic systems, datasets, and computational tools supporting this growing field.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0113-e012f792c6", "paper_id": "P0113", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Furthermore, we review standardized datasets, open-source tools, and autonomous experimental platforms that collectively fuel the development and integration of FMs into research workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0113-34dbc1be9b", "paper_id": "P0113", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Foundation models (FMs) are catalyzing a transformative shift in materials science (MatSci) by enabling scalable, general-purpose, and multimodal AI systems for scientific discovery.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0113-099d1eaa8f", "paper_id": "P0113", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike traditional machine learning models, which are typically narrow in scope and require task-specific engineering, FMs offer cross-domain generalization and exhibit emergent capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0113-80a53d8d03", "paper_id": "P0113", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Their versatility is especially well-suited to materials science, where research challenges span diverse data types and scales.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0113-29dfc29320", "paper_id": "P0113", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey provides a comprehensive overview of foundation models, agentic systems, datasets, and computational tools supporting this growing field.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0113-e5f06504bd", "paper_id": "P0113", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce a task-driven taxonomy encompassing six broad application areas: data extraction, interpretation and Q\\&A; atomistic simulation; property prediction; materials structure, design and discovery; process planning, discovery, and optimization; and multiscale modeling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0113-7acf4de689", "paper_id": "P0113", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "We assess the early successes of foundation models and identify persistent limitations, including challenges in generalizability, interpretability, data imbalance, safety concerns, and limited multimodal fusion.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0114-b0f9bdaa65", "paper_id": "P0114", "bibkey": "Lidayan2025Abbel", "title": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a general framework for LLM agents to maintain concise contexts through multi-step interaction: Acting through Belief Bottlenecks Expressed in Language (ABBEL), and methods to further improve ABBEL agents with RL post-training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0114-0af79eac07", "paper_id": "P0114", "bibkey": "Lidayan2025Abbel", "title": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments demonstrate the ability of RL to improve ABBEL's performance beyond the full context setting, while using less memory than contemporaneous approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#key_results[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0114-41f7c44c90", "paper_id": "P0114", "bibkey": "Lidayan2025Abbel", "title": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As the length of sequential decision-making tasks increases, it becomes computationally impractical to keep full interaction histories in context.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0114-06f0c88925", "paper_id": "P0114", "bibkey": "Lidayan2025Abbel", "title": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce a general framework for LLM agents to maintain concise contexts through multi-step interaction: Acting through Belief Bottlenecks Expressed in Language (ABBEL), and methods to further improve ABBEL agents with RL post-training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0114-de918dd756", "paper_id": "P0114", "bibkey": "Lidayan2025Abbel", "title": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ABBEL replaces long multi-step interaction history by a belief state, i.e., a natural language summary of what has been discovered about task-relevant unknowns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0114-80462418f8", "paper_id": "P0114", "bibkey": "Lidayan2025Abbel", "title": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Under ABBEL, at each step the agent first updates a prior belief with the most recent observation from the environment to form a posterior belief, then uses only the posterior to select an action.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0114-a6ff0ab506", "paper_id": "P0114", "bibkey": "Lidayan2025Abbel", "title": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We systematically evaluate frontier models under ABBEL across six diverse multi-step environments, finding that ABBEL supports generating interpretable beliefs while maintaining near-constant memory use over interaction steps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0115-7165555871", "paper_id": "P0115", "bibkey": "Kang2025Acon", "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Agent Context Optimization (ACON), a unified framework that optimally compresses both environment observations and interaction histories into concise yet informative condensations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0115-8628272498", "paper_id": "P0115", "bibkey": "Kang2025Acon", "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on AppWorld, OfficeBench, and Multi-objective QA show that ACON reduces memory usage by 26-54% (peak tokens) while largely preserving task performance, preserves over 95% of accuracy when distilled into smaller compressors, and enhances smaller LMs as long-horizon agents with up to 46% performance improvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0115-108346ac22", "paper_id": "P0115", "bibkey": "Kang2025Acon", "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large language models (LLMs) are increasingly deployed as agents in dynamic, real-world environments, where success requires both reasoning and effective tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#key_results[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0115-f12a5fafca", "paper_id": "P0115", "bibkey": "Kang2025Acon", "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are increasingly deployed as agents in dynamic, real-world environments, where success requires both reasoning and effective tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0115-5d195eea5e", "paper_id": "P0115", "bibkey": "Kang2025Acon", "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A central challenge for agentic tasks is the growing context length, as agents must accumulate long histories of actions and observations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0115-7f5cd00b5a", "paper_id": "P0115", "bibkey": "Kang2025Acon", "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This expansion raises costs and reduces efficiency in long-horizon tasks, yet prior work on context compression has mostly focused on single-step tasks or narrow applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0115-dacdc67888", "paper_id": "P0115", "bibkey": "Kang2025Acon", "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Agent Context Optimization (ACON), a unified framework that optimally compresses both environment observations and interaction histories into concise yet informative condensations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0115-26def3943a", "paper_id": "P0115", "bibkey": "Kang2025Acon", "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ACON leverages compression guideline optimization in natural language space: given paired trajectories where full context succeeds but compressed context fails, capable LLMs analyze the causes of failure, and the compression guideline is updated accordingly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0116-b5e7e85f9d", "paper_id": "P0116", "bibkey": "Yao2025Agents", "title": "AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Extensive human expert evaluation demonstrates our framework's ability to accurately adhere to user intent, generating high quality augmented scenarios comparable to those created manually.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0116-d70ef2c75f", "paper_id": "P0116", "bibkey": "Yao2025Agents", "title": "AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Relying solely on real-world driving scenes requires collecting massive datasets to capture these scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0116-78b9ea1065", "paper_id": "P0116", "bibkey": "Yao2025Agents", "title": "AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "An approach that is unable to meet the demands for scale in the evaluation of self-driving systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0116-38d9577160", "paper_id": "P0116", "bibkey": "Yao2025Agents", "title": "AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Rare, yet critical, scenarios pose a significant challenge in testing and evaluating autonomous driving planners.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0116-b89e7a98d0", "paper_id": "P0116", "bibkey": "Yao2025Agents", "title": "AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Relying solely on real-world driving scenes requires collecting massive datasets to capture these scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0116-947904da7f", "paper_id": "P0116", "bibkey": "Yao2025Agents", "title": "AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While automatic generation of traffic scenarios appears promising, data-driven models require extensive training data and often lack fine-grained control over the output.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0116-a0745c204b", "paper_id": "P0116", "bibkey": "Yao2025Agents", "title": "AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Moreover, generating novel scenarios from scratch can introduce a distributional shift from the original training scenes which undermines the validity of evaluations especially for learning-based planners.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0116-f728d6b7bb", "paper_id": "P0116", "bibkey": "Yao2025Agents", "title": "AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To sidestep this, recent work proposes to generate challenging scenarios by augmenting original scenarios from the test set.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0116-61df98360c", "paper_id": "P0116", "bibkey": "Yao2025Agents", "title": "AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Therefore, this paper introduces a novel LLM-agent based framework for augmenting real-world traffic scenarios using natural language descriptions, addressing the limitations of existing methods.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0117-720f073ef2", "paper_id": "P0117", "bibkey": "Luo2025Agrail", "title": "AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose AGrail, a lifelong agent guardrail to enhance LLM agent safety, which features adaptive safety check generation, effective safety check optimization, and tool compatibility and flexibility.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#method"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0117-d90ba36b89", "paper_id": "P0117", "bibkey": "Luo2025Agrail", "title": "AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments demonstrate that AGrail not only achieves strong performance against task-specific and system risks but also exhibits transferability across different LLM agents' tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0117-5b0bc84f31", "paper_id": "P0117", "bibkey": "Luo2025Agrail", "title": "AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid advancements in Large Language Models (LLMs) have enabled their deployment as autonomous agents for handling complex tasks in dynamic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0117-5c5d3f4391", "paper_id": "P0117", "bibkey": "Luo2025Agrail", "title": "AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These LLMs demonstrate strong problem-solving capabilities and adaptability to multifaceted scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0117-a8d810dc96", "paper_id": "P0117", "bibkey": "Luo2025Agrail", "title": "AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, their use as agents also introduces significant risks, including task-specific risks, which are identified by the agent administrator based on the specific task requirements and constraints, and systemic risks, which stem from vulnerabilities in their design or interactions, potentially compromising confidentiality, integrity, or availability (CIA) of information and triggering security risks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0117-6047d9fe0f", "paper_id": "P0117", "bibkey": "Luo2025Agrail", "title": "AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing defense agencies fail to adaptively and effectively mitigate these risks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0117-60555e4218", "paper_id": "P0117", "bibkey": "Luo2025Agrail", "title": "AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose AGrail, a lifelong agent guardrail to enhance LLM agent safety, which features adaptive safety check generation, effective safety check optimization, and tool compatibility and flexibility.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#summary_bullets[4]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0118-71d985298a", "paper_id": "P0118", "bibkey": "Abolnejadian2025Ainsight", "title": "AInsight: Augmenting Expert Decision-Making with On-the-Fly Insights Grounded in Historical Data", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In decision-making conversations, experts must navigate complex choices and make on-the-spot decisions while engaged in conversation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0118-9fabbed24a", "paper_id": "P0118", "bibkey": "Abolnejadian2025Ainsight", "title": "AInsight: Augmenting Expert Decision-Making with On-the-Fly Insights Grounded in Historical Data", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our system continuously listens to the conversation, identifies patient problems and doctor-suggested solutions, and retrieves related data from an embedded dataset, generating concise insights using a pipeline built around a retrieval-based Large Language Model (LLM) agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0118-cfe717be06", "paper_id": "P0118", "bibkey": "Abolnejadian2025Ainsight", "title": "AInsight: Augmenting Expert Decision-Making with On-the-Fly Insights Grounded in Historical Data", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluated the prototype by embedding Health Canada datasets into a vector database and conducting simulated studies using sample doctor-patient dialogues, showing effectiveness but also challenges, setting directions for the next steps of our work.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0118-96caf6ea85", "paper_id": "P0118", "bibkey": "Abolnejadian2025Ainsight", "title": "AInsight: Augmenting Expert Decision-Making with On-the-Fly Insights Grounded in Historical Data", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In decision-making conversations, experts must navigate complex choices and make on-the-spot decisions while engaged in conversation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0118-30dd0dc007", "paper_id": "P0118", "bibkey": "Abolnejadian2025Ainsight", "title": "AInsight: Augmenting Expert Decision-Making with On-the-Fly Insights Grounded in Historical Data", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Although extensive historical data often exists, the real-time nature of these scenarios makes it infeasible for decision-makers to review and leverage relevant information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0118-eb9d312419", "paper_id": "P0118", "bibkey": "Abolnejadian2025Ainsight", "title": "AInsight: Augmenting Expert Decision-Making with On-the-Fly Insights Grounded in Historical Data", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This raises an interesting question: What if experts could utilize relevant past data in real-time decision-making through insights derived from past data?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0118-c1b2d740a5", "paper_id": "P0118", "bibkey": "Abolnejadian2025Ainsight", "title": "AInsight: Augmenting Expert Decision-Making with On-the-Fly Insights Grounded in Historical Data", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To explore this, we implemented a conversational user interface, taking doctor-patient interactions as an example use case.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0118-371246c2af", "paper_id": "P0118", "bibkey": "Abolnejadian2025Ainsight", "title": "AInsight: Augmenting Expert Decision-Making with On-the-Fly Insights Grounded in Historical Data", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our system continuously listens to the conversation, identifies patient problems and doctor-suggested solutions, and retrieves related data from an embedded dataset, generating concise insights using a pipeline built around a retrieval-based Large Language Model (LLM) agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0119-6a2382b553", "paper_id": "P0119", "bibkey": "Tawosi2025Almas", "title": "ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose a vision for ALMAS, an Autonomous LLM-based Multi-Agent Software Engineering framework, which follows the above SDLC philosophy such that it may work within an agile software development team to perform several tasks end-to-end.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0119-9afe0b358b", "paper_id": "P0119", "bibkey": "Tawosi2025Almas", "title": "ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "ALMAS aligns its agents with agile roles, and can be used in a modular fashion to seamlessly integrate with human developers and their development environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0119-c892f342d1", "paper_id": "P0119", "bibkey": "Tawosi2025Almas", "title": "ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Multi-agent Large Language Model (LLM) systems have been leading the way in applied LLM research across a number of fields.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0119-7f0f8f7517", "paper_id": "P0119", "bibkey": "Tawosi2025Almas", "title": "ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "One notable area is software development, where researchers have advanced the automation of code implementation, code testing, code maintenance, inter alia, using LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0119-d15fcbb6d4", "paper_id": "P0119", "bibkey": "Tawosi2025Almas", "title": "ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, software development is a multifaceted environment that extends beyond just code.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0119-e5275d0383", "paper_id": "P0119", "bibkey": "Tawosi2025Almas", "title": "ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As such, a successful LLM system must factor in multiple stages of the software development life-cycle (SDLC).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0119-d3751b498a", "paper_id": "P0119", "bibkey": "Tawosi2025Almas", "title": "ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose a vision for ALMAS, an Autonomous LLM-based Multi-Agent Software Engineering framework, which follows the above SDLC philosophy such that it may work within an agile software development team to perform several tasks end-to-end.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0120-2e27831bd8", "paper_id": "P0120", "bibkey": "Mousist2025Astrea", "title": "ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "This paper presents ASTREA, the first agentic system executed on flight-heritage hardware (TRL 9) for autonomous spacecraft operations, with on-orbit operation aboard the International Space Station (ISS).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#method"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0120-1217ff58cf", "paper_id": "P0120", "bibkey": "Mousist2025Astrea", "title": "ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This paper presents ASTREA, the first agentic system executed on flight-heritage hardware (TRL 9) for autonomous spacecraft operations, with on-orbit operation aboard the International Space Station (ISS).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0120-8c1b8ccb4a", "paper_id": "P0120", "bibkey": "Mousist2025Astrea", "title": "ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents ASTREA, the first agentic system executed on flight-heritage hardware (TRL 9) for autonomous spacecraft operations, with on-orbit operation aboard the International Space Station (ISS).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#summary_bullets[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0120-5fc32de361", "paper_id": "P0120", "bibkey": "Mousist2025Astrea", "title": "ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Using thermal control as a representative use case, we integrate a resource-constrained Large Language Model (LLM) agent with a reinforcement learning controller in an asynchronous architecture tailored for space-qualified platforms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0120-266968ca70", "paper_id": "P0120", "bibkey": "Mousist2025Astrea", "title": "ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Ground experiments show that LLM-guided supervision improves thermal stability and reduces violations, confirming the feasibility of combining semantic reasoning with adaptive control under hardware constraints.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0120-ffe26fe63e", "paper_id": "P0120", "bibkey": "Mousist2025Astrea", "title": "ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "On-orbit validation aboard the ISS initially faced challenges due to inference latency misaligned with the rapid thermal cycles of Low Earth Orbit (LEO) satellites.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0120-54a584fa5e", "paper_id": "P0120", "bibkey": "Mousist2025Astrea", "title": "ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Synchronization with the orbit length successfully surpassed the baseline with reduced violations, extended episode durations, and improved CPU utilization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0121-748c458559", "paper_id": "P0121", "bibkey": "Song2025Agent", "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To this end, we introduce the agent data protocol (ADP), a light-weight representation language that serves as an \"interlingua\" between agent datasets in diverse formats and unified agent training pipelines downstream.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0121-44cc8fbce0", "paper_id": "P0121", "bibkey": "Song2025Agent", "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We performed SFT on these data, and demonstrated an average performance gain of ~20% over corresponding base models, and delivers state-of-the-art or near-SOTA performance on standard coding, browsing, tool use, and research benchmarks, without domain-specific tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0121-c7832ac97d", "paper_id": "P0121", "bibkey": "Song2025Agent", "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In experiments, we unified a broad collection of 13 existing agent training datasets into ADP format, and converted the standardized ADP data into training-ready formats for multiple agent frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0121-4e0011b9d1", "paper_id": "P0121", "bibkey": "Song2025Agent", "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Public research results on large-scale supervised finetuning of AI agents remain relatively rare, since the collection of agent training data presents unique challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0121-de962efdc3", "paper_id": "P0121", "bibkey": "Song2025Agent", "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we argue that the bottleneck is not a lack of underlying data sources, but that a large variety of data is fragmented across heterogeneous formats, tools, and interfaces.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0121-a7fba2f7bd", "paper_id": "P0121", "bibkey": "Song2025Agent", "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To this end, we introduce the agent data protocol (ADP), a light-weight representation language that serves as an \"interlingua\" between agent datasets in diverse formats and unified agent training pipelines downstream.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0121-c30ec00508", "paper_id": "P0121", "bibkey": "Song2025Agent", "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The design of ADP is expressive enough to capture a large variety of tasks, including API/tool use, browsing, coding, software engineering, and general agentic workflows, while remaining simple to parse and train on without engineering at a per-dataset level.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0121-c23634658d", "paper_id": "P0121", "bibkey": "Song2025Agent", "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In experiments, we unified a broad collection of 13 existing agent training datasets into ADP format, and converted the standardized ADP data into training-ready formats for multiple agent frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0122-232d105c9e", "paper_id": "P0122", "bibkey": "Sha2025Agent", "title": "Agent Safety Alignment via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose the first unified safety-alignment framework for tool-using agents, enabling models to handle both channels of threat via structured reasoning and sandboxed reinforcement learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#method"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0122-20fed7f11c", "paper_id": "P0122", "bibkey": "Sha2025Agent", "title": "Agent Safety Alignment via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through extensive evaluations on public and self-built benchmarks, including Agent SafetyBench, InjecAgent, and BFCL, we demonstrate that our safety-aligned agents significantly improve resistance to security threats while preserving strong utility on benign tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0122-eab3e7c194", "paper_id": "P0122", "bibkey": "Sha2025Agent", "title": "Agent Safety Alignment via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The emergence of autonomous Large Language Model (LLM) agents capable of tool usage has introduced new safety risks that go beyond traditional conversational misuse.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0122-27bffbbc82", "paper_id": "P0122", "bibkey": "Sha2025Agent", "title": "Agent Safety Alignment via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These agents, empowered to execute external functions, are vulnerable to both user-initiated threats (e.g., adversarial prompts) and tool-initiated threats (e.g., malicious outputs from compromised tools).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#summary_bullets[1]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0122-80d595c4ca", "paper_id": "P0122", "bibkey": "Sha2025Agent", "title": "Agent Safety Alignment via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose the first unified safety-alignment framework for tool-using agents, enabling models to handle both channels of threat via structured reasoning and sandboxed reinforcement learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#summary_bullets[2]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0122-8f0cc1dcf0", "paper_id": "P0122", "bibkey": "Sha2025Agent", "title": "Agent Safety Alignment via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce a tri-modal taxonomy, including benign, malicious, and sensitive for both user prompts and tool responses, and define a policy-driven decision model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0122-d8c552e7b0", "paper_id": "P0122", "bibkey": "Sha2025Agent", "title": "Agent Safety Alignment via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our framework employs a custom-designed sandbox environment that simulates real-world tool execution and allows fine-grained reward shaping.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#summary_bullets[4]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0123-006ad9b321", "paper_id": "P0123", "bibkey": "Loffredo2025Agent", "title": "Agent-Enhanced Large Language Models for Researching Political Institutions", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To demonstrate the potential of this approach, we introduce CongressRA, an LLM agent designed to support scholars studying the U.S.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0123-21c9e7ad44", "paper_id": "P0123", "bibkey": "Loffredo2025Agent", "title": "Agent-Enhanced Large Language Models for Researching Political Institutions", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through this example, we highlight how LLM agents can reduce the costs of replicating, testing, and extending empirical research using the domain-specific data that drives the study of political institutions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0123-1897573eec", "paper_id": "P0123", "bibkey": "Loffredo2025Agent", "title": "Agent-Enhanced Large Language Models for Researching Political Institutions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The applications of Large Language Models (LLMs) in political science are rapidly expanding.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0123-9d164d3888", "paper_id": "P0123", "bibkey": "Loffredo2025Agent", "title": "Agent-Enhanced Large Language Models for Researching Political Institutions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper demonstrates how LLMs, when augmented with predefined functions and specialized tools, can serve as dynamic agents capable of streamlining tasks such as data collection, preprocessing, and analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0123-07a916953d", "paper_id": "P0123", "bibkey": "Loffredo2025Agent", "title": "Agent-Enhanced Large Language Models for Researching Political Institutions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Central to this approach is agentic retrieval-augmented generation (Agentic RAG), which equips LLMs with action-calling capabilities for interaction with external knowledge bases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0123-f5e144cc1c", "paper_id": "P0123", "bibkey": "Loffredo2025Agent", "title": "Agent-Enhanced Large Language Models for Researching Political Institutions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Beyond information retrieval, LLM agents may incorporate modular tools for tasks like document summarization, transcript coding, qualitative variable classification, and statistical modeling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0123-a12ea1ccf6", "paper_id": "P0123", "bibkey": "Loffredo2025Agent", "title": "Agent-Enhanced Large Language Models for Researching Political Institutions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To demonstrate the potential of this approach, we introduce CongressRA, an LLM agent designed to support scholars studying the U.S.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0124-64407d3670", "paper_id": "P0124", "bibkey": "Cheng2025Agent", "title": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Secondly, we introduce Agent-R1, a modular, flexible, and user-friendly training framework for RL-based LLM Agents, designed for straightforward adaptation across diverse task scenarios and interactive environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0124-459806f5ee", "paper_id": "P0124", "bibkey": "Cheng2025Agent", "title": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We conducted experiments on Multihop QA benchmark tasks, providing initial validation for the effectiveness of our proposed methods and framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0124-7ef16b36af", "paper_id": "P0124", "bibkey": "Cheng2025Agent", "title": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) are increasingly being explored for building Agents capable of active environmental interaction (e.g., via tool use) to solve complex problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0124-20d62d78d4", "paper_id": "P0124", "bibkey": "Cheng2025Agent", "title": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reinforcement Learning (RL) is considered a key technology with significant potential for training such Agents; however, the effective application of RL to LLM Agents is still in its nascent stages and faces considerable challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0124-d1e6d786e3", "paper_id": "P0124", "bibkey": "Cheng2025Agent", "title": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Currently, this emerging field lacks in-depth exploration into RL approaches specifically tailored for the LLM Agent context, alongside a scarcity of flexible and easily extensible training frameworks designed for this purpose.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0124-030720b607", "paper_id": "P0124", "bibkey": "Cheng2025Agent", "title": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To help advance this area, this paper first revisits and clarifies Reinforcement Learning methodologies for LLM Agents by systematically extending the Markov Decision Process (MDP) framework to comprehensively define the key components of an LLM Agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0124-adc9e64316", "paper_id": "P0124", "bibkey": "Cheng2025Agent", "title": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Secondly, we introduce Agent-R1, a modular, flexible, and user-friendly training framework for RL-based LLM Agents, designed for straightforward adaptation across diverse task scenarios and interactive environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0125-bd4c2a4c01", "paper_id": "P0125", "bibkey": "Kulkarni2025Agent", "title": "Agent-S: LLM Agentic workflow to automate Standard Operating Procedures", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose an LLM-based agentic workflow for automating Standard Operating Procedures (SOP).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0125-6dec6b27ee", "paper_id": "P0125", "bibkey": "Kulkarni2025Agent", "title": "Agent-S: LLM Agentic workflow to automate Standard Operating Procedures", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "For customer care operations, an SOP defines a logical step-by-step process for human agents to resolve customer issues.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0125-933d480ea0", "paper_id": "P0125", "bibkey": "Kulkarni2025Agent", "title": "Agent-S: LLM Agentic workflow to automate Standard Operating Procedures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "AI agents using Large Language Models (LLMs) as foundations have shown promise in solving complex real-world tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0125-283b27c846", "paper_id": "P0125", "bibkey": "Kulkarni2025Agent", "title": "Agent-S: LLM Agentic workflow to automate Standard Operating Procedures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose an LLM-based agentic workflow for automating Standard Operating Procedures (SOP).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0125-e4485f250b", "paper_id": "P0125", "bibkey": "Kulkarni2025Agent", "title": "Agent-S: LLM Agentic workflow to automate Standard Operating Procedures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "For customer care operations, an SOP defines a logical step-by-step process for human agents to resolve customer issues.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0125-7f59ebbf1a", "paper_id": "P0125", "bibkey": "Kulkarni2025Agent", "title": "Agent-S: LLM Agentic workflow to automate Standard Operating Procedures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We observe that any step in the SOP can be categorized as user interaction or API call, while the logical flow in the SOP defines the navigation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0125-0f5ef2bb9c", "paper_id": "P0125", "bibkey": "Kulkarni2025Agent", "title": "Agent-S: LLM Agentic workflow to automate Standard Operating Procedures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We use LLMs augmented with memory and environments (API tools, user interface, external knowledge source) for SOP automation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0126-01a0700f8e", "paper_id": "P0126", "bibkey": "Cui2025Agentdns", "title": "AgentDNS: A Root Domain Naming System for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose AgentDNS, a root domain naming and service discovery system designed to enable LLM agents to autonomously discover, resolve, and securely invoke third-party agent and tool services across organizational and technological boundaries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0126-ba22992f5e", "paper_id": "P0126", "bibkey": "Cui2025Agentdns", "title": "AgentDNS: A Root Domain Naming System for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The source code will be published on https://github.com/agentdns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0126-2c001052e7", "paper_id": "P0126", "bibkey": "Cui2025Agentdns", "title": "AgentDNS: A Root Domain Naming System for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid evolution of Large Language Model (LLM) agents has highlighted critical challenges in cross-vendor service discovery, interoperability, and communication.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0126-5cf6222d40", "paper_id": "P0126", "bibkey": "Cui2025Agentdns", "title": "AgentDNS: A Root Domain Naming System for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing protocols like model context protocol and agent-to-agent protocol have made significant strides in standardizing interoperability between agents and tools, as well as communication among multi-agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0126-c2ae36f609", "paper_id": "P0126", "bibkey": "Cui2025Agentdns", "title": "AgentDNS: A Root Domain Naming System for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, there remains a lack of standardized protocols and solutions for service discovery across different agent and tool vendors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0126-0f7ac62360", "paper_id": "P0126", "bibkey": "Cui2025Agentdns", "title": "AgentDNS: A Root Domain Naming System for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose AgentDNS, a root domain naming and service discovery system designed to enable LLM agents to autonomously discover, resolve, and securely invoke third-party agent and tool services across organizational and technological boundaries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0126-05dc33af2c", "paper_id": "P0126", "bibkey": "Cui2025Agentdns", "title": "AgentDNS: A Root Domain Naming System for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Inspired by the principles of the traditional DNS, AgentDNS introduces a structured mechanism for service registration, semantic service discovery, secure invocation, and unified billing.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0127-1355c1ade0", "paper_id": "P0127", "bibkey": "Horovicz2025Agentshap", "title": "AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce AgentSHAP, the first framework for explaining tool importance in LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0127-e9686e9095", "paper_id": "P0127", "bibkey": "Horovicz2025Agentshap", "title": "AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our contributions are: (1) the first explainability method for agent tool attribution, grounded in Shapley values from game theory; (2) Monte Carlo sampling that reduces cost from O(2n) to practical levels; and (3) comprehensive experiments on API-Bank showing that AgentSHAP produces consistent scores across runs, correctly identifies which tools matter, and distinguishes relevant from irrelevant tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0127-666cd64891", "paper_id": "P0127", "bibkey": "Horovicz2025Agentshap", "title": "AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM agents that use external tools can solve complex tasks, but understanding which tools actually contributed to a response remains a blind spot.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0127-fb83d2e00f", "paper_id": "P0127", "bibkey": "Horovicz2025Agentshap", "title": "AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "No existing XAI methods address tool-level explanations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0127-ab8125783d", "paper_id": "P0127", "bibkey": "Horovicz2025Agentshap", "title": "AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce AgentSHAP, the first framework for explaining tool importance in LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0127-86b3f2d170", "paper_id": "P0127", "bibkey": "Horovicz2025Agentshap", "title": "AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "AgentSHAP is model-agnostic: it treats the agent as a black box and works with any LLM (GPT, Claude, Llama, etc.) without needing access to internal weights or gradients.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0127-3b99841db0", "paper_id": "P0127", "bibkey": "Horovicz2025Agentshap", "title": "AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Using Monte Carlo Shapley values, AgentSHAP tests how an agent responds with different tool subsets and computes fair importance scores based on game theory.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0128-a565550b5e", "paper_id": "P0128", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we propose AgentSwift, a novel framework for automated agent design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0128-904ba35500", "paper_id": "P0128", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\\% over both existing automated agent search methods and manually designed agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0128-9d669c9af7", "paper_id": "P0128", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Current automated agent design approaches are often constrained by limited search spaces that primarily optimize workflows but fail to integrate crucial human-designed components like memory, planning, and tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#key_results[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0128-3b666704bd", "paper_id": "P0128", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents have demonstrated strong capabilities across diverse domains, yet automated agent design remains a significant challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0128-5631a9e933", "paper_id": "P0128", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current automated agent design approaches are often constrained by limited search spaces that primarily optimize workflows but fail to integrate crucial human-designed components like memory, planning, and tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0128-7fa82de592", "paper_id": "P0128", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Furthermore, these methods are hampered by high evaluation costs, as evaluating even a single new agent on a benchmark can require tens of dollars.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0128-d01f35a38b", "paper_id": "P0128", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The difficulty of this exploration is further exacerbated by inefficient search strategies that struggle to navigate the large design space effectively, making the discovery of novel agents a slow and resource-intensive process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0128-c66133f1cc", "paper_id": "P0128", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these challenges, we propose AgentSwift, a novel framework for automated agent design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0129-890295afd8", "paper_id": "P0129", "bibkey": "Tu2025Agentic", "title": "Agentic Program Verification", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we present a first LLM agent, AutoRocq, for conducting program verification.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0129-1c8de134c2", "paper_id": "P0129", "bibkey": "Tu2025Agentic", "title": "Agentic Program Verification", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experimental evaluation on SV-COMP benchmarks and on Linux kernel modules shows promising efficacy in achieving automated program verification.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0129-8f45a926f8", "paper_id": "P0129", "bibkey": "Tu2025Agentic", "title": "Agentic Program Verification", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Automatically generated code is gaining traction recently, owing to the prevalence of Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0129-4c37655193", "paper_id": "P0129", "bibkey": "Tu2025Agentic", "title": "Agentic Program Verification", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Further, the AlphaProof initiative has demonstrated the possibility of using AI for general mathematical reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0129-10f9de3dee", "paper_id": "P0129", "bibkey": "Tu2025Agentic", "title": "Agentic Program Verification", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reasoning about computer programs (software) can be accomplished via general mathematical reasoning; however, it tends to be more structured and richer in contexts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0129-5fb5885bcb", "paper_id": "P0129", "bibkey": "Tu2025Agentic", "title": "Agentic Program Verification", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This forms an attractive proposition, since then AI agents can be used to reason about voluminous code that gets generated by AI.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0129-d870db3fb0", "paper_id": "P0129", "bibkey": "Tu2025Agentic", "title": "Agentic Program Verification", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we present a first LLM agent, AutoRocq, for conducting program verification.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0130-dac95cdbce", "paper_id": "P0130", "bibkey": "Wu2025Agentic", "title": "Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Agentic Reasoning, a framework that enhances large language model (LLM) reasoning by integrating external tool-using agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0130-d25c02babe", "paper_id": "P0130", "bibkey": "Wu2025Agentic", "title": "Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "When deployed on DeepSeek-R1, our method achieves a new state-of-the-art (SOTA) among public models and delivers performance comparable to OpenAI Deep Research, the leading proprietary model in this domain.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0130-4096e01329", "paper_id": "P0130", "bibkey": "Wu2025Agentic", "title": "Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Agentic Reasoning, a framework that enhances large language model (LLM) reasoning by integrating external tool-using agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0130-3afec4c535", "paper_id": "P0130", "bibkey": "Wu2025Agentic", "title": "Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agentic Reasoning dynamically leverages web search, code execution, and structured memory to address complex problems requiring deep research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0130-055fef6a8b", "paper_id": "P0130", "bibkey": "Wu2025Agentic", "title": "Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A key innovation in our framework is the Mind-Map agent, which constructs a structured knowledge graph to store reasoning context and track logical relationships, ensuring coherence in long reasoning chains with extensive tool usage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0130-7660f47595", "paper_id": "P0130", "bibkey": "Wu2025Agentic", "title": "Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Additionally, we conduct a comprehensive exploration of the Web-Search agent, leading to a highly effective search mechanism that surpasses all prior approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0130-a3ecc6efc4", "paper_id": "P0130", "bibkey": "Wu2025Agentic", "title": "Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "When deployed on DeepSeek-R1, our method achieves a new state-of-the-art (SOTA) among public models and delivers performance comparable to OpenAI Deep Research, the leading proprietary model in this domain.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0131-d0a861c27d", "paper_id": "P0131", "bibkey": "Koubaa2025Agentic", "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Unmanned Aerial Vehicles (UAVs) are increasingly used in defense, surveillance, and disaster response, yet most systems still operate at SAE Level 2 to 3 autonomy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#method"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0131-02eb45e937", "paper_id": "P0131", "bibkey": "Koubaa2025Agentic", "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In simulated search-and-rescue scenarios, agentic UAVs achieved higher detection confidence (0.79 compared to 0.72), improved person detection rates (91% compared to 75%), and a major increase in correct action recommendations (92% compared to 4.5%).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0131-8e39e9502f", "paper_id": "P0131", "bibkey": "Koubaa2025Agentic", "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Unmanned Aerial Vehicles (UAVs) are increasingly used in defense, surveillance, and disaster response, yet most systems still operate at SAE Level 2 to 3 autonomy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0131-35f944f4f0", "paper_id": "P0131", "bibkey": "Koubaa2025Agentic", "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unmanned Aerial Vehicles (UAVs) are increasingly used in defense, surveillance, and disaster response, yet most systems still operate at SAE Level 2 to 3 autonomy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#summary_bullets[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0131-7a8b3388d6", "paper_id": "P0131", "bibkey": "Koubaa2025Agentic", "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Their dependence on rule-based control and narrow AI limits adaptability in dynamic and uncertain missions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0131-03780b49f3", "paper_id": "P0131", "bibkey": "Koubaa2025Agentic", "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current UAV architectures lack context-aware reasoning, autonomous decision-making, and integration with external systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0131-417713b664", "paper_id": "P0131", "bibkey": "Koubaa2025Agentic", "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Importantly, none make use of Large Language Model (LLM) agents with tool-calling for real-time knowledge access.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0131-a3198b4477", "paper_id": "P0131", "bibkey": "Koubaa2025Agentic", "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper introduces the Agentic UAVs framework, a five-layer architecture consisting of Perception, Reasoning, Action, Integration, and Learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0132-4ef4e06ede", "paper_id": "P0132", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose HexMachina, a continual learning multi-agent system that separates environment discovery (inducing an adapter layer without documentation) from strategy improvement (evolving a compiled player through code refinement and simulation).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0132-7929ef7a56", "paper_id": "P0132", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In controlled Catanatron experiments, HexMachina learns from scratch and evolves players that outperform the strongest human-crafted baseline (AlphaBeta), achieving a 54% win rate and surpassing prompt-driven and no-discovery baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0132-eae2720c71", "paper_id": "P0132", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Settlers of Catan provides a challenging benchmark: success depends on balancing short- and long-term goals amid randomness, trading, expansion, and blocking.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0132-c9e00a13bf", "paper_id": "P0132", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We address the long-horizon gap in large language model (LLM) agents by enabling them to sustain coherent strategies in adversarial, stochastic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0132-cecd47b994", "paper_id": "P0132", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Settlers of Catan provides a challenging benchmark: success depends on balancing short- and long-term goals amid randomness, trading, expansion, and blocking.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0132-ab714c0ab3", "paper_id": "P0132", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Prompt-centric LLM agents (e.g., ReAct, Reflexion) must re-interpret large, evolving game states each turn, quickly saturating context windows and losing strategic consistency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0132-9ae0223c4b", "paper_id": "P0132", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose HexMachina, a continual learning multi-agent system that separates environment discovery (inducing an adapter layer without documentation) from strategy improvement (evolving a compiled player through code refinement and simulation).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0132-5fb8c3f637", "paper_id": "P0132", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This design preserves executable artifacts, allowing the LLM to focus on high-level strategy rather than per-turn reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0133-c074d67e76", "paper_id": "P0133", "bibkey": "nl2025Auditable", "title": "An Auditable Agent Platform For Automated Molecular Optimisation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Drug discovery frequently loses momentum when data, expertise, and tools are scattered, slowing design cycles.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0133-b33e217125", "paper_id": "P0133", "bibkey": "nl2025Auditable", "title": "An Auditable Agent Platform For Automated Molecular Optimisation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "After ranking the models by mean docking score, we ran 20 independent scale ups on the two top performers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0133-4a1af65aa3", "paper_id": "P0133", "bibkey": "nl2025Auditable", "title": "An Auditable Agent Platform For Automated Molecular Optimisation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results reveal an architectural trade off, the multi agent setting excelled at focused binding optimization, improving average predicted binding affinity by 31%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0133-a6b8eb9ff2", "paper_id": "P0133", "bibkey": "nl2025Auditable", "title": "An Auditable Agent Platform For Automated Molecular Optimisation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Drug discovery frequently loses momentum when data, expertise, and tools are scattered, slowing design cycles.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0133-6c8b8526ac", "paper_id": "P0133", "bibkey": "nl2025Auditable", "title": "An Auditable Agent Platform For Automated Molecular Optimisation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To shorten this loop we built a hierarchical, tool using agent framework that automates molecular optimisation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0133-3358267c29", "paper_id": "P0133", "bibkey": "nl2025Auditable", "title": "An Auditable Agent Platform For Automated Molecular Optimisation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A Principal Researcher defines each objective, a Database agent retrieves target information, an AI Expert generates de novo scaffolds with a sequence to molecule deep learning model, a Medicinal Chemist edits them while invoking a docking tool, a Ranking agent scores the candidates, and a Scientific Critic polices the logic.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0133-08ba5805d3", "paper_id": "P0133", "bibkey": "nl2025Auditable", "title": "An Auditable Agent Platform For Automated Molecular Optimisation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Each tool call is summarised and stored causing the full reasoning path to remain inspectable.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0133-cfa9db2ff9", "paper_id": "P0133", "bibkey": "nl2025Auditable", "title": "An Auditable Agent Platform For Automated Molecular Optimisation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The agents communicate through concise provenance records that capture molecular lineage, to build auditable, molecule centered reasoning trajectories and reuse successful transformations via in context learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0134-50daa6f4f6", "paper_id": "P0134", "bibkey": "GoganiKhiabani2025Agentic", "title": "An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present an agentic approach for developing legal-critical software, using U.S.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0134-6a9440e737", "paper_id": "P0134", "bibkey": "GoganiKhiabani2025Agentic", "title": "An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In experiments, our framework using a smaller model (GPT-4o-mini) achieves a worst-case pass rate of 45%, outperforming frontier models (GPT-4o and Claude 3.5, 9-15%) on complex tax-code tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0134-bc35dd0f15", "paper_id": "P0134", "bibkey": "GoganiKhiabani2025Agentic", "title": "An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) show promise for translating natural-language statutes into executable logic, but reliability in legally critical settings remains challenging due to ambiguity and hallucinations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0134-bd6ca49492", "paper_id": "P0134", "bibkey": "GoganiKhiabani2025Agentic", "title": "An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present an agentic approach for developing legal-critical software, using U.S.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0134-c6d93432ca", "paper_id": "P0134", "bibkey": "GoganiKhiabani2025Agentic", "title": "An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "federal tax preparation as a case study.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0134-b301d2c908", "paper_id": "P0134", "bibkey": "GoganiKhiabani2025Agentic", "title": "An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The key challenge is test-case generation under the oracle problem, where correct outputs require interpreting law.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0134-6e90c12fde", "paper_id": "P0134", "bibkey": "GoganiKhiabani2025Agentic", "title": "An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Building on metamorphic testing, we introduce higher-order metamorphic relations that compare system outputs across structured shifts among similar individuals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0135-dc6bc1c562", "paper_id": "P0135", "bibkey": "Duan2025Clarify", "title": "Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0135-40579bfa15", "paper_id": "P0135", "bibkey": "Duan2025Clarify", "title": "Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0135-1e8c48bc63", "paper_id": "P0135", "bibkey": "Duan2025Clarify", "title": "Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned \"digital twin\" of a boundedly rational manager that enables scalable, reproducible stress-testing.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0135-78daf67872", "paper_id": "P0135", "bibkey": "Duan2025Clarify", "title": "Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0135-a5f419675d", "paper_id": "P0135", "bibkey": "Duan2025Clarify", "title": "Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper investigates whether Large Language Models (LLMs) can help bridge this gap.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0135-0608e5eeaa", "paper_id": "P0135", "bibkey": "Duan2025Clarify", "title": "Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We show that employing LLMs as direct, end-to-end solvers incurs a significant \"hallucination tax\": a performance gap arising from the model's inability to perform grounded stochastic reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0135-ab315942f2", "paper_id": "P0135", "bibkey": "Duan2025Clarify", "title": "Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0135-f5774f856a", "paper_id": "P0135", "bibkey": "Duan2025Clarify", "title": "Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0136-a40f113c0a", "paper_id": "P0136", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To demonstrate and exploit this vulnerability, we propose the Attractive Metadata Attack (AMA), a black-box in-context learning framework that generates highly attractive but syntactically and semantically valid tool metadata through iterative optimization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#method"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0136-a0b404d928", "paper_id": "P0136", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments across ten realistic, simulated tool-use scenarios and a range of popular LLM agents demonstrate consistently high attack success rates (81\\%-95\\%) and significant privacy leakage, with negligible impact on primary task execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "security", "tooling"]}
{"evidence_id": "E-P0136-00dc8ff622", "paper_id": "P0136", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents have demonstrated remarkable capabilities in complex reasoning and decision-making by leveraging external tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0136-38b7cc5d37", "paper_id": "P0136", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, this tool-centric paradigm introduces a previously underexplored attack surface, where adversaries can manipulate tool metadata -- such as names, descriptions, and parameter schemas -- to influence agent behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#summary_bullets[1]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0136-b47df2ba00", "paper_id": "P0136", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We identify this as a new and stealthy threat surface that allows malicious tools to be preferentially selected by LLM agents, without requiring prompt injection or access to model internals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#summary_bullets[2]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0136-aba55adbcb", "paper_id": "P0136", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To demonstrate and exploit this vulnerability, we propose the Attractive Metadata Attack (AMA), a black-box in-context learning framework that generates highly attractive but syntactically and semantically valid tool metadata through iterative optimization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#summary_bullets[3]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0136-46859b3993", "paper_id": "P0136", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The proposed attack integrates seamlessly into standard tool ecosystems and requires no modification to the agent's execution framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#summary_bullets[4]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0137-9fe7cff3bf", "paper_id": "P0137", "bibkey": "Martin2025Autoodd", "title": "AutoODD: Agentic Audits via Bayesian Red Teaming in Black-Box Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To alleviate this, we introduce \\coolname, an LLM-Agent centric framework for automated generation of semantically relevant test cases to search for failure modes in specialized black-box models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0137-ae085bd2c6", "paper_id": "P0137", "bibkey": "Martin2025Autoodd", "title": "AutoODD: Agentic Audits via Bayesian Red Teaming in Black-Box Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, given the high-dimensional input spaces, this process often requires significant human resources and domain expertise.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0137-88081e54fd", "paper_id": "P0137", "bibkey": "Martin2025Autoodd", "title": "AutoODD: Agentic Audits via Bayesian Red Teaming in Black-Box Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We demonstrate this process in a simple case using models trained with missing digits on the MNIST dataset and in the real world setting of vision-based intruder detection for aerial vehicles.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0137-db4e79eafb", "paper_id": "P0137", "bibkey": "Martin2025Autoodd", "title": "AutoODD: Agentic Audits via Bayesian Red Teaming in Black-Box Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Specialized machine learning models, regardless of architecture and training, are susceptible to failures in deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0137-1d63fae407", "paper_id": "P0137", "bibkey": "Martin2025Autoodd", "title": "AutoODD: Agentic Audits via Bayesian Red Teaming in Black-Box Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With their increasing use in high risk situations, the ability to audit these models by determining their operational design domain (ODD) is crucial in ensuring safety and compliance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0137-1f29167804", "paper_id": "P0137", "bibkey": "Martin2025Autoodd", "title": "AutoODD: Agentic Audits via Bayesian Red Teaming in Black-Box Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, given the high-dimensional input spaces, this process often requires significant human resources and domain expertise.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0137-52540a791f", "paper_id": "P0137", "bibkey": "Martin2025Autoodd", "title": "AutoODD: Agentic Audits via Bayesian Red Teaming in Black-Box Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To alleviate this, we introduce \\coolname, an LLM-Agent centric framework for automated generation of semantically relevant test cases to search for failure modes in specialized black-box models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0137-492afbc695", "paper_id": "P0137", "bibkey": "Martin2025Autoodd", "title": "AutoODD: Agentic Audits via Bayesian Red Teaming in Black-Box Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By leveraging LLM-Agents as tool orchestrators, we aim to fit a uncertainty-aware failure distribution model on a learned text-embedding manifold by projecting the high-dimension input space to low-dimension text-embedding latent space.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0138-f6681abfd4", "paper_id": "P0138", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "A recent area of increasing research is the use of Large Language Models (LLMs) in penetration testing, which promises to reduce costs and thus allow for higher frequency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0138-7e9d7616ab", "paper_id": "P0138", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Both approaches are able to complete 15-25 % of the subtasks on the HTB machines, with AutoPentest slightly outperforming ChatGPT.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0138-89865e4c80", "paper_id": "P0138", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We measure a total cost of \\$96.20 US when using AutoPentest across all experiments, while a one-month subscription to ChatGPT Plus costs \\$20.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0138-b543eff594", "paper_id": "P0138", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A recent area of increasing research is the use of Large Language Models (LLMs) in penetration testing, which promises to reduce costs and thus allow for higher frequency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0138-3dc72e8dbb", "paper_id": "P0138", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We conduct a review of related work, identifying best practices and common evaluation issues.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0138-4d926d8b04", "paper_id": "P0138", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We then present AutoPentest, an application for performing black-box penetration tests with a high degree of autonomy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0138-411467c5dc", "paper_id": "P0138", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "AutoPentest is based on the LLM GPT-4o from OpenAI and the LLM agent framework LangChain.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0138-42e8547e71", "paper_id": "P0138", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It can perform complex multi-step tasks, augmented by external tools and knowledge bases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0139-5a4cc2957d", "paper_id": "P0139", "bibkey": "Ginige2025Autopentester", "title": "AutoPentester: An LLM Agent-based Framework for Automated Pentesting", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To this end, we propose a novel LLM agent-based framework, AutoPentester, which automates the pentesting process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0139-c2d3c6e21c", "paper_id": "P0139", "bibkey": "Ginige2025Autopentester", "title": "AutoPentester: An LLM Agent-based Framework for Automated Pentesting", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Results show that AutoPentester achieves a 27.0% better subtask completion rate and 39.5% more vulnerability coverage with fewer steps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers", "security"]}
{"evidence_id": "E-P0139-4a265106aa", "paper_id": "P0139", "bibkey": "Ginige2025Autopentester", "title": "AutoPentester: An LLM Agent-based Framework for Automated Pentesting", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On average, AutoPentester received a score of 3.93 out of 5 based on user reviews, which was 19.8% higher than PentestGPT.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0139-8dd4512d1f", "paper_id": "P0139", "bibkey": "Ginige2025Autopentester", "title": "AutoPentester: An LLM Agent-based Framework for Automated Pentesting", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Penetration testing and vulnerability assessment are essential industry practices for safeguarding computer systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0139-0788aedb1b", "paper_id": "P0139", "bibkey": "Ginige2025Autopentester", "title": "AutoPentester: An LLM Agent-based Framework for Automated Pentesting", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As cyber threats grow in scale and complexity, the demand for pentesting has surged, surpassing the capacity of human professionals to meet it effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0139-55d7c5c9a9", "paper_id": "P0139", "bibkey": "Ginige2025Autopentester", "title": "AutoPentester: An LLM Agent-based Framework for Automated Pentesting", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With advances in AI, particularly Large Language Models (LLMs), there have been attempts to automate the pentesting process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0139-439f9fc629", "paper_id": "P0139", "bibkey": "Ginige2025Autopentester", "title": "AutoPentester: An LLM Agent-based Framework for Automated Pentesting", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing tools such as PentestGPT are still semi-manual, requiring significant professional human interaction to conduct pentests.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0139-b45785a162", "paper_id": "P0139", "bibkey": "Ginige2025Autopentester", "title": "AutoPentester: An LLM Agent-based Framework for Automated Pentesting", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To this end, we propose a novel LLM agent-based framework, AutoPentester, which automates the pentesting process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0140-0a6bcfbb77", "paper_id": "P0140", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this study, we propose an innovative pipeline utilizing Large Language Model (LLM) agents to automate data-driven modeling and analysis, with a particular emphasis on regression tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0140-5da77482d9", "paper_id": "P0140", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We validate our approach using a critical heat flux (CHF) prediction benchmark, involving approximately 25,000 experimental data points from the OECD/NEA benchmark dataset.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0140-c2a5689efc", "paper_id": "P0140", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Results indicate that our LLM-agent-developed model surpasses traditional CHF lookup tables and delivers predictive accuracy and UQ on par with state-of-the-art Bayesian optimized deep neural network models developed by human experts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0140-5a5e822b1f", "paper_id": "P0140", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Modern engineering increasingly relies on vast datasets generated by experiments and simulations, driving a growing demand for efficient, reliable, and broadly applicable modeling strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0140-c68a10fc29", "paper_id": "P0140", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "There is also heightened interest in developing data-driven approaches, particularly neural network models, for effective prediction and analysis of scientific datasets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0140-4ac701e24b", "paper_id": "P0140", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional data-driven methods frequently involve extensive manual intervention, limiting their ability to scale effectively and generalize to diverse applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0140-d996fad7c9", "paper_id": "P0140", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this study, we propose an innovative pipeline utilizing Large Language Model (LLM) agents to automate data-driven modeling and analysis, with a particular emphasis on regression tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0140-277b996d9c", "paper_id": "P0140", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluate two LLM-agent frameworks: a multi-agent system featuring specialized collaborative agents, and a single-agent system based on the Reasoning and Acting (ReAct) paradigm.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0141-63d4fd2153", "paper_id": "P0141", "bibkey": "GendreauDistler2025Automating", "title": "Automating High Energy Physics Data Analysis with LLM-Powered Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present a proof-of-principle study demonstrating the use of large language model (LLM) agents to automate a representative high energy physics (HEP) analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0141-fad03785c5", "paper_id": "P0141", "bibkey": "GendreauDistler2025Automating", "title": "Automating High Energy Physics Data Analysis with LLM-Powered Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To characterize variability across architectures, we benchmark a representative selection of state-of-the-art LLMs spanning the Gemini and GPT-5 series, the Claude family, and leading open-weight models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0141-2f415ec90c", "paper_id": "P0141", "bibkey": "GendreauDistler2025Automating", "title": "Automating High Energy Physics Data Analysis with LLM-Powered Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This work was accepted as a poster at the Machine Learning and the Physical Sciences (ML4PS) workshop at NeurIPS 2025.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0141-4ac17770b9", "paper_id": "P0141", "bibkey": "GendreauDistler2025Automating", "title": "Automating High Energy Physics Data Analysis with LLM-Powered Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present a proof-of-principle study demonstrating the use of large language model (LLM) agents to automate a representative high energy physics (HEP) analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0141-b9d637281c", "paper_id": "P0141", "bibkey": "GendreauDistler2025Automating", "title": "Automating High Energy Physics Data Analysis with LLM-Powered Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Using the Higgs boson diphoton cross-section measurement as a case study with ATLAS Open Data, we design a hybrid system that combines an LLM-based supervisor-coder agent with the Snakemake workflow manager.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0141-7f1e93156a", "paper_id": "P0141", "bibkey": "GendreauDistler2025Automating", "title": "Automating High Energy Physics Data Analysis with LLM-Powered Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this architecture, the workflow manager enforces reproducibility and determinism, while the agent autonomously generates, executes, and iteratively corrects analysis code in response to user instructions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0141-e92736c177", "paper_id": "P0141", "bibkey": "GendreauDistler2025Automating", "title": "Automating High Energy Physics Data Analysis with LLM-Powered Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We define quantitative evaluation metrics including success rate, error distribution, costs per specific task, and average number of API calls, to assess agent performance across multi-stage workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0141-3f3355df5e", "paper_id": "P0141", "bibkey": "GendreauDistler2025Automating", "title": "Automating High Energy Physics Data Analysis with LLM-Powered Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To characterize variability across architectures, we benchmark a representative selection of state-of-the-art LLMs spanning the Gemini and GPT-5 series, the Claude family, and leading open-weight models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0141-d7508ee416", "paper_id": "P0141", "bibkey": "GendreauDistler2025Automating", "title": "Automating High Energy Physics Data Analysis with LLM-Powered Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "This study establishes the first LLM-agent-driven automated data-analysis framework in HEP, enabling systematic benchmarking of model capabilities, stability, and limitations in real-world scientific computing environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#limitations[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0142-9c4389e8f6", "paper_id": "P0142", "bibkey": "Zhao2025Autonomous", "title": "Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused Ultrasound Ablation Surgery", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce FUAS-Agents, an autonomous agent system that leverages the multimodal understanding and tool-using capabilities of large language models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#method"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0142-c518e51f4c", "paper_id": "P0142", "bibkey": "Zhao2025Autonomous", "title": "Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused Ultrasound Ablation Surgery", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Human assessment by four senior FUAS experts indicates that 82.5%, 82.5%, 87.5%, and 97.5% of the generated plans were rated 4 or above (on a 5-point scale) in terms of completeness, accuracy, fluency, and clinical compliance, respectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0142-d073304a30", "paper_id": "P0142", "bibkey": "Zhao2025Autonomous", "title": "Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused Ultrasound Ablation Surgery", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Focused Ultrasound Ablation Surgery (FUAS) has emerged as a promising non-invasive therapeutic modality, valued for its safety and precision.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0142-dd7cf953e0", "paper_id": "P0142", "bibkey": "Zhao2025Autonomous", "title": "Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused Ultrasound Ablation Surgery", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Nevertheless, its clinical implementation entails intricate tasks such as multimodal image interpretation, personalized dose planning, and real-time intraoperative decision-making processes that demand intelligent assistance to improve efficiency and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0142-9b7bfc4397", "paper_id": "P0142", "bibkey": "Zhao2025Autonomous", "title": "Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused Ultrasound Ablation Surgery", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce FUAS-Agents, an autonomous agent system that leverages the multimodal understanding and tool-using capabilities of large language models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0142-2c6648bf0d", "paper_id": "P0142", "bibkey": "Zhao2025Autonomous", "title": "Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused Ultrasound Ablation Surgery", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By integrating patient profiles and MRI data, FUAS-Agents orchestrates a suite of specialized medical AI tools, including segmentation, treatment dose prediction, and clinical guideline retrieval, to generate personalized treatment plans comprising MRI image, dose parameters, and therapeutic strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0142-bbad95a2f2", "paper_id": "P0142", "bibkey": "Zhao2025Autonomous", "title": "Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused Ultrasound Ablation Surgery", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluate the system in a uterine fibroid treatment scenario.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0143-2c680f4a5b", "paper_id": "P0143", "bibkey": "Yang2025Bioverge", "title": "BioVerge: A Comprehensive Benchmark and Study of Self-Evaluating Agents for Biomedical Hypothesis Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this, we introduce BioVerge, a comprehensive benchmark, and BioVerge Agent, an LLM-based agent framework, to create a standardized environment for exploring biomedical hypothesis generation at the frontier of existing scientific knowledge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0143-fa93c04884", "paper_id": "P0143", "bibkey": "Yang2025Bioverge", "title": "BioVerge: A Comprehensive Benchmark and Study of Self-Evaluating Agents for Biomedical Hypothesis Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through extensive experimentation, we uncover key insights: 1) different architectures of BioVerge Agent influence exploration diversity and reasoning strategies; 2) structured and textual information sources each provide unique, critical contexts that enhance hypothesis generation; and 3) self-evaluation significantly improves the novelty and relevance of proposed hypotheses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0143-6c00a8fc63", "paper_id": "P0143", "bibkey": "Yang2025Bioverge", "title": "BioVerge: A Comprehensive Benchmark and Study of Self-Evaluating Agents for Biomedical Hypothesis Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, their application to biomedical hypothesis generation has been limited by the absence of standardized datasets and execution environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0143-32dd339a49", "paper_id": "P0143", "bibkey": "Yang2025Bioverge", "title": "BioVerge: A Comprehensive Benchmark and Study of Self-Evaluating Agents for Biomedical Hypothesis Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Hypothesis generation in biomedical research has traditionally centered on uncovering hidden relationships within vast scientific literature, often using methods like Literature-Based Discovery (LBD).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0143-b34dd086c0", "paper_id": "P0143", "bibkey": "Yang2025Bioverge", "title": "BioVerge: A Comprehensive Benchmark and Study of Self-Evaluating Agents for Biomedical Hypothesis Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite progress, current approaches typically depend on single data types or predefined extraction patterns, which restricts the discovery of novel and complex connections.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0143-5b8b4fc40d", "paper_id": "P0143", "bibkey": "Yang2025Bioverge", "title": "BioVerge: A Comprehensive Benchmark and Study of Self-Evaluating Agents for Biomedical Hypothesis Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in Large Language Model (LLM) agents show significant potential, with capabilities in information retrieval, reasoning, and generation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0143-b8660dba17", "paper_id": "P0143", "bibkey": "Yang2025Bioverge", "title": "BioVerge: A Comprehensive Benchmark and Study of Self-Evaluating Agents for Biomedical Hypothesis Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, their application to biomedical hypothesis generation has been limited by the absence of standardized datasets and execution environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0143-e1bef5e224", "paper_id": "P0143", "bibkey": "Yang2025Bioverge", "title": "BioVerge: A Comprehensive Benchmark and Study of Self-Evaluating Agents for Biomedical Hypothesis Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this, we introduce BioVerge, a comprehensive benchmark, and BioVerge Agent, an LLM-based agent framework, to create a standardized environment for exploring biomedical hypothesis generation at the frontier of existing scientific knowledge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0144-4d4bf65d20", "paper_id": "P0144", "bibkey": "Zhang2025Bridging", "title": "Bridging Literature and the Universe Via A Multi-Agent Large Language Model System", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To improve efficiency in physics research and accelerate the cosmological simulation process, we introduce SimAgents, a multi-agent system designed to automate both parameter configuration from the literature and preliminary analysis for cosmology research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0144-e52cad3d44", "paper_id": "P0144", "bibkey": "Zhang2025Bridging", "title": "Bridging Literature and the Universe Via A Multi-Agent Large Language Model System", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We also construct a cosmological parameter extraction evaluation dataset by collecting over 40 simulations in published papers from Arxiv and leading journals that cover diverse simulation types.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0144-7740cbfa54", "paper_id": "P0144", "bibkey": "Zhang2025Bridging", "title": "Bridging Literature and the Universe Via A Multi-Agent Large Language Model System", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on the dataset demonstrate a strong performance of SimAgents, highlighting its effectiveness and potential to accelerate scientific research for physicists.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0144-b7d358e96f", "paper_id": "P0144", "bibkey": "Zhang2025Bridging", "title": "Bridging Literature and the Universe Via A Multi-Agent Large Language Model System", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As cosmological simulations and their associated software become increasingly complex, physicists face the challenge of searching through vast amounts of literature and user manuals to extract simulation parameters from dense academic papers, each using different models and formats.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0144-b4ce6f626e", "paper_id": "P0144", "bibkey": "Zhang2025Bridging", "title": "Bridging Literature and the Universe Via A Multi-Agent Large Language Model System", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Translating these parameters into executable scripts remains a time-consuming and error-prone process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0144-391bb69e8a", "paper_id": "P0144", "bibkey": "Zhang2025Bridging", "title": "Bridging Literature and the Universe Via A Multi-Agent Large Language Model System", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To improve efficiency in physics research and accelerate the cosmological simulation process, we introduce SimAgents, a multi-agent system designed to automate both parameter configuration from the literature and preliminary analysis for cosmology research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0144-df867d8850", "paper_id": "P0144", "bibkey": "Zhang2025Bridging", "title": "Bridging Literature and the Universe Via A Multi-Agent Large Language Model System", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "SimAgents is powered by specialized LLM agents capable of physics reasoning, simulation software validation, and tool execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0144-624154303a", "paper_id": "P0144", "bibkey": "Zhang2025Bridging", "title": "Bridging Literature and the Universe Via A Multi-Agent Large Language Model System", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These agents collaborate through structured communication, ensuring that extracted parameters are physically meaningful, internally consistent, and software-compliant.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0145-1237d4c5e2", "paper_id": "P0145", "bibkey": "Qin2025Compass", "title": "COMPASS: A Multi-Turn Benchmark for Tool-Mediated Planning & Preference Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce COMPASS (Constrained Optimization through Multi-turn Planning and Strategic Solutions), a benchmark that evaluates agents on realistic travel-planning scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0145-a9f01cfcb9", "paper_id": "P0145", "bibkey": "Qin2025Compass", "title": "COMPASS: A Multi-Turn Benchmark for Tool-Mediated Planning & Preference Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To support this, we build a realistic travel database covering transportation, accommodation, and ticketing for 20 U.S.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0145-c90a434db5", "paper_id": "P0145", "bibkey": "Qin2025Compass", "title": "COMPASS: A Multi-Turn Benchmark for Tool-Mediated Planning & Preference Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We introduce COMPASS (Constrained Optimization through Multi-turn Planning and Strategic Solutions), a benchmark that evaluates agents on realistic travel-planning scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0145-9cd4add4a4", "paper_id": "P0145", "bibkey": "Qin2025Compass", "title": "COMPASS: A Multi-Turn Benchmark for Tool-Mediated Planning & Preference Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Real-world large language model (LLM) agents must master strategic tool use and user preference optimization through multi-turn interactions to assist users with complex planning tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0145-e71c54f7ee", "paper_id": "P0145", "bibkey": "Qin2025Compass", "title": "COMPASS: A Multi-Turn Benchmark for Tool-Mediated Planning & Preference Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce COMPASS (Constrained Optimization through Multi-turn Planning and Strategic Solutions), a benchmark that evaluates agents on realistic travel-planning scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0145-6438407405", "paper_id": "P0145", "bibkey": "Qin2025Compass", "title": "COMPASS: A Multi-Turn Benchmark for Tool-Mediated Planning & Preference Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We cast travel planning as a constrained preference optimization problem, where agents must satisfy hard constraints while simultaneously optimizing soft user preferences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0145-5949726a79", "paper_id": "P0145", "bibkey": "Qin2025Compass", "title": "COMPASS: A Multi-Turn Benchmark for Tool-Mediated Planning & Preference Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To support this, we build a realistic travel database covering transportation, accommodation, and ticketing for 20 U.S.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0145-86bccd1043", "paper_id": "P0145", "bibkey": "Qin2025Compass", "title": "COMPASS: A Multi-Turn Benchmark for Tool-Mediated Planning & Preference Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "National Parks, along with a comprehensive tool ecosystem that mirrors commercial booking platforms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0146-dbf1dc1f7c", "paper_id": "P0146", "bibkey": "Michelakis2025Core", "title": "CORE: Full-Path Evaluation of LLM Agents Beyond Final State", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose a framework based on deterministic finite automata (DFAs) that encodes tasks as sets of valid tool-use paths, enabling principled assessment of agent behavior in diverse world models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0146-4ac9a2931e", "paper_id": "P0146", "bibkey": "Michelakis2025Core", "title": "CORE: Full-Path Evaluation of LLM Agents Beyond Final State", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Existing agentic benchmarks often reduce evaluation to a binary judgment of the final state, overlooking critical aspects such as safety, efficiency, and intermediate correctness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0146-ceb4754147", "paper_id": "P0146", "bibkey": "Michelakis2025Core", "title": "CORE: Full-Path Evaluation of LLM Agents Beyond Final State", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Building on this foundation, we introduce CORE, a suite of five metrics, namely Path Correctness, Path Correctness - Kendall's tau Composite, Prefix Criticality, Harmful-Call Rate, and Efficiency, that quantify alignment with expected execution patterns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0146-ca60e3c84e", "paper_id": "P0146", "bibkey": "Michelakis2025Core", "title": "CORE: Full-Path Evaluation of LLM Agents Beyond Final State", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Evaluating AI agents that solve real-world tasks through function-call sequences remains an open challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0146-a2cb956a35", "paper_id": "P0146", "bibkey": "Michelakis2025Core", "title": "CORE: Full-Path Evaluation of LLM Agents Beyond Final State", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing agentic benchmarks often reduce evaluation to a binary judgment of the final state, overlooking critical aspects such as safety, efficiency, and intermediate correctness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0146-a6fd357339", "paper_id": "P0146", "bibkey": "Michelakis2025Core", "title": "CORE: Full-Path Evaluation of LLM Agents Beyond Final State", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose a framework based on deterministic finite automata (DFAs) that encodes tasks as sets of valid tool-use paths, enabling principled assessment of agent behavior in diverse world models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0146-afd359ed05", "paper_id": "P0146", "bibkey": "Michelakis2025Core", "title": "CORE: Full-Path Evaluation of LLM Agents Beyond Final State", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Building on this foundation, we introduce CORE, a suite of five metrics, namely Path Correctness, Path Correctness - Kendall's tau Composite, Prefix Criticality, Harmful-Call Rate, and Efficiency, that quantify alignment with expected execution patterns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0146-a6a27d074b", "paper_id": "P0146", "bibkey": "Michelakis2025Core", "title": "CORE: Full-Path Evaluation of LLM Agents Beyond Final State", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Across diverse worlds, our method reveals important performance differences between agents that would otherwise appear equivalent under traditional final-state evaluation schemes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0146-686e475d00", "paper_id": "P0146", "bibkey": "Michelakis2025Core", "title": "CORE: Full-Path Evaluation of LLM Agents Beyond Final State", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Evaluating AI agents that solve real-world tasks through function-call sequences remains an open challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#limitations[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0147-c20bb0d116", "paper_id": "P0147", "bibkey": "Kwon2025Agentnet", "title": "CP-AgentNet: Autonomous and Explainable Communication Protocol Design Using Generative Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In response, we propose CP-AgentNet, the first framework designed to use generative agents for developing communication network protocols.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0147-5ba05a6db8", "paper_id": "P0147", "bibkey": "Kwon2025Agentnet", "title": "CP-AgentNet: Autonomous and Explainable Communication Protocol Design Using Generative Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Although DRL (deep reinforcement learning) has emerged as a powerful tool for making better decisions than existing hand-crafted communication protocols, it faces significant limitations: 1) Selecting the appropriate neural network architecture and setting hyperparameters are crucial for achieving desired performance levels, requiring domain expertise.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0147-023b5eebd8", "paper_id": "P0147", "bibkey": "Kwon2025Agentnet", "title": "CP-AgentNet: Autonomous and Explainable Communication Protocol Design Using Generative Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "2) The decision-making process in DRL models is often opaque, commonly described as a 'black box.' 3) DRL models are data hungry.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0147-3224549366", "paper_id": "P0147", "bibkey": "Kwon2025Agentnet", "title": "CP-AgentNet: Autonomous and Explainable Communication Protocol Design Using Generative Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Although DRL (deep reinforcement learning) has emerged as a powerful tool for making better decisions than existing hand-crafted communication protocols, it faces significant limitations: 1) Selecting the appropriate neural network architecture and setting hyperparameters are crucial for achieving desired performance levels, requiring domain expertise.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#summary_bullets[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0147-c35445586f", "paper_id": "P0147", "bibkey": "Kwon2025Agentnet", "title": "CP-AgentNet: Autonomous and Explainable Communication Protocol Design Using Generative Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "2) The decision-making process in DRL models is often opaque, commonly described as a 'black box.' 3) DRL models are data hungry.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0147-7d60e45237", "paper_id": "P0147", "bibkey": "Kwon2025Agentnet", "title": "CP-AgentNet: Autonomous and Explainable Communication Protocol Design Using Generative Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In response, we propose CP-AgentNet, the first framework designed to use generative agents for developing communication network protocols.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0147-6967977e6a", "paper_id": "P0147", "bibkey": "Kwon2025Agentnet", "title": "CP-AgentNet: Autonomous and Explainable Communication Protocol Design Using Generative Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This approach addresses these challenges by creating an autonomous system for protocol design, significantly reducing human effort.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0147-69b9bbc98b", "paper_id": "P0147", "bibkey": "Kwon2025Agentnet", "title": "CP-AgentNet: Autonomous and Explainable Communication Protocol Design Using Generative Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We developed LLMA (LLM-agents-based multiple access) and CPTCP (CP-Agent-based TCP) for heterogeneous environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0147-578706f7a5", "paper_id": "P0147", "bibkey": "Kwon2025Agentnet", "title": "CP-AgentNet: Autonomous and Explainable Communication Protocol Design Using Generative Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Although DRL (deep reinforcement learning) has emerged as a powerful tool for making better decisions than existing hand-crafted communication protocols, it faces significant limitations: 1) Selecting the appropriate neural network architecture and setting hyperparameters are crucial for achieving desired performance levels, requiring domain expertise.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#limitations[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0148-6716c8d937", "paper_id": "P0148", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The ability to coordinate actions across multiple agents is critical for solving complex, real-world problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0148-b35b53de13", "paper_id": "P0148", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We systematically evaluate their performance using a suite of coordination-sensitive metrics, including task success rate, redundant actions, room conflicts, and urgency-weighted efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0148-baa622fa7f", "paper_id": "P0148", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This study offers new insights into the strengths and failure modes of LLMs in physically grounded multi-agent collaboration tasks, contributing to future benchmarks and architectural improvements.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0148-2dfd2491a4", "paper_id": "P0148", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The ability to coordinate actions across multiple agents is critical for solving complex, real-world problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0148-66af67b58a", "paper_id": "P0148", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have shown strong capabilities in communication, planning, and reasoning, raising the question of whether they can also support effective collaboration in multi-agent settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0148-e886e27049", "paper_id": "P0148", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we investigate the use of LLM agents to solve a structured victim rescue task that requires division of labor, prioritization, and cooperative planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0148-db71054bee", "paper_id": "P0148", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agents operate in a fully known graph-based environment and must allocate resources to victims with varying needs and urgency levels.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0148-33c24bc13c", "paper_id": "P0148", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We systematically evaluate their performance using a suite of coordination-sensitive metrics, including task success rate, redundant actions, room conflicts, and urgency-weighted efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0149-5e1cd49574", "paper_id": "P0149", "bibkey": "Yoo2025Capturing", "title": "Capturing Semantic Flow of ML-based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose semantic flow, a concept designed to capture the internal behaviour of ML-based system and to provide a platform for traditional dynamic analysis techniques to be adapted to.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0149-c0043b7144", "paper_id": "P0149", "bibkey": "Yoo2025Capturing", "title": "Capturing Semantic Flow of ML-based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We propose the idea of semantic flow, introduce two examples using a DNN and an LLM agent, and finally sketch its properties and how it can be used to adapt existing dynamic analysis techniques for use in ML-based software systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0149-4940733e42", "paper_id": "P0149", "bibkey": "Yoo2025Capturing", "title": "Capturing Semantic Flow of ML-based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ML-based systems are software systems that incorporates machine learning components such as Deep Neural Networks (DNNs) or Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0149-381fa970d9", "paper_id": "P0149", "bibkey": "Yoo2025Capturing", "title": "Capturing Semantic Flow of ML-based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While such systems enable advanced features such as high performance computer vision, natural language processing, and code generation, their internal behaviour remain largely opaque to traditional dynamic analysis such as testing: existing analysis typically concern only what is observable from the outside, such as input similarity or class label changes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0149-49a7fa1424", "paper_id": "P0149", "bibkey": "Yoo2025Capturing", "title": "Capturing Semantic Flow of ML-based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose semantic flow, a concept designed to capture the internal behaviour of ML-based system and to provide a platform for traditional dynamic analysis techniques to be adapted to.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0149-87663248d5", "paper_id": "P0149", "bibkey": "Yoo2025Capturing", "title": "Capturing Semantic Flow of ML-based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Semantic flow combines the idea of control flow with internal states taken from executions of ML-based systems, such as activation values of a specific layer in a DNN, or embeddings of LLM responses at a specific inference step of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0149-5620926011", "paper_id": "P0149", "bibkey": "Yoo2025Capturing", "title": "Capturing Semantic Flow of ML-based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The resulting representation, summarised as semantic flow graphs, can capture internal decisions that are not explicitly represented in the traditional control flow of ML-based systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0150-997a296af2", "paper_id": "P0150", "bibkey": "Rama2025Cerebrum", "title": "Cerebrum (AIOS SDK): A Platform for Agent Development, Deployment, Distribution, and Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present Cerebrum, an Agent SDK for AIOS that addresses this gap through three key components: (1) a comprehensive SDK featuring a modular four-layer architecture for agent development, encompassing LLM, memory, storage, and tool management; (2) a community-driven Agent Hub for sharing and discovering agents, complete with version control and dependency management; (3) an interactive web interface for testing and evaluating agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#method"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0150-8a4fefd92b", "paper_id": "P0150", "bibkey": "Rama2025Cerebrum", "title": "Cerebrum (AIOS SDK): A Platform for Agent Development, Deployment, Distribution, and Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We present Cerebrum, an Agent SDK for AIOS that addresses this gap through three key components: (1) a comprehensive SDK featuring a modular four-layer architecture for agent development, encompassing LLM, memory, storage, and tool management; (2) a community-driven Agent Hub for sharing and discovering agents, complete with version control and dependency management; (3) an interactive web interface for testing and evaluating agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0150-3c8a546137", "paper_id": "P0150", "bibkey": "Rama2025Cerebrum", "title": "Cerebrum (AIOS SDK): A Platform for Agent Development, Deployment, Distribution, and Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Autonomous LLM-based agents have emerged as a powerful paradigm for complex task execution, yet the field lacks standardized tools for development, deployment, distribution and discovery of agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0150-1a72fa7855", "paper_id": "P0150", "bibkey": "Rama2025Cerebrum", "title": "Cerebrum (AIOS SDK): A Platform for Agent Development, Deployment, Distribution, and Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present Cerebrum, an Agent SDK for AIOS that addresses this gap through three key components: (1) a comprehensive SDK featuring a modular four-layer architecture for agent development, encompassing LLM, memory, storage, and tool management; (2) a community-driven Agent Hub for sharing and discovering agents, complete with version control and dependency management; (3) an interactive web interface for testing and evaluating agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0150-9c59435619", "paper_id": "P0150", "bibkey": "Rama2025Cerebrum", "title": "Cerebrum (AIOS SDK): A Platform for Agent Development, Deployment, Distribution, and Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The platform's effectiveness is demonstrated through implementations of various agent architectures, including Chain of Thought (CoT), ReAct, and tool-use agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0150-90e88c1993", "paper_id": "P0150", "bibkey": "Rama2025Cerebrum", "title": "Cerebrum (AIOS SDK): A Platform for Agent Development, Deployment, Distribution, and Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Cerebrum advances the field by providing a unified framework that standardizes agent development while maintaining flexibility for researchers and developers to innovate and distribute their agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0150-1e342b37ed", "paper_id": "P0150", "bibkey": "Rama2025Cerebrum", "title": "Cerebrum (AIOS SDK): A Platform for Agent Development, Deployment, Distribution, and Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The live website is at https://app.aios.foundation, the code is at https://github.com/agiresearch/Cerebrum, and video is at https://app.aios.foundation/video-demo.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0151-959fb538d9", "paper_id": "P0151", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present an LLM assistant, ChatVis, that aids the LLM to generate Python code for ParaView scientific visualization tasks, without the need for retraining or fine-tuning the LLM.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0151-4af4bd8bf3", "paper_id": "P0151", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "An integral part of our approach is a benchmark suite of canonical visualization tasks, ParaView regression tests, and scientific use cases that includes comprehensive evaluation metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0151-825bc530a5", "paper_id": "P0151", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We find that all the metrics are significantly improved with ChatVis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0151-fa0414ceff", "paper_id": "P0151", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are rapidly increasing in capability, but they still struggle with highly specialized programming tasks such as scientific visualization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0151-6af97a93b1", "paper_id": "P0151", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present an LLM assistant, ChatVis, that aids the LLM to generate Python code for ParaView scientific visualization tasks, without the need for retraining or fine-tuning the LLM.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0151-38ab24096b", "paper_id": "P0151", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ChatVis employs chain-of-thought prompt simplification, retrieval-augmented prompt generation using a vector database of documentation and code examples, and error checking with iterative prompt feedback to correct errors until a visualization is produced.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0151-f910200edc", "paper_id": "P0151", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "An integral part of our approach is a benchmark suite of canonical visualization tasks, ParaView regression tests, and scientific use cases that includes comprehensive evaluation metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0151-b6886a54df", "paper_id": "P0151", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluate our visualization assistant by comparing results with a variety of top-performing unassisted LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0152-ea4ec898b8", "paper_id": "P0152", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose using \"quitting\" as a simple yet effective behavioral mechanism for LLM agents to recognize and withdraw from situations where they lack confidence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0152-7edb91824f", "paper_id": "P0152", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Leveraging the ToolEmu framework, we conduct a systematic evaluation of quitting behavior across 12 state-of-the-art LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0152-0550cab83d", "paper_id": "P0152", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results demonstrate a highly favorable safety-helpfulness trade-off: agents prompted to quit with explicit instructions improve safety by an average of +0.39 on a 0-3 scale across all models (+0.64 for proprietary models), while maintaining a negligible average decrease of -0.03 in helpfulness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0152-ed9d5a5002", "paper_id": "P0152", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As Large Language Model (LLM) agents increasingly operate in complex environments with real-world consequences, their safety becomes critical.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0152-fcdca39700", "paper_id": "P0152", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While uncertainty quantification is well-studied for single-turn tasks, multi-turn agentic scenarios with real-world tool access present unique challenges where uncertainties and ambiguities compound, leading to severe or catastrophic risks beyond traditional text generation failures.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0152-53dd169482", "paper_id": "P0152", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose using \"quitting\" as a simple yet effective behavioral mechanism for LLM agents to recognize and withdraw from situations where they lack confidence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0152-6058a4905d", "paper_id": "P0152", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Leveraging the ToolEmu framework, we conduct a systematic evaluation of quitting behavior across 12 state-of-the-art LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0152-0bf0084c85", "paper_id": "P0152", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our results demonstrate a highly favorable safety-helpfulness trade-off: agents prompted to quit with explicit instructions improve safety by an average of +0.39 on a 0-3 scale across all models (+0.64 for proprietary models), while maintaining a negligible average decrease of -0.03 in helpfulness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0153-1582bbb499", "paper_id": "P0153", "bibkey": "Tao2025Code", "title": "Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To this end, we introduce Code Graph Models (CGMs), which integrate repository code graph structures into the LLM's attention mechanism and map node attributes to the LLM's input space using a specialized adapter.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0153-9bd58ce21b", "paper_id": "P0153", "bibkey": "Tao2025Code", "title": "Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "When combined with an agentless graph RAG framework, our approach achieves a 43.00% resolution rate on the SWE-bench Lite benchmark using the open-source Qwen2.5-72B model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0153-f9f61dfd9a", "paper_id": "P0153", "bibkey": "Tao2025Code", "title": "Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This performance ranks first among open weight models, second among methods with open-source systems, and eighth overall, surpassing the previous best open-source model-based method by 12.33%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0153-045d079fae", "paper_id": "P0153", "bibkey": "Tao2025Code", "title": "Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in Large Language Models (LLMs) have shown promise in function-level code generation, yet repository-level software engineering tasks remain challenging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0153-301117dccb", "paper_id": "P0153", "bibkey": "Tao2025Code", "title": "Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current solutions predominantly rely on proprietary LLM agents, which introduce unpredictability and limit accessibility, raising concerns about data privacy and model customization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0153-859f184e42", "paper_id": "P0153", "bibkey": "Tao2025Code", "title": "Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper investigates whether open-source LLMs can effectively address repository-level tasks without requiring agent-based approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0153-8ab1ab14a4", "paper_id": "P0153", "bibkey": "Tao2025Code", "title": "Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We demonstrate this is possible by enabling LLMs to comprehend functions and files within codebases through their semantic information and structural dependencies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0153-db710a2301", "paper_id": "P0153", "bibkey": "Tao2025Code", "title": "Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To this end, we introduce Code Graph Models (CGMs), which integrate repository code graph structures into the LLM's attention mechanism and map node attributes to the LLM's input space using a specialized adapter.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0154-3c9791fc6e", "paper_id": "P0154", "bibkey": "Zhao2025Connecting", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we propose Cochain, a collaboration prompting framework that effectively solves business workflow collaboration problem by combining knowledge and prompts at a reduced cost.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0154-5621a1353b", "paper_id": "P0154", "bibkey": "Zhao2025Connecting", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Additionally, expert evaluation results indicate that the use of a small model in combination with Cochain outperforms GPT-4.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0154-0f7f5c9804", "paper_id": "P0154", "bibkey": "Zhao2025Connecting", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We perform extensive evaluations of Cochain across multiple datasets, demonstrating that Cochain outperforms all baselines in both prompt engineering and multi-agent LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0154-82fa8c4398", "paper_id": "P0154", "bibkey": "Zhao2025Connecting", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have demonstrated impressive performance in executing complex reasoning tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0154-ff6062abed", "paper_id": "P0154", "bibkey": "Zhao2025Connecting", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Chain-of-thought effectively enhances reasoning capabilities by unlocking the potential of large models, while multi-agent systems provide more comprehensive solutions by integrating collective intelligence of multiple agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0154-fea88e9b0c", "paper_id": "P0154", "bibkey": "Zhao2025Connecting", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, both approaches face significant limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0154-6af9738b57", "paper_id": "P0154", "bibkey": "Zhao2025Connecting", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Single-agent with chain-of-thought, due to the inherent complexity of designing cross-domain prompts, faces collaboration challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0154-446aaa4705", "paper_id": "P0154", "bibkey": "Zhao2025Connecting", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Meanwhile, multi-agent systems consume substantial tokens and inevitably dilute the primary problem, which is particularly problematic in business workflow tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0154-f5921ca1c2", "paper_id": "P0154", "bibkey": "Zhao2025Connecting", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "However, both approaches face significant limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0155-c96bf29a87", "paper_id": "P0155", "bibkey": "Yang2025Contextagent", "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce ContextAgent, the first context-aware proactive agent that incorporates extensive sensory contexts surrounding humans to enhance the proactivity of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0155-0fc82f8849", "paper_id": "P0155", "bibkey": "Yang2025Contextagent", "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To evaluate this new task, we curate ContextAgentBench, the first benchmark for evaluating context-aware proactive LLM agents, covering 1,000 samples across nine daily scenarios and twenty tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0155-4c78c05170", "paper_id": "P0155", "bibkey": "Yang2025Contextagent", "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on ContextAgentBench show that ContextAgent outperforms baselines by achieving up to 8.5% and 6.0% higher accuracy in proactive predictions and tool calling, respectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0155-8cbe115035", "paper_id": "P0155", "bibkey": "Yang2025Contextagent", "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in Large Language Models (LLMs) have propelled intelligent agents from reactive responses to proactive support.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0155-953adb6bcd", "paper_id": "P0155", "bibkey": "Yang2025Contextagent", "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While promising, existing proactive agents either rely exclusively on observations from enclosed environments (e.g., desktop UIs) with direct LLM inference or employ rule-based proactive notifications, leading to suboptimal user intent understanding and limited functionality for proactive service.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0155-9ab24789e9", "paper_id": "P0155", "bibkey": "Yang2025Contextagent", "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce ContextAgent, the first context-aware proactive agent that incorporates extensive sensory contexts surrounding humans to enhance the proactivity of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0155-f531daf84a", "paper_id": "P0155", "bibkey": "Yang2025Contextagent", "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ContextAgent first extracts multi-dimensional contexts from massive sensory perceptions on wearables (e.g., video and audio) to understand user intentions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0155-7303a84adc", "paper_id": "P0155", "bibkey": "Yang2025Contextagent", "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ContextAgent then leverages the sensory contexts and personas from historical data to predict the necessity for proactive services.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0156-0b34b55332", "paper_id": "P0156", "bibkey": "Fumero2025Cybersleuth", "title": "CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose CyberSleuth, an autonomous agent that processes packet-level traces and application logs to identify the targeted service, the exploited vulnerability (CVE), and attack success.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0156-c8c4670812", "paper_id": "P0156", "bibkey": "Fumero2025Cybersleuth", "title": "CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We benchmark four agent architectures and six LLM backends on 20 incident scenarios of increasing complexity, identifying CyberSleuth as the best-performing design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0156-18b5f42fc9", "paper_id": "P0156", "bibkey": "Fumero2025Cybersleuth", "title": "CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "At last, we conduct a human study with 22 experts, which rated the reports of CyberSleuth as complete, useful, and coherent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0156-cab22cf105", "paper_id": "P0156", "bibkey": "Fumero2025Cybersleuth", "title": "CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents are powerful tools for automating complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0156-db091c226f", "paper_id": "P0156", "bibkey": "Fumero2025Cybersleuth", "title": "CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In cybersecurity, researchers have primarily explored their use in red-team operations such as vulnerability discovery and penetration tests.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0156-618309ef93", "paper_id": "P0156", "bibkey": "Fumero2025Cybersleuth", "title": "CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Defensive uses for incident response and forensics have received comparatively less attention and remain at an early stage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0156-515a0d78bb", "paper_id": "P0156", "bibkey": "Fumero2025Cybersleuth", "title": "CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This work presents a systematic study of LLM-agent design for the forensic investigation of realistic web application attacks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#summary_bullets[3]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0156-78166a9d77", "paper_id": "P0156", "bibkey": "Fumero2025Cybersleuth", "title": "CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose CyberSleuth, an autonomous agent that processes packet-level traces and application logs to identify the targeted service, the exploited vulnerability (CVE), and attack success.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#summary_bullets[4]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0157-5fe6dbb13b", "paper_id": "P0157", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Our approach decomposes demonstration knowledge into transferable and non-transferable components through a causal lens, showing how the latter can introduce spurious dependencies that impair generalization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0157-384d450350", "paper_id": "P0157", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments across diverse domains demonstrate our method's effectiveness and generality, highlighting the importance of principled, context-aware demo selection for robust and efficient LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0157-56b0c62e72", "paper_id": "P0157", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model-based agents, empowered by in-context learning (ICL), have demonstrated strong capabilities in complex reasoning and tool-use tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0157-83df58a7e9", "paper_id": "P0157", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing works have shown that the effectiveness of ICL is highly sensitive to the choice of demonstrations, with suboptimal examples often leading to unstable or degraded performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0157-e88cf45af9", "paper_id": "P0157", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While prior work has explored example selection, including in some agentic or multi-step settings, existing approaches typically rely on heuristics or task-specific designs and lack a general, theoretically grounded criterion for what constitutes an effective demonstration across reasoning steps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0157-f5fa406e91", "paper_id": "P0157", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Therefore, it is non-trivial to develop a principled, general-purpose method for selecting demonstrations that consistently benefit agent performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0157-13abb5674e", "paper_id": "P0157", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we address this challenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a theoretically grounded ICL framework for agentic tasks that selects the most relevant demonstrations at each step of reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0158-2de2887c8b", "paper_id": "P0158", "bibkey": "Wang2025Dsmentor", "title": "DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we develop a novel inference-time optimization framework, referred to as DSMentor, which leverages curriculum learning -- a strategy that introduces simpler task first and progressively moves to more complex ones as the learner improves -- to enhance LLM agent performance in challenging data science tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0158-69c0aa3079", "paper_id": "P0158", "bibkey": "Wang2025Dsmentor", "title": "DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments show that DSMentor using Claude-3.5-Sonnet improves the pass rate by up to 5.2% on DSEval and QRData compared to baseline agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0158-837897e787", "paper_id": "P0158", "bibkey": "Wang2025Dsmentor", "title": "DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Furthermore, DSMentor demonstrates stronger causal reasoning ability, improving the pass rate by 8.8% on the causality problems compared to GPT-4 using Program-of-Thoughts prompts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0158-5140dbcb6d", "paper_id": "P0158", "bibkey": "Wang2025Dsmentor", "title": "DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents have shown promising performance in generating code for solving complex data science problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0158-ccce40e88d", "paper_id": "P0158", "bibkey": "Wang2025Dsmentor", "title": "DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent studies primarily focus on enhancing in-context learning through improved search, sampling, and planning techniques, while overlooking the importance of the order in which problems are tackled during inference.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0158-ebeebd65c5", "paper_id": "P0158", "bibkey": "Wang2025Dsmentor", "title": "DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we develop a novel inference-time optimization framework, referred to as DSMentor, which leverages curriculum learning -- a strategy that introduces simpler task first and progressively moves to more complex ones as the learner improves -- to enhance LLM agent performance in challenging data science tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0158-e73e183d40", "paper_id": "P0158", "bibkey": "Wang2025Dsmentor", "title": "DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our mentor-guided framework organizes data science tasks in order of increasing difficulty and incorporates a growing long-term memory to retain prior experiences, guiding the agent's learning progression and enabling more effective utilization of accumulated knowledge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0158-84cdef463a", "paper_id": "P0158", "bibkey": "Wang2025Dsmentor", "title": "DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluate DSMentor through extensive experiments on DSEval and QRData benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0159-b9e7423acc", "paper_id": "P0159", "bibkey": "Zhang2025Datascibench", "title": "DataSciBench: An LLM Agent Benchmark for Data Science", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We develop a semi-automated pipeline for generating ground truth (GT) and validating evaluation metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0159-ee6e0931f8", "paper_id": "P0159", "bibkey": "Zhang2025Datascibench", "title": "DataSciBench: An LLM Agent Benchmark for Data Science", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experimental framework involves testing 6 API-based models, 8 open-source general models, and 9 open-source code generation models using the diverse set of prompts we have gathered.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0159-39281e5083", "paper_id": "P0159", "bibkey": "Zhang2025Datascibench", "title": "DataSciBench: An LLM Agent Benchmark for Data Science", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experimental results demonstrate that API-based models outperform open-sourced models on all metrics and Deepseek-Coder-33B-Instruct achieves the highest score among open-sourced models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0159-db3ee8cd01", "paper_id": "P0159", "bibkey": "Zhang2025Datascibench", "title": "DataSciBench: An LLM Agent Benchmark for Data Science", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents DataSciBench, a comprehensive benchmark for evaluating Large Language Model (LLM) capabilities in data science.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0159-d60d3c7269", "paper_id": "P0159", "bibkey": "Zhang2025Datascibench", "title": "DataSciBench: An LLM Agent Benchmark for Data Science", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent related benchmarks have primarily focused on single tasks, easily obtainable ground truth, and straightforward evaluation metrics, which limits the scope of tasks that can be evaluated.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0159-647bee3494", "paper_id": "P0159", "bibkey": "Zhang2025Datascibench", "title": "DataSciBench: An LLM Agent Benchmark for Data Science", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In contrast, DataSciBench is constructed based on a more comprehensive and curated collection of natural and challenging prompts for uncertain ground truth and evaluation metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0159-84c8d4a9cb", "paper_id": "P0159", "bibkey": "Zhang2025Datascibench", "title": "DataSciBench: An LLM Agent Benchmark for Data Science", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We develop a semi-automated pipeline for generating ground truth (GT) and validating evaluation metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0159-c979c42a8e", "paper_id": "P0159", "bibkey": "Zhang2025Datascibench", "title": "DataSciBench: An LLM Agent Benchmark for Data Science", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This pipeline utilizes and implements an LLM-based self-consistency and human verification strategy to produce accurate GT by leveraging collected prompts, predefined task types, and aggregate functions (metrics).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0160-feb5b24b0b", "paper_id": "P0160", "bibkey": "Russo2025Deep", "title": "Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "With advances in large language models (LLMs), researchers are creating new systems that can perform AI-driven analytics over large unstructured datasets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0160-5a311b394a", "paper_id": "P0160", "bibkey": "Russo2025Deep", "title": "Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Compared to a standard open Deep Research agent, our prototype achieves up to 1.95x better F1-score.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0160-a8b0d15cbe", "paper_id": "P0160", "bibkey": "Russo2025Deep", "title": "Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Furthermore, even if we give the agent access to semantic operators as tools, our prototype still achieves cost and runtime savings of up to 76.8% and 72.7% thanks to its optimized execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0160-86f24a9705", "paper_id": "P0160", "bibkey": "Russo2025Deep", "title": "Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With advances in large language models (LLMs), researchers are creating new systems that can perform AI-driven analytics over large unstructured datasets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0160-c1f4e397d8", "paper_id": "P0160", "bibkey": "Russo2025Deep", "title": "Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent work has explored executing such analytics queries using semantic operators -- a declarative set of AI-powered data transformations with natural language specifications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0160-1cf78a9190", "paper_id": "P0160", "bibkey": "Russo2025Deep", "title": "Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, even when optimized, these operators can be expensive to execute on millions of records and their iterator execution semantics make them ill-suited for interactive data analytics tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0160-3d9366ffa7", "paper_id": "P0160", "bibkey": "Russo2025Deep", "title": "Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In another line of work, Deep Research systems have demonstrated an ability to answer natural language question(s) over large datasets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0160-6e4b69c665", "paper_id": "P0160", "bibkey": "Russo2025Deep", "title": "Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These systems use one or more LLM agent(s) to plan their execution, process the dataset(s), and iteratively refine their answer.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0161-17fb12f5b7", "paper_id": "P0161", "bibkey": "Kang2025Distilling", "title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose Agent Distillation, a framework for transferring not only reasoning capability but full task-solving behavior from LLM-based agents into sLMs with retrieval and code tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#method"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0161-b3e71bf0cd", "paper_id": "P0161", "bibkey": "Kang2025Distilling", "title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We improve agent distillation along two complementary axes: (1) we introduce a prompting method called first-thought prefix to enhance the quality of teacher-generated trajectories; and (2) we propose a self-consistent action generation for improving test-time robustness of small agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0161-dc7fe955d8", "paper_id": "P0161", "bibkey": "Kang2025Distilling", "title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results show that sLMs as small as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the potential of agent distillation for building practical, tool-using small agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0161-8d8d325e8f", "paper_id": "P0161", "bibkey": "Kang2025Distilling", "title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) excel at complex reasoning tasks but remain computationally expensive, limiting their practical deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0161-6e79c5f1e0", "paper_id": "P0161", "bibkey": "Kang2025Distilling", "title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this, recent works have focused on distilling reasoning capabilities into smaller language models (sLMs) using chain-of-thought (CoT) traces from teacher LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0161-b7298b8786", "paper_id": "P0161", "bibkey": "Kang2025Distilling", "title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, this approach struggles in scenarios requiring rare factual knowledge or precise computation, where sLMs often hallucinate due to limited capability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0161-102a6715d9", "paper_id": "P0161", "bibkey": "Kang2025Distilling", "title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we propose Agent Distillation, a framework for transferring not only reasoning capability but full task-solving behavior from LLM-based agents into sLMs with retrieval and code tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0161-3a272583e8", "paper_id": "P0161", "bibkey": "Kang2025Distilling", "title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We improve agent distillation along two complementary axes: (1) we introduce a prompting method called first-thought prefix to enhance the quality of teacher-generated trajectories; and (2) we propose a self-consistent action generation for improving test-time robustness of small agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0162-192e78b614", "paper_id": "P0162", "bibkey": "Dong2025Etom", "title": "ETOM: A Five-Level Benchmark for Evaluating Tool Orchestration within the MCP Ecosystem", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce ETOM, a five-level benchmark for evaluating multi-hop, end-to-end tool orchestration by LLM agents within a hierarchical Model-Context Protocol (MCP) ecosystem.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0162-6ee6d5b951", "paper_id": "P0162", "bibkey": "Dong2025Etom", "title": "ETOM: A Five-Level Benchmark for Evaluating Tool Orchestration within the MCP Ecosystem", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We introduce ETOM, a five-level benchmark for evaluating multi-hop, end-to-end tool orchestration by LLM agents within a hierarchical Model-Context Protocol (MCP) ecosystem.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0162-55ce44af76", "paper_id": "P0162", "bibkey": "Dong2025Etom", "title": "ETOM: A Five-Level Benchmark for Evaluating Tool Orchestration within the MCP Ecosystem", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Existing benchmarks often assess tools in isolation, overlooking challenges such as functional overlap and cross-server orchestration, which can lead to overly optimistic evaluations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0162-1c769526d3", "paper_id": "P0162", "bibkey": "Dong2025Etom", "title": "ETOM: A Five-Level Benchmark for Evaluating Tool Orchestration within the MCP Ecosystem", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce ETOM, a five-level benchmark for evaluating multi-hop, end-to-end tool orchestration by LLM agents within a hierarchical Model-Context Protocol (MCP) ecosystem.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0162-5bfe17f8c0", "paper_id": "P0162", "bibkey": "Dong2025Etom", "title": "ETOM: A Five-Level Benchmark for Evaluating Tool Orchestration within the MCP Ecosystem", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing benchmarks often assess tools in isolation, overlooking challenges such as functional overlap and cross-server orchestration, which can lead to overly optimistic evaluations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0162-c703fd224d", "paper_id": "P0162", "bibkey": "Dong2025Etom", "title": "ETOM: A Five-Level Benchmark for Evaluating Tool Orchestration within the MCP Ecosystem", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ETOM addresses these gaps by constructing ground truth through \"equal function sets\", enabling objective metrics such as F1 score and reducing reliance on LLM-as-a-judge evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0162-1a350c6925", "paper_id": "P0162", "bibkey": "Dong2025Etom", "title": "ETOM: A Five-Level Benchmark for Evaluating Tool Orchestration within the MCP Ecosystem", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Its five-level curriculum systematically tests agent capabilities, from single-tool orchestration to complex cross-server planning, as well as robustness to out-of-scope requests.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0162-f81bafd7ab", "paper_id": "P0162", "bibkey": "Dong2025Etom", "title": "ETOM: A Five-Level Benchmark for Evaluating Tool Orchestration within the MCP Ecosystem", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Experiments reveal that rigid hierarchies can hinder performance without co-designed strategies, and even state-of-the-art agents exhibit systemic weaknesses in robustness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0162-092dfe6461", "paper_id": "P0162", "bibkey": "Dong2025Etom", "title": "ETOM: A Five-Level Benchmark for Evaluating Tool Orchestration within the MCP Ecosystem", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "ETOM provides a diagnostic framework to expose these limitations and guide the development of more capable and efficient tool-using agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#limitations[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0163-88d96fc54b", "paper_id": "P0163", "bibkey": "Salama2025Edge", "title": "Edge Agentic AI Framework for Autonomous Network Optimisation in O-RAN", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Integrated into the RAN Intelligent Controller (RIC), our framework leverages multimodal data fusion, including network KPIs, a traffic prediction model, and external information sources, to anticipate and respond to dynamic network conditions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0163-84b88bc47a", "paper_id": "P0163", "bibkey": "Salama2025Edge", "title": "Edge Agentic AI Framework for Autonomous Network Optimisation in O-RAN", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive evaluation using realistic 5G scenarios demonstrates that the edge framework achieves zero network outages under high-stress conditions, compared to 8.4% for traditional fixed-power networks and 3.3% for large language model (LLM) agent-based approaches, while maintaining near real-time responsiveness and consistent QoS.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0163-f695f9aaa3", "paper_id": "P0163", "bibkey": "Salama2025Edge", "title": "Edge Agentic AI Framework for Autonomous Network Optimisation in O-RAN", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This paper presents a novel Edge AI framework for autonomous network optimisation in Open RAN environments, addressing these challenges through three core innovations: (1) a persona-based multi-tools architecture enabling distributed, context-aware decision-making; (2) proactive anomaly detection agent powered by traffic predictive tool; and (3) a safety, aligned reward mechanism that balances performance with operational stability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0163-f076b4afe0", "paper_id": "P0163", "bibkey": "Salama2025Edge", "title": "Edge Agentic AI Framework for Autonomous Network Optimisation in O-RAN", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The deployment of AI agents within legacy Radio Access Network (RAN) infrastructure poses significant safety and reliability challenges for future 6G networks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0163-deabb22717", "paper_id": "P0163", "bibkey": "Salama2025Edge", "title": "Edge Agentic AI Framework for Autonomous Network Optimisation in O-RAN", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents a novel Edge AI framework for autonomous network optimisation in Open RAN environments, addressing these challenges through three core innovations: (1) a persona-based multi-tools architecture enabling distributed, context-aware decision-making; (2) proactive anomaly detection agent powered by traffic predictive tool; and (3) a safety, aligned reward mechanism that balances performance with operational stability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0163-b78d4bb94e", "paper_id": "P0163", "bibkey": "Salama2025Edge", "title": "Edge Agentic AI Framework for Autonomous Network Optimisation in O-RAN", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Integrated into the RAN Intelligent Controller (RIC), our framework leverages multimodal data fusion, including network KPIs, a traffic prediction model, and external information sources, to anticipate and respond to dynamic network conditions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0163-60f37fbfe3", "paper_id": "P0163", "bibkey": "Salama2025Edge", "title": "Edge Agentic AI Framework for Autonomous Network Optimisation in O-RAN", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Extensive evaluation using realistic 5G scenarios demonstrates that the edge framework achieves zero network outages under high-stress conditions, compared to 8.4% for traditional fixed-power networks and 3.3% for large language model (LLM) agent-based approaches, while maintaining near real-time responsiveness and consistent QoS.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0163-b7945e2fa9", "paper_id": "P0163", "bibkey": "Salama2025Edge", "title": "Edge Agentic AI Framework for Autonomous Network Optimisation in O-RAN", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These results establish that, when equipped with the right tools and contextual awareness, AI agents can be safely and effectively deployed in critical network infrastructure, laying the framework for intelligent and autonomous 5G and beyond network operations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0164-2d013e566c", "paper_id": "P0164", "bibkey": "He2025Enabling", "title": "Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this limitation, we propose the Adaptive Reflective Interactive Agent (ARIA), an LLM agent framework designed specifically to continuously learn updated domain knowledge at test time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0164-c806898fd3", "paper_id": "P0164", "bibkey": "He2025Enabling", "title": "Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "ARIA is deployed within TikTok Pay serving over 150 million monthly active users, confirming its practicality and effectiveness for operational use in rapidly evolving environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0164-559009a2a6", "paper_id": "P0164", "bibkey": "He2025Enabling", "title": "Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "ARIA assesses its own uncertainty through structured self-dialogue, proactively identifying knowledge gaps and requesting targeted explanations or corrections from human experts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0164-ddc8679a18", "paper_id": "P0164", "bibkey": "He2025Enabling", "title": "Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents often struggle in environments where rules and required domain knowledge frequently change, such as regulatory compliance and user risk screening.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0164-6900ea557b", "paper_id": "P0164", "bibkey": "He2025Enabling", "title": "Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current approaches, like offline fine-tuning and standard prompting, are insufficient because they cannot effectively adapt to new knowledge during actual operation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0164-66ffaf47ce", "paper_id": "P0164", "bibkey": "He2025Enabling", "title": "Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this limitation, we propose the Adaptive Reflective Interactive Agent (ARIA), an LLM agent framework designed specifically to continuously learn updated domain knowledge at test time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0164-28d8a9a84f", "paper_id": "P0164", "bibkey": "He2025Enabling", "title": "Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ARIA assesses its own uncertainty through structured self-dialogue, proactively identifying knowledge gaps and requesting targeted explanations or corrections from human experts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0164-ddb140749c", "paper_id": "P0164", "bibkey": "He2025Enabling", "title": "Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It then systematically updates an internal, timestamped knowledge repository with provided human guidance, detecting and resolving conflicting or outdated knowledge through comparisons and clarification queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0164-53c86c7d64", "paper_id": "P0164", "bibkey": "He2025Enabling", "title": "Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address this limitation, we propose the Adaptive Reflective Interactive Agent (ARIA), an LLM agent framework designed specifically to continuously learn updated domain knowledge at test time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0165-cdc1f1371a", "paper_id": "P0165", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we propose Reinforcement Learning with Tool-use Rewards (RLTR), a novel framework that decouples the training process to enable a focused, single-objective optimization of the planning module.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0165-cdf254f6f5", "paper_id": "P0165", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Moreover, this enhanced planning capability, in turn, translates to a 5%-6% increase in the final response quality of the overall agent system.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0165-f04cd37d30", "paper_id": "P0165", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments demonstrate that RLTR achieves an 8%-12% improvement in planning performance compared to end-to-end baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0165-1b6c72f6f2", "paper_id": "P0165", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The functionality of Large Language Model (LLM) agents is primarily determined by two capabilities: action planning and answer summarization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0165-8ee1b9d3b0", "paper_id": "P0165", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The former, action planning, is the core capability that dictates an agent's performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0165-7a25ab45ba", "paper_id": "P0165", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, prevailing training paradigms employ end-to-end, multi-objective optimization that jointly trains both capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0165-9af9d0e1a3", "paper_id": "P0165", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paradigm faces two critical challenges: imbalanced optimization objective allocation and scarcity of verifiable data, making it difficult to enhance the agent's planning capability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0165-807ff4919b", "paper_id": "P0165", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these challenges, we propose Reinforcement Learning with Tool-use Rewards (RLTR), a novel framework that decouples the training process to enable a focused, single-objective optimization of the planning module.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0166-c55694b715", "paper_id": "P0166", "bibkey": "Tang2025Edge", "title": "End-to-End Edge AI Service Provisioning Framework in 6G ORAN", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We implement a prototype using open-source O-RAN projects (OpenAirInterface and FlexRIC) to demonstrate the feasibility and functionality of our framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0166-7eeb1727a4", "paper_id": "P0166", "bibkey": "Tang2025Edge", "title": "End-to-End Edge AI Service Provisioning Framework in 6G ORAN", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This work highlights the potential of integrating LLM-driven automation into 6G O-RAN ecosystems, paving the way for more accessible and efficient edge AI ecosystems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0166-fa4d63db9f", "paper_id": "P0166", "bibkey": "Tang2025Edge", "title": "End-to-End Edge AI Service Provisioning Framework in 6G ORAN", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the advent of 6G, Open Radio Access Network (O-RAN) architectures are evolving to support intelligent, adaptive, and automated network orchestration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0166-efb92074bb", "paper_id": "P0166", "bibkey": "Tang2025Edge", "title": "End-to-End Edge AI Service Provisioning Framework in 6G ORAN", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper proposes a novel Edge AI and Network Service Orchestration framework that leverages Large Language Model (LLM) agents deployed as O-RAN rApps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0166-8edce7d1e5", "paper_id": "P0166", "bibkey": "Tang2025Edge", "title": "End-to-End Edge AI Service Provisioning Framework in 6G ORAN", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The proposed LLM-agent-powered system enables interactive and intuitive orchestration by translating the user's use case description into deployable AI services and corresponding network configurations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0166-49beb442e0", "paper_id": "P0166", "bibkey": "Tang2025Edge", "title": "End-to-End Edge AI Service Provisioning Framework in 6G ORAN", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The LLM agent automates multiple tasks, including AI model selection from repositories (e.g., Hugging Face), service deployment, network adaptation, and real-time monitoring via xApps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0166-9bea3df960", "paper_id": "P0166", "bibkey": "Tang2025Edge", "title": "End-to-End Edge AI Service Provisioning Framework in 6G ORAN", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We implement a prototype using open-source O-RAN projects (OpenAirInterface and FlexRIC) to demonstrate the feasibility and functionality of our framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0167-de0ba6ae9d", "paper_id": "P0167", "bibkey": "Samaei2025Epidemiqs", "title": "EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce \\textbf{EpidemIQs}, a novel multi-agent LLM framework that integrates user inputs and autonomously conducts literature review, analytical derivation, network modeling, mechanistic modeling, stochastic simulations, data visualization and analysis, and finally documentation of findings in a structured manuscript.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0167-3cc79392d4", "paper_id": "P0167", "bibkey": "Samaei2025Epidemiqs", "title": "EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Specifically, using GPT 4.1 and GPT 4.1 mini as backbone LLMs for scientist and task-expert agents, respectively, the autonomous process completed with average total token usage 870K at a cost of about \\$1.57 per study, achieving a 100\\% completion success rate through our experiments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0167-ca050ed55f", "paper_id": "P0167", "bibkey": "Samaei2025Epidemiqs", "title": "EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate EpidemIQs across different epidemic scenarios, measuring computational cost, completion success rate, and AI and human expert reviews of generated reports.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0167-e64646cadb", "paper_id": "P0167", "bibkey": "Samaei2025Epidemiqs", "title": "EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) offer new opportunities to automate complex interdisciplinary research domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0167-05a1d6be09", "paper_id": "P0167", "bibkey": "Samaei2025Epidemiqs", "title": "EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Epidemic modeling, characterized by its complexity and reliance on network science, dynamical systems, epidemiology, and stochastic simulations, represents a prime candidate for leveraging LLM-driven automation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0167-f62118a912", "paper_id": "P0167", "bibkey": "Samaei2025Epidemiqs", "title": "EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce \\textbf{EpidemIQs}, a novel multi-agent LLM framework that integrates user inputs and autonomously conducts literature review, analytical derivation, network modeling, mechanistic modeling, stochastic simulations, data visualization and analysis, and finally documentation of findings in a structured manuscript.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0167-9ee37a550a", "paper_id": "P0167", "bibkey": "Samaei2025Epidemiqs", "title": "EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduced two types of agents: a scientist agent for planning, coordination, reflection, and generation of final results, and a task-expert agent to focus exclusively on one specific duty serving as a tool to the scientist agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0167-4580504073", "paper_id": "P0167", "bibkey": "Samaei2025Epidemiqs", "title": "EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The framework consistently generated complete reports in scientific article format.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0168-7adb7943bf", "paper_id": "P0168", "bibkey": "Mohammadi2025Evaluation", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The rise of LLM-based agents has opened new frontiers in AI applications, yet evaluating these agents remains a complex and underdeveloped area.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0168-37f9ea924c", "paper_id": "P0168", "bibkey": "Mohammadi2025Evaluation", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and (2) evaluation process -- how to evaluate, including interaction modes, datasets and benchmarks, metric computation methods, and tooling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0168-e973488a75", "paper_id": "P0168", "bibkey": "Mohammadi2025Evaluation", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We also identify future research directions, including holistic, more realistic, and scalable evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0168-c1704b916e", "paper_id": "P0168", "bibkey": "Mohammadi2025Evaluation", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rise of LLM-based agents has opened new frontiers in AI applications, yet evaluating these agents remains a complex and underdeveloped area.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0168-d95d39169b", "paper_id": "P0168", "bibkey": "Mohammadi2025Evaluation", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and (2) evaluation process -- how to evaluate, including interaction modes, datasets and benchmarks, metric computation methods, and tooling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0168-5ec1dd06bf", "paper_id": "P0168", "bibkey": "Mohammadi2025Evaluation", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In addition to taxonomy, we highlight enterprise-specific challenges, such as role-based access to data, the need for reliability guarantees, dynamic and long-horizon interactions, and compliance, which are often overlooked in current research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0168-01a13edd85", "paper_id": "P0168", "bibkey": "Mohammadi2025Evaluation", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We also identify future research directions, including holistic, more realistic, and scalable evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0168-8594c1b3da", "paper_id": "P0168", "bibkey": "Mohammadi2025Evaluation", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This work aims to bring clarity to the fragmented landscape of agent evaluation and provide a framework for systematic assessment, enabling researchers and practitioners to evaluate LLM agents for real-world deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0169-043e05ef50", "paper_id": "P0169", "bibkey": "Wu2025Evolver", "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we introduce EvolveR, a framework designed to enable agent to self-improve through a complete, closed-loop experience lifecycle.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0169-0c10233369", "paper_id": "P0169", "bibkey": "Wu2025Evolver", "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This lifecycle comprises two key stages: (1) Offline Self-Distillation, where the agent's interaction trajectories are synthesized into a structured repository of abstract, reusable strategic principles; (2) Online Interaction, where the agent interacts with tasks and actively retrieves distilled principles to guide its decision-making, accumulating a diverse set of behavioral trajectories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0169-1a05555e85", "paper_id": "P0169", "bibkey": "Wu2025Evolver", "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We demonstrate the effectiveness of EvolveR on complex multi-hop question-answering benchmarks, where it achieves superior performance over strong agentic baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0169-00be30b3b7", "paper_id": "P0169", "bibkey": "Wu2025Evolver", "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current Large Language Model (LLM) agents show strong performance in tool use, but lack the crucial capability to systematically learn from their own experiences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0169-d7bc6b040e", "paper_id": "P0169", "bibkey": "Wu2025Evolver", "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While existing frameworks mainly focus on mitigating external knowledge gaps, they fail to address a more fundamental limitation: the inability to iteratively refine problem-solving strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0169-84e01d467b", "paper_id": "P0169", "bibkey": "Wu2025Evolver", "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we introduce EvolveR, a framework designed to enable agent to self-improve through a complete, closed-loop experience lifecycle.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0169-5424f5abaa", "paper_id": "P0169", "bibkey": "Wu2025Evolver", "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This lifecycle comprises two key stages: (1) Offline Self-Distillation, where the agent's interaction trajectories are synthesized into a structured repository of abstract, reusable strategic principles; (2) Online Interaction, where the agent interacts with tasks and actively retrieves distilled principles to guide its decision-making, accumulating a diverse set of behavioral trajectories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0169-0591d8717e", "paper_id": "P0169", "bibkey": "Wu2025Evolver", "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This loop employs a policy reinforcement mechanism to iteratively update the agent based on its performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0169-e7e8e5879f", "paper_id": "P0169", "bibkey": "Wu2025Evolver", "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "While existing frameworks mainly focus on mitigating external knowledge gaps, they fail to address a more fundamental limitation: the inability to iteratively refine problem-solving strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0170-015495fe2a", "paper_id": "P0170", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present FEABench, a benchmark to evaluate the ability of large language models (LLMs) and LLM agents to simulate and solve physics, mathematics and engineering problems using finite element analysis (FEA).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0170-e4ac5005b3", "paper_id": "P0170", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our best performing strategy generates executable API calls 88% of the time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0170-4334d22ac9", "paper_id": "P0170", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We present FEABench, a benchmark to evaluate the ability of large language models (LLMs) and LLM agents to simulate and solve physics, mathematics and engineering problems using finite element analysis (FEA).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0170-fc7bc9b610", "paper_id": "P0170", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Building precise simulations of the real world and invoking numerical solvers to answer quantitative problems is an essential requirement in engineering and science.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0170-13181b0530", "paper_id": "P0170", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present FEABench, a benchmark to evaluate the ability of large language models (LLMs) and LLM agents to simulate and solve physics, mathematics and engineering problems using finite element analysis (FEA).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0170-607af02a49", "paper_id": "P0170", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce a comprehensive evaluation scheme to investigate the ability of LLMs to solve these problems end-to-end by reasoning over natural language problem descriptions and operating COMSOL Multiphysics$^\\circledR$, an FEA software, to compute the answers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0170-27165a6af8", "paper_id": "P0170", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We additionally design a language model agent equipped with the ability to interact with the software through its Application Programming Interface (API), examine its outputs and use tools to improve its solutions over multiple iterations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0170-9257baaeb4", "paper_id": "P0170", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our best performing strategy generates executable API calls 88% of the time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0171-8518d9662a", "paper_id": "P0171", "bibkey": "Nitin2025Faultline", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present FaultLine, an LLM agent workflow that uses a set of carefully designed reasoning steps, inspired by aspects of traditional static and dynamic program analysis, to automatically generate PoV test cases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0171-91a368737e", "paper_id": "P0171", "bibkey": "Nitin2025Faultline", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On this dataset, FaultLine is able to generate PoV tests for 16 projects, compared to just 9 for CodeAct 2.1, a popular state-of-the-art open-source agentic framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0171-74188ef933", "paper_id": "P0171", "bibkey": "Nitin2025Faultline", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To evaluate FaultLine, we collate a challenging multi-lingual dataset of 100 known vulnerabilities in Java, C and C++ projects.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0171-6f7ce49ae0", "paper_id": "P0171", "bibkey": "Nitin2025Faultline", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite the critical threat posed by software security vulnerabilities, reports are often incomplete, lacking the proof-of-vulnerability (PoV) tests needed to validate fixes and prevent regressions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0171-81924d16d6", "paper_id": "P0171", "bibkey": "Nitin2025Faultline", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These tests are crucial not only for ensuring patches work, but also for helping developers understand how vulnerabilities can be exploited.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0171-6c37295be6", "paper_id": "P0171", "bibkey": "Nitin2025Faultline", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Generating PoV tests is a challenging problem, requiring reasoning about the flow of control and data through deeply nested levels of a program.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0171-15f22a9a7d", "paper_id": "P0171", "bibkey": "Nitin2025Faultline", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present FaultLine, an LLM agent workflow that uses a set of carefully designed reasoning steps, inspired by aspects of traditional static and dynamic program analysis, to automatically generate PoV test cases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0171-1fc4e30596", "paper_id": "P0171", "bibkey": "Nitin2025Faultline", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Given a software project with an accompanying vulnerability report, FaultLine 1) traces the flow of an input from an externally accessible API (\"source\") to the \"sink\" corresponding to the vulnerability, 2) reasons about the conditions that an input must satisfy in order to traverse the branch conditions encountered along the flow, and 3) uses this reasoning to generate a PoV test case in a feedback-driven loop.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers", "security", "tooling"]}
{"evidence_id": "E-P0171-ab9d23fcf2", "paper_id": "P0171", "bibkey": "Nitin2025Faultline", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "FaultLine does not use language-specific static or dynamic analysis components, which enables it to be used across programming languages.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0172-19a50b297c", "paper_id": "P0172", "bibkey": "Zhang2025Detective", "title": "GEO-Detective: Unveiling Location Privacy Risks in Images with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To explore the full potential and associated privacy risks, we present Geo-Detective, an agent that mimics human reasoning and tool use for image geolocation inference.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0172-a26669bc23", "paper_id": "P0172", "bibkey": "Zhang2025Detective", "title": "GEO-Detective: Unveiling Location Privacy Risks in Images with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In country level geolocation tasks, it achieves an improvement of over 11.1% compared to baseline LLMs, and even at finer grained levels, it still provides around a 5.2% performance gain.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0172-17be361436", "paper_id": "P0172", "bibkey": "Zhang2025Detective", "title": "GEO-Detective: Unveiling Location Privacy Risks in Images with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Meanwhile, when equipped with external clues, GEO-Detective becomes more likely to produce accurate predictions, reducing the \"unknown\" prediction rate by more than 50.6%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0172-340f4d0c09", "paper_id": "P0172", "bibkey": "Zhang2025Detective", "title": "GEO-Detective: Unveiling Location Privacy Risks in Images with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Images shared on social media often expose geographic cues.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0172-bde8737f52", "paper_id": "P0172", "bibkey": "Zhang2025Detective", "title": "GEO-Detective: Unveiling Location Privacy Risks in Images with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While early geolocation methods required expert effort and lacked generalization, the rise of Large Vision Language Models (LVLMs) now enables accurate geolocation even for ordinary users.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0172-6485b84fa1", "paper_id": "P0172", "bibkey": "Zhang2025Detective", "title": "GEO-Detective: Unveiling Location Privacy Risks in Images with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing approaches are not optimized for this task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0172-2d772ab1bd", "paper_id": "P0172", "bibkey": "Zhang2025Detective", "title": "GEO-Detective: Unveiling Location Privacy Risks in Images with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To explore the full potential and associated privacy risks, we present Geo-Detective, an agent that mimics human reasoning and tool use for image geolocation inference.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0172-25e9735fae", "paper_id": "P0172", "bibkey": "Zhang2025Detective", "title": "GEO-Detective: Unveiling Location Privacy Risks in Images with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It follows a procedure with four steps that adaptively selects strategies based on image difficulty and is equipped with specialized tools such as visual reverse search, which emulates how humans gather external geographic clues.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0173-dfcba7a565", "paper_id": "P0173", "bibkey": "Zhu2025Agent", "title": "GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To understand and analyze the agentic reasoning patterns, we propose the concept of agentic reasoning graph: cluster the environment's document embeddings into nodes, and map each tool call to its nearest node to build a reasoning path.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0173-37cf9e4e74", "paper_id": "P0173", "bibkey": "Zhu2025Agent", "title": "GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Although the original tasks are grade-school math problems, we observe that even frontier models like GPT-5 only achieve 67% accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0173-66900cdb54", "paper_id": "P0173", "bibkey": "Zhu2025Agent", "title": "GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Current agent benchmarks often mix agentic reasoning with challenging math reasoning, expert-level knowledge, and other advanced capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0173-c990d1816b", "paper_id": "P0173", "bibkey": "Zhu2025Agent", "title": "GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As LLMs are increasingly deployed as agents, agentic reasoning - the ability to combine tool use, especially search, and reasoning - becomes a critical skill.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0173-6e5060f5ec", "paper_id": "P0173", "bibkey": "Zhu2025Agent", "title": "GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, it is hard to disentangle agentic reasoning when evaluated in complex environments and tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0173-037841bea5", "paper_id": "P0173", "bibkey": "Zhu2025Agent", "title": "GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current agent benchmarks often mix agentic reasoning with challenging math reasoning, expert-level knowledge, and other advanced capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0173-0a4c736710", "paper_id": "P0173", "bibkey": "Zhu2025Agent", "title": "GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To fill this gap, we build a novel benchmark, GSM-Agent, where an LLM agent is required to solve grade-school-level reasoning problems, but is only presented with the question in the prompt without the premises that contain the necessary information to solve the task, and needs to proactively collect that information using tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0173-06e49d6589", "paper_id": "P0173", "bibkey": "Zhu2025Agent", "title": "GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Although the original tasks are grade-school math problems, we observe that even frontier models like GPT-5 only achieve 67% accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0174-77b20954a5", "paper_id": "P0174", "bibkey": "Du2025Generalizable", "title": "Generalizable End-to-End Tool-Use RL with Synthetic CodeGym", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Motivated by this, we introduce CodeGym, a scalable framework that synthesizes diverse, verifiable, and controllable multi-turn tool-use environments for agent RL, enabling LLM agents to explore and master various workflows actively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0174-c880ea04d5", "paper_id": "P0174", "bibkey": "Du2025Generalizable", "title": "Generalizable End-to-End Tool-Use RL with Synthetic CodeGym", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Models of varying sizes and chain-of-thought configurations, trained in CodeGym, exhibit consistent out-of-distribution generalizability; for example, Qwen2.5-32B-Instruct achieves an absolute accuracy gain of 8.7 points on the OOD benchmark $$-Bench.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0174-77619c1dd6", "paper_id": "P0174", "bibkey": "Du2025Generalizable", "title": "Generalizable End-to-End Tool-Use RL with Synthetic CodeGym", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tool-augmented large language models (LLMs), hereafter LLM agents, leverage external tools to solve diverse tasks and interface with the real world.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0174-728c4885d1", "paper_id": "P0174", "bibkey": "Du2025Generalizable", "title": "Generalizable End-to-End Tool-Use RL with Synthetic CodeGym", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, current training practices largely rely on supervised fine-tuning (SFT) over static trajectories or reinforcement learning (RL) on narrow tasks, and generalize poorly beyond development settings, leading to brittleness with new tools and unseen workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0174-625bc2815e", "paper_id": "P0174", "bibkey": "Du2025Generalizable", "title": "Generalizable End-to-End Tool-Use RL with Synthetic CodeGym", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Because code execution reflects many structures of real-world workflows, coding problems provide a natural basis for building agent training environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0174-36579e44f4", "paper_id": "P0174", "bibkey": "Du2025Generalizable", "title": "Generalizable End-to-End Tool-Use RL with Synthetic CodeGym", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Motivated by this, we introduce CodeGym, a scalable framework that synthesizes diverse, verifiable, and controllable multi-turn tool-use environments for agent RL, enabling LLM agents to explore and master various workflows actively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0174-be3abd313e", "paper_id": "P0174", "bibkey": "Du2025Generalizable", "title": "Generalizable End-to-End Tool-Use RL with Synthetic CodeGym", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "CodeGym rewrites static coding problems into interactive environments by extracting atomic functions or logic into callable tools, yielding verifiable tasks that span various tool-execution workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0175-ba2296b38e", "paper_id": "P0175", "bibkey": "Li2025Graphcodeagent", "title": "GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this challenge, we propose GraphCodeAgent, a dual graph-guided LLM agent for retrieval-augmented repo-level code generation, bridging the gap between NL requirements and programming implementations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0175-d568c53e1d", "paper_id": "P0175", "bibkey": "Li2025Graphcodeagent", "title": "GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluated GraphCodeAgent on three advanced LLMs with the two widely-used repo-level code generation benchmarks DevEval and CoderEval.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0175-b4ffe74009", "paper_id": "P0175", "bibkey": "Li2025Graphcodeagent", "title": "GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiment results show that GraphCodeAgent significantly outperforms state-of-the-art baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0175-e124a9d46d", "paper_id": "P0175", "bibkey": "Li2025Graphcodeagent", "title": "GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Writing code requires significant time and effort in software development.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0175-2b0173ae88", "paper_id": "P0175", "bibkey": "Li2025Graphcodeagent", "title": "GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To automate this process, researchers have made substantial progress for code generation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0175-72b6664644", "paper_id": "P0175", "bibkey": "Li2025Graphcodeagent", "title": "GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, large language models (LLMs) have demonstrated remarkable proficiency in function-level code generation, yet their performance significantly degrades in the real-world software development process, where coding tasks are deeply embedded within specific repository contexts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0175-f3e87dcba0", "paper_id": "P0175", "bibkey": "Li2025Graphcodeagent", "title": "GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing studies attempt to use retrieval-augmented code generation (RACG) approaches to mitigate this demand.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0175-0b2e4a5b5e", "paper_id": "P0175", "bibkey": "Li2025Graphcodeagent", "title": "GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, there is a gap between natural language (NL) requirements and programming implementations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0176-ac87dbfe2b", "paper_id": "P0176", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these issues, we propose two distinct and complementary strategies for adapting LLM agents by leveraging environment-specific information available during deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0176-5df3b00510", "paper_id": "P0176", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "For example, on the WebArena multi-site split, this method increases the agent's success rate from 2% to 23%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0176-af945eb2fa", "paper_id": "P0176", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate these strategies across diverse agentic benchmarks, including function calling and web navigation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0176-209ec6be9d", "paper_id": "P0176", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM)-based agents struggle to generalize to novel and complex environments, such as unseen websites or new sets of functions, due to a fundamental mismatch between their pre-training and test-time conditions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0176-cb9f56b1cb", "paper_id": "P0176", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This challenge stems from two distinct failure modes: a syntactic misunderstanding of environment-specific components like observation formats, and a semantic misunderstanding of state-transition dynamics, which are only revealed at test time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0176-47addec32c", "paper_id": "P0176", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these issues, we propose two distinct and complementary strategies for adapting LLM agents by leveraging environment-specific information available during deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0176-4359e69080", "paper_id": "P0176", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "First, an online distributional adaptation method parameterizes environmental nuances by learning a lightweight adaptation vector that biases the model's output distribution, enabling rapid alignment with an environment response format.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0176-f296300dbb", "paper_id": "P0176", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Second, a deployment-time dynamics grounding method employs a persona-driven exploration phase to systematically probe and learn the environment's causal dynamics before task execution, equipping the agent with a nonparametric world model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0177-2c3b7eae80", "paper_id": "P0177", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose Group-in-Group Policy Optimization (GiGPO), a novel RL algorithm that achieves fine-grained credit assignment for LLM agents while preserving the appealing properties of group-based RL: critic-free, low memory, and stable convergence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0177-4b027dfb27", "paper_id": "P0177", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate GiGPO on challenging agent benchmarks, including ALFWorld and WebShop, as well as tool-integrated reasoning on search-augmented QA tasks, using Qwen2.5-1.5B/3B/7B-Instruct.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0177-af024eea6f", "paper_id": "P0177", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Crucially, GiGPO delivers fine-grained per-step credit signals, achieves performance gains of > 12% on ALFWorld and > 9% on WebShop over GRPO, and obtains superior performance on QA tasks (42.1% on 3B and 47.2% on 7B): all while maintaining the same GPU memory overhead, identical LLM rollout, and incurring little to no additional time cost.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0177-dccace20fe", "paper_id": "P0177", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in group-based reinforcement learning (RL) have driven frontier large language models (LLMs) in single-turn tasks like mathematical reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0177-4c1e30b52c", "paper_id": "P0177", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, their scalability to multi-turn LLM agent training remains limited.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0177-930a33b2d7", "paper_id": "P0177", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike static tasks, agent-environment interactions unfold over many steps and often yield sparse or delayed rewards, making credit assignment across individual steps significantly more challenging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0177-95b61e4b66", "paper_id": "P0177", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we propose Group-in-Group Policy Optimization (GiGPO), a novel RL algorithm that achieves fine-grained credit assignment for LLM agents while preserving the appealing properties of group-based RL: critic-free, low memory, and stable convergence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0177-85a2626c89", "paper_id": "P0177", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "GiGPO introduces a two-level structure for estimating relative advantage: (i) At the episode-level, GiGPO computes macro relative advantages based on groups of complete trajectories; (ii) At the step-level, GiGPO introduces an anchor state grouping mechanism that retroactively constructs step-level groups by identifying repeated environment states across trajectories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0178-756c2663f6", "paper_id": "P0178", "bibkey": "Yu2025Infiagent", "title": "InfiAgent: Self-Evolving Pyramid Agent Framework for Infinite Scenarios", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we propose \\textbf{InfiAgent}, a Pyramid-like DAG-based Multi-Agent Framework that can be applied to \\textbf{infi}nite scenarios, which introduces several key innovations: a generalized \"agent-as-a-tool\" mechanism that automatically decomposes complex agents into hierarchical multi-agent systems; a dual-audit mechanism that ensures the quality and stability of task completion; an agent routing function that enables efficient task-agent matching; and an agent self-evolution mechanism that autonomously restructures the agent DAG based on new tasks, poor performance, or optimization opportunities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0178-d099f5e3ee", "paper_id": "P0178", "bibkey": "Yu2025Infiagent", "title": "InfiAgent: Self-Evolving Pyramid Agent Framework for Infinite Scenarios", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluations on multiple benchmarks demonstrate that InfiAgent achieves 9.9\\% higher performance compared to ADAS (similar auto-generated agent framework), while a case study of the AI research assistant InfiHelper shows that it generates scientific papers that have received recognition from human reviewers at top-tier IEEE conferences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0178-d2e33c86f7", "paper_id": "P0178", "bibkey": "Yu2025Infiagent", "title": "InfiAgent: Self-Evolving Pyramid Agent Framework for Infinite Scenarios", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents have demonstrated remarkable capabilities in organizing and executing complex tasks, and many such agents are now widely used in various application scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0178-d9af2c49f8", "paper_id": "P0178", "bibkey": "Yu2025Infiagent", "title": "InfiAgent: Self-Evolving Pyramid Agent Framework for Infinite Scenarios", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, developing these agents requires carefully designed workflows, carefully crafted prompts, and iterative tuning, which requires LLM techniques and domain-specific expertise.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0178-60ca4843ef", "paper_id": "P0178", "bibkey": "Yu2025Infiagent", "title": "InfiAgent: Self-Evolving Pyramid Agent Framework for Infinite Scenarios", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These hand-crafted limitations hinder the scalability and cost-effectiveness of LLM agents across a wide range of industries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0178-7c63903fbe", "paper_id": "P0178", "bibkey": "Yu2025Infiagent", "title": "InfiAgent: Self-Evolving Pyramid Agent Framework for Infinite Scenarios", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these challenges, we propose \\textbf{InfiAgent}, a Pyramid-like DAG-based Multi-Agent Framework that can be applied to \\textbf{infi}nite scenarios, which introduces several key innovations: a generalized \"agent-as-a-tool\" mechanism that automatically decomposes complex agents into hierarchical multi-agent systems; a dual-audit mechanism that ensures the quality and stability of task completion; an agent routing function that enables efficient task-agent matching; and an agent self-evolution mechanism that autonomously restructures the agent DAG based on new tasks, poor performance, or optimization opportunities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0178-08a176ebcf", "paper_id": "P0178", "bibkey": "Yu2025Infiagent", "title": "InfiAgent: Self-Evolving Pyramid Agent Framework for Infinite Scenarios", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Furthermore, InfiAgent's atomic task design supports agent parallelism, significantly improving execution efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0178-669943306c", "paper_id": "P0178", "bibkey": "Yu2025Infiagent", "title": "InfiAgent: Self-Evolving Pyramid Agent Framework for Infinite Scenarios", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "These hand-crafted limitations hinder the scalability and cost-effectiveness of LLM agents across a wide range of industries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0179-8dcf87d918", "paper_id": "P0179", "bibkey": "Wang2025Information", "title": "Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose Information Gain-based Policy Optimization (IGPO), a simple yet effective RL framework that provides dense and intrinsic supervision for multi-turn agent training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0179-5035839252", "paper_id": "P0179", "bibkey": "Wang2025Information", "title": "Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments on both in-domain and out-of-domain benchmarks demonstrate that IGPO consistently outperforms strong baselines in multi-turn scenarios, achieving higher accuracy and improved sample efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0179-7ac738fb1f", "paper_id": "P0179", "bibkey": "Wang2025Information", "title": "Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In this paper, we propose Information Gain-based Policy Optimization (IGPO), a simple yet effective RL framework that provides dense and intrinsic supervision for multi-turn agent training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0179-4d6b34a461", "paper_id": "P0179", "bibkey": "Wang2025Information", "title": "Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM)-based agents are increasingly trained with reinforcement learning (RL) to enhance their ability to interact with external environments through tool use, particularly in search-based settings that require multi-turn reasoning and knowledge acquisition.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0179-bb95849313", "paper_id": "P0179", "bibkey": "Wang2025Information", "title": "Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing approaches typically rely on outcome-based rewards that are only provided at the final answer.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0179-34a38c81b5", "paper_id": "P0179", "bibkey": "Wang2025Information", "title": "Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This reward sparsity becomes particularly problematic in multi-turn settings, where long trajectories exacerbate two critical issues: (i) advantage collapse, where all rollouts receive identical rewards and provide no useful learning signals, and (ii) lack of fine-grained credit assignment, where dependencies between turns are obscured, especially in long-horizon tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0179-2d903004e4", "paper_id": "P0179", "bibkey": "Wang2025Information", "title": "Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose Information Gain-based Policy Optimization (IGPO), a simple yet effective RL framework that provides dense and intrinsic supervision for multi-turn agent training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0179-a03c9f3823", "paper_id": "P0179", "bibkey": "Wang2025Information", "title": "Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "IGPO models each interaction turn as an incremental process of acquiring information about the ground truth, and defines turn-level rewards as the marginal increase in the policy's probability of producing the correct answer.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0180-d477baa444", "paper_id": "P0180", "bibkey": "Baker2025Larc", "title": "LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Here, we present LARC, the first LLM-based Agentic framework for Retrosynthesis planning under Constraints.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0180-31041fd2ac", "paper_id": "P0180", "bibkey": "Baker2025Larc", "title": "LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "LARC achieves a 72.9% success rate on these tasks, vastly outperforming LLM baselines and approaching human expert-level success in substantially less time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0180-55a2731a38", "paper_id": "P0180", "bibkey": "Baker2025Larc", "title": "LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We rigorously evaluate LARC on a carefully curated set of 48 constrained retrosynthesis planning tasks across 3 constraint types.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0180-3f3b60279f", "paper_id": "P0180", "bibkey": "Baker2025Larc", "title": "LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agent evaluators leverage specialized tools to ground the rational decision-making of LLMs, making them well-suited to aid in scientific discoveries, such as constrained retrosynthesis planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0180-acf04b0b46", "paper_id": "P0180", "bibkey": "Baker2025Larc", "title": "LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Constrained retrosynthesis planning is an essential, yet challenging, process within chemistry for identifying synthetic routes from commercially available starting materials to desired target molecules, subject to practical constraints.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0180-996f951fd3", "paper_id": "P0180", "bibkey": "Baker2025Larc", "title": "LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Here, we present LARC, the first LLM-based Agentic framework for Retrosynthesis planning under Constraints.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0180-a355aa1f0e", "paper_id": "P0180", "bibkey": "Baker2025Larc", "title": "LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LARC incorporates agentic constraint evaluation, through an Agent-as-a-Judge, directly into the retrosynthesis planning process, using agentic feedback grounded in tool-based reasoning to guide and constrain route generation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0180-c1d4eb230d", "paper_id": "P0180", "bibkey": "Baker2025Larc", "title": "LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We rigorously evaluate LARC on a carefully curated set of 48 constrained retrosynthesis planning tasks across 3 constraint types.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0181-e06391c6c4", "paper_id": "P0181", "bibkey": "Akhond2025Assisted", "title": "LLM Assisted Coding with Metamorphic Specification Mutation Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this challenge, we present CodeMetaAgent (CMA), a metamorphic relation-driven LLM agent that systematically refines task specifications and generates semantically constrained test cases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0181-9014430618", "paper_id": "P0181", "bibkey": "Akhond2025Assisted", "title": "LLM Assisted Coding with Metamorphic Specification Mutation Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "It improved code generation accuracy by up to 17% and achieved code coverage gains of up to 99.81%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0181-67c3ffbee9", "paper_id": "P0181", "bibkey": "Akhond2025Assisted", "title": "LLM Assisted Coding with Metamorphic Specification Mutation Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our framework has been evaluated on the HumanEval-Pro, MBPP-Pro, and SWE-Bench_Lite datasets using the GPT-4o, Mistral Large, GPT-OSS, and Qwen3-Coder models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0181-2d94e45848", "paper_id": "P0181", "bibkey": "Akhond2025Assisted", "title": "LLM Assisted Coding with Metamorphic Specification Mutation Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Metamorphic Relations (MRs) serve as a foundational mechanism for generating semantically equivalent mutations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0181-a532ce1ce3", "paper_id": "P0181", "bibkey": "Akhond2025Assisted", "title": "LLM Assisted Coding with Metamorphic Specification Mutation Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Software engineering has advanced significantly in recent years with the advent of Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0181-f9fa9c326b", "paper_id": "P0181", "bibkey": "Akhond2025Assisted", "title": "LLM Assisted Coding with Metamorphic Specification Mutation Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the reliability of LLMs in software engineering is often compromised by ambiguities and inconsistencies due to improper user specification.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0181-0625ebf729", "paper_id": "P0181", "bibkey": "Akhond2025Assisted", "title": "LLM Assisted Coding with Metamorphic Specification Mutation Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this challenge, we present CodeMetaAgent (CMA), a metamorphic relation-driven LLM agent that systematically refines task specifications and generates semantically constrained test cases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0181-39bf4e90db", "paper_id": "P0181", "bibkey": "Akhond2025Assisted", "title": "LLM Assisted Coding with Metamorphic Specification Mutation Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our proposed framework uses MRs with LLMs to improve generation consistency and reduce variability caused by specifications, unlike the traditional use of MRs as post validations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0182-7305a8073f", "paper_id": "P0182", "bibkey": "Zhang2025Llms", "title": "LLMs as Firmware Experts: A Runtime-Grown Tree-of-Agents Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Models (LLMs) and their agent systems have recently demonstrated strong potential in automating code reasoning and vulnerability detection.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0182-58224070ca", "paper_id": "P0182", "bibkey": "Zhang2025Llms", "title": "LLMs as Firmware Experts: A Runtime-Grown Tree-of-Agents Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Compared to state-of-the-art (SOTA) security tools, FIRMHIVE identifies about 1.5x more vulnerabilities (1,802 total) and achieves 71% precision, representing significant improvements in both yield and fidelity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "security", "tooling"]}
{"evidence_id": "E-P0182-fcac4c80ba", "paper_id": "P0182", "bibkey": "Zhang2025Llms", "title": "LLMs as Firmware Experts: A Runtime-Grown Tree-of-Agents Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "FIRMHIVE introduces two key mechanisms: (1) transforming delegation into a per-agent, executable primitive and (2) constructing a runtime Tree of Agents (ToA) for decentralized coordination.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0182-834fd94cd2", "paper_id": "P0182", "bibkey": "Zhang2025Llms", "title": "LLMs as Firmware Experts: A Runtime-Grown Tree-of-Agents Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) and their agent systems have recently demonstrated strong potential in automating code reasoning and vulnerability detection.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0182-91d994871a", "paper_id": "P0182", "bibkey": "Zhang2025Llms", "title": "LLMs as Firmware Experts: A Runtime-Grown Tree-of-Agents Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, when applied to large-scale firmware, their performance degrades due to the binary nature of firmware, complex dependency structures, and heterogeneous components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0182-047649948c", "paper_id": "P0182", "bibkey": "Zhang2025Llms", "title": "LLMs as Firmware Experts: A Runtime-Grown Tree-of-Agents Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this challenge, this paper presents FIRMHIVE, a recursive agent hive that enables LLMs to act as autonomous firmware security analysts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0182-9b9551d1df", "paper_id": "P0182", "bibkey": "Zhang2025Llms", "title": "LLMs as Firmware Experts: A Runtime-Grown Tree-of-Agents Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "FIRMHIVE introduces two key mechanisms: (1) transforming delegation into a per-agent, executable primitive and (2) constructing a runtime Tree of Agents (ToA) for decentralized coordination.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0182-0e742b8193", "paper_id": "P0182", "bibkey": "Zhang2025Llms", "title": "LLMs as Firmware Experts: A Runtime-Grown Tree-of-Agents Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluate FIRMHIVE using real-world firmware images obtained from publicly available datasets, covering five representative security analysis tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0183-eba413d010", "paper_id": "P0183", "bibkey": "Yano2025Lamdagent", "title": "LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we introduce LaMDAgent (short for Language Model Developing Agent), a novel framework that autonomously constructs and optimizes full post-training pipelines through the use of LLM-based agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0183-49a56990f5", "paper_id": "P0183", "bibkey": "Yano2025Lamdagent", "title": "LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments show that LaMDAgent improves tool-use accuracy by 9.0 points while preserving instruction-following capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0183-78bde774bf", "paper_id": "P0183", "bibkey": "Yano2025Lamdagent", "title": "LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "LaMDAgent systematically explores diverse model generation techniques, datasets, and hyperparameter configurations, leveraging task-based feedback to discover high-performing pipelines with minimal human intervention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0183-d8bac8b402", "paper_id": "P0183", "bibkey": "Yano2025Lamdagent", "title": "LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have demonstrated exceptional performance across a wide range of tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0183-ac6496144c", "paper_id": "P0183", "bibkey": "Yano2025Lamdagent", "title": "LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To further tailor LLMs to specific domains or applications, post-training techniques such as Supervised Fine-Tuning (SFT), Preference Learning, and model merging are commonly employed.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0183-8e4422d0ae", "paper_id": "P0183", "bibkey": "Yano2025Lamdagent", "title": "LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While each of these methods has been extensively studied in isolation, the automated construction of complete post-training pipelines remains an underexplored area.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0183-20b9135ccd", "paper_id": "P0183", "bibkey": "Yano2025Lamdagent", "title": "LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing approaches typically rely on manual design or focus narrowly on optimizing individual components, such as data ordering or merging strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0183-3364ef1aa4", "paper_id": "P0183", "bibkey": "Yano2025Lamdagent", "title": "LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we introduce LaMDAgent (short for Language Model Developing Agent), a novel framework that autonomously constructs and optimizes full post-training pipelines through the use of LLM-based agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0184-cdec58bfbb", "paper_id": "P0184", "bibkey": "Li2025Learn", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Inspired by centralized training with decentralized execution in multi-agent reinforcement learning, we propose a \\textit{Learn as Individuals, Evolve as a Team (LIET)} paradigm for multi-agent LLMs adaptation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0184-d19d8e1143", "paper_id": "P0184", "bibkey": "Li2025Learn", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "At the individual level, LLM agents learn a local utility function from exploratory datasets to better comprehend the embodied environment, which is then queried during test time to support informed decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0184-1dd544863c", "paper_id": "P0184", "bibkey": "Li2025Learn", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments on Communicative Watch-And-Help and ThreeD-World Multi-Agent Transport benchmarks demonstrate that LIET, instantiated with both LLaMA and GPT-4o, outperforms existing baselines and exhibits strong cooperative planning abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0184-c4c7a48c82", "paper_id": "P0184", "bibkey": "Li2025Learn", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) possess extensive knowledge bases and strong reasoning capabilities, making them promising tools for complex, multi-agent planning in embodied environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0184-da8f148a2b", "paper_id": "P0184", "bibkey": "Li2025Learn", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, despite LLMs' advanced abilities and the sophisticated modular design of agentic methods, existing LLM-based planning algorithms remain limited by weak adaptation capabilities to multi-agent embodied scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0184-d9a6ff4c1a", "paper_id": "P0184", "bibkey": "Li2025Learn", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We address this limitation by introducing a framework that enables LLM agents to learn and evolve both before and during test time, equipping them with environment-relevant knowledge for better planning and enhanced communication for improved cooperation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0184-38240e4a8b", "paper_id": "P0184", "bibkey": "Li2025Learn", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Inspired by centralized training with decentralized execution in multi-agent reinforcement learning, we propose a \\textit{Learn as Individuals, Evolve as a Team (LIET)} paradigm for multi-agent LLMs adaptation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0184-1c9f5b4881", "paper_id": "P0184", "bibkey": "Li2025Learn", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "At the individual level, LLM agents learn a local utility function from exploratory datasets to better comprehend the embodied environment, which is then queried during test time to support informed decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0184-01f439b837", "paper_id": "P0184", "bibkey": "Li2025Learn", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "We address this limitation by introducing a framework that enables LLM agents to learn and evolve both before and during test time, equipping them with environment-relevant knowledge for better planning and enhanced communication for improved cooperation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0185-ad5a194896", "paper_id": "P0185", "bibkey": "Li2025Leveraging", "title": "Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these two aforementioned issues, we propose a three-stage meta-judge selection pipeline: 1) developing a comprehensive rubric with GPT-4 and human experts, 2) using three advanced LLM agents to score judgments, and 3) applying a threshold to filter out low-scoring judgments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#method"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0185-36a8b2675c", "paper_id": "P0185", "bibkey": "Li2025Leveraging", "title": "Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To address these two aforementioned issues, we propose a three-stage meta-judge selection pipeline: 1) developing a comprehensive rubric with GPT-4 and human experts, 2) using three advanced LLM agents to score judgments, and 3) applying a threshold to filter out low-scoring judgments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0185-82b5e4eda3", "paper_id": "P0185", "bibkey": "Li2025Leveraging", "title": "Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experimental results on the JudgeBench dataset show about 15.55\\% improvement compared to raw judgments and about 8.37\\% improvement over the single-agent baseline.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0185-9ab7abdc41", "paper_id": "P0185", "bibkey": "Li2025Leveraging", "title": "Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are being widely applied across various fields, but as tasks become more complex, evaluating their responses is increasingly challenging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0185-41d5ef99a1", "paper_id": "P0185", "bibkey": "Li2025Leveraging", "title": "Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Compared to human evaluators, the use of LLMs to support performance evaluation offers a more efficient alternative.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0185-fb427f3d2c", "paper_id": "P0185", "bibkey": "Li2025Leveraging", "title": "Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, most studies focus mainly on aligning LLMs' judgments with human preferences, overlooking the existence of biases and mistakes in human judgment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0185-59c5f7311c", "paper_id": "P0185", "bibkey": "Li2025Leveraging", "title": "Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Furthermore, how to select suitable LLM judgments given multiple potential LLM responses remains underexplored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0185-bc3e0d61d5", "paper_id": "P0185", "bibkey": "Li2025Leveraging", "title": "Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these two aforementioned issues, we propose a three-stage meta-judge selection pipeline: 1) developing a comprehensive rubric with GPT-4 and human experts, 2) using three advanced LLM agents to score judgments, and 3) applying a threshold to filter out low-scoring judgments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0186-8bcb673a7d", "paper_id": "P0186", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#method"}, "confidence": "medium", "tags": ["evaluation", "security", "tooling"]}
{"evidence_id": "E-P0186-d6095e10e9", "paper_id": "P0186", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed attacks; (2) an evaluation harness that executes attacks by running real tools (both benign and malicious) via MCP rather than simulation; and (3) a robustness metric that quantifies the trade-off between security and performance: Net Resilient Performance (NRP).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0186-7a6ec4daed", "paper_id": "P0186", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate nine popular LLM agents across 10 domains and 400+ tools, producing 2,000 attack instances.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0186-04669fc5b8", "paper_id": "P0186", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The Model Context Protocol (MCP) standardizes how large language model (LLM) agents discover, describe, and call external tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0186-e58dfe941a", "paper_id": "P0186", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While MCP unlocks broad interoperability, it also enlarges the attack surface by making tools first-class, composable objects with natural-language metadata, and standardized I/O.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#summary_bullets[1]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0186-e61edf509b", "paper_id": "P0186", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "security", "tooling"]}
{"evidence_id": "E-P0186-f8cf967a0d", "paper_id": "P0186", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed attacks; (2) an evaluation harness that executes attacks by running real tools (both benign and malicious) via MCP rather than simulation; and (3) a robustness metric that quantifies the trade-off between security and performance: Net Resilient Performance (NRP).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0186-65e66ae9c1", "paper_id": "P0186", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluate nine popular LLM agents across 10 domains and 400+ tools, producing 2,000 attack instances.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0187-0c0c7fd177", "paper_id": "P0187", "bibkey": "Wang2025Bench", "title": "MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce MCP-Bench, a benchmark for evaluating large language models (LLMs) on realistic, multi-step tasks that demand tool use, cross-tool coordination, precise parameter control, and planning/reasoning for solving tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0187-9c914b3dcf", "paper_id": "P0187", "bibkey": "Wang2025Bench", "title": "MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Built on the Model Context Protocol (MCP), MCP-Bench connects LLMs to 28 representative live MCP servers spanning 250 tools across domains such as finance, traveling, scientific computing, and academic search.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0187-eccef7821e", "paper_id": "P0187", "bibkey": "Wang2025Bench", "title": "MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on 20 advanced LLMs reveal persistent challenges in MCP-Bench.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0187-a68e136cd4", "paper_id": "P0187", "bibkey": "Wang2025Bench", "title": "MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce MCP-Bench, a benchmark for evaluating large language models (LLMs) on realistic, multi-step tasks that demand tool use, cross-tool coordination, precise parameter control, and planning/reasoning for solving tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0187-cc168f3929", "paper_id": "P0187", "bibkey": "Wang2025Bench", "title": "MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Built on the Model Context Protocol (MCP), MCP-Bench connects LLMs to 28 representative live MCP servers spanning 250 tools across domains such as finance, traveling, scientific computing, and academic search.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0187-186916fe6b", "paper_id": "P0187", "bibkey": "Wang2025Bench", "title": "MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike prior API-based benchmarks, each MCP server provides a set of complementary tools designed to work together, enabling the construction of authentic, multi-step tasks with rich input-output coupling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0187-876d9ef4d9", "paper_id": "P0187", "bibkey": "Wang2025Bench", "title": "MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tasks in MCP-Bench test agents' ability to retrieve relevant tools from fuzzy instructions without explicit tool names, plan multi-hop execution trajectories for complex objectives, ground responses in intermediate tool outputs, and orchestrate cross-domain workflows - capabilities not adequately evaluated by existing benchmarks that rely on explicit tool specifications, shallow few-step workflows, and isolated domain operations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0187-2a5dffe766", "paper_id": "P0187", "bibkey": "Wang2025Bench", "title": "MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose a multi-faceted evaluation framework covering tool-level schema understanding and usage, trajectory-level planning, and task completion.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0188-45466fa20e", "paper_id": "P0188", "bibkey": "Wang2025Flow", "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To overcome these limitations, we introduce MCP-Flow, an automated web-agent-driven pipeline for large-scale server discovery, data synthesis, and model training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0188-07f9bd6a8b", "paper_id": "P0188", "bibkey": "Wang2025Flow", "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "MCP-Flow collects and filters data from 1166 servers and 11536 tools, producing 68733 high-quality instruction-function call pairs and 6439 trajectories, far exceeding prior work in scale and diversity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0188-172333f7c5", "paper_id": "P0188", "bibkey": "Wang2025Flow", "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) increasingly rely on external tools to perform complex, realistic tasks, yet their ability to utilize the rapidly expanding Model Contextual Protocol (MCP) ecosystem remains limited.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0188-38a71d165e", "paper_id": "P0188", "bibkey": "Wang2025Flow", "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing MCP research covers few servers, depends on costly manual curation, and lacks training support, hindering progress toward real-world deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0188-715be99d2c", "paper_id": "P0188", "bibkey": "Wang2025Flow", "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To overcome these limitations, we introduce MCP-Flow, an automated web-agent-driven pipeline for large-scale server discovery, data synthesis, and model training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0188-47a7dea4cf", "paper_id": "P0188", "bibkey": "Wang2025Flow", "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "MCP-Flow collects and filters data from 1166 servers and 11536 tools, producing 68733 high-quality instruction-function call pairs and 6439 trajectories, far exceeding prior work in scale and diversity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0188-582811f7c8", "paper_id": "P0188", "bibkey": "Wang2025Flow", "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Extensive experiments demonstrate MCP-Flow's effectiveness in driving superior MCP tool selection, function-call generation, and enhanced agentic task performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0188-c1e63c5b8f", "paper_id": "P0188", "bibkey": "Wang2025Flow", "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To overcome these limitations, we introduce MCP-Flow, an automated web-agent-driven pipeline for large-scale server discovery, data synthesis, and model training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#limitations[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0189-155255a855", "paper_id": "P0189", "bibkey": "Gao2025Radar", "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "As Large Language Models (LLMs) evolve from passive text generators to active reasoning agents capable of interacting with external tools, the Model Context Protocol (MCP) has emerged as a key standardized framework for dynamic tool discovery and orchestration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0189-419e1464da", "paper_id": "P0189", "bibkey": "Gao2025Radar", "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "MCP-RADAR features a challenging dataset of 507 tasks spanning six domains: mathematical reasoning, web search, email, calendar, file management, and terminal operations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0189-55cf3ec701", "paper_id": "P0189", "bibkey": "Gao2025Radar", "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Despite its widespread industry adoption, existing evaluation methods do not adequately assess tool utilization capabilities under this new paradigm.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0189-f3b1559bcc", "paper_id": "P0189", "bibkey": "Gao2025Radar", "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As Large Language Models (LLMs) evolve from passive text generators to active reasoning agents capable of interacting with external tools, the Model Context Protocol (MCP) has emerged as a key standardized framework for dynamic tool discovery and orchestration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0189-daf259cf01", "paper_id": "P0189", "bibkey": "Gao2025Radar", "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite its widespread industry adoption, existing evaluation methods do not adequately assess tool utilization capabilities under this new paradigm.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0189-ca089d06c0", "paper_id": "P0189", "bibkey": "Gao2025Radar", "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, this paper introduces MCP-RADAR, the first comprehensive benchmark specifically designed to evaluate LLM performance within the MCP framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0189-afa24ec1b8", "paper_id": "P0189", "bibkey": "Gao2025Radar", "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "MCP-RADAR features a challenging dataset of 507 tasks spanning six domains: mathematical reasoning, web search, email, calendar, file management, and terminal operations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0189-de724ce1af", "paper_id": "P0189", "bibkey": "Gao2025Radar", "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It quantifies performance based on two primary criteria: answer correctness and operational accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0190-84445d1a19", "paper_id": "P0190", "bibkey": "Luo2025Universe", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this critical gap, we introduce MCP-Universe, the first comprehensive benchmark specifically designed to evaluate LLMs in realistic and hard tasks through interaction with real-world MCP servers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0190-619c307f9a", "paper_id": "P0190", "bibkey": "Luo2025Universe", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through extensive evaluation of leading LLMs, we find that even SOTA models such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit significant performance limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0190-9866fbcaba", "paper_id": "P0190", "bibkey": "Luo2025Universe", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our benchmark encompasses 6 core domains spanning 11 different MCP servers: Location Navigation, Repository Management, Financial Analysis, 3D Design, Browser Automation, and Web Searching.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0190-7fb7d586be", "paper_id": "P0190", "bibkey": "Luo2025Universe", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The Model Context Protocol has emerged as a transformative standard for connecting large language models to external data sources and tools, rapidly gaining adoption across major AI providers and development platforms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0190-dee38d5a65", "paper_id": "P0190", "bibkey": "Luo2025Universe", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing benchmarks are overly simplistic and fail to capture real application challenges such as long-horizon reasoning and large, unfamiliar tool spaces.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0190-e0c143baab", "paper_id": "P0190", "bibkey": "Luo2025Universe", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this critical gap, we introduce MCP-Universe, the first comprehensive benchmark specifically designed to evaluate LLMs in realistic and hard tasks through interaction with real-world MCP servers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0190-ec31ee7373", "paper_id": "P0190", "bibkey": "Luo2025Universe", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our benchmark encompasses 6 core domains spanning 11 different MCP servers: Location Navigation, Repository Management, Financial Analysis, 3D Design, Browser Automation, and Web Searching.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0190-a42030b436", "paper_id": "P0190", "bibkey": "Luo2025Universe", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To ensure rigorous evaluation, we implement execution-based evaluators, including format evaluators for agent format compliance, static evaluators for time-invariant content matching, and dynamic evaluators that automatically retrieve real-time ground truth for temporally sensitive tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0190-3c65d38a2a", "paper_id": "P0190", "bibkey": "Luo2025Universe", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Through extensive evaluation of leading LLMs, we find that even SOTA models such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit significant performance limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#limitations[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0191-312a342670", "paper_id": "P0191", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0191-3a4792de2b", "paper_id": "P0191", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0191-67d5c4342c", "paper_id": "P0191", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0191-875ce4a305", "paper_id": "P0191", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) are increasingly serving as autonomous agents, and their utilization of external tools via the Model Context Protocol (MCP) is considered a future trend.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0191-cda5a4d930", "paper_id": "P0191", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0191-dee80dc348", "paper_id": "P0191", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0191-e28c680e85", "paper_id": "P0191", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We construct a dataset containing authentic tasks and simulated MCP tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0191-fe43274f4d", "paper_id": "P0191", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The evaluation employs a dynamic sandbox environment that presents agents with candidate tool lists containing distractors, thereby testing their tool selection and discrimination abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "security", "tooling"]}
{"evidence_id": "E-P0191-f7a14123f9", "paper_id": "P0191", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#limitations[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0192-13324f44e8", "paper_id": "P0192", "bibkey": "Testini2025Measuring", "title": "Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Data science aims to extract insights from data to support decision-making processes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0192-929e10a17b", "paper_id": "P0192", "bibkey": "Testini2025Measuring", "title": "Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We find (1) a dominant focus on a small subset of goal-oriented activities, largely ignoring data management and exploratory activities; (2) a concentration on pure assistance or fully autonomous agents, without considering intermediate levels of human-AI collaboration; and (3) an emphasis on human substitution, therefore neglecting the possibility of higher levels of automation thanks to task transformation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0192-ae7e925d66", "paper_id": "P0192", "bibkey": "Testini2025Measuring", "title": "Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In this paper, we survey the evaluation of LLM assistants and agents for data science.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0192-1e00c6ee35", "paper_id": "P0192", "bibkey": "Testini2025Measuring", "title": "Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Data science aims to extract insights from data to support decision-making processes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0192-7ac2af2ef7", "paper_id": "P0192", "bibkey": "Testini2025Measuring", "title": "Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, Large Language Models (LLMs) have been increasingly used as assistants for data science, by suggesting ideas, techniques and small code snippets, or for the interpretation of results and reporting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0192-5b8148477d", "paper_id": "P0192", "bibkey": "Testini2025Measuring", "title": "Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Proper automation of some data-science activities is now promised by the rise of LLM agents, i.e., AI systems powered by an LLM equipped with additional affordances--such as code execution and knowledge bases--that can perform self-directed actions and interact with digital environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0192-6555fc5db9", "paper_id": "P0192", "bibkey": "Testini2025Measuring", "title": "Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we survey the evaluation of LLM assistants and agents for data science.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0192-e04834a4d2", "paper_id": "P0192", "bibkey": "Testini2025Measuring", "title": "Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We find (1) a dominant focus on a small subset of goal-oriented activities, largely ignoring data management and exploratory activities; (2) a concentration on pure assistance or fully autonomous agents, without considering intermediate levels of human-AI collaboration; and (3) an emphasis on human substitution, therefore neglecting the possibility of higher levels of automation thanks to task transformation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0193-2941d61a03", "paper_id": "P0193", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this need, we present \\textbf{MedicalOS}, a unified agent-based operational system designed as such a domain-specific abstract layer for healthcare.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0193-6075ffa788", "paper_id": "P0193", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We empirically validate MedicalOS on 214 patient cases across 22 specialties, demonstrating high diagnostic accuracy and confidence, clinically sound examination requests, and consistent generation of structured reports and medication recommendations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0193-26f893d6cd", "paper_id": "P0193", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This shift highlights the need for an abstraction layer, an agent-computer interface, that translates human language into machine-executable commands.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0193-3b9601b81e", "paper_id": "P0193", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Decades' advances in digital health technologies, such as electronic health records, have largely streamlined routine clinical processes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0193-cbfa085708", "paper_id": "P0193", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Yet, most these systems are still hard to learn and use: Clinicians often face the burden of managing multiple tools, repeating manual actions for each patient, navigating complicated UI trees to locate functions, and spending significant time on administration instead of caring for patients.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0193-27adc3f95a", "paper_id": "P0193", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The recent rise of large language model (LLM) based agents demonstrates exceptional capability in coding and computer operation, revealing the potential for humans to interact with operating systems and software not by direct manipulation, but by instructing agents through natural language.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0193-c375334acd", "paper_id": "P0193", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This shift highlights the need for an abstraction layer, an agent-computer interface, that translates human language into machine-executable commands.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0193-eb86510027", "paper_id": "P0193", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In digital healthcare, however, requires a more domain-specific abstractions that strictly follow trusted clinical guidelines and procedural standards to ensure safety, transparency, and compliance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0194-d4a4183b68", "paper_id": "P0194", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce MemTool, a short-term memory framework enabling LLM agents to dynamically manage tools or MCP server contexts across multi-turn conversations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#method"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0194-35271418ac", "paper_id": "P0194", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0194-38dc800de9", "paper_id": "P0194", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "MemTool offers three agentic architectures: 1) Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow Mode, providing deterministic control without autonomy, and 3) Hybrid Mode, combining autonomous and deterministic control.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0194-64ae1a2cfc", "paper_id": "P0194", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents have shown significant autonomous capabilities in dynamically searching and incorporating relevant tools or Model Context Protocol (MCP) servers for individual queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0194-6243350e0e", "paper_id": "P0194", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, fixed context windows limit effectiveness in multi-turn interactions requiring repeated, independent tool usage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0194-50ae553d5f", "paper_id": "P0194", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce MemTool, a short-term memory framework enabling LLM agents to dynamically manage tools or MCP server contexts across multi-turn conversations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0194-f391e41a6e", "paper_id": "P0194", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "MemTool offers three agentic architectures: 1) Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow Mode, providing deterministic control without autonomy, and 3) Hybrid Mode, combining autonomous and deterministic control.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0194-95db5fe235", "paper_id": "P0194", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0195-101f24dcb3", "paper_id": "P0195", "bibkey": "Bai2025Merge", "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Optimizing artificial intelligence (AI) for dynamic environments remains a fundamental challenge in machine learning research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0195-075a0ecd31", "paper_id": "P0195", "bibkey": "Bai2025Merge", "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The single-agent system achieved substantial improvements, with an average increase of 473.2 points per cycle, and with clear upward trends (correlation $$=0.607) across training cycles.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0195-c581d566a4", "paper_id": "P0195", "bibkey": "Bai2025Merge", "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In this paper, we examine evolutionary training methods for optimizing AI to solve the game 2048, a 2D sliding puzzle.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0195-0cd4a82803", "paper_id": "P0195", "bibkey": "Bai2025Merge", "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Optimizing artificial intelligence (AI) for dynamic environments remains a fundamental challenge in machine learning research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0195-4754270a05", "paper_id": "P0195", "bibkey": "Bai2025Merge", "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we examine evolutionary training methods for optimizing AI to solve the game 2048, a 2D sliding puzzle.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0195-49dbafeba8", "paper_id": "P0195", "bibkey": "Bai2025Merge", "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "2048, with its mix of strategic gameplay and stochastic elements, presents an ideal playground for studying decision-making, long-term planning, and dynamic adaptation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0195-ffa15fecc4", "paper_id": "P0195", "bibkey": "Bai2025Merge", "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We implemented two distinct systems: a two-agent metaprompting system where a \"thinker\" large language model (LLM) agent refines gameplay strategies for an \"executor\" LLM agent, and a single-agent system based on refining a value function for a limited Monte Carlo Tree Search.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0195-c8a1985d62", "paper_id": "P0195", "bibkey": "Bai2025Merge", "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We also experimented with rollback features to avoid performance degradation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0196-89c733716e", "paper_id": "P0196", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work we introduce Meta-Policy Reflexion (MPR): a hybrid framework that consolidates LLM-generated reflections into a structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at inference time through two complementary mechanisms soft memory-guided decoding and hard rule admissibility checks(HAC).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0196-8a3b04d40f", "paper_id": "P0196", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We formalize the MPM representation, present algorithms for update and decoding, and validate the approach in a text-based agent environment following the experimental protocol described in the provided implementation (AlfWorld-based).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0196-edaf17f9f6", "paper_id": "P0196", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Empirical results reported in the supplied material indicate consistent gains in execution accuracy and robustness when compared to Reflexion baselines; rule admissibility further improves stability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0196-6cc12d806b", "paper_id": "P0196", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents achieve impressive single-task performance but commonly exhibit repeated failures, inefficient exploration, and limited cross-task adaptability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0196-37a908f409", "paper_id": "P0196", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing reflective strategies (e.g., Reflexion, ReAct) improve per-episode behavior but typically produce ephemeral, task-specific traces that are not reused across tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0196-e643297350", "paper_id": "P0196", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reinforcement-learning based alternatives can produce transferable policies but require substantial parameter updates and compute.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0196-b01e4bcd58", "paper_id": "P0196", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work we introduce Meta-Policy Reflexion (MPR): a hybrid framework that consolidates LLM-generated reflections into a structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at inference time through two complementary mechanisms soft memory-guided decoding and hard rule admissibility checks(HAC).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0196-ab9f3dbe40", "paper_id": "P0196", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "MPR (i) externalizes reusable corrective knowledge without model weight updates, (ii) enforces domain constraints to reduce unsafe or invalid actions, and (iii) retains the adaptability of language-based reflection.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0197-d8f84c5470", "paper_id": "P0197", "bibkey": "Abbineni2025Muallm", "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for circuit design assistance that integrates a hybrid Retrieval-Augmented Generation (RAG) framework with an adaptive vector database of circuit design research papers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0197-4d40260657", "paper_id": "P0197", "bibkey": "Abbineni2025Muallm", "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "At the maximum context length supported by standard LLMs, MuaLLM remains up to 10x less costly and 1.6x faster while maintaining the same accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0197-e294aeefb5", "paper_id": "P0197", "bibkey": "Abbineni2025Muallm", "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval and citation performance, and Reasoning-100 (Reas-100), focused on multistep reasoning in circuit design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0197-221eec994b", "paper_id": "P0197", "bibkey": "Abbineni2025Muallm", "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Conducting a comprehensive literature review is crucial for advancing circuit design methodologies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0197-32cca2747f", "paper_id": "P0197", "bibkey": "Abbineni2025Muallm", "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the rapid influx of state-of-the-art research, inconsistent data representation, and the complexity of optimizing circuit design objectives make this task significantly challenging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0197-f7669f742d", "paper_id": "P0197", "bibkey": "Abbineni2025Muallm", "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for circuit design assistance that integrates a hybrid Retrieval-Augmented Generation (RAG) framework with an adaptive vector database of circuit design research papers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0197-1caad8790e", "paper_id": "P0197", "bibkey": "Abbineni2025Muallm", "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike conventional LLMs, the MuaLLM agent employs a Reason + Act (ReAct) workflow for iterative reasoning, goal-setting, and multi-step information retrieval.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0197-a939ea696a", "paper_id": "P0197", "bibkey": "Abbineni2025Muallm", "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It functions as a question-answering design assistant, capable of interpreting complex queries and providing reasoned responses grounded in circuit literature.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0198-8f7aeed767", "paper_id": "P0198", "bibkey": "Zhu2025Multiagentbench", "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce MultiAgentBench, a comprehensive benchmark designed to evaluate LLM-based multi-agent systems across diverse, interactive scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0198-ff07210df8", "paper_id": "P0198", "bibkey": "Zhu2025Multiagentbench", "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Notably, gpt-4o-mini reaches the average highest task score, graph structure performs the best among coordination protocols in the research scenario, and cognitive planning improves milestone achievement rates by 3%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0198-fff2e5a141", "paper_id": "P0198", "bibkey": "Zhu2025Multiagentbench", "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large Language Models (LLMs) have shown remarkable capabilities as autonomous agents, yet existing benchmarks either focus on single-agent tasks or are confined to narrow domains, failing to capture the dynamics of multi-agent coordination and competition.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0198-2f5e7fbea8", "paper_id": "P0198", "bibkey": "Zhu2025Multiagentbench", "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have shown remarkable capabilities as autonomous agents, yet existing benchmarks either focus on single-agent tasks or are confined to narrow domains, failing to capture the dynamics of multi-agent coordination and competition.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0198-9cde31a808", "paper_id": "P0198", "bibkey": "Zhu2025Multiagentbench", "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce MultiAgentBench, a comprehensive benchmark designed to evaluate LLM-based multi-agent systems across diverse, interactive scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0198-6895fd5100", "paper_id": "P0198", "bibkey": "Zhu2025Multiagentbench", "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our framework measures not only task completion but also the quality of collaboration and competition using novel, milestone-based key performance indicators.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0198-c7db08bf54", "paper_id": "P0198", "bibkey": "Zhu2025Multiagentbench", "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Moreover, we evaluate various coordination protocols (including star, chain, tree, and graph topologies) and innovative strategies such as group discussion and cognitive planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0198-2fd8405fae", "paper_id": "P0198", "bibkey": "Zhu2025Multiagentbench", "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Notably, gpt-4o-mini reaches the average highest task score, graph structure performs the best among coordination protocols in the research scenario, and cognitive planning improves milestone achievement rates by 3%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0199-744db6fb50", "paper_id": "P0199", "bibkey": "Zhang2025Multimind", "title": "MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Model (LLM) agents have demonstrated impressive capabilities in social deduction games (SDGs) like Werewolf, where strategic reasoning and social deception are essential.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0199-9406c14ad1", "paper_id": "P0199", "bibkey": "Zhang2025Multimind", "title": "MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through comprehensive evaluation in both agent-versus-agent simulations and studies with human players, we demonstrate MultiMind's superior performance in gameplay.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0199-4cca6cb99b", "paper_id": "P0199", "bibkey": "Zhang2025Multimind", "title": "MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our work presents a significant advancement toward LLM agents capable of human-like social reasoning across multimodal domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0199-ced3e846ad", "paper_id": "P0199", "bibkey": "Zhang2025Multimind", "title": "MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents have demonstrated impressive capabilities in social deduction games (SDGs) like Werewolf, where strategic reasoning and social deception are essential.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0199-9e8bf7130b", "paper_id": "P0199", "bibkey": "Zhang2025Multimind", "title": "MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, current approaches remain limited to textual information, ignoring crucial multimodal cues such as facial expressions and tone of voice that humans naturally use to communicate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0199-1c6132272a", "paper_id": "P0199", "bibkey": "Zhang2025Multimind", "title": "MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Moreover, existing SDG agents primarily focus on inferring other players' identities without modeling how others perceive themselves or fellow players.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0199-a19425260b", "paper_id": "P0199", "bibkey": "Zhang2025Multimind", "title": "MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these limitations, we use One Night Ultimate Werewolf (ONUW) as a testbed and present MultiMind, the first framework integrating multimodal information into SDG agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0199-753249d228", "paper_id": "P0199", "bibkey": "Zhang2025Multimind", "title": "MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "MultiMind processes facial expressions and vocal tones alongside verbal content, while employing a Theory of Mind (ToM) model to represent each player's suspicion levels toward others.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0199-e37e4dcb12", "paper_id": "P0199", "bibkey": "Zhang2025Multimind", "title": "MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address these limitations, we use One Night Ultimate Werewolf (ONUW) as a testbed and present MultiMind, the first framework integrating multimodal information into SDG agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0200-f689eed921", "paper_id": "P0200", "bibkey": "Zheng2025Newtonbench", "title": "NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these critical gaps, we introduce NewtonBench, a benchmark comprising 324 scientific law discovery tasks across 12 physics domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#method"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0200-39cf43509f", "paper_id": "P0200", "bibkey": "Zheng2025Newtonbench", "title": "NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To address these critical gaps, we introduce NewtonBench, a benchmark comprising 324 scientific law discovery tasks across 12 physics domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0200-33da4447d6", "paper_id": "P0200", "bibkey": "Zheng2025Newtonbench", "title": "NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, existing benchmarks for this task suffer from a fundamental methodological trilemma, forcing a trade-off between scientific relevance, scalability, and resistance to memorization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0200-3a30f6cde7", "paper_id": "P0200", "bibkey": "Zheng2025Newtonbench", "title": "NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models are emerging as powerful tools for scientific law discovery, a foundational challenge in AI-driven science.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0200-1b63cc3f52", "paper_id": "P0200", "bibkey": "Zheng2025Newtonbench", "title": "NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing benchmarks for this task suffer from a fundamental methodological trilemma, forcing a trade-off between scientific relevance, scalability, and resistance to memorization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0200-c514673dd4", "paper_id": "P0200", "bibkey": "Zheng2025Newtonbench", "title": "NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Furthermore, they oversimplify discovery as static function fitting, failing to capture the authentic scientific process of uncovering embedded laws through the interactive exploration of complex model systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0200-e0f59e2073", "paper_id": "P0200", "bibkey": "Zheng2025Newtonbench", "title": "NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these critical gaps, we introduce NewtonBench, a benchmark comprising 324 scientific law discovery tasks across 12 physics domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0200-45835a2614", "paper_id": "P0200", "bibkey": "Zheng2025Newtonbench", "title": "NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our design mitigates the evaluation trilemma by using counterfactual law shifts - systematic alterations of canonical laws - to generate a vast suite of problems that are scalable, scientifically relevant, and memorization-resistant.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0201-0f6e4d4e48", "paper_id": "P0201", "bibkey": "Ghose2025Orfs", "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we introduce ORFS-agent, an LLM-based iterative optimization agent that automates parameter tuning in an open-source hardware design flow.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0201-1d5f67b08e", "paper_id": "P0201", "bibkey": "Ghose2025Orfs", "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our empirical evaluations on two different technology nodes and a range of circuit benchmarks indicate that ORFS-agent can improve both routed wirelength and effective clock period by over 13%, all while using 40% fewer optimization iterations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0201-ddd045953e", "paper_id": "P0201", "bibkey": "Ghose2025Orfs", "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "ORFS-agent adaptively explores parameter configurations, demonstrating clear improvements over standard Bayesian optimization approaches in terms of resource efficiency and final design metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0201-7961345211", "paper_id": "P0201", "bibkey": "Ghose2025Orfs", "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Machine learning has been widely used to optimize complex engineering workflows across numerous domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0201-e8ec1c25f5", "paper_id": "P0201", "bibkey": "Ghose2025Orfs", "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In the context of integrated circuit design, modern flows (e.g., going from a register-transfer level netlist to physical layouts) involve extensive configuration via thousands of parameters, and small changes to these parameters can have large downstream impacts on desired outcomes - namely design performance, power, and area.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0201-faa314ed93", "paper_id": "P0201", "bibkey": "Ghose2025Orfs", "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in Large Language Models (LLMs) offer new opportunities for learning and reasoning within such high-dimensional optimization tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0201-8b1e43a98a", "paper_id": "P0201", "bibkey": "Ghose2025Orfs", "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we introduce ORFS-agent, an LLM-based iterative optimization agent that automates parameter tuning in an open-source hardware design flow.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0201-3650bafc87", "paper_id": "P0201", "bibkey": "Ghose2025Orfs", "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ORFS-agent adaptively explores parameter configurations, demonstrating clear improvements over standard Bayesian optimization approaches in terms of resource efficiency and final design metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0202-b0c245804e", "paper_id": "P0202", "bibkey": "Bharadwaj2025Omnireflect", "title": "OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce OmniReflect, a hierarchical, reflection-driven framework that constructs a constitution, a compact set of guiding principles distilled from task experiences, to enhance the effectiveness and efficiency of an LLM agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0202-85b5f3734b", "paper_id": "P0202", "bibkey": "Bharadwaj2025Omnireflect", "title": "OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Empirical results averaged across models show major improvements in task success, with absolute gains of +10.3% on ALFWorld, +23.8% on BabyAI, and +8.3% on PDDL in the Self-sustaining mode.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0202-0aeb5b5530", "paper_id": "P0202", "bibkey": "Bharadwaj2025Omnireflect", "title": "OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Efforts to improve Large Language Model (LLM) agent performance on complex tasks have largely focused on fine-tuning and iterative self-correction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0202-820eb3e8ca", "paper_id": "P0202", "bibkey": "Bharadwaj2025Omnireflect", "title": "OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, these approaches often lack generalizable mechanisms for longterm learning and remain inefficient in dynamic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0202-1a0551a690", "paper_id": "P0202", "bibkey": "Bharadwaj2025Omnireflect", "title": "OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce OmniReflect, a hierarchical, reflection-driven framework that constructs a constitution, a compact set of guiding principles distilled from task experiences, to enhance the effectiveness and efficiency of an LLM agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0202-71237bf6e5", "paper_id": "P0202", "bibkey": "Bharadwaj2025Omnireflect", "title": "OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "OmniReflect operates in two modes: Self-sustaining, where a single agent periodically curates its own reflections during task execution, and Co-operative, where a Meta-advisor derives a constitution from a small calibration set to guide another agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0202-21796e3ead", "paper_id": "P0202", "bibkey": "Bharadwaj2025Omnireflect", "title": "OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To construct these constitutional principles, we employ Neural, Symbolic, and NeuroSymbolic techniques, offering a balance between contextual adaptability and computational efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0203-adca046a71", "paper_id": "P0203", "bibkey": "Zhu2025Overhearing", "title": "Overhearing LLM Agents: A Survey, Taxonomy, and Roadmap", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "While modern conversational LLM agents directly assist human users with tasks through a chat interface, we study this alternative paradigm for interacting with LLM agents, which we call \"overhearing agents.\" Rather than demanding the user's attention, overhearing agents continuously monitor ambient activity and intervene only when they can provide contextual assistance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0203-3935c498e6", "paper_id": "P0203", "bibkey": "Zhu2025Overhearing", "title": "Overhearing LLM Agents: A Survey, Taxonomy, and Roadmap", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "While modern conversational LLM agents directly assist human users with tasks through a chat interface, we study this alternative paradigm for interacting with LLM agents, which we call \"overhearing agents.\" Rather than demanding the user's attention, overhearing agents continuously monitor ambient activity and intervene only when they can provide contextual assistance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0203-0215890169", "paper_id": "P0203", "bibkey": "Zhu2025Overhearing", "title": "Overhearing LLM Agents: A Survey, Taxonomy, and Roadmap", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In this paper, we present the first analysis of overhearing LLM agents as a distinct paradigm in human-AI interaction and establish a taxonomy of overhearing agent interactions and tasks grounded in a survey of works on prior LLM-powered agents and exploratory HCI studies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0203-dd473ec552", "paper_id": "P0203", "bibkey": "Zhu2025Overhearing", "title": "Overhearing LLM Agents: A Survey, Taxonomy, and Roadmap", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Imagine AI assistants that enhance conversations without interrupting them: quietly providing relevant information during a medical consultation, seamlessly preparing materials as teachers discuss lesson plans, or unobtrusively scheduling meetings as colleagues debate calendars.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0203-b6b2281f48", "paper_id": "P0203", "bibkey": "Zhu2025Overhearing", "title": "Overhearing LLM Agents: A Survey, Taxonomy, and Roadmap", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While modern conversational LLM agents directly assist human users with tasks through a chat interface, we study this alternative paradigm for interacting with LLM agents, which we call \"overhearing agents.\" Rather than demanding the user's attention, overhearing agents continuously monitor ambient activity and intervene only when they can provide contextual assistance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0203-356838d51a", "paper_id": "P0203", "bibkey": "Zhu2025Overhearing", "title": "Overhearing LLM Agents: A Survey, Taxonomy, and Roadmap", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we present the first analysis of overhearing LLM agents as a distinct paradigm in human-AI interaction and establish a taxonomy of overhearing agent interactions and tasks grounded in a survey of works on prior LLM-powered agents and exploratory HCI studies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0203-526754502e", "paper_id": "P0203", "bibkey": "Zhu2025Overhearing", "title": "Overhearing LLM Agents: A Survey, Taxonomy, and Roadmap", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Based on this taxonomy, we create a list of best practices for researchers and developers building overhearing agent systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0203-4493c4c3ce", "paper_id": "P0203", "bibkey": "Zhu2025Overhearing", "title": "Overhearing LLM Agents: A Survey, Taxonomy, and Roadmap", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Finally, we outline the remaining research gaps and reveal opportunities for future research in the overhearing paradigm.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0204-2bfcc7e836", "paper_id": "P0204", "bibkey": "Borah2025Persuasion", "title": "Persuasion at Play: Understanding Misinformation Dynamics in Demographic-Aware Human-LLM Interactions", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We analyze human-to-LLM influence using human-stance datasets and assess LLM-to-human influence by generating LLM-based persuasive arguments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0204-d796e68761", "paper_id": "P0204", "bibkey": "Borah2025Persuasion", "title": "Persuasion at Play: Understanding Misinformation Dynamics in Demographic-Aware Human-LLM Interactions", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We analyze human-to-LLM influence using human-stance datasets and assess LLM-to-human influence by generating LLM-based persuasive arguments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0204-082a209c31", "paper_id": "P0204", "bibkey": "Borah2025Persuasion", "title": "Persuasion at Play: Understanding Misinformation Dynamics in Demographic-Aware Human-LLM Interactions", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our findings show that demographic factors influence susceptibility to misinformation in LLMs, closely reflecting the demographic-based patterns seen in human susceptibility.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0204-5f5bafb91d", "paper_id": "P0204", "bibkey": "Borah2025Persuasion", "title": "Persuasion at Play: Understanding Misinformation Dynamics in Demographic-Aware Human-LLM Interactions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing challenges in misinformation exposure and susceptibility vary across demographic groups, as some populations are more vulnerable to misinformation than others.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0204-4f3ecb35ef", "paper_id": "P0204", "bibkey": "Borah2025Persuasion", "title": "Persuasion at Play: Understanding Misinformation Dynamics in Demographic-Aware Human-LLM Interactions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) introduce new dimensions to these challenges through their ability to generate persuasive content at scale and reinforcing existing biases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0204-7a8453619c", "paper_id": "P0204", "bibkey": "Borah2025Persuasion", "title": "Persuasion at Play: Understanding Misinformation Dynamics in Demographic-Aware Human-LLM Interactions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study investigates the bidirectional persuasion dynamics between LLMs and humans when exposed to misinformative content.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0204-da9af79330", "paper_id": "P0204", "bibkey": "Borah2025Persuasion", "title": "Persuasion at Play: Understanding Misinformation Dynamics in Demographic-Aware Human-LLM Interactions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We analyze human-to-LLM influence using human-stance datasets and assess LLM-to-human influence by generating LLM-based persuasive arguments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0204-82e463dd86", "paper_id": "P0204", "bibkey": "Borah2025Persuasion", "title": "Persuasion at Play: Understanding Misinformation Dynamics in Demographic-Aware Human-LLM Interactions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Additionally, we use a multi-agent LLM framework to analyze the spread of misinformation under persuasion among demographic-oriented LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0205-30685104ae", "paper_id": "P0205", "bibkey": "Hong2025Planning", "title": "Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To remedy this, we propose a novel approach that uses goal-conditioned value functions to guide the reasoning of LLM agents, that scales even to large API-based models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0205-1ad09376fe", "paper_id": "P0205", "bibkey": "Hong2025Planning", "title": "Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We validate our method on tasks requiring interaction, including tool use, social deduction, and dialogue, demonstrating superior performance over both RL fine-tuning and prompting methods while maintaining efficiency and scalability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0205-ab203de788", "paper_id": "P0205", "bibkey": "Hong2025Planning", "title": "Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) excel in tasks like question answering and dialogue, but complex tasks requiring interaction, such as negotiation and persuasion, require additional long-horizon reasoning and planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0205-ae998ce589", "paper_id": "P0205", "bibkey": "Hong2025Planning", "title": "Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reinforcement learning (RL) fine-tuning can enable such planning in principle, but suffers from drawbacks that hinder scalability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0205-dadfe50856", "paper_id": "P0205", "bibkey": "Hong2025Planning", "title": "Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In particular, multi-turn RL training incurs high memory and computational costs, which are exacerbated when training LLMs as policies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0205-513cd3b01a", "paper_id": "P0205", "bibkey": "Hong2025Planning", "title": "Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Furthermore, the largest LLMs do not expose the APIs necessary to be trained in such manner.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0205-37226dcf30", "paper_id": "P0205", "bibkey": "Hong2025Planning", "title": "Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As a result, modern methods to improve the reasoning of LLMs rely on sophisticated prompting mechanisms rather than RL fine-tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0206-3cdda9660a", "paper_id": "P0206", "bibkey": "Yang2025Proagent", "title": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose ProAgent, the first end-to-end proactive agent system that harnesses massive sensory contexts and LLM reasoning to deliver proactive assistance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0206-aa504d163c", "paper_id": "P0206", "bibkey": "Yang2025Proagent", "title": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Results show that ProAgent achieves up to 33.4% higher proactive prediction accuracy, 16.8% higher tool-calling F1 score, and notable improvements in user satisfaction over state-of-the-art baselines, marking a significant step toward proactive assistants.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0206-50bf74b151", "paper_id": "P0206", "bibkey": "Yang2025Proagent", "title": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We implement ProAgent on Augmented Reality (AR) glasses with an edge server and extensively evaluate it on a real-world testbed, a public dataset, and through a user study.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0206-766ab3b466", "paper_id": "P0206", "bibkey": "Yang2025Proagent", "title": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents are emerging to transform daily life.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0206-fc5914ac63", "paper_id": "P0206", "bibkey": "Yang2025Proagent", "title": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing LLM agents primarily follow a reactive paradigm, relying on explicit user instructions to initiate services, which increases both physical and cognitive workload.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0206-b5810d78d7", "paper_id": "P0206", "bibkey": "Yang2025Proagent", "title": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose ProAgent, the first end-to-end proactive agent system that harnesses massive sensory contexts and LLM reasoning to deliver proactive assistance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0206-4a4434e696", "paper_id": "P0206", "bibkey": "Yang2025Proagent", "title": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ProAgent first employs a proactive-oriented context extraction approach with on-demand tiered perception to continuously sense the environment and derive hierarchical contexts that incorporate both sensory and persona cues.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0206-544e3328df", "paper_id": "P0206", "bibkey": "Yang2025Proagent", "title": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ProAgent then adopts a context-aware proactive reasoner to map these contexts to user needs and tool calls, providing proactive assistance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0207-9fcd1a0d17", "paper_id": "P0207", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Motivated by the fact that human experts exhibit significantly better rewrite ability but suffer from scalability, and Large Language Models (LLMs) have demonstrated nearly human-level semantic and reasoning abilities, we propose a new approach of using LLMs to rewrite SQL queries beyond rules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0207-a9d61ac1b4", "paper_id": "P0207", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments show that QUITE reduces query execution time by up to 35.8% over state-of-the-art approaches and produces 24.1% more rewrites than prior methods, covering query cases that earlier systems did not handle.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0207-efd40e95eb", "paper_id": "P0207", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This limitation stems from three challenges of rule-based query rewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite rules do not generalize to new query patterns, and (3) some rewrite techniques cannot be expressed as fixed rules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0207-fb4ae99b92", "paper_id": "P0207", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Query rewrite transforms SQL queries into semantically equivalent forms that run more efficiently.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0207-ea3cd071bc", "paper_id": "P0207", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing approaches mainly rely on predefined rewrite rules, but they handle a limited subset of queries and can cause performance regressions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0207-49862df15e", "paper_id": "P0207", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This limitation stems from three challenges of rule-based query rewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite rules do not generalize to new query patterns, and (3) some rewrite techniques cannot be expressed as fixed rules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0207-0485e2f8b0", "paper_id": "P0207", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Motivated by the fact that human experts exhibit significantly better rewrite ability but suffer from scalability, and Large Language Models (LLMs) have demonstrated nearly human-level semantic and reasoning abilities, we propose a new approach of using LLMs to rewrite SQL queries beyond rules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0207-4b2fdaaffe", "paper_id": "P0207", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Due to the hallucination problems in LLMs, directly applying LLMs often leads to nonequivalent and suboptimal queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0207-7165541801", "paper_id": "P0207", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "This limitation stems from three challenges of rule-based query rewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite rules do not generalize to new query patterns, and (3) some rewrite techniques cannot be expressed as fixed rules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#limitations[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0208-8b3195ff10", "paper_id": "P0208", "bibkey": "Fu2025Eval", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address the absence of standardized evaluation benchmarks for these agents in dynamic environments, we introduce RAS-Eval, a comprehensive security benchmark supporting both simulated and real-world tool execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0208-2895472ae1", "paper_id": "P0208", "bibkey": "Fu2025Eval", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate 6 state-of-the-art LLMs across diverse scenarios, revealing significant vulnerabilities: attacks reduced agent task completion rates (TCR) by 36.78% on average and achieved an 85.65% success rate in academic settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "security"]}
{"evidence_id": "E-P0208-753416ce70", "paper_id": "P0208", "bibkey": "Fu2025Eval", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "RAS-Eval comprises 80 test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration (CWE) categories, with tools implemented in JSON, LangGraph, and Model Context Protocol (MCP) formats.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0208-d371b57225", "paper_id": "P0208", "bibkey": "Fu2025Eval", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid deployment of Large language model (LLM) agents in critical domains like healthcare and finance necessitates robust security frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0208-b48003285d", "paper_id": "P0208", "bibkey": "Fu2025Eval", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address the absence of standardized evaluation benchmarks for these agents in dynamic environments, we introduce RAS-Eval, a comprehensive security benchmark supporting both simulated and real-world tool execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0208-ee4e7f8954", "paper_id": "P0208", "bibkey": "Fu2025Eval", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "RAS-Eval comprises 80 test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration (CWE) categories, with tools implemented in JSON, LangGraph, and Model Context Protocol (MCP) formats.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0208-607aedf6fd", "paper_id": "P0208", "bibkey": "Fu2025Eval", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluate 6 state-of-the-art LLMs across diverse scenarios, revealing significant vulnerabilities: attacks reduced agent task completion rates (TCR) by 36.78% on average and achieved an 85.65% success rate in academic settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "security"]}
{"evidence_id": "E-P0208-47191cdaba", "paper_id": "P0208", "bibkey": "Fu2025Eval", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Notably, scaling laws held for security capabilities, with larger models outperforming smaller counterparts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0209-021a994837", "paper_id": "P0209", "bibkey": "Chen2025Remsa", "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce the RSFM Database (RS-FMD), a structured resource covering over 150 RSFMs spanning multiple data modalities, resolutions, and learning paradigms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#method"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0209-c664716bd8", "paper_id": "P0209", "bibkey": "Chen2025Remsa", "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We also propose a benchmark of 75 expert-verified RS query scenarios, producing 900 configurations under an expert-centered evaluation protocol.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0209-0b559cdb98", "paper_id": "P0209", "bibkey": "Chen2025Remsa", "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We introduce the RSFM Database (RS-FMD), a structured resource covering over 150 RSFMs spanning multiple data modalities, resolutions, and learning paradigms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0209-9ed69382dd", "paper_id": "P0209", "bibkey": "Chen2025Remsa", "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Foundation Models (FMs) are increasingly used in remote sensing (RS) for tasks such as environmental monitoring, disaster assessment, and land-use mapping.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0209-c495219427", "paper_id": "P0209", "bibkey": "Chen2025Remsa", "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These models include unimodal vision encoders trained on a single data modality and multimodal architectures trained on combinations of SAR, multispectral, hyperspectral, and image-text data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0209-5df0f0ffed", "paper_id": "P0209", "bibkey": "Chen2025Remsa", "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "They support diverse RS tasks including semantic segmentation, image classification, change detection, and visual question answering.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0209-fa3b2a7221", "paper_id": "P0209", "bibkey": "Chen2025Remsa", "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, selecting an appropriate remote sensing foundation model (RSFM) remains difficult due to scattered documentation, heterogeneous formats, and varied deployment constraints.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0209-fd3e430efd", "paper_id": "P0209", "bibkey": "Chen2025Remsa", "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce the RSFM Database (RS-FMD), a structured resource covering over 150 RSFMs spanning multiple data modalities, resolutions, and learning paradigms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0209-3bd89c8b09", "paper_id": "P0209", "bibkey": "Chen2025Remsa", "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "It operates entirely on publicly available metadata and does not access private or sensitive data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0210-3c861470d3", "paper_id": "P0210", "bibkey": "Edwards2025Rexbench", "title": "RExBench: Can coding agents autonomously implement AI research extensions?", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Agents based on Large Language Models (LLMs) have shown promise for performing sophisticated software engineering tasks autonomously.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0210-0f6ca2718e", "paper_id": "P0210", "bibkey": "Edwards2025Rexbench", "title": "RExBench: Can coding agents autonomously implement AI research extensions?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "RExBench is a benchmark consisting of 12 realistic research experiment implementation tasks that aim to investigate research hypotheses that have not previously been implemented.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0210-0865a18722", "paper_id": "P0210", "bibkey": "Edwards2025Rexbench", "title": "RExBench: Can coding agents autonomously implement AI research extensions?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Although the success rate improves with additional human-written hints, the best performance under this setting remains below 40%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0210-711891958e", "paper_id": "P0210", "bibkey": "Edwards2025Rexbench", "title": "RExBench: Can coding agents autonomously implement AI research extensions?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agents based on Large Language Models (LLMs) have shown promise for performing sophisticated software engineering tasks autonomously.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0210-d2ea946ea1", "paper_id": "P0210", "bibkey": "Edwards2025Rexbench", "title": "RExBench: Can coding agents autonomously implement AI research extensions?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In addition, there has been progress towards developing agents that can perform parts of the research pipeline in machine learning and the natural sciences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0210-ca3c6b9837", "paper_id": "P0210", "bibkey": "Edwards2025Rexbench", "title": "RExBench: Can coding agents autonomously implement AI research extensions?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We argue that research extension and its implementation is a critical capability for such systems, and introduce RExBench to support the evaluation of this capability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0210-1e7f84bf0f", "paper_id": "P0210", "bibkey": "Edwards2025Rexbench", "title": "RExBench: Can coding agents autonomously implement AI research extensions?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "RExBench is a benchmark consisting of 12 realistic research experiment implementation tasks that aim to investigate research hypotheses that have not previously been implemented.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0210-e931645a82", "paper_id": "P0210", "bibkey": "Edwards2025Rexbench", "title": "RExBench: Can coding agents autonomously implement AI research extensions?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Each task is set up as an extension to an existing research paper and codebase, accompanied by domain expert-written instructions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0211-6e4feb950e", "paper_id": "P0211", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this limitation, we propose ReAcTree, a hierarchical task-planning method that decomposes a complex goal into more manageable subgoals within a dynamically constructed agent tree.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0211-800068dfc6", "paper_id": "P0211", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Notably, on WAH-NL, ReAcTree achieves a 61% goal success rate with Qwen 2.5 72B, nearly doubling ReAct's 31%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0211-4bcafdb221", "paper_id": "P0211", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on the WAH-NL and ALFRED datasets demonstrate that ReAcTree consistently outperforms strong task-planning baselines such as ReAct across diverse LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0211-27052609b0", "paper_id": "P0211", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in large language models (LLMs) have enabled significant progress in decision-making and task planning for embodied autonomous agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0211-19186aab0d", "paper_id": "P0211", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, most existing methods still struggle with complex, long-horizon tasks because they rely on a monolithic trajectory that entangles all past decisions and observations, attempting to solve the entire task in a single unified process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0211-5e26d15f21", "paper_id": "P0211", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this limitation, we propose ReAcTree, a hierarchical task-planning method that decomposes a complex goal into more manageable subgoals within a dynamically constructed agent tree.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0211-9d42ef9d52", "paper_id": "P0211", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Each subgoal is handled by an LLM agent node capable of reasoning, acting, and further expanding the tree, while control flow nodes coordinate the execution strategies of agent nodes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0211-46eaac56a0", "paper_id": "P0211", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In addition, we integrate two complementary memory systems: each agent node retrieves goal-specific, subgoal-level examples from episodic memory and shares environment-specific observations through working memory.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0211-c782275d8d", "paper_id": "P0211", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address this limitation, we propose ReAcTree, a hierarchical task-planning method that decomposes a complex goal into more manageable subgoals within a dynamically constructed agent tree.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0212-240fb1a34d", "paper_id": "P0212", "bibkey": "Kale2025Reliable", "title": "Reliable Weak-to-Strong Monitoring of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We stress test monitoring systems for detecting covert misbehavior in autonomous LLM agents (e.g., secretly sharing private information).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0212-e0345118bc", "paper_id": "P0212", "bibkey": "Kale2025Reliable", "title": "Reliable Weak-to-Strong Monitoring of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To this end, we systematize a monitor red teaming (MRT) workflow that incorporates: (1) varying levels of agent and monitor situational awareness; (2) distinct adversarial strategies to evade the monitor, such as prompt injection; and (3) two datasets and environments -- SHADE-Arena for tool-calling agents and our new CUA-SHADE-Arena, which extends TheAgentCompany, for computer-use agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0212-cbf79d0e49", "paper_id": "P0212", "bibkey": "Kale2025Reliable", "title": "Reliable Weak-to-Strong Monitoring of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Third, in a human-in-the-loop setting where humans discuss with the LLM monitor to get an updated judgment for the agent's behavior, targeted human oversight is most effective; escalating only pre-flagged cases to human reviewers improved the TPR by approximately 15% at FPR = 0.01.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0212-35c8592727", "paper_id": "P0212", "bibkey": "Kale2025Reliable", "title": "Reliable Weak-to-Strong Monitoring of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We stress test monitoring systems for detecting covert misbehavior in autonomous LLM agents (e.g., secretly sharing private information).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0212-a982005b09", "paper_id": "P0212", "bibkey": "Kale2025Reliable", "title": "Reliable Weak-to-Strong Monitoring of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To this end, we systematize a monitor red teaming (MRT) workflow that incorporates: (1) varying levels of agent and monitor situational awareness; (2) distinct adversarial strategies to evade the monitor, such as prompt injection; and (3) two datasets and environments -- SHADE-Arena for tool-calling agents and our new CUA-SHADE-Arena, which extends TheAgentCompany, for computer-use agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0212-c5ff6f2e8f", "paper_id": "P0212", "bibkey": "Kale2025Reliable", "title": "Reliable Weak-to-Strong Monitoring of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We run MRT on existing LLM monitor scaffoldings, which orchestrate LLMs and parse agent trajectories, alongside a new hybrid hierarchical-sequential scaffolding proposed in this work.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0212-4a6a85cd89", "paper_id": "P0212", "bibkey": "Kale2025Reliable", "title": "Reliable Weak-to-Strong Monitoring of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our empirical results yield three key findings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0212-0e5f9f0447", "paper_id": "P0212", "bibkey": "Kale2025Reliable", "title": "Reliable Weak-to-Strong Monitoring of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "First, agent awareness dominates monitor awareness: an agent's knowledge that it is being monitored substantially degrades the monitor's reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0213-b5271ed255", "paper_id": "P0213", "bibkey": "Curvo2025Reproducibility", "title": "Reproducibility Study of \"Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents\"", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Furthermore, we introduce new settings: we create a heterogeneous multi-agent environment, study a scenario using Japanese instructions, and explore an \"inverse environment\" where agents must cooperate to mitigate harmful resource distributions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0213-1955492450", "paper_id": "P0213", "bibkey": "Curvo2025Reproducibility", "title": "Reproducibility Study of \"Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents\"", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "By replicating key experiments, we validate claims regarding the performance of large models, such as GPT-4-turbo, compared to smaller models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0213-00a2cfd5d1", "paper_id": "P0213", "bibkey": "Curvo2025Reproducibility", "title": "Reproducibility Study of \"Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents\"", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results confirm that the benchmark can be applied to new models, scenarios, and languages, offering valuable insights into the adaptability of LLMs in complex cooperative tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0213-86945c051a", "paper_id": "P0213", "bibkey": "Curvo2025Reproducibility", "title": "Reproducibility Study of \"Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents\"", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study evaluates and extends the findings made by Piatti et al., who introduced GovSim, a simulation framework designed to assess the cooperative decision-making capabilities of large language models (LLMs) in resource-sharing scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0213-cc2967b6f2", "paper_id": "P0213", "bibkey": "Curvo2025Reproducibility", "title": "Reproducibility Study of \"Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents\"", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By replicating key experiments, we validate claims regarding the performance of large models, such as GPT-4-turbo, compared to smaller models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0213-db728ce3da", "paper_id": "P0213", "bibkey": "Curvo2025Reproducibility", "title": "Reproducibility Study of \"Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents\"", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The impact of the universalization principle is also examined, with results showing that large models can achieve sustainable cooperation, with or without the principle, while smaller models fail without it.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0213-56dba472df", "paper_id": "P0213", "bibkey": "Curvo2025Reproducibility", "title": "Reproducibility Study of \"Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents\"", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In addition, we provide multiple extensions to explore the applicability of the framework to new settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0213-0af5d1a5bd", "paper_id": "P0213", "bibkey": "Curvo2025Reproducibility", "title": "Reproducibility Study of \"Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents\"", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluate additional models, such as DeepSeek-V3 and GPT-4o-mini, to test whether cooperative behavior generalizes across different architectures and model sizes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0214-4eb2118d43", "paper_id": "P0214", "bibkey": "Kutasov2025Shade", "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We study the ability of frontier LLMs to evade monitoring and achieve harmful hidden goals while completing a wide array of realistic tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0214-6cfb49759f", "paper_id": "P0214", "bibkey": "Kutasov2025Shade", "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "When measuring agent ability to (a) complete the main task, (b) complete the side task, and (c) avoid detection, we find that the best performing frontier models score 27% (Claude 3.7 Sonnet) and 15% (Gemini 2.5 Pro) as sabotage agents when overseen by Claude 3.6 Sonnet.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0214-32da43fe95", "paper_id": "P0214", "bibkey": "Kutasov2025Shade", "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We also use SHADE-Arena to measure models' monitoring abilities, with the top monitor (Gemini 2.5 Pro) achieving an AUC of 0.87 at distinguishing benign and malign transcripts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0214-c9d8c4a8a8", "paper_id": "P0214", "bibkey": "Kutasov2025Shade", "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As Large Language Models (LLMs) are increasingly deployed as autonomous agents in complex and long horizon settings, it is critical to evaluate their ability to sabotage users by pursuing hidden objectives.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0214-73ae72665e", "paper_id": "P0214", "bibkey": "Kutasov2025Shade", "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We study the ability of frontier LLMs to evade monitoring and achieve harmful hidden goals while completing a wide array of realistic tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0214-0483573b91", "paper_id": "P0214", "bibkey": "Kutasov2025Shade", "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluate a broad range of frontier LLMs using SHADE (Subtle Harmful Agent Detection & Evaluation)-Arena, the first highly diverse agent evaluation dataset for sabotage and monitoring capabilities of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0214-f8ca039993", "paper_id": "P0214", "bibkey": "Kutasov2025Shade", "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "SHADE-Arena consists of complex pairs of benign main tasks and harmful side objectives in complicated environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0214-b8e0c7de03", "paper_id": "P0214", "bibkey": "Kutasov2025Shade", "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agents are evaluated on their ability to complete the side task without appearing suspicious to an LLM monitor.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0215-eebdf19f2d", "paper_id": "P0215", "bibkey": "Zhou2025Siraj", "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present SIRAJ: a generic red-teaming framework for arbitrary black-box LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0215-0b753b9422", "paper_id": "P0215", "bibkey": "Zhou2025Siraj", "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across diverse evaluation agent settings, our seed test case generation approach yields 2 -- 2.5x boost to the coverage of risk outcomes and tool-calling trajectories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0215-1099fa6a48", "paper_id": "P0215", "bibkey": "Zhou2025Siraj", "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our distilled 8B red-teamer model improves attack success rate by 100%, surpassing the 671B Deepseek-R1 model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "security"]}
{"evidence_id": "E-P0215-c9c078ab3d", "paper_id": "P0215", "bibkey": "Zhou2025Siraj", "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The ability of LLM agents to plan and invoke tools exposes them to new safety risks, making a comprehensive red-teaming system crucial for discovering vulnerabilities and ensuring their safe deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#summary_bullets[0]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0215-3bc26d9063", "paper_id": "P0215", "bibkey": "Zhou2025Siraj", "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present SIRAJ: a generic red-teaming framework for arbitrary black-box LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0215-477f35eb97", "paper_id": "P0215", "bibkey": "Zhou2025Siraj", "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We employ a dynamic two-step process that starts with an agent definition and generates diverse seed test cases that cover various risk outcomes, tool-use trajectories, and risk sources.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0215-e8d33155f6", "paper_id": "P0215", "bibkey": "Zhou2025Siraj", "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Then, it iteratively constructs and refines model-based adversarial attacks based on the execution trajectories of former attempts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#summary_bullets[3]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0215-39cb448446", "paper_id": "P0215", "bibkey": "Zhou2025Siraj", "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To optimize the red-teaming cost, we present a model distillation approach that leverages structured forms of a teacher model's reasoning to train smaller models that are equally effective.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0216-3a9c3491f4", "paper_id": "P0216", "bibkey": "Zhu2025Safescientist", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To systematically address these challenges, we introduce \\textbf{SafeScientist}, an innovative AI scientist framework explicitly designed to enhance safety and ethical responsibility in AI-driven scientific exploration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0216-17ce80dca8", "paper_id": "P0216", "bibkey": "Zhu2025Safescientist", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Complementing SafeScientist, we propose \\textbf{SciSafetyBench}, a novel benchmark specifically designed to evaluate AI safety in scientific contexts, comprising 240 high-risk scientific tasks across 6 domains, alongside 30 specially designed scientific tools and 120 tool-related risk tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0216-a38e27f78c", "paper_id": "P0216", "bibkey": "Zhu2025Safescientist", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments demonstrate that SafeScientist significantly improves safety performance by 35\\% compared to traditional AI scientist frameworks, without compromising scientific output quality.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0216-790600193f", "paper_id": "P0216", "bibkey": "Zhu2025Safescientist", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in large language model (LLM) agents have significantly accelerated scientific discovery automation, yet concurrently raised critical ethical and safety concerns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0216-e070a79e48", "paper_id": "P0216", "bibkey": "Zhu2025Safescientist", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To systematically address these challenges, we introduce \\textbf{SafeScientist}, an innovative AI scientist framework explicitly designed to enhance safety and ethical responsibility in AI-driven scientific exploration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0216-ccda9664f2", "paper_id": "P0216", "bibkey": "Zhu2025Safescientist", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "SafeScientist proactively refuses ethically inappropriate or high-risk tasks and rigorously emphasizes safety throughout the research process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0216-9340389eab", "paper_id": "P0216", "bibkey": "Zhu2025Safescientist", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To achieve comprehensive safety oversight, we integrate multiple defensive mechanisms, including prompt monitoring, agent-collaboration monitoring, tool-use monitoring, and an ethical reviewer component.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0216-cecc45b583", "paper_id": "P0216", "bibkey": "Zhu2025Safescientist", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Complementing SafeScientist, we propose \\textbf{SciSafetyBench}, a novel benchmark specifically designed to evaluate AI safety in scientific contexts, comprising 240 high-risk scientific tasks across 6 domains, alongside 30 specially designed scientific tools and 120 tool-related risk tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0217-00ab90b01f", "paper_id": "P0217", "bibkey": "Sun2025Scaling", "title": "Scaling Long-Horizon LLM Agent via Context-Folding", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Context-Folding, a framework that empowers agents to actively manage their working context.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0217-15bfe390bb", "paper_id": "P0217", "bibkey": "Sun2025Scaling", "title": "Scaling Long-Horizon LLM Agent via Context-Folding", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On complex long-horizon tasks (Deep Research and SWE), our folding agent matches or outperforms the ReAct baselines while using an active context 10$\\times$ smaller and significantly outperforms models that rely on summarization-based context management.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0217-2d802019a6", "paper_id": "P0217", "bibkey": "Sun2025Scaling", "title": "Scaling Long-Horizon LLM Agent via Context-Folding", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents are fundamentally constrained by context length on long-horizon tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0217-61e9029a4f", "paper_id": "P0217", "bibkey": "Sun2025Scaling", "title": "Scaling Long-Horizon LLM Agent via Context-Folding", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Context-Folding, a framework that empowers agents to actively manage their working context.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0217-840a18bc41", "paper_id": "P0217", "bibkey": "Sun2025Scaling", "title": "Scaling Long-Horizon LLM Agent via Context-Folding", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "An agent can procedurally branch into a sub-trajectory to handle a subtask and then fold it upon completion, collapsing the intermediate steps while retaining a concise summary of the outcome.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0217-028598364b", "paper_id": "P0217", "bibkey": "Sun2025Scaling", "title": "Scaling Long-Horizon LLM Agent via Context-Folding", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To make this behavior learnable, we develop an end-to-end reinforcement learning framework FoldGRPO with specific process rewards to encourage effective task decomposition and context management.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0217-3c27235fd2", "paper_id": "P0217", "bibkey": "Sun2025Scaling", "title": "Scaling Long-Horizon LLM Agent via Context-Folding", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "On complex long-horizon tasks (Deep Research and SWE), our folding agent matches or outperforms the ReAct baselines while using an active context 10$\\times$ smaller and significantly outperforms models that rely on summarization-based context management.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0218-c23c422fde", "paper_id": "P0218", "bibkey": "Gaonkar2025Sciml", "title": "SciML Agents: Write the Solver, Not the Solution", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Recent work in scientific machine learning aims to tackle scientific tasks directly by predicting target values with neural networks (e.g., physics-informed neural networks, neural ODEs, neural operators, etc.), but attaining high accuracy and robustness has been challenging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0218-f88a90722e", "paper_id": "P0218", "bibkey": "Gaonkar2025Sciml", "title": "SciML Agents: Write the Solver, Not the Solution", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "As such, we first introduce two new datasets: a diagnostic dataset of adversarial \"misleading\" problems; and a large-scale benchmark of 1,000 diverse ODE tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0218-804bff6e88", "paper_id": "P0218", "bibkey": "Gaonkar2025Sciml", "title": "SciML Agents: Write the Solver, Not the Solution", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Recent work in scientific machine learning aims to tackle scientific tasks directly by predicting target values with neural networks (e.g., physics-informed neural networks, neural ODEs, neural operators, etc.), but attaining high accuracy and robustness has been challenging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0218-fa7fda2cbb", "paper_id": "P0218", "bibkey": "Gaonkar2025Sciml", "title": "SciML Agents: Write the Solver, Not the Solution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent work in scientific machine learning aims to tackle scientific tasks directly by predicting target values with neural networks (e.g., physics-informed neural networks, neural ODEs, neural operators, etc.), but attaining high accuracy and robustness has been challenging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0218-1ab64c1acb", "paper_id": "P0218", "bibkey": "Gaonkar2025Sciml", "title": "SciML Agents: Write the Solver, Not the Solution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We explore an alternative view: use LLMs to write code that leverages decades of numerical algorithms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0218-7784caf432", "paper_id": "P0218", "bibkey": "Gaonkar2025Sciml", "title": "SciML Agents: Write the Solver, Not the Solution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This shifts the burden from learning a solution function to making domain-aware numerical choices.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0218-4cdcabeb80", "paper_id": "P0218", "bibkey": "Gaonkar2025Sciml", "title": "SciML Agents: Write the Solver, Not the Solution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We ask whether LLMs can act as SciML agents that, given a natural-language ODE description, generate runnable code that is scientifically appropriate, selecting suitable solvers (stiff vs. non-stiff), and enforcing stability checks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0218-da6d450eba", "paper_id": "P0218", "bibkey": "Gaonkar2025Sciml", "title": "SciML Agents: Write the Solver, Not the Solution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "There is currently no benchmark to measure this kind of capability for scientific computing tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0219-9152db24bd", "paper_id": "P0219", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Subsequently, we present the vision of a zero-trust multi-LLM framework in EGI.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0219-ee26c8ba8a", "paper_id": "P0219", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This survey serves as the first systematic treatment of zero-trust applied to multi-LLM systems, providing both theoretical foundations and practical strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0219-a1049afe06", "paper_id": "P0219", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agentification serves as a critical enabler of Edge General Intelligence (EGI), transforming massive edge devices into cognitive agents through integrating Large Language Models (LLMs) and perception, reasoning, and acting modules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0219-547b5447b2", "paper_id": "P0219", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These agents collaborate across heterogeneous edge infrastructures, forming multi-LLM agentic AI systems that leverage collective intelligence and specialized capabilities to tackle complex, multi-step tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0219-5bf56d0771", "paper_id": "P0219", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the collaborative nature of multi-LLM systems introduces critical security vulnerabilities, including insecure inter-LLM communications, expanded attack surfaces, and cross-domain data leakage that traditional perimeter-based security cannot adequately address.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0219-eb1a711733", "paper_id": "P0219", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To this end, this survey introduces zero-trust security of multi-LLM in EGI, a paradigmatic shift following the ``never trust, always verify'' principle.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0219-f33a682f9c", "paper_id": "P0219", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We begin by systematically analyzing the security risks in multi-LLM systems within EGI contexts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0220-f213ab51ad", "paper_id": "P0220", "bibkey": "Serenari2025Semantically", "title": "Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this challenge, we present the Local Optimizations for Pseudonymization with Semantic Integrity Directed Entity Detection (LOPSIDED) framework, a semantically-aware privacy agent designed to safeguard sensitive PII data when using remote LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0220-fdb7fe50b2", "paper_id": "P0220", "bibkey": "Serenari2025Semantically", "title": "Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results show that LOPSIDED reduces semantic utility errors by a factor of 5 compared to baseline techniques, all while enhancing privacy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0220-7bc837ce7e", "paper_id": "P0220", "bibkey": "Serenari2025Semantically", "title": "Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the increasing use of conversational AI systems, there is growing concern over privacy leaks, especially when users share sensitive personal data in interactions with Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0220-a63c1b64b0", "paper_id": "P0220", "bibkey": "Serenari2025Semantically", "title": "Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Conversations shared with these models may contain Personally Identifiable Information (PII), which, if exposed, could lead to security breaches or identity theft.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0220-51e44276bd", "paper_id": "P0220", "bibkey": "Serenari2025Semantically", "title": "Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this challenge, we present the Local Optimizations for Pseudonymization with Semantic Integrity Directed Entity Detection (LOPSIDED) framework, a semantically-aware privacy agent designed to safeguard sensitive PII data when using remote LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0220-9e7a8d4141", "paper_id": "P0220", "bibkey": "Serenari2025Semantically", "title": "Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike prior work that often degrade response quality, our approach dynamically replaces sensitive PII entities in user prompts with semantically consistent pseudonyms, preserving the contextual integrity of conversations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0220-9e50f942b4", "paper_id": "P0220", "bibkey": "Serenari2025Semantically", "title": "Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Once the model generates its response, the pseudonyms are automatically depseudonymized, ensuring the user receives an accurate, privacy-preserving output.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0221-13807dfb3d", "paper_id": "P0221", "bibkey": "Hu2025Simulating", "title": "Simulating Rumor Spreading in Social Networks using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Our framework assesses the effectiveness of different network constructions and agent behaviors in influencing the spread of rumors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0221#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0221-c5fb857109", "paper_id": "P0221", "bibkey": "Hu2025Simulating", "title": "Simulating Rumor Spreading in Social Networks using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The evaluations indicate that network structure, personas, and spreading schemes can significantly influence rumor dissemination, ranging from no spread to affecting 83\\% of agents in iterations, thereby offering a realistic simulation of rumor spread in social networks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0221#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0221-4863cd0a0c", "paper_id": "P0221", "bibkey": "Hu2025Simulating", "title": "Simulating Rumor Spreading in Social Networks using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the rise of social media, misinformation has become increasingly prevalent, fueled largely by the spread of rumors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0221#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0221-bdf43cef19", "paper_id": "P0221", "bibkey": "Hu2025Simulating", "title": "Simulating Rumor Spreading in Social Networks using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study explores the use of Large Language Model (LLM) agents within a novel framework to simulate and analyze the dynamics of rumor propagation across social networks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0221#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0221-a38f686cd7", "paper_id": "P0221", "bibkey": "Hu2025Simulating", "title": "Simulating Rumor Spreading in Social Networks using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To this end, we design a variety of LLM-based agent types and construct four distinct network structures to conduct these simulations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0221#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0221-59ad8b0c71", "paper_id": "P0221", "bibkey": "Hu2025Simulating", "title": "Simulating Rumor Spreading in Social Networks using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our framework assesses the effectiveness of different network constructions and agent behaviors in influencing the spread of rumors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0221#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0221-6ac90c7836", "paper_id": "P0221", "bibkey": "Hu2025Simulating", "title": "Simulating Rumor Spreading in Social Networks using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our results demonstrate that the framework can simulate rumor spreading across more than one hundred agents in various networks with thousands of edges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0221#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0222-32b2c8cf19", "paper_id": "P0222", "bibkey": "Cao2025Skyrl", "title": "SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce SkyRL-Agent, a framework for efficient, multi-turn, long-horizon agent training and evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0222#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0222-3af1ce8090", "paper_id": "P0222", "bibkey": "Cao2025Skyrl", "title": "SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Using SkyRL-Agent, we train SA-SWE-32B, a software engineering agent trained from Qwen3-32B (24.4% Pass@1) purely with reinforcement learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0222#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0222-5ed988eb67", "paper_id": "P0222", "bibkey": "Cao2025Skyrl", "title": "SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We introduce two key components: an optimized asynchronous pipeline dispatcher that achieves a 1.55x speedup over naive asynchronous batching, and a tool-enhanced training recipe leveraging an AST-based search tool to facilitate code navigation, boost rollout Pass@K, and improve training efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0222#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers", "tooling"]}
{"evidence_id": "E-P0222-6d4d6c2f88", "paper_id": "P0222", "bibkey": "Cao2025Skyrl", "title": "SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce SkyRL-Agent, a framework for efficient, multi-turn, long-horizon agent training and evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0222#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0222-60a60b10a5", "paper_id": "P0222", "bibkey": "Cao2025Skyrl", "title": "SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It provides efficient asynchronous dispatching, lightweight tool integration, and flexible backend interoperability, enabling seamless use with existing RL frameworks such as SkyRL-train, VeRL, and Tinker.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0222#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0222-e61a040022", "paper_id": "P0222", "bibkey": "Cao2025Skyrl", "title": "SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Using SkyRL-Agent, we train SA-SWE-32B, a software engineering agent trained from Qwen3-32B (24.4% Pass@1) purely with reinforcement learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0222#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0222-9917eb7456", "paper_id": "P0222", "bibkey": "Cao2025Skyrl", "title": "SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce two key components: an optimized asynchronous pipeline dispatcher that achieves a 1.55x speedup over naive asynchronous batching, and a tool-enhanced training recipe leveraging an AST-based search tool to facilitate code navigation, boost rollout Pass@K, and improve training efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0222#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory", "numbers", "tooling"]}
{"evidence_id": "E-P0222-da73f2b4d4", "paper_id": "P0222", "bibkey": "Cao2025Skyrl", "title": "SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Together, these optimizations enable SA-SWE-32B to reach 39.4% Pass@1 on SWE-Bench Verified with more than 2x cost reduction compared to prior models reaching similar performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0222#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0223-de316a8af3", "paper_id": "P0223", "bibkey": "Maritan2025Staffpro", "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We cast these problems in a formal mathematical framework that links scheduling decisions to latent feature estimation, and we introduce StaffPro, an LLM agent that addresses staffing and profiling jointly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0223#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0223-85d4ca0495", "paper_id": "P0223", "bibkey": "Maritan2025Staffpro", "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "StaffPro interacts directly with humans by establishing a continuous human-agent feedback loop, ensuring natural and intuitive use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0223#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0223-83e7dbefb5", "paper_id": "P0223", "bibkey": "Maritan2025Staffpro", "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "By analyzing human feedback, our agent continuously estimates the latent features of workers, realizing life-long worker profiling and ensuring optimal staffing performance over time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0223#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0223-401df265bc", "paper_id": "P0223", "bibkey": "Maritan2025Staffpro", "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents integrate pre-trained LLMs with modular algorithmic components and have shown remarkable reasoning and decision-making abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0223#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0223-caa0924a99", "paper_id": "P0223", "bibkey": "Maritan2025Staffpro", "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we investigate their use for two tightly intertwined challenges in workforce management: staffing, i.e., the assignment and scheduling of tasks to workers, which may require team formation; and profiling, i.e., the continuous estimation of workers' skills, preferences, and other latent attributes from unstructured data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0223#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0223-4e4a128148", "paper_id": "P0223", "bibkey": "Maritan2025Staffpro", "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We cast these problems in a formal mathematical framework that links scheduling decisions to latent feature estimation, and we introduce StaffPro, an LLM agent that addresses staffing and profiling jointly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0223#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0223-cdb0834b0a", "paper_id": "P0223", "bibkey": "Maritan2025Staffpro", "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Differently from existing staffing solutions, StaffPro allows expressing optimization objectives using natural language, accepts textual task descriptions and provides high flexibility.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0223#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0223-1565218d37", "paper_id": "P0223", "bibkey": "Maritan2025Staffpro", "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "StaffPro interacts directly with humans by establishing a continuous human-agent feedback loop, ensuring natural and intuitive use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0223#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0224-3b338d80bc", "paper_id": "P0224", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we introduce StockBench, a contamination-free benchmark designed to evaluate LLM agents in realistic, multi-month stock trading environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0224#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0224-99aa4ad8d4", "paper_id": "P0224", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation of state-of-the-art proprietary (e.g., GPT-5, Claude-4) and open-weight (e.g., Qwen3, Kimi-K2, GLM-4.5) models shows that while most LLM agents struggle to outperform the simple buy-and-hold baseline, several models demonstrate the potential to deliver higher returns and manage risk more effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0224#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0224-79963782cf", "paper_id": "P0224", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "While prior benchmarks have evaluated LLM agents in domains such as software engineering and scientific discovery, the finance domain remains underexplored, despite its direct relevance to economic value and high-stakes decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0224#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0224-e22b501ea6", "paper_id": "P0224", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have recently demonstrated strong capabilities as autonomous agents, showing promise in reasoning, tool use, and sequential decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0224#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0224-a043637334", "paper_id": "P0224", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While prior benchmarks have evaluated LLM agents in domains such as software engineering and scientific discovery, the finance domain remains underexplored, despite its direct relevance to economic value and high-stakes decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0224#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0224-18024362ec", "paper_id": "P0224", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing financial benchmarks primarily test static knowledge through question answering, but they fall short of capturing the dynamic and iterative nature of trading.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0224#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0224-375d5bbce3", "paper_id": "P0224", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, we introduce StockBench, a contamination-free benchmark designed to evaluate LLM agents in realistic, multi-month stock trading environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0224#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0224-fa8ba221d1", "paper_id": "P0224", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agents receive daily market signals -- including prices, fundamentals, and news -- and must make sequential buy, sell, or hold decisions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0224#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0224-4f9b0e7b78", "paper_id": "P0224", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "These findings highlight both the challenges and opportunities in developing LLM-powered financial agents, showing that excelling at static financial knowledge tasks does not necessarily translate into successful trading strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0224#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0225-c8648baf8e", "paper_id": "P0225", "bibkey": "Suri2025Structured", "title": "Structured Uncertainty guided Clarification for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a principled formulation of structured uncertainty over tool-call parameters, modeling joint tool-argument clarification as a POMDP with Expected Value of Perfect Information (EVPI) objective for optimal question selection and aspect-based cost modeling to prevent redundancy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0225#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0225-2d77903ddb", "paper_id": "P0225", "bibkey": "Suri2025Structured", "title": "Structured Uncertainty guided Clarification for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Additionally, we demonstrate that structured uncertainty provides effective training signals for reinforcement learning, boosting When2Call accuracy from 36.5\\% to 65.2\\% (3B model) and 36.7\\% to 62.9\\% (7B model) through uncertainty-weighted GRPO training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0225#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0225-be7675fbfc", "paper_id": "P0225", "bibkey": "Suri2025Structured", "title": "Structured Uncertainty guided Clarification for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our SAGE-Agent leverages this structured uncertainty to achieve superior efficiency: increasing coverage on ambiguous tasks by 7-39\\% while reducing clarification questions by 1.5-2.7$\\times$ compared to strong prompting and uncertainty-based baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0225#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0225-5a0557ebb9", "paper_id": "P0225", "bibkey": "Suri2025Structured", "title": "Structured Uncertainty guided Clarification for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM agents extend large language models with tool-calling capabilities, but ambiguous user instructions often lead to incorrect invocations and task failures.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0225#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0225-cb9cd76755", "paper_id": "P0225", "bibkey": "Suri2025Structured", "title": "Structured Uncertainty guided Clarification for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce a principled formulation of structured uncertainty over tool-call parameters, modeling joint tool-argument clarification as a POMDP with Expected Value of Perfect Information (EVPI) objective for optimal question selection and aspect-based cost modeling to prevent redundancy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0225#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0225-0acac7ecd1", "paper_id": "P0225", "bibkey": "Suri2025Structured", "title": "Structured Uncertainty guided Clarification for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our SAGE-Agent leverages this structured uncertainty to achieve superior efficiency: increasing coverage on ambiguous tasks by 7-39\\% while reducing clarification questions by 1.5-2.7$\\times$ compared to strong prompting and uncertainty-based baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0225#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0225-e5c028ae2a", "paper_id": "P0225", "bibkey": "Suri2025Structured", "title": "Structured Uncertainty guided Clarification for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present ClarifyBench, the first multi-turn tool-augmented disambiguation benchmark with realistic LLM-based user simulation across diverse domains including document editing, vehicle control, and travel booking.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0225#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0225-5b7a075f89", "paper_id": "P0225", "bibkey": "Suri2025Structured", "title": "Structured Uncertainty guided Clarification for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Additionally, we demonstrate that structured uncertainty provides effective training signals for reinforcement learning, boosting When2Call accuracy from 36.5\\% to 65.2\\% (3B model) and 36.7\\% to 62.9\\% (7B model) through uncertainty-weighted GRPO training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0225#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0226-06d57587c6", "paper_id": "P0226", "bibkey": "Ye2025Task", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose the Task Memory Engine (TME), a lightweight and structured memory module that tracks task execution using a hierarchical Task Memory Tree (TMT).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0226#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0226-44aade70d9", "paper_id": "P0226", "bibkey": "Ye2025Task", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through case studies and comparative experiments on multi-step agent tasks, we demonstrate that TME leads to better task completion accuracy and more interpretable behavior with minimal implementation overhead.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0226#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0226-a455c5978d", "paper_id": "P0226", "bibkey": "Ye2025Task", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) are increasingly used as autonomous agents for multi-step tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0226#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0226-34787ad3ea", "paper_id": "P0226", "bibkey": "Ye2025Task", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, most existing frameworks fail to maintain a structured understanding of the task state, often relying on linear prompt concatenation or shallow memory buffers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0226#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0226-b5af4bb401", "paper_id": "P0226", "bibkey": "Ye2025Task", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This leads to brittle performance, frequent hallucinations, and poor long-range coherence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0226#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0226-feff2879fc", "paper_id": "P0226", "bibkey": "Ye2025Task", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we propose the Task Memory Engine (TME), a lightweight and structured memory module that tracks task execution using a hierarchical Task Memory Tree (TMT).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0226#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0226-b4137b44fa", "paper_id": "P0226", "bibkey": "Ye2025Task", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Each node in the tree corresponds to a task step, storing relevant input, output, status, and sub-task relationships.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0226#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0227-a0fe046ece", "paper_id": "P0227", "bibkey": "Ye2025Taska", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce the Task Memory Engine (TME), a modular memory controller that transforms existing LLMs into robust, revision-aware agents without fine-tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0227#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0227-3bf4dab38c", "paper_id": "P0227", "bibkey": "Ye2025Taska", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns, outperforming ReAct.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0227#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0227-53536132a8", "paper_id": "P0227", "bibkey": "Ye2025Taska", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We release TME's codebase, benchmarks, and components as open-source resources, enabling researchers to develop reliable LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0227#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0227-d509f280df", "paper_id": "P0227", "bibkey": "Ye2025Taska", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) falter in multi-step interactions -- often hallucinating, repeating actions, or misinterpreting user corrections -- due to reliance on linear, unstructured context.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0227#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0227-5997082b9f", "paper_id": "P0227", "bibkey": "Ye2025Taska", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This fragility stems from the lack of persistent memory to track evolving goals and task dependencies, undermining trust in autonomous agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0227#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0227-5da3033ff7", "paper_id": "P0227", "bibkey": "Ye2025Taska", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce the Task Memory Engine (TME), a modular memory controller that transforms existing LLMs into robust, revision-aware agents without fine-tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0227#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0227-ababb74345", "paper_id": "P0227", "bibkey": "Ye2025Taska", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "TME implements a spatial memory framework that replaces flat context with graph-based structures to support consistent, multi-turn reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0227#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0227-d813ce4e04", "paper_id": "P0227", "bibkey": "Ye2025Taska", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Departing from linear concatenation and ReAct-style prompting, TME builds a dynamic task graph -- either a tree or directed acyclic graph (DAG) -- to map user inputs to subtasks, align them with prior context, and enable dependency-tracked revisions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0227#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0228-181f092d50", "paper_id": "P0228", "bibkey": "Zeng2025Toolace", "title": "ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose a novel Non-Autoregressive Iterative Generation framework, called ToolACE-MT, for constructing high-quality multi-turn agentic dialogues.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0228#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0228-f01b7d3df3", "paper_id": "P0228", "bibkey": "Zeng2025Toolace", "title": "ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments demonstrate that ToolACE-MT enables efficient, effective and generalizable agentic data generation, offering a new paradigm for high-quality data construction in tool-augmented LLM scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0228#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0228-8c040b0998", "paper_id": "P0228", "bibkey": "Zeng2025Toolace", "title": "ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agentic task-solving with Large Language Models (LLMs) requires multi-turn, multi-step interactions, often involving complex function calls and dynamic user-agent exchanges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0228#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0228-8551c6ead0", "paper_id": "P0228", "bibkey": "Zeng2025Toolace", "title": "ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing simulation-based data generation methods for such scenarios rely heavily on costly autoregressive interactions between multiple LLM agents, thereby limiting real-world performance of agentic tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0228#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0228-a699987ff8", "paper_id": "P0228", "bibkey": "Zeng2025Toolace", "title": "ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose a novel Non-Autoregressive Iterative Generation framework, called ToolACE-MT, for constructing high-quality multi-turn agentic dialogues.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0228#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0228-a4c7321f5a", "paper_id": "P0228", "bibkey": "Zeng2025Toolace", "title": "ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ToolACE-MT generates full conversational trajectories through three stages: coarse-grained initialization, iterative refinement, and offline verification.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0228#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0228-a08fbbcf79", "paper_id": "P0228", "bibkey": "Zeng2025Toolace", "title": "ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The initialization phase builds a structurally complete yet semantically coarse dialogue skeleton; the iterative refinement phase introduces realistic complexities and continued refinement via mask-and-fill operations; and the offline verification phase ensures correctness and coherence via rule- and model-based checks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0228#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0229-32b9aafe57", "paper_id": "P0229", "bibkey": "Liu2025Toolscope", "title": "ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we propose ToolScope, which includes: (1) ToolScopeMerger with Auto-Correction to automatically audit and fix tool merges, reducing redundancy, and (2) ToolScopeRetriever to rank and select only the most relevant tools for each query, compressing toolsets to fit within context limits without sacrificing accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0229#method"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0229-468a77ff1d", "paper_id": "P0229", "bibkey": "Liu2025Toolscope", "title": "ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluations on three state-of-the-art LLMs and three open-source tool-use benchmarks show gains of 8.38% to 38.6% in tool selection accuracy, demonstrating ToolScope's effectiveness in enhancing LLM tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0229#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0229-cb30da23cb", "paper_id": "P0229", "bibkey": "Liu2025Toolscope", "title": "ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To address these challenges, we propose ToolScope, which includes: (1) ToolScopeMerger with Auto-Correction to automatically audit and fix tool merges, reducing redundancy, and (2) ToolScopeRetriever to rank and select only the most relevant tools for each query, compressing toolsets to fit within context limits without sacrificing accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0229#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0229-a8760599dc", "paper_id": "P0229", "bibkey": "Liu2025Toolscope", "title": "ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents rely on external tools to solve complex tasks, but real-world toolsets often contain redundant tools with overlapping names and descriptions, introducing ambiguity and reducing selection accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0229#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0229-7b391ae6f0", "paper_id": "P0229", "bibkey": "Liu2025Toolscope", "title": "ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLMs also face strict input context limits, preventing efficient consideration of large toolsets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0229#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0229-c91925707a", "paper_id": "P0229", "bibkey": "Liu2025Toolscope", "title": "ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these challenges, we propose ToolScope, which includes: (1) ToolScopeMerger with Auto-Correction to automatically audit and fix tool merges, reducing redundancy, and (2) ToolScopeRetriever to rank and select only the most relevant tools for each query, compressing toolsets to fit within context limits without sacrificing accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0229#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0229-cfce481297", "paper_id": "P0229", "bibkey": "Liu2025Toolscope", "title": "ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Evaluations on three state-of-the-art LLMs and three open-source tool-use benchmarks show gains of 8.38% to 38.6% in tool selection accuracy, demonstrating ToolScope's effectiveness in enhancing LLM tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0229#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0230-4c5009df7f", "paper_id": "P0230", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "With the proliferation of Large Language Models (LLMs), the detection of misinformation has become increasingly important and complex.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0230#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0230-171b93237a", "paper_id": "P0230", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate using standard misinformation datasets such as FakeNewsNet, comparing with traditional machine learning models and LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0230#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0230-15e523063d", "paper_id": "P0230", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluation metrics include standard classification metrics, quality assessment of reasoning processes, and robustness testing against rewritten content.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0230#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0230-b24ddee6fb", "paper_id": "P0230", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the proliferation of Large Language Models (LLMs), the detection of misinformation has become increasingly important and complex.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0230#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0230-9f6e16eaaf", "paper_id": "P0230", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This research proposes an innovative verifiable misinformation detection LLM agent that goes beyond traditional true/false binary judgments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0230#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0230-5ab215976a", "paper_id": "P0230", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The agent actively verifies claims through dynamic interaction with diverse web sources, assesses information source credibility, synthesizes evidence, and provides a complete verifiable reasoning process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0230#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0230-023c432ba9", "paper_id": "P0230", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our designed agent architecture includes three core tools: precise web search tool, source credibility assessment tool and numerical claim verification tool.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0230#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0230-50852c98c4", "paper_id": "P0230", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These tools enable the agent to execute multi-step verification strategies, maintain evidence logs, and form comprehensive assessment conclusions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0230#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0231-0242bf2bd9", "paper_id": "P0231", "bibkey": "Zwerdling2025Towards", "title": "Towards Enforcing Company Policy Adherence in Agentic Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this study we introduce a deterministic, transparent, and modular framework for enforcing business policy adherence in agentic workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0231#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0231-dd09f9d6ca", "paper_id": "P0231", "bibkey": "Zwerdling2025Towards", "title": "Towards Enforcing Company Policy Adherence in Agentic Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our method operates in two phases: (1) an offline buildtime stage that compiles policy documents into verifiable guard code associated with tool use, and (2) a runtime integration where these guards ensure compliance before each agent action.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0231#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0231-f86a15b1fc", "paper_id": "P0231", "bibkey": "Zwerdling2025Towards", "title": "Towards Enforcing Company Policy Adherence in Agentic Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents hold promise for a flexible and scalable alternative to traditional business process automation, but struggle to reliably follow complex company policies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0231#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0231-eec4170e1c", "paper_id": "P0231", "bibkey": "Zwerdling2025Towards", "title": "Towards Enforcing Company Policy Adherence in Agentic Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this study we introduce a deterministic, transparent, and modular framework for enforcing business policy adherence in agentic workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0231#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0231-c47faf1170", "paper_id": "P0231", "bibkey": "Zwerdling2025Towards", "title": "Towards Enforcing Company Policy Adherence in Agentic Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our method operates in two phases: (1) an offline buildtime stage that compiles policy documents into verifiable guard code associated with tool use, and (2) a runtime integration where these guards ensure compliance before each agent action.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0231#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0231-bc771d33b7", "paper_id": "P0231", "bibkey": "Zwerdling2025Towards", "title": "Towards Enforcing Company Policy Adherence in Agentic Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We demonstrate our approach on the challenging $$-bench Airlines domain, showing encouraging preliminary results in policy enforcement, and further outline key challenges for real-world deployments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0231#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0232-3e7f84d255", "paper_id": "P0232", "bibkey": "Tomaevi2025Towards", "title": "Towards Operational Validation of LLM-Agent Social Simulations: A Replicated Study of a Reddit-like Technology Forum", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Models (LLMs) enable generative social simulations that can capture culturally informed, norm-guided interaction on online social platforms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0232#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0232-2477025df5", "paper_id": "P0232", "bibkey": "Tomaevi2025Towards", "title": "Towards Operational Validation of LLM-Agent Social Simulations: A Replicated Study of a Reddit-like Technology Forum", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Using the YSocial framework, we seed the simulation with a fixed catalog of technology links sampled from Voat's shared URLs (covering 30+ domains) and calibrate parameters to Voat's v/technology using samples from the MADOC dataset.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0232#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0232-3f6bfc6a7f", "paper_id": "P0232", "bibkey": "Tomaevi2025Towards", "title": "Towards Operational Validation of LLM-Agent Social Simulations: A Replicated Study of a Reddit-like Technology Forum", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Limitations of the current study include the stateless agent design and evaluation based on a single 30-day run, which constrains external validity and variance estimates.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0232#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0232-b4d55755f3", "paper_id": "P0232", "bibkey": "Tomaevi2025Towards", "title": "Towards Operational Validation of LLM-Agent Social Simulations: A Replicated Study of a Reddit-like Technology Forum", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) enable generative social simulations that can capture culturally informed, norm-guided interaction on online social platforms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0232#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0232-2f9744805b", "paper_id": "P0232", "bibkey": "Tomaevi2025Towards", "title": "Towards Operational Validation of LLM-Agent Social Simulations: A Replicated Study of a Reddit-like Technology Forum", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We build a technology community simulation modeled on Voat, a Reddit-like alt-right news aggregator and discussion platform active from 2014 to 2020.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0232#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0232-6ae72a3319", "paper_id": "P0232", "bibkey": "Tomaevi2025Towards", "title": "Towards Operational Validation of LLM-Agent Social Simulations: A Replicated Study of a Reddit-like Technology Forum", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Using the YSocial framework, we seed the simulation with a fixed catalog of technology links sampled from Voat's shared URLs (covering 30+ domains) and calibrate parameters to Voat's v/technology using samples from the MADOC dataset.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0232#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0232-0b888fab90", "paper_id": "P0232", "bibkey": "Tomaevi2025Towards", "title": "Towards Operational Validation of LLM-Agent Social Simulations: A Replicated Study of a Reddit-like Technology Forum", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agents use a base, uncensored model (Dolphin 3.0, based on Llama 3.1 8B) and concise personas (demographics, political leaning, interests, education, toxicity propensity) to generate posts, replies, and reactions under platform rules for link and text submissions, threaded replies and daily activity cycles.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0232#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0232-57c254082d", "paper_id": "P0232", "bibkey": "Tomaevi2025Towards", "title": "Towards Operational Validation of LLM-Agent Social Simulations: A Replicated Study of a Reddit-like Technology Forum", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We run a 30-day simulation and evaluate operational validity by comparing distributions and structures with matched Voat data: activity patterns, interaction networks, toxicity, and topic coverage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0232#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0232-1232593f0e", "paper_id": "P0232", "bibkey": "Tomaevi2025Towards", "title": "Towards Operational Validation of LLM-Agent Social Simulations: A Replicated Study of a Reddit-like Technology Forum", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Limitations of the current study include the stateless agent design and evaluation based on a single 30-day run, which constrains external validity and variance estimates.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0232#limitations[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0233-f4d80ca542", "paper_id": "P0233", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Models (LLMs) have demonstrated remarkable capabilities in knowledge acquisition, reasoning, and tool use, making them promising candidates for autonomous agent applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0233#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0233-771620f84f", "paper_id": "P0233", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0233#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0233-5a257bd496", "paper_id": "P0233", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our theoretical analysis shows that GRPO improvement on single-turn task reasoning results in a lower bound of the multi-turn success probability under the minimal turns, as well as the generalization to subtasks with shorter horizons.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0233#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0233-efac948251", "paper_id": "P0233", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have demonstrated remarkable capabilities in knowledge acquisition, reasoning, and tool use, making them promising candidates for autonomous agent applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0233#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0233-291455ba2c", "paper_id": "P0233", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, training LLM agents for complex multi-turn task planning faces significant challenges, including sparse episode-wise rewards, credit assignment across long horizons, and the computational overhead of reinforcement learning in multi-turn interaction settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0233#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0233-ac96b98574", "paper_id": "P0233", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To this end, this paper introduces a novel approach that transforms multi-turn task planning into single-turn task reasoning problems, enabling efficient policy optimization through Group Relative Policy Optimization (GRPO) with dense and verifiable reward from expert trajectories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0233#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0233-2976c895e6", "paper_id": "P0233", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our theoretical analysis shows that GRPO improvement on single-turn task reasoning results in a lower bound of the multi-turn success probability under the minimal turns, as well as the generalization to subtasks with shorter horizons.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0233#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0233-057551f064", "paper_id": "P0233", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0233#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0234-ed4c8ec45f", "paper_id": "P0234", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The COVID-19 infodemic calls for scalable fact-checking solutions that handle long-form misinformation with accuracy and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0234#method"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0234-866b979e15", "paper_id": "P0234", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The COVID-19 infodemic calls for scalable fact-checking solutions that handle long-form misinformation with accuracy and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0234#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0234-4af0cf3c02", "paper_id": "P0234", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This study presents SAFE (system for accurate fact extraction and evaluation), an agent system that combines large language models with retrieval-augmented generation (RAG) to improve automated fact-checking of long-form COVID-19 misinformation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0234#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0234-83d97ab146", "paper_id": "P0234", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The COVID-19 infodemic calls for scalable fact-checking solutions that handle long-form misinformation with accuracy and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0234#summary_bullets[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0234-e8d583cea2", "paper_id": "P0234", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study presents SAFE (system for accurate fact extraction and evaluation), an agent system that combines large language models with retrieval-augmented generation (RAG) to improve automated fact-checking of long-form COVID-19 misinformation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0234#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0234-19278ea365", "paper_id": "P0234", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "SAFE includes two agents - one for claim extraction and another for claim verification using LOTR-RAG, which leverages a 130,000-document COVID-19 research corpus.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0234#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0234-8e7b909939", "paper_id": "P0234", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "An enhanced variant, SAFE (LOTR-RAG + SRAG), incorporates Self-RAG to refine retrieval via query rewriting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0234#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0234-a749e91e9a", "paper_id": "P0234", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluated both systems on 50 fake news articles (2-17 pages) containing 246 annotated claims (M = 4.922, SD = 3.186), labeled as true (14.1%), partly true (14.4%), false (27.0%), partly false (2.2%), and misleading (21.0%) by public health professionals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0234#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0234-c9781caf3b", "paper_id": "P0234", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "SAFE demonstrates robust improvements in long-form COVID-19 fact-checking by addressing LLM limitations in consistency and explainability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0234#limitations[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0235-dff408fb18", "paper_id": "P0235", "bibkey": "Almeida2025Using", "title": "Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Keeping software systems up to date is essential to avoid technical debt, security vulnerabilities, and the rigidity typical of legacy systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0235#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0235-b0064305fc", "paper_id": "P0235", "bibkey": "Almeida2025Using", "title": "Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The results of our study show that the LLM agent was capable of migrating functionalities and API usages between SQLAlchemy versions (migration coverage: 100%, median), but failed to maintain the application functionality, leading to a low test-pass rate (39.75%, median).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0235#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers", "tooling"]}
{"evidence_id": "E-P0235-9c4c917ef3", "paper_id": "P0235", "bibkey": "Almeida2025Using", "title": "Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In this paper, we evaluate the update of a well-known Python library, SQLAlchemy, across a dataset of ten client applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0235#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0235-4ee2dff303", "paper_id": "P0235", "bibkey": "Almeida2025Using", "title": "Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Keeping software systems up to date is essential to avoid technical debt, security vulnerabilities, and the rigidity typical of legacy systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0235#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0235-9194c35ac6", "paper_id": "P0235", "bibkey": "Almeida2025Using", "title": "Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, updating libraries and frameworks remains a time consuming and error-prone process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0235#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0235-b1536d6934", "paper_id": "P0235", "bibkey": "Almeida2025Using", "title": "Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in Large Language Models (LLMs) and agentic coding systems offer new opportunities for automating such maintenance tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0235#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0235-184fce31e3", "paper_id": "P0235", "bibkey": "Almeida2025Using", "title": "Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we evaluate the update of a well-known Python library, SQLAlchemy, across a dataset of ten client applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0235#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0235-5437af787b", "paper_id": "P0235", "bibkey": "Almeida2025Using", "title": "Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "For this task, we use the Github's Copilot Agent Mode, an autonomous AI systema capable of planning and executing multi-step migration workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0235#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0236-f3afc49a32", "paper_id": "P0236", "bibkey": "Fang2025Should", "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The development of large language models (LLMs) has entered in a experience-driven era, flagged by the emergence of environment feedback-driven learning via reinforcement learning and tool-using agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0236#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0236-dcb97bbb10", "paper_id": "P0236", "bibkey": "Fang2025Should", "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "(1) We first construct \\framework, a controlled framework to examine safety issues in MCP-powered agent systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0236#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0236-3cd6217549", "paper_id": "P0236", "bibkey": "Fang2025Should", "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "(2) We then conduct a series of pilot experiments to demonstrate the safety risks in MCP-powered agent systems is a real threat and its defense is not trivial.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0236#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0236-215a0ff6ef", "paper_id": "P0236", "bibkey": "Fang2025Should", "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The development of large language models (LLMs) has entered in a experience-driven era, flagged by the emergence of environment feedback-driven learning via reinforcement learning and tool-using agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0236#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0236-2053d546a5", "paper_id": "P0236", "bibkey": "Fang2025Should", "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This encourages the emergenece of model context protocol (MCP), which defines the standard on how should a LLM interact with external services, such as \\api and data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0236#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0236-8d29c7793f", "paper_id": "P0236", "bibkey": "Fang2025Should", "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, as MCP becomes the de facto standard for LLM agent systems, it also introduces new safety risks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0236#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0236-77a70b49c8", "paper_id": "P0236", "bibkey": "Fang2025Should", "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In particular, MCP introduces third-party services, which are not controlled by the LLM developers, into the agent systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0236#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0236-1ca9e70d75", "paper_id": "P0236", "bibkey": "Fang2025Should", "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These third-party MCP services provider are potentially malicious and have the economic incentives to exploit vulnerabilities and sabotage user-agent interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0236#summary_bullets[4]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0237-e34319b92c", "paper_id": "P0237", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "There is growing interest in using Large Language Models as agents (LLM agents) for social simulations to inform policy, yet real-world adoption remains limited.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0237#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0237-ccc7d0cc50", "paper_id": "P0237", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across multiple design iterations, we iteratively developed a system of 13,000 LLM agents that simulate crowd movement and communication during a large-scale gathering under various emergency scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0237#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0237-0e210813b4", "paper_id": "P0237", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "There is growing interest in using Large Language Models as agents (LLM agents) for social simulations to inform policy, yet real-world adoption remains limited.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0237#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0237-2651954a10", "paper_id": "P0237", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper addresses the question: How can LLM agent simulations be made genuinely useful for policy?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0237#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0237-955593c3c4", "paper_id": "P0237", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We report on a year-long iterative design engagement with a university emergency preparedness team.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0237#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0237-31107a1a8d", "paper_id": "P0237", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Across multiple design iterations, we iteratively developed a system of 13,000 LLM agents that simulate crowd movement and communication during a large-scale gathering under various emergency scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0237#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0237-7691655ded", "paper_id": "P0237", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These simulations informed actual policy implementation, shaping volunteer training, evacuation protocols, and infrastructure planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0237#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0238-32516d8b0b", "paper_id": "P0238", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "First, we introduce the AgentErrorTaxonomy, a modular classification of failure modes spanning memory, reflection, planning, action, and system-level operations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0238#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0238-3a24449737", "paper_id": "P0238", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on AgentErrorBench show that AgentDebug achieves 24% higher all-correct accuracy and 17% higher step accuracy compared to the strongest baseline.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0238#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0238-cb04969cfe", "paper_id": "P0238", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Beyond detection, the targeted feedback generated by AgentDebug enables LLM agents to iteratively recover from failures, yielding up to 26% relative improvements in task success across ALFWorld, GAIA, and WebShop.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0238#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0238-085ad78ac8", "paper_id": "P0238", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents, which integrate planning, memory, reflection, and tool-use modules, have shown promise in solving complex, multi-step tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0238#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0238-46914a4804", "paper_id": "P0238", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Yet their sophisticated architectures amplify vulnerability to cascading failures, where a single root-cause error propagates through subsequent decisions, leading to task failure.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0238#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0238-f1dcce8f4d", "paper_id": "P0238", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current systems lack a framework that can comprehensively understand agent error in a modular and systemic way, and therefore fail to detect these errors accordingly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0238#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0238-cfb691cbc4", "paper_id": "P0238", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We address this gap with three contributions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0238#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0238-0d0d8bae59", "paper_id": "P0238", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "First, we introduce the AgentErrorTaxonomy, a modular classification of failure modes spanning memory, reflection, planning, action, and system-level operations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0238#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0239-e4cf8cd093", "paper_id": "P0239", "bibkey": "Shi2025Youtu", "title": "Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these issues, we propose \\textbf{Youtu-Agent}, a modular framework designed for the automated generation and continuous evolution of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0239#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0239-5ad9d205d0", "paper_id": "P0239", "bibkey": "Shi2025Youtu", "title": "Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our automated generation pipeline achieves over 81\\% tool synthesis success rate, while the Practice module improves performance on AIME 2024/2025 by +2.7\\% and +5.4\\% respectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0239#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0239-9af3444274", "paper_id": "P0239", "bibkey": "Shi2025Youtu", "title": "Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Moreover, our Agent RL training achieves 40\\% speedup with steady performance improvement on 7B LLMs, enhancing coding/reasoning and searching capabilities respectively up to 35\\% and 21\\% on Maths and general/multi-hop QA benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0239#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0239-07d5c43cac", "paper_id": "P0239", "bibkey": "Shi2025Youtu", "title": "Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0239#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0239-0bf3698407", "paper_id": "P0239", "bibkey": "Shi2025Youtu", "title": "Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic environments without expensive fine-tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0239#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0239-cd19a2a6e6", "paper_id": "P0239", "bibkey": "Shi2025Youtu", "title": "Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these issues, we propose \\textbf{Youtu-Agent}, a modular framework designed for the automated generation and continuous evolution of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0239#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0239-66842fd0e4", "paper_id": "P0239", "bibkey": "Shi2025Youtu", "title": "Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Youtu-Agent features a structured configuration system that decouples execution environments, toolkits, and context management, enabling flexible reuse and automated synthesis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0239#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0239-4b1b8ca943", "paper_id": "P0239", "bibkey": "Shi2025Youtu", "title": "Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce two generation paradigms: a \\textbf{Workflow} mode for standard tasks and a \\textbf{Meta-Agent} mode for complex, non-standard requirements, capable of automatically generating tool code, prompts, and configurations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0239#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0240-14955cd54a", "paper_id": "P0240", "bibkey": "Ferraro2024Agent", "title": "Agent-Based Modelling Meets Generative AI in Social Network Simulations", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose a novel framework utilizing LLM-empowered agents to simulate social network users based on their interests and personality traits.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0240#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0240-622df08efc", "paper_id": "P0240", "bibkey": "Ferraro2024Agent", "title": "Agent-Based Modelling Meets Generative AI in Social Network Simulations", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We validate our framework using a comprehensive Twitter dataset from the 2020 US election, demonstrating that LLM-agents accurately replicate real users' behaviors, including linguistic patterns and political inclinations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0240#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0240-7e15329dea", "paper_id": "P0240", "bibkey": "Ferraro2024Agent", "title": "Agent-Based Modelling Meets Generative AI in Social Network Simulations", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Integrating modern Large Language Models (LLMs) with ABM presents a promising avenue to address these challenges and enhance simulation fidelity, leveraging LLMs' human-like capabilities in sensing, reasoning, and behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0240#key_results[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0240-9e5904a1d3", "paper_id": "P0240", "bibkey": "Ferraro2024Agent", "title": "Agent-Based Modelling Meets Generative AI in Social Network Simulations", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agent-Based Modelling (ABM) has emerged as an essential tool for simulating social networks, encompassing diverse phenomena such as information dissemination, influence dynamics, and community formation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0240#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0240-fa9f61c750", "paper_id": "P0240", "bibkey": "Ferraro2024Agent", "title": "Agent-Based Modelling Meets Generative AI in Social Network Simulations", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, manually configuring varied agent interactions and information flow dynamics poses challenges, often resulting in oversimplified models that lack real-world generalizability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0240#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0240-68ccb20836", "paper_id": "P0240", "bibkey": "Ferraro2024Agent", "title": "Agent-Based Modelling Meets Generative AI in Social Network Simulations", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Integrating modern Large Language Models (LLMs) with ABM presents a promising avenue to address these challenges and enhance simulation fidelity, leveraging LLMs' human-like capabilities in sensing, reasoning, and behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0240#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0240-18fd0ce656", "paper_id": "P0240", "bibkey": "Ferraro2024Agent", "title": "Agent-Based Modelling Meets Generative AI in Social Network Simulations", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose a novel framework utilizing LLM-empowered agents to simulate social network users based on their interests and personality traits.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0240#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0240-9323d11875", "paper_id": "P0240", "bibkey": "Ferraro2024Agent", "title": "Agent-Based Modelling Meets Generative AI in Social Network Simulations", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The framework allows for customizable agent interactions resembling various social network platforms, including mechanisms for content resharing and personalized recommendations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0240#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0241-cd6a2150b0", "paper_id": "P0241", "bibkey": "Zhang2024Agent", "title": "Agent-SafetyBench: Evaluating the Safety of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce Agent-SafetyBench, a comprehensive benchmark designed to evaluate the safety of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0241#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0241-e26328e18c", "paper_id": "P0241", "bibkey": "Zhang2024Agent", "title": "Agent-SafetyBench: Evaluating the Safety of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation of 16 popular LLM agents reveals a concerning result: none of the agents achieves a safety score above 60%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0241#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0241-51b52c66a1", "paper_id": "P0241", "bibkey": "Zhang2024Agent", "title": "Agent-SafetyBench: Evaluating the Safety of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Agent-SafetyBench encompasses 349 interaction environments and 2,000 test cases, evaluating 8 categories of safety risks and covering 10 common failure modes frequently encountered in unsafe interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0241#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0241-c2eb54b5d1", "paper_id": "P0241", "bibkey": "Zhang2024Agent", "title": "Agent-SafetyBench: Evaluating the Safety of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As large language models (LLMs) are increasingly deployed as agents, their integration into interactive environments and tool use introduce new safety challenges beyond those associated with the models themselves.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0241#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0241-4f7fc773bd", "paper_id": "P0241", "bibkey": "Zhang2024Agent", "title": "Agent-SafetyBench: Evaluating the Safety of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the absence of comprehensive benchmarks for evaluating agent safety presents a significant barrier to effective assessment and further improvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0241#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0241-7449e0af3a", "paper_id": "P0241", "bibkey": "Zhang2024Agent", "title": "Agent-SafetyBench: Evaluating the Safety of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce Agent-SafetyBench, a comprehensive benchmark designed to evaluate the safety of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0241#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0241-baeab75906", "paper_id": "P0241", "bibkey": "Zhang2024Agent", "title": "Agent-SafetyBench: Evaluating the Safety of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agent-SafetyBench encompasses 349 interaction environments and 2,000 test cases, evaluating 8 categories of safety risks and covering 10 common failure modes frequently encountered in unsafe interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0241#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0241-96e35bac3f", "paper_id": "P0241", "bibkey": "Zhang2024Agent", "title": "Agent-SafetyBench: Evaluating the Safety of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our evaluation of 16 popular LLM agents reveals a concerning result: none of the agents achieves a safety score above 60%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0241#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0242-506e1faa5d", "paper_id": "P0242", "bibkey": "Jin2024Agentreview", "title": "AgentReview: Exploring Peer Review Dynamics with LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce AgentReview, the first large language model (LLM) based peer review simulation framework, which effectively disentangles the impacts of multiple latent factors and addresses the privacy issue.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0242#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0242-db73816454", "paper_id": "P0242", "bibkey": "Jin2024Agentreview", "title": "AgentReview: Exploring Peer Review Dynamics with LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our study reveals significant insights, including a notable 37.1% variation in paper decisions due to reviewers' biases, supported by sociological theories such as the social influence theory, altruism fatigue, and authority bias.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0242#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0242-dc6e26b39f", "paper_id": "P0242", "bibkey": "Jin2024Agentreview", "title": "AgentReview: Exploring Peer Review Dynamics with LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Peer review is fundamental to the integrity and advancement of scientific publication.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0242#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0242-4ce1577440", "paper_id": "P0242", "bibkey": "Jin2024Agentreview", "title": "AgentReview: Exploring Peer Review Dynamics with LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional methods of peer review analyses often rely on exploration and statistics of existing peer review data, which do not adequately address the multivariate nature of the process, account for the latent variables, and are further constrained by privacy concerns due to the sensitive nature of the data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0242#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0242-3c02e42f6a", "paper_id": "P0242", "bibkey": "Jin2024Agentreview", "title": "AgentReview: Exploring Peer Review Dynamics with LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce AgentReview, the first large language model (LLM) based peer review simulation framework, which effectively disentangles the impacts of multiple latent factors and addresses the privacy issue.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0242#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0242-56d50beac1", "paper_id": "P0242", "bibkey": "Jin2024Agentreview", "title": "AgentReview: Exploring Peer Review Dynamics with LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our study reveals significant insights, including a notable 37.1% variation in paper decisions due to reviewers' biases, supported by sociological theories such as the social influence theory, altruism fatigue, and authority bias.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0242#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0242-b8d6dfb50f", "paper_id": "P0242", "bibkey": "Jin2024Agentreview", "title": "AgentReview: Exploring Peer Review Dynamics with LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We believe that this study could offer valuable insights to improve the design of peer review mechanisms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0242#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0243-f37cede190", "paper_id": "P0243", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce a new research problem: Modularized LLM Agent Search (MoLAS).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0243#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0243-38a26e4777", "paper_id": "P0243", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0243#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0243-dca71a3ca8", "paper_id": "P0243", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in Large Language Models (LLMs) have led to a rapid growth of agentic systems capable of handling a wide range of complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0243#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0243-9dc7792507", "paper_id": "P0243", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, current research largely relies on manual, task-specific design, limiting their adaptability to novel tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0243#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0243-df54024240", "paper_id": "P0243", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce a new research problem: Modularized LLM Agent Search (MoLAS).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0243#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0243-d863729a45", "paper_id": "P0243", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose a modular design space that abstracts existing LLM agent designs into four fundamental modules with uniform IO interface: Planning, Reasoning, Tool Use, and Memory.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0243#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0243-33a25da160", "paper_id": "P0243", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Building on this design space, we present a novel LLM agent search framework called AgentSquare, which introduces two core mechanisms, i.e., module evolution and recombination, to efficiently search for optimized LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0243#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0244-a8edcaf3a9", "paper_id": "P0244", "bibkey": "Chen2024Agent", "title": "An LLM Agent for Automatic Geospatial Data Analysis", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To tackle these problems, we introduce GeoAgent, a new interactive framework designed to help LLMs handle geospatial data processing more effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0244#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0244-5c782bca09", "paper_id": "P0244", "bibkey": "Chen2024Agent", "title": "An LLM Agent for Automatic Geospatial Data Analysis", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "In addition, we contribute a new benchmark specifically designed to evaluate the LLM-based approach in geospatial tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0244#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0244-1d3ae55419", "paper_id": "P0244", "bibkey": "Chen2024Agent", "title": "An LLM Agent for Automatic Geospatial Data Analysis", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "This benchmark leverages a variety of Python libraries and includes both single-turn and multi-turn tasks such as data acquisition, data analysis, and visualization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0244#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0244-8026945f34", "paper_id": "P0244", "bibkey": "Chen2024Agent", "title": "An LLM Agent for Automatic Geospatial Data Analysis", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are being used in data science code generation tasks, but they often struggle with complex sequential tasks, leading to logical errors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0244#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0244-e98481a751", "paper_id": "P0244", "bibkey": "Chen2024Agent", "title": "An LLM Agent for Automatic Geospatial Data Analysis", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Their application to geospatial data processing is particularly challenging due to difficulties in incorporating complex data structures and spatial constraints, effectively utilizing diverse function calls, and the tendency to hallucinate less-used geospatial libraries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0244#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0244-b04c45078f", "paper_id": "P0244", "bibkey": "Chen2024Agent", "title": "An LLM Agent for Automatic Geospatial Data Analysis", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To tackle these problems, we introduce GeoAgent, a new interactive framework designed to help LLMs handle geospatial data processing more effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0244#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0244-58fb8d79dd", "paper_id": "P0244", "bibkey": "Chen2024Agent", "title": "An LLM Agent for Automatic Geospatial Data Analysis", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "GeoAgent pioneers the integration of a code interpreter, static analysis, and Retrieval-Augmented Generation (RAG) techniques within a Monte Carlo Tree Search (MCTS) algorithm, offering a novel approach to geospatial data processing.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0244#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0244-d89444a7a3", "paper_id": "P0244", "bibkey": "Chen2024Agent", "title": "An LLM Agent for Automatic Geospatial Data Analysis", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In addition, we contribute a new benchmark specifically designed to evaluate the LLM-based approach in geospatial tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0244#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0245-da0ee5f82c", "paper_id": "P0245", "bibkey": "Ginart2024Asynchronous", "title": "Asynchronous Tool Usage for Real-Time Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this limitation, we introduce asynchronous AI agents capable of parallel processing and real-time tool-use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0245#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0245-93e0e37550", "paper_id": "P0245", "bibkey": "Ginart2024Asynchronous", "title": "Asynchronous Tool Usage for Real-Time Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Drawing inspiration from the concepts originally developed for real-time operating systems, this work presents both a conceptual framework and practical tools for creating AI agents capable of fluid, multitasking interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0245#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0245-e1585fe1d0", "paper_id": "P0245", "bibkey": "Ginart2024Asynchronous", "title": "Asynchronous Tool Usage for Real-Time Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While frontier large language models (LLMs) are capable tool-using agents, current AI systems still operate in a strict turn-based fashion, oblivious to passage of time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0245#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0245-0b44232dea", "paper_id": "P0245", "bibkey": "Ginart2024Asynchronous", "title": "Asynchronous Tool Usage for Real-Time Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This synchronous design forces user queries and tool-use to occur sequentially, preventing the systems from multitasking and reducing interactivity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0245#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0245-504872fe71", "paper_id": "P0245", "bibkey": "Ginart2024Asynchronous", "title": "Asynchronous Tool Usage for Real-Time Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this limitation, we introduce asynchronous AI agents capable of parallel processing and real-time tool-use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0245#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0245-15164c10af", "paper_id": "P0245", "bibkey": "Ginart2024Asynchronous", "title": "Asynchronous Tool Usage for Real-Time Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our key contribution is an event-driven finite-state machine architecture for agent execution and prompting, integrated with automatic speech recognition and text-to-speech.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0245#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0245-8eb2126b81", "paper_id": "P0245", "bibkey": "Ginart2024Asynchronous", "title": "Asynchronous Tool Usage for Real-Time Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Drawing inspiration from the concepts originally developed for real-time operating systems, this work presents both a conceptual framework and practical tools for creating AI agents capable of fluid, multitasking interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0245#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0245-9b22ac70aa", "paper_id": "P0245", "bibkey": "Ginart2024Asynchronous", "title": "Asynchronous Tool Usage for Real-Time Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address this limitation, we introduce asynchronous AI agents capable of parallel processing and real-time tool-use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0245#limitations[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0246-9effa35196", "paper_id": "P0246", "bibkey": "Wu2024Avatar", "title": "AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Here, we introduce AvaTaR, a novel and automated framework that optimizes an LLM agent to effectively leverage provided tools, improving performance on a given task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0246#method"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0246-3575a7c673", "paper_id": "P0246", "bibkey": "Wu2024Avatar", "title": "AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We find AvaTaR consistently outperforms state-of-the-art approaches across all seven tasks, exhibiting strong generalization ability when applied to novel cases and achieving an average relative improvement of 14% on the Hit@1 metric for the retrieval datasets and 13% for the QA datasets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0246#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0246-2032a098fd", "paper_id": "P0246", "bibkey": "Wu2024Avatar", "title": "AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large language model (LLM) agents have demonstrated impressive capabilities in utilizing external tools and knowledge to boost accuracy and reduce hallucinations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0246#key_results[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0246-9d487b28b3", "paper_id": "P0246", "bibkey": "Wu2024Avatar", "title": "AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents have demonstrated impressive capabilities in utilizing external tools and knowledge to boost accuracy and reduce hallucinations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0246#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0246-89c6a36649", "paper_id": "P0246", "bibkey": "Wu2024Avatar", "title": "AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, developing prompting techniques that enable LLM agents to effectively use these tools and knowledge remains a heuristic and labor-intensive task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0246#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0246-c8fa7cd7e1", "paper_id": "P0246", "bibkey": "Wu2024Avatar", "title": "AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Here, we introduce AvaTaR, a novel and automated framework that optimizes an LLM agent to effectively leverage provided tools, improving performance on a given task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0246#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0246-40118b1fc6", "paper_id": "P0246", "bibkey": "Wu2024Avatar", "title": "AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "During optimization, we design a comparator module to iteratively deliver insightful and comprehensive prompts to the LLM agent by contrastively reasoning between positive and negative examples sampled from training data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0246#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0246-83bd99b4fc", "paper_id": "P0246", "bibkey": "Wu2024Avatar", "title": "AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We demonstrate AvaTaR on four complex multimodal retrieval datasets featuring textual, visual, and relational information, and three general question-answering (QA) datasets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0246#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0247-aeefb30e73", "paper_id": "P0247", "bibkey": "Choudhury2024Better", "title": "Better than Your Teacher: LLM Agents that learn from Privileged AI Feedback", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose LEAP, an iterative fine-tuning framework that continually improves LLM agents using feedback from AI expert teachers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0247#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0247-6282c58bee", "paper_id": "P0247", "bibkey": "Choudhury2024Better", "title": "Better than Your Teacher: LLM Agents that learn from Privileged AI Feedback", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments show that LEAP (1) outperforms behavior cloning and ReAct baselines (2) enables weak student models (e.g., Llama3-8B) to exceed the performance of strong teacher models (GPT4-o), and (3) allows weak models to self-improve using privileged versions of themselves.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0247#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0247-1ae14640b0", "paper_id": "P0247", "bibkey": "Choudhury2024Better", "title": "Better than Your Teacher: LLM Agents that learn from Privileged AI Feedback", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate LEAP on diverse decision-making benchmarks, including text-based games (ALFWorld), web navigation (WebShop), and interactive coding (Intercode Bash).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0247#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0247-c376d9a3f9", "paper_id": "P0247", "bibkey": "Choudhury2024Better", "title": "Better than Your Teacher: LLM Agents that learn from Privileged AI Feedback", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While large language models (LLMs) show impressive decision-making abilities, current methods lack a mechanism for automatic self-improvement from errors during task execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0247#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0247-6641d2f99a", "paper_id": "P0247", "bibkey": "Choudhury2024Better", "title": "Better than Your Teacher: LLM Agents that learn from Privileged AI Feedback", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose LEAP, an iterative fine-tuning framework that continually improves LLM agents using feedback from AI expert teachers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0247#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0247-4ec5d5302a", "paper_id": "P0247", "bibkey": "Choudhury2024Better", "title": "Better than Your Teacher: LLM Agents that learn from Privileged AI Feedback", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our key insight is to equip the expert teachers with a privileged state -- information that is available during training but hidden at test time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0247#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0247-a824409838", "paper_id": "P0247", "bibkey": "Choudhury2024Better", "title": "Better than Your Teacher: LLM Agents that learn from Privileged AI Feedback", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This allows even weak experts to provide precise guidance, significantly improving the student agent's performance without access to privileged information at test time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0247#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0247-615499d31a", "paper_id": "P0247", "bibkey": "Choudhury2024Better", "title": "Better than Your Teacher: LLM Agents that learn from Privileged AI Feedback", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluate LEAP on diverse decision-making benchmarks, including text-based games (ALFWorld), web navigation (WebShop), and interactive coding (Intercode Bash).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0247#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0248-45be765e9d", "paper_id": "P0248", "bibkey": "Huang2024Crmarena", "title": "CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this issue, we introduce CRMArena, a novel benchmark designed to evaluate AI agents on realistic tasks grounded in professional work environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0248#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0248-40e92b5d3f", "paper_id": "P0248", "bibkey": "Huang2024Crmarena", "title": "CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The benchmark includes 16 commonly used industrial objects (e.g., account, order, knowledge article, case) with high interconnectivity, along with latent variables (e.g., complaint habits, policy violations) to simulate realistic data distributions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0248#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0248-2526ef1c6a", "paper_id": "P0248", "bibkey": "Huang2024Crmarena", "title": "CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experimental results reveal that state-of-the-art LLM agents succeed in less than 40% of the tasks with ReAct prompting, and less than 55% even with function-calling abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0248#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0248-64a0a34fea", "paper_id": "P0248", "bibkey": "Huang2024Crmarena", "title": "CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Customer Relationship Management (CRM) systems are vital for modern enterprises, providing a foundation for managing customer interactions and data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0248#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0248-ba0a8ab690", "paper_id": "P0248", "bibkey": "Huang2024Crmarena", "title": "CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Integrating AI agents into CRM systems can automate routine processes and enhance personalized service.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0248#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0248-87e213d22b", "paper_id": "P0248", "bibkey": "Huang2024Crmarena", "title": "CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, deploying and evaluating these agents is challenging due to the lack of realistic benchmarks that reflect the complexity of real-world CRM tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0248#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0248-33d9f2b0d1", "paper_id": "P0248", "bibkey": "Huang2024Crmarena", "title": "CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this issue, we introduce CRMArena, a novel benchmark designed to evaluate AI agents on realistic tasks grounded in professional work environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0248#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0248-922a0f492f", "paper_id": "P0248", "bibkey": "Huang2024Crmarena", "title": "CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Following guidance from CRM experts and industry best practices, we designed CRMArena with nine customer service tasks distributed across three personas: service agent, analyst, and manager.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0248#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0249-792f56ca3e", "paper_id": "P0249", "bibkey": "Ma2024Caution", "title": "Caution for the Environment: Multimodal LLM Agents are Susceptible to Environmental Distractions", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "This paper investigates the faithfulness of multimodal large language model (MLLM) agents in a graphical user interface (GUI) environment, aiming to address the research question of whether multimodal GUI agents can be distracted by environmental context.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0249#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0249-5ea5e4c03e", "paper_id": "P0249", "bibkey": "Ma2024Caution", "title": "Caution for the Environment: Multimodal LLM Agents are Susceptible to Environmental Distractions", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "A wide range of MLLMs are evaluated as GUI agents using a simulated dataset, following three working patterns with different levels of perception.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0249#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0249-fba9295bd9", "paper_id": "P0249", "bibkey": "Ma2024Caution", "title": "Caution for the Environment: Multimodal LLM Agents are Susceptible to Environmental Distractions", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper investigates the faithfulness of multimodal large language model (MLLM) agents in a graphical user interface (GUI) environment, aiming to address the research question of whether multimodal GUI agents can be distracted by environmental context.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0249#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0249-8b6d7aeb74", "paper_id": "P0249", "bibkey": "Ma2024Caution", "title": "Caution for the Environment: Multimodal LLM Agents are Susceptible to Environmental Distractions", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A general scenario is proposed where both the user and the agent are benign, and the environment, while not malicious, contains unrelated content.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0249#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0249-29b44fe82a", "paper_id": "P0249", "bibkey": "Ma2024Caution", "title": "Caution for the Environment: Multimodal LLM Agents are Susceptible to Environmental Distractions", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A wide range of MLLMs are evaluated as GUI agents using a simulated dataset, following three working patterns with different levels of perception.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0249#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0249-f24ddec279", "paper_id": "P0249", "bibkey": "Ma2024Caution", "title": "Caution for the Environment: Multimodal LLM Agents are Susceptible to Environmental Distractions", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Experimental results reveal that even the most powerful models, whether generalist agents or specialist GUI agents, are susceptible to distractions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0249#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0249-c482dc86b7", "paper_id": "P0249", "bibkey": "Ma2024Caution", "title": "Caution for the Environment: Multimodal LLM Agents are Susceptible to Environmental Distractions", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While recent studies predominantly focus on the helpfulness of agents, our findings first indicate that these agents are prone to environmental distractions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0249#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0250-3bb0779957", "paper_id": "P0250", "bibkey": "Gupta2024Codenav", "title": "CodeNav: Beyond tool-use to using real-world codebases with LLM agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present CodeNav, an LLM agent that navigates and leverages previously unseen code repositories to solve user queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0250#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0250-a8aa0f8a7d", "paper_id": "P0250", "bibkey": "Gupta2024Codenav", "title": "CodeNav: Beyond tool-use to using real-world codebases with LLM agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Next, on three benchmarks, we quantitatively compare the effectiveness of code-use (which only has access to the target codebase) to tool-use (which has privileged access to all tool names and descriptions).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0250#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0250-901450fe50", "paper_id": "P0250", "bibkey": "Gupta2024Codenav", "title": "CodeNav: Beyond tool-use to using real-world codebases with LLM agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present CodeNav, an LLM agent that navigates and leverages previously unseen code repositories to solve user queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0250#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0250-bce5ff06ef", "paper_id": "P0250", "bibkey": "Gupta2024Codenav", "title": "CodeNav: Beyond tool-use to using real-world codebases with LLM agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In contrast to tool-use LLM agents that require ``registration'' of all relevant tools via manual descriptions within the LLM context, CodeNav automatically indexes and searches over code blocks in the target codebase, finds relevant code snippets, imports them, and uses them to iteratively generate a solution with execution feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0250#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0250-64b0e24763", "paper_id": "P0250", "bibkey": "Gupta2024Codenav", "title": "CodeNav: Beyond tool-use to using real-world codebases with LLM agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To highlight the core-capabilities of CodeNav, we first showcase three case studies where we use CodeNav for solving complex user queries using three diverse codebases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0250#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0250-70ab05ee6b", "paper_id": "P0250", "bibkey": "Gupta2024Codenav", "title": "CodeNav: Beyond tool-use to using real-world codebases with LLM agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Next, on three benchmarks, we quantitatively compare the effectiveness of code-use (which only has access to the target codebase) to tool-use (which has privileged access to all tool names and descriptions).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0250#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0250-a7c3966cdf", "paper_id": "P0250", "bibkey": "Gupta2024Codenav", "title": "CodeNav: Beyond tool-use to using real-world codebases with LLM agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Finally, we study the effect of varying kinds of tool and library descriptions on code-use performance, as well as investigate the advantage of the agent seeing source code as opposed to natural descriptions of code.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0250#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0251-8930fe3a07", "paper_id": "P0251", "bibkey": "Li2024Codetree", "title": "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this problem, we propose CodeTree, a framework for LLM agents to efficiently explore the search space in different stages of the code generation process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0251#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0251-7c8012e69f", "paper_id": "P0251", "bibkey": "Li2024Codetree", "title": "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We comprehensively evaluated CodeTree on 7 code generation benchmarks and demonstrated the significant performance gains of CodeTree against strong baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0251#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0251-6d63ed82d0", "paper_id": "P0251", "bibkey": "Li2024Codetree", "title": "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Using GPT-4o as the base model, we consistently achieved top results of 95.1 on HumanEval, 98.7 on MBPP, and 43.0 on CodeContests.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0251#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0251-8722819889", "paper_id": "P0251", "bibkey": "Li2024Codetree", "title": "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Pre-trained on massive amounts of code and text data, large language models (LLMs) have demonstrated remarkable achievements in performing code generation tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0251#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0251-f20745998b", "paper_id": "P0251", "bibkey": "Li2024Codetree", "title": "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With additional execution-based feedback, these models can act as agents with capabilities to self-refine and improve generated code autonomously.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0251#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0251-da633ef626", "paper_id": "P0251", "bibkey": "Li2024Codetree", "title": "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, on challenging coding tasks with extremely large search space, current agentic approaches still struggle with multi-stage planning, generating, and debugging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0251#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0251-c7100326b2", "paper_id": "P0251", "bibkey": "Li2024Codetree", "title": "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this problem, we propose CodeTree, a framework for LLM agents to efficiently explore the search space in different stages of the code generation process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0251#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0251-6daba26048", "paper_id": "P0251", "bibkey": "Li2024Codetree", "title": "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Specifically, we adopted a unified tree structure to explicitly explore different coding strategies, generate corresponding coding solutions, and subsequently refine the solutions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0251#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0252-9b9579b708", "paper_id": "P0252", "bibkey": "Liu2024Codexgraph", "title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To mitigate these limitations, we introduce CodexGraph, a system that integrates LLM agents with graph database interfaces extracted from code repositories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0252#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0252-90b8aa89af", "paper_id": "P0252", "bibkey": "Liu2024Codexgraph", "title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We assess CodexGraph using three benchmarks: CrossCodeEval, SWE-bench, and EvoCodeBench.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0252#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0252-ae02a4a92c", "paper_id": "P0252", "bibkey": "Liu2024Codexgraph", "title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) excel in stand-alone code tasks like HumanEval and MBPP, but struggle with handling entire code repositories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0252#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0252-0bb26ce6d5", "paper_id": "P0252", "bibkey": "Liu2024Codexgraph", "title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This challenge has prompted research on enhancing LLM-codebase interaction at a repository scale.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0252#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0252-0792aa0f0f", "paper_id": "P0252", "bibkey": "Liu2024Codexgraph", "title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current solutions rely on similarity-based retrieval or manual tools and APIs, each with notable drawbacks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0252#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0252-3ff855b60d", "paper_id": "P0252", "bibkey": "Liu2024Codexgraph", "title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Similarity-based retrieval often has low recall in complex tasks, while manual tools and APIs are typically task-specific and require expert knowledge, reducing their generalizability across diverse code tasks and real-world applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0252#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0252-71594ba143", "paper_id": "P0252", "bibkey": "Liu2024Codexgraph", "title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To mitigate these limitations, we introduce CodexGraph, a system that integrates LLM agents with graph database interfaces extracted from code repositories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0252#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0252-a4fe3000ca", "paper_id": "P0252", "bibkey": "Liu2024Codexgraph", "title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To mitigate these limitations, we introduce CodexGraph, a system that integrates LLM agents with graph database interfaces extracted from code repositories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0252#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0253-7d75f47368", "paper_id": "P0253", "bibkey": "Rahn2024Controlling", "title": "Controlling Large Language Model Agents with Entropic Activation Steering", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "The rise of large language models (LLMs) has prompted increasing interest in their use as in-context learning agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0253#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0253-1f5f29e59a", "paper_id": "P0253", "bibkey": "Rahn2024Controlling", "title": "Controlling Large Language Model Agents with Entropic Activation Steering", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our work paves the way for a new understanding of the functioning of LLM agents and to effective control of their decision-making behaviors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0253#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0253-6e8b61b3ee", "paper_id": "P0253", "bibkey": "Rahn2024Controlling", "title": "Controlling Large Language Model Agents with Entropic Activation Steering", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rise of large language models (LLMs) has prompted increasing interest in their use as in-context learning agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0253#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0253-d93517352e", "paper_id": "P0253", "bibkey": "Rahn2024Controlling", "title": "Controlling Large Language Model Agents with Entropic Activation Steering", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "At the core of agentic behavior is the capacity for exploration, or the ability to actively gather information about the environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0253#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0253-a7841481d2", "paper_id": "P0253", "bibkey": "Rahn2024Controlling", "title": "Controlling Large Language Model Agents with Entropic Activation Steering", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "But how do LLM agents explore, and how can we control their exploratory behaviors?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0253#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0253-35ee9ddf15", "paper_id": "P0253", "bibkey": "Rahn2024Controlling", "title": "Controlling Large Language Model Agents with Entropic Activation Steering", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To answer these questions, we take a representation-level perspective, and introduce Entropic Activation Steering (EAST), an activation steering method for in-context LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0253#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0253-ffc843d887", "paper_id": "P0253", "bibkey": "Rahn2024Controlling", "title": "Controlling Large Language Model Agents with Entropic Activation Steering", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Firstly, we demonstrate that EAST can effectively manipulate an LLM agent's exploration by directly affecting the high-level actions parsed from the outputs of the LLM, in contrast to token-level temperature sampling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0253#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0254-2aaf9d7fde", "paper_id": "P0254", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose EHRAgent, an LLM agent empowered with a code interface, to autonomously generate and execute code for multi-tabular reasoning within electronic health records (EHRs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0254#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0254-2a7ea60588", "paper_id": "P0254", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on three real-world multi-tabular EHR datasets show that EHRAgent outperforms the strongest baseline by up to 29.6% in success rate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0254#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0254-3fd4eb3e47", "paper_id": "P0254", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have demonstrated exceptional capabilities in planning and tool utilization as autonomous agents, but few have been developed for medical problem-solving.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0254#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0254-04a0a547bf", "paper_id": "P0254", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose EHRAgent, an LLM agent empowered with a code interface, to autonomously generate and execute code for multi-tabular reasoning within electronic health records (EHRs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0254#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0254-bb81f94c2f", "paper_id": "P0254", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "First, we formulate an EHR question-answering task into a tool-use planning process, efficiently decomposing a complicated task into a sequence of manageable actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0254#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0254-0280ca8062", "paper_id": "P0254", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By integrating interactive coding and execution feedback, EHRAgent learns from error messages and improves the originally generated code through iterations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0254#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0254-a4e0896aa4", "paper_id": "P0254", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Furthermore, we enhance the LLM agent by incorporating long-term memory, which allows EHRAgent to effectively select and build upon the most relevant successful cases from past experiences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0254#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0255-fa0ff2b30b", "paper_id": "P0255", "bibkey": "Ataei2024Elicitron", "title": "Elicitron: An LLM Agent-Based Simulation Framework for Design Requirements Elicitation", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We validate our framework with three experiments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0255#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0255-edeb21f3a3", "paper_id": "P0255", "bibkey": "Ataei2024Elicitron", "title": "Elicitron: An LLM Agent-Based Simulation Framework for Design Requirements Elicitation", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Second, we show how our framework effectively mimics empathic lead user interviews, identifying a greater number of latent needs than conventional human interviews.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0255#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0255-c360585add", "paper_id": "P0255", "bibkey": "Ataei2024Elicitron", "title": "Elicitron: An LLM Agent-Based Simulation Framework for Design Requirements Elicitation", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our work highlights the potential of using LLM agents to accelerate early-stage product development, reduce costs, and increase innovation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0255#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0255-65c599c940", "paper_id": "P0255", "bibkey": "Ataei2024Elicitron", "title": "Elicitron: An LLM Agent-Based Simulation Framework for Design Requirements Elicitation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Requirements elicitation, a critical, yet time-consuming and challenging step in product development, often fails to capture the full spectrum of user needs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0255#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0255-61b7bfe457", "paper_id": "P0255", "bibkey": "Ataei2024Elicitron", "title": "Elicitron: An LLM Agent-Based Simulation Framework for Design Requirements Elicitation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This may lead to products that fall short of expectations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0255#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0255-21c09a260b", "paper_id": "P0255", "bibkey": "Ataei2024Elicitron", "title": "Elicitron: An LLM Agent-Based Simulation Framework for Design Requirements Elicitation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper introduces a novel framework that leverages Large Language Models (LLMs) to automate and enhance the requirements elicitation process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0255#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0255-f0317dbdbb", "paper_id": "P0255", "bibkey": "Ataei2024Elicitron", "title": "Elicitron: An LLM Agent-Based Simulation Framework for Design Requirements Elicitation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLMs are used to generate a vast array of simulated users (LLM agents), enabling the exploration of a much broader range of user needs and unforeseen use cases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0255#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0255-a119ce85d9", "paper_id": "P0255", "bibkey": "Ataei2024Elicitron", "title": "Elicitron: An LLM Agent-Based Simulation Framework for Design Requirements Elicitation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These agents engage in product experience scenarios, through explaining their actions, observations, and challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0255#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0256-b78c7da9ae", "paper_id": "P0256", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a framework LearnAct with an iterative learning strategy to create and improve actions in the form of Python functions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0256#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0256-9a9b9f50ae", "paper_id": "P0256", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experimental evaluations across Robotic Planning and Alfworld environments reveal that after learning on a few training task instances, our approach to open-action learning markedly improves agent performance for the type of task (by 32 percent in AlfWorld compared to ReAct+Reflexion, for instance) highlighting the importance of experiential action learning in the development of more intelligent LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0256#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0256-644765145d", "paper_id": "P0256", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) Agents have recently garnered increasing interest yet they are limited in their ability to learn from trial and error, a key element of intelligent behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0256#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0256-3a3ae3749a", "paper_id": "P0256", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we argue that the capacity to learn new actions from experience is fundamental to the advancement of learning in LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0256#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0256-4c29be4bc6", "paper_id": "P0256", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While humans naturally expand their action spaces and develop skills through experiential learning, LLM agents typically operate within fixed action spaces, limiting their potential for growth.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0256#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0256-8c6bb7f5f0", "paper_id": "P0256", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these challenges, our study explores open-action learning for language agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0256#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0256-206cbf4f78", "paper_id": "P0256", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce a framework LearnAct with an iterative learning strategy to create and improve actions in the form of Python functions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0256#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0257-1a576948d3", "paper_id": "P0257", "bibkey": "Zhai2024Enhancing", "title": "Enhancing Decision-Making for LLM Agents via Step-Level Q-Value Models", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose leveraging a task-relevant Q-value model to guide action selection.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0257#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0257-d50314c901", "paper_id": "P0257", "bibkey": "Zhai2024Enhancing", "title": "Enhancing Decision-Making for LLM Agents via Step-Level Q-Value Models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Notably, the performance of the agent built with Phi-3-mini-4k-instruct improved by 103% on WebShop and 75% on HotPotQA when enhanced with Q-value models, even surpassing GPT-4o-mini.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0257#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0257-f98a413d13", "paper_id": "P0257", "bibkey": "Zhai2024Enhancing", "title": "Enhancing Decision-Making for LLM Agents via Step-Level Q-Value Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agents significantly enhance the capabilities of standalone Large Language Models (LLMs) by perceiving environments, making decisions, and executing actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0257#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0257-daa1dfd1ba", "paper_id": "P0257", "bibkey": "Zhai2024Enhancing", "title": "Enhancing Decision-Making for LLM Agents via Step-Level Q-Value Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, LLM agents still face challenges in tasks that require multiple decision-making steps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0257#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0257-965c21b245", "paper_id": "P0257", "bibkey": "Zhai2024Enhancing", "title": "Enhancing Decision-Making for LLM Agents via Step-Level Q-Value Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Estimating the value of actions in specific tasks is difficult when intermediate actions are neither appropriately rewarded nor penalized.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0257#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0257-2076a94497", "paper_id": "P0257", "bibkey": "Zhai2024Enhancing", "title": "Enhancing Decision-Making for LLM Agents via Step-Level Q-Value Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose leveraging a task-relevant Q-value model to guide action selection.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0257#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0257-cf50e6c54e", "paper_id": "P0257", "bibkey": "Zhai2024Enhancing", "title": "Enhancing Decision-Making for LLM Agents via Step-Level Q-Value Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Specifically, we first collect decision-making trajectories annotated with step-level Q values via Monte Carlo Tree Search (MCTS) and construct preference data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0257#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0258-8970f8df6a", "paper_id": "P0258", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose a Theory of Mind (ToM) planning technique that allows LLM agents to adapt their strategy against various adversaries using only game rules, current state, and historical context as input.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0258#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0258-95dc2415e7", "paper_id": "P0258", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large language models (LLMs) have shown success in handling simple games with imperfect information and enabling multi-agent coordination, but their ability to facilitate practical collaboration against other agents in complex, imperfect information environments, especially in a non-English environment, still needs to be explored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0258#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0258-ad27d52e29", "paper_id": "P0258", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results show that although a performance gap exists between current LLMs and state-of-the-art reinforcement learning (RL) models, LLMs demonstrate ToM capabilities in this game setting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0258#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0258-693265b6e9", "paper_id": "P0258", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have shown success in handling simple games with imperfect information and enabling multi-agent coordination, but their ability to facilitate practical collaboration against other agents in complex, imperfect information environments, especially in a non-English environment, still needs to be explored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0258#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0258-7e2c5dab0a", "paper_id": "P0258", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study investigates the applicability of knowledge acquired by open-source and API-based LLMs to sophisticated text-based games requiring agent collaboration under imperfect information, comparing their performance to established baselines using other types of agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0258#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0258-6e3d8b24b2", "paper_id": "P0258", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose a Theory of Mind (ToM) planning technique that allows LLM agents to adapt their strategy against various adversaries using only game rules, current state, and historical context as input.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0258#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0258-ef9b7840cc", "paper_id": "P0258", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "An external tool was incorporated to mitigate the challenge of dynamic and extensive action spaces in this card game.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0258#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0258-080b3e774c", "paper_id": "P0258", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our results show that although a performance gap exists between current LLMs and state-of-the-art reinforcement learning (RL) models, LLMs demonstrate ToM capabilities in this game setting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0258#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0259-58d126e9cf", "paper_id": "P0259", "bibkey": "Wang2024Executable", "title": "Executable Code Actions Elicit Better LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Model (LLM) agents, capable of performing a broad range of actions, such as invoking tools and controlling robots, show great potential in tackling real-world challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0259#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0259-f712a72411", "paper_id": "P0259", "bibkey": "Wang2024Executable", "title": "Executable Code Actions Elicit Better LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our extensive analysis of 17 LLMs on API-Bank and a newly curated benchmark shows that CodeAct outperforms widely used alternatives (up to 20% higher success rate).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0259#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0259-34838e48f6", "paper_id": "P0259", "bibkey": "Wang2024Executable", "title": "Executable Code Actions Elicit Better LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "To this end, we collect an instruction-tuning dataset CodeActInstruct that consists of 7k multi-turn interactions using CodeAct.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0259#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0259-cee887cc58", "paper_id": "P0259", "bibkey": "Wang2024Executable", "title": "Executable Code Actions Elicit Better LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents, capable of performing a broad range of actions, such as invoking tools and controlling robots, show great potential in tackling real-world challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0259#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0259-c05e9326a7", "paper_id": "P0259", "bibkey": "Wang2024Executable", "title": "Executable Code Actions Elicit Better LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM agents are typically prompted to produce actions by generating JSON or text in a pre-defined format, which is usually limited by constrained action space (e.g., the scope of pre-defined tools) and restricted flexibility (e.g., inability to compose multiple tools).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0259#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0259-1184bf3259", "paper_id": "P0259", "bibkey": "Wang2024Executable", "title": "Executable Code Actions Elicit Better LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This work proposes to use executable Python code to consolidate LLM agents' actions into a unified action space (CodeAct).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0259#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0259-ff84f69415", "paper_id": "P0259", "bibkey": "Wang2024Executable", "title": "Executable Code Actions Elicit Better LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Integrated with a Python interpreter, CodeAct can execute code actions and dynamically revise prior actions or emit new actions upon new observations through multi-turn interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0259#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0259-c398685094", "paper_id": "P0259", "bibkey": "Wang2024Executable", "title": "Executable Code Actions Elicit Better LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our extensive analysis of 17 LLMs on API-Bank and a newly curated benchmark shows that CodeAct outperforms widely used alternatives (up to 20% higher success rate).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0259#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0260-7d9502f3aa", "paper_id": "P0260", "bibkey": "Wu2024Federated", "title": "Federated In-Context LLM Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose a novel privacy-preserving Federated In-Context LLM Agent Learning (FICAL) algorithm, which to our best knowledge for the first work unleashes the power of in-context learning to train diverse LLM agents through FL.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0260#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0260-76aa5df0e2", "paper_id": "P0260", "bibkey": "Wu2024Federated", "title": "Federated In-Context LLM Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We conducted extensive experiments and the results show that FICAL has competitive performance compared to other SOTA baselines with a significant communication cost decrease of $\\mathbf{3.33\\times10^5}$ times.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0260#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0260-d235ac38e0", "paper_id": "P0260", "bibkey": "Wu2024Federated", "title": "Federated In-Context LLM Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have revolutionized intelligent services by enabling logical reasoning, tool use, and interaction with external systems as agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0260#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0260-f3bb411693", "paper_id": "P0260", "bibkey": "Wu2024Federated", "title": "Federated In-Context LLM Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The advancement of LLMs is frequently hindered by the scarcity of high-quality data, much of which is inherently sensitive.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0260#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0260-fa8dd83368", "paper_id": "P0260", "bibkey": "Wu2024Federated", "title": "Federated In-Context LLM Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Federated learning (FL) offers a potential solution by facilitating the collaborative training of distributed LLMs while safeguarding private data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0260#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0260-1b64d3d107", "paper_id": "P0260", "bibkey": "Wu2024Federated", "title": "Federated In-Context LLM Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, FL frameworks face significant bandwidth and computational demands, along with challenges from heterogeneous data distributions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0260#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0260-d6978c61a7", "paper_id": "P0260", "bibkey": "Wu2024Federated", "title": "Federated In-Context LLM Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The emerging in-context learning capability of LLMs offers a promising approach by aggregating natural language rather than bulky model parameters.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0260#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0261-c15e31de91", "paper_id": "P0261", "bibkey": "He2024Give", "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present Graph Inspired Veracity Extrapolation (GIVE), a novel reasoning method that merges parametric and non-parametric memories to improve accurate reasoning with minimal external input.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0261#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0261-199af74195", "paper_id": "P0261", "bibkey": "He2024Give", "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "(4) GIVE is a training-free method that enables LLMs to tackle new problems that extend beyond their training data (up to 43.5% -> 88.2%} accuracy improvement).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0261#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0261-0a21878800", "paper_id": "P0261", "bibkey": "He2024Give", "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments demonstrated the following benefits of our framework: (1) GIVE boosts the performance of LLMs across various sizes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0261#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0261-0800fcd3eb", "paper_id": "P0261", "bibkey": "He2024Give", "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing approaches based on context prompting or reinforcement learning (RL) to improve the reasoning capacities of large language models (LLMs) depend on the LLMs' internal knowledge to produce reliable Chain-Of-Thought (CoT).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0261#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0261-04742cc93d", "paper_id": "P0261", "bibkey": "He2024Give", "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, no matter the size of LLMs, certain problems cannot be resolved in a single forward pass.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0261#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0261-619de5d716", "paper_id": "P0261", "bibkey": "He2024Give", "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Meanwhile, agent-based reasoning systems require access to a comprehensive nonparametric knowledge base, which is often costly or not feasible for use in scientific and niche domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0261#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0261-7653cebbbf", "paper_id": "P0261", "bibkey": "He2024Give", "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present Graph Inspired Veracity Extrapolation (GIVE), a novel reasoning method that merges parametric and non-parametric memories to improve accurate reasoning with minimal external input.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0261#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0261-3bb5400f58", "paper_id": "P0261", "bibkey": "He2024Give", "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "GIVE guides the LLM agent to select the most pertinent expert data (observe), engage in query-specific divergent thinking (reflect), and then synthesize this information to produce the final output (speak).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0261#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0262-1dd9d20fe2", "paper_id": "P0262", "bibkey": "Chin2024Human", "title": "Human-Centered LLM-Agent User Interface: A Position Paper", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To illustrate LAUI, we present Flute X GPT, a concrete example using an LLM agent, a prompt manager, and a flute-tutoring multi-modal software-hardware system to facilitate the complex, real-time user experience of learning to play the flute.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0262#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0262-a2c7df05af", "paper_id": "P0262", "bibkey": "Chin2024Human", "title": "Human-Centered LLM-Agent User Interface: A Position Paper", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large Language Model (LLM) -in-the-loop applications have been shown to effectively interpret the human user's commands, make plans, and operate external tools/systems accordingly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0262#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0262-5e54ecc604", "paper_id": "P0262", "bibkey": "Chin2024Human", "title": "Human-Centered LLM-Agent User Interface: A Position Paper", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) -in-the-loop applications have been shown to effectively interpret the human user's commands, make plans, and operate external tools/systems accordingly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0262#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0262-42b991836a", "paper_id": "P0262", "bibkey": "Chin2024Human", "title": "Human-Centered LLM-Agent User Interface: A Position Paper", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Still, the operation scope of the LLM agent is limited to passively following the user, requiring the user to frame his/her needs with regard to the underlying tools/systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0262#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0262-33f6db5cdb", "paper_id": "P0262", "bibkey": "Chin2024Human", "title": "Human-Centered LLM-Agent User Interface: A Position Paper", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We note that the potential of an LLM-Agent User Interface (LAUI) is much greater.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0262#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0262-4040d63a1f", "paper_id": "P0262", "bibkey": "Chin2024Human", "title": "Human-Centered LLM-Agent User Interface: A Position Paper", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A user mostly ignorant to the underlying tools/systems should be able to work with a LAUI to discover an emergent workflow.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0262#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0262-9d83537bef", "paper_id": "P0262", "bibkey": "Chin2024Human", "title": "Human-Centered LLM-Agent User Interface: A Position Paper", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Contrary to the conventional way of designing an explorable GUI to teach the user a predefined set of ways to use the system, in the ideal LAUI, the LLM agent is initialized to be proficient with the system, proactively studies the user and his/her needs, and proposes new interaction schemes to the user.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0262#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0263-6f708c6c73", "paper_id": "P0263", "bibkey": "Fu2024Imprompter", "title": "Imprompter: Tricking LLM Agents into Improper Tool Use", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Model (LLM) Agents are an emerging computing paradigm that blends generative machine learning with tools such as code interpreters, web browsing, email, and more generally, external resources.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0263#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0263-0ea7b39672", "paper_id": "P0263", "bibkey": "Fu2024Imprompter", "title": "Imprompter: Tricking LLM Agents into Improper Tool Use", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "This attack shows a nearly 80% success rate in an end-to-end evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0263#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0263-44c3189244", "paper_id": "P0263", "bibkey": "Fu2024Imprompter", "title": "Imprompter: Tricking LLM Agents into Improper Tool Use", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) Agents are an emerging computing paradigm that blends generative machine learning with tools such as code interpreters, web browsing, email, and more generally, external resources.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0263#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0263-920004ca19", "paper_id": "P0263", "bibkey": "Fu2024Imprompter", "title": "Imprompter: Tricking LLM Agents into Improper Tool Use", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These agent-based systems represent an emerging shift in personal computing.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0263#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0263-151c9f651e", "paper_id": "P0263", "bibkey": "Fu2024Imprompter", "title": "Imprompter: Tricking LLM Agents into Improper Tool Use", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We contribute to the security foundations of agent-based systems and surface a new class of automatically computed obfuscated adversarial prompt attacks that violate the confidentiality and integrity of user resources connected to an LLM agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0263#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0263-f6463baaf3", "paper_id": "P0263", "bibkey": "Fu2024Imprompter", "title": "Imprompter: Tricking LLM Agents into Improper Tool Use", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We show how prompt optimization techniques can find such prompts automatically given the weights of a model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0263#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0263-2a927415fc", "paper_id": "P0263", "bibkey": "Fu2024Imprompter", "title": "Imprompter: Tricking LLM Agents into Improper Tool Use", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We demonstrate that such attacks transfer to production-level agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0263#summary_bullets[4]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0264-0121e8acac", "paper_id": "P0264", "bibkey": "Sun2024Interpreting", "title": "Interpreting Multi-band Galaxy Observations with Large Language Model-Based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose mephisto, a multi-agent collaboration framework that mimics human reasoning to interpret multi-band galaxy observations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0264#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0264-042ed25983", "paper_id": "P0264", "bibkey": "Sun2024Interpreting", "title": "Interpreting Multi-band Galaxy Observations with Large Language Model-Based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We propose mephisto, a multi-agent collaboration framework that mimics human reasoning to interpret multi-band galaxy observations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0264#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0264-72f4e993d6", "paper_id": "P0264", "bibkey": "Sun2024Interpreting", "title": "Interpreting Multi-band Galaxy Observations with Large Language Model-Based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "mephisto attains near-human proficiency in reasoning about galaxies' physical scenarios, even when dealing with a recently discovered population of \"Little Red Dot\" galaxies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0264#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0264-25dc57251d", "paper_id": "P0264", "bibkey": "Sun2024Interpreting", "title": "Interpreting Multi-band Galaxy Observations with Large Language Model-Based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Astronomical research traditionally relies on extensive domain knowledge to interpret observations and narrow down hypotheses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0264#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0264-acf3db89b4", "paper_id": "P0264", "bibkey": "Sun2024Interpreting", "title": "Interpreting Multi-band Galaxy Observations with Large Language Model-Based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We demonstrate that this process can be emulated using large language model-based agents to accelerate research workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0264#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0264-fb0a419594", "paper_id": "P0264", "bibkey": "Sun2024Interpreting", "title": "Interpreting Multi-band Galaxy Observations with Large Language Model-Based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose mephisto, a multi-agent collaboration framework that mimics human reasoning to interpret multi-band galaxy observations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0264#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0264-c082615cf1", "paper_id": "P0264", "bibkey": "Sun2024Interpreting", "title": "Interpreting Multi-band Galaxy Observations with Large Language Model-Based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "mephisto interacts with the CIGALE codebase, which includes spectral energy distribution (SED) models to explain observations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0264#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0264-817520e3ee", "paper_id": "P0264", "bibkey": "Sun2024Interpreting", "title": "Interpreting Multi-band Galaxy Observations with Large Language Model-Based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this open-world setting, mephisto learns from its self-play experience, performs tree search, and accumulates knowledge in a dynamically updated base.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0264#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0265-a173e1c2b0", "paper_id": "P0265", "bibkey": "Wei2024Smartaudit", "title": "LLM-SmartAudit: Advanced Smart Contract Vulnerability Detection", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Furthermore, our framework can detect complex logic vulnerabilities that traditional tools have previously overlooked.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0265#method"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0265-8b9a084212", "paper_id": "P0265", "bibkey": "Wei2024Smartaudit", "title": "LLM-SmartAudit: Advanced Smart Contract Vulnerability Detection", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, a comprehensive tool capable of detecting a wide range of vulnerabilities with high accuracy is lacking.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0265#key_results[0]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0265-9101232ecf", "paper_id": "P0265", "bibkey": "Wei2024Smartaudit", "title": "LLM-SmartAudit: Advanced Smart Contract Vulnerability Detection", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "To evaluate the effectiveness of LLM-SmartAudit, we compiled two distinct datasets: a labeled dataset for benchmarking against traditional tools and a real-world dataset for assessing practical applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0265#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0265-d93cf67478", "paper_id": "P0265", "bibkey": "Wei2024Smartaudit", "title": "LLM-SmartAudit: Advanced Smart Contract Vulnerability Detection", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The immutable nature of blockchain technology, while revolutionary, introduces significant security challenges, particularly in smart contracts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0265#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0265-d933779b46", "paper_id": "P0265", "bibkey": "Wei2024Smartaudit", "title": "LLM-SmartAudit: Advanced Smart Contract Vulnerability Detection", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These security issues can lead to substantial financial losses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0265#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0265-0150b70770", "paper_id": "P0265", "bibkey": "Wei2024Smartaudit", "title": "LLM-SmartAudit: Advanced Smart Contract Vulnerability Detection", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current tools and approaches often focus on specific types of vulnerabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0265#summary_bullets[2]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0265-cba325c54a", "paper_id": "P0265", "bibkey": "Wei2024Smartaudit", "title": "LLM-SmartAudit: Advanced Smart Contract Vulnerability Detection", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, a comprehensive tool capable of detecting a wide range of vulnerabilities with high accuracy is lacking.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0265#summary_bullets[3]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0265-3cd0f8f14a", "paper_id": "P0265", "bibkey": "Wei2024Smartaudit", "title": "LLM-SmartAudit: Advanced Smart Contract Vulnerability Detection", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper introduces LLM-SmartAudit, a novel framework leveraging the advanced capabilities of Large Language Models (LLMs) to detect and analyze vulnerabilities in smart contracts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0265#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory", "security"]}
{"evidence_id": "E-P0266-a61362c028", "paper_id": "P0266", "bibkey": "Yang2024Based", "title": "LLM-based Multi-Agent Systems: Techniques and Business Perspectives", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In the era of (multi-modal) large language models, most operational processes can be reformulated and reproduced using LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0266#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0266-d627852f52", "paper_id": "P0266", "bibkey": "Yang2024Based", "title": "LLM-based Multi-Agent Systems: Techniques and Business Perspectives", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "As such, LaMAS would be a practical solution to achieve artificial collective intelligence in the near future.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0266#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0266-060fbf8570", "paper_id": "P0266", "bibkey": "Yang2024Based", "title": "LLM-based Multi-Agent Systems: Techniques and Business Perspectives", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In the era of (multi-modal) large language models, most operational processes can be reformulated and reproduced using LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0266#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0266-01ac4c76d0", "paper_id": "P0266", "bibkey": "Yang2024Based", "title": "LLM-based Multi-Agent Systems: Techniques and Business Perspectives", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The LLM agents can perceive, control, and get feedback from the environment so as to accomplish the given tasks in an autonomous manner.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0266#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0266-e9d2baeabe", "paper_id": "P0266", "bibkey": "Yang2024Based", "title": "LLM-based Multi-Agent Systems: Techniques and Business Perspectives", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Besides the environment-interaction property, the LLM agents can call various external tools to ease the task completion process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0266#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0266-6c645308cc", "paper_id": "P0266", "bibkey": "Yang2024Based", "title": "LLM-based Multi-Agent Systems: Techniques and Business Perspectives", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The tools can be regarded as a predefined operational process with private or real-time knowledge that does not exist in the parameters of LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0266#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0266-978420edf4", "paper_id": "P0266", "bibkey": "Yang2024Based", "title": "LLM-based Multi-Agent Systems: Techniques and Business Perspectives", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As a natural trend of development, the tools for calling are becoming autonomous agents, thus the full intelligent system turns out to be a LLM-based Multi-Agent System (LaMAS).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0266#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0266-c92a9d34cf", "paper_id": "P0266", "bibkey": "Yang2024Based", "title": "LLM-based Multi-Agent Systems: Techniques and Business Perspectives", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "The tools can be regarded as a predefined operational process with private or real-time knowledge that does not exist in the parameters of LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0266#limitations[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0267-78d07f4b17", "paper_id": "P0267", "bibkey": "Wang2024Large", "title": "Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Our approach addresses three research questions: aligning LLMs with real-world urban mobility data, developing reliable activity generation strategies, and exploring LLM applications in urban mobility.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0267#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0267-0a4321e245", "paper_id": "P0267", "bibkey": "Wang2024Large", "title": "Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Overall, this study marks the pioneering work of designing an LLM agent framework for activity generation based on real-world human activity data, offering a promising tool for urban mobility analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0267#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0267-a97e266f9e", "paper_id": "P0267", "bibkey": "Wang2024Large", "title": "Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate our LLM agent framework and compare it with state-of-the-art personal mobility generation approaches, demonstrating the effectiveness of our approach and its potential applications in urban mobility.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0267#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0267-745abb5d90", "paper_id": "P0267", "bibkey": "Wang2024Large", "title": "Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper introduces a novel approach using Large Language Models (LLMs) integrated into an agent framework for flexible and effective personal mobility generation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0267#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0267-27a3310f5e", "paper_id": "P0267", "bibkey": "Wang2024Large", "title": "Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLMs overcome the limitations of previous models by effectively processing semantic data and offering versatility in modeling various tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0267#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0267-b2444d74ee", "paper_id": "P0267", "bibkey": "Wang2024Large", "title": "Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our approach addresses three research questions: aligning LLMs with real-world urban mobility data, developing reliable activity generation strategies, and exploring LLM applications in urban mobility.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0267#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0267-e5aaddc5e2", "paper_id": "P0267", "bibkey": "Wang2024Large", "title": "Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The key technical contribution is a novel LLM agent framework that accounts for individual activity patterns and motivations, including a self-consistency approach to align LLMs with real-world activity data and a retrieval-augmented strategy for interpretable activity generation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0267#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0267-558a724c68", "paper_id": "P0267", "bibkey": "Wang2024Large", "title": "Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluate our LLM agent framework and compare it with state-of-the-art personal mobility generation approaches, demonstrating the effectiveness of our approach and its potential applications in urban mobility.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0267#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0267-89e112e457", "paper_id": "P0267", "bibkey": "Wang2024Large", "title": "Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "LLMs overcome the limitations of previous models by effectively processing semantic data and offering versatility in modeling various tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0267#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0268-5d0fde2094", "paper_id": "P0268", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose LightVA, a lightweight VA framework that supports task decomposition, data analysis, and interactive exploration through human-agent collaboration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0268#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0268-51a6b462f1", "paper_id": "P0268", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We propose LightVA, a lightweight VA framework that supports task decomposition, data analysis, and interactive exploration through human-agent collaboration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0268#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0268-f4a2d7fd7a", "paper_id": "P0268", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Visual analytics (VA) requires analysts to iteratively propose analysis tasks based on observations and execute tasks by creating visualizations and interactive exploration to gain insights.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0268#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0268-ff9efa8f17", "paper_id": "P0268", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Visual analytics (VA) requires analysts to iteratively propose analysis tasks based on observations and execute tasks by creating visualizations and interactive exploration to gain insights.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0268#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0268-2882a3157e", "paper_id": "P0268", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This process demands skills in programming, data processing, and visualization tools, highlighting the need for a more intelligent, streamlined VA approach.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0268#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0268-3354309c5e", "paper_id": "P0268", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have recently been developed as agents to handle various tasks with dynamic planning and tool-using capabilities, offering the potential to enhance the efficiency and versatility of VA.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0268#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0268-baadd34100", "paper_id": "P0268", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose LightVA, a lightweight VA framework that supports task decomposition, data analysis, and interactive exploration through human-agent collaboration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0268#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0268-1ee9da8443", "paper_id": "P0268", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our method is designed to help users progressively translate high-level analytical goals into low-level tasks, producing visualizations and deriving insights.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0268#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0269-d25f89f2dc", "paper_id": "P0269", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we introduce MIRAI, a novel benchmark designed to systematically evaluate LLM agents as temporal forecasters in the context of international events.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0269#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0269-6a339fd402", "paper_id": "P0269", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "In summary, MIRAI comprehensively evaluates the agents' capabilities in three dimensions: 1) autonomously source and integrate critical information from large global databases; 2) write codes using domain-specific APIs and libraries for tool-use; and 3) jointly reason over historical knowledge from diverse formats and time to accurately predict future events.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0269#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0269-d16fef84ae", "paper_id": "P0269", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Despite such a growing interest, there is a lack of a rigorous benchmark of LLM agents' forecasting capability and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0269#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0269-4a854901de", "paper_id": "P0269", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in Large Language Models (LLMs) have empowered LLM agents to autonomously collect world information, over which to conduct reasoning to solve complex problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0269#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0269-aef311d66d", "paper_id": "P0269", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Given this capability, increasing interests have been put into employing LLM agents for predicting international events, which can influence decision-making and shape policy development on an international scale.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0269#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0269-4157a930a1", "paper_id": "P0269", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite such a growing interest, there is a lack of a rigorous benchmark of LLM agents' forecasting capability and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0269#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0269-fd67002ed1", "paper_id": "P0269", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, we introduce MIRAI, a novel benchmark designed to systematically evaluate LLM agents as temporal forecasters in the context of international events.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0269#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0269-18250a26e4", "paper_id": "P0269", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our benchmark features an agentic environment with tools for accessing an extensive database of historical, structured events and textual news articles.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0269#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0270-675224b347", "paper_id": "P0270", "bibkey": "Yang2024Mvvm", "title": "MVVM: Deploy Your AI Agents-Securely, Efficiently, Everywhere", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present MVVM, a WebAssembly-based secure container framework that enables transparent live migration of LLM agent workspaces between edge devices and cloud servers with end-to-end privacy guarantees, resilient multi-tier replication, speculative execution for latency optimization, and integrated validation for safety assurance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0270#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0270-5146c726ad", "paper_id": "P0270", "bibkey": "Yang2024Mvvm", "title": "MVVM: Deploy Your AI Agents-Securely, Efficiently, Everywhere", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation demonstrates that MVVM is validated on three separate devices across 18 workloads.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0270#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0270-dda84e50a5", "paper_id": "P0270", "bibkey": "Yang2024Mvvm", "title": "MVVM: Deploy Your AI Agents-Securely, Efficiently, Everywhere", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "MVVM introduces two key innovations: (1) a two-way sandboxing framework leveraging hardware enclaves and accelerator extensions that protects both the agent from malicious hosts and the host from compromised agents; (2) an efficient cross platform migration mechanism using WebAssembly and WASI's platform-agnostic design, enabling seamless movement across ARM phones, RISC-V MCUs, x86 servers, and heterogeneous accelerators; and three astonishing use cases: (1) privacy-aware daemon that automatically determines whether to execute locally or remotely based on data sensitivity and resource availability; (2) multi-tier replication with intelligent quality degradation that maintains service availability despite network failures or resource constraints; (3) a comprehensive execution framework combining speculative execution for 10x latency reduction with parallel validation that ensures output safety without compromising responsiveness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0270#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers", "security"]}
{"evidence_id": "E-P0270-195b7b1580", "paper_id": "P0270", "bibkey": "Yang2024Mvvm", "title": "MVVM: Deploy Your AI Agents-Securely, Efficiently, Everywhere", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rise of AI agents powered by Large Language Models (LLMs) presents critical challenges: how to securely execute and migrate these agents across heterogeneous environments while protecting sensitive user data, maintaining availability during network failures, minimizing response latency for time-critical decisions, and ensuring output safety in mission-critical applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0270#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0270-04553f2760", "paper_id": "P0270", "bibkey": "Yang2024Mvvm", "title": "MVVM: Deploy Your AI Agents-Securely, Efficiently, Everywhere", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present MVVM, a WebAssembly-based secure container framework that enables transparent live migration of LLM agent workspaces between edge devices and cloud servers with end-to-end privacy guarantees, resilient multi-tier replication, speculative execution for latency optimization, and integrated validation for safety assurance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0270#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0270-21c1654373", "paper_id": "P0270", "bibkey": "Yang2024Mvvm", "title": "MVVM: Deploy Your AI Agents-Securely, Efficiently, Everywhere", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "MVVM introduces two key innovations: (1) a two-way sandboxing framework leveraging hardware enclaves and accelerator extensions that protects both the agent from malicious hosts and the host from compromised agents; (2) an efficient cross platform migration mechanism using WebAssembly and WASI's platform-agnostic design, enabling seamless movement across ARM phones, RISC-V MCUs, x86 servers, and heterogeneous accelerators; and three astonishing use cases: (1) privacy-aware daemon that automatically determines whether to execute locally or remotely based on data sensitivity and resource availability; (2) multi-tier replication with intelligent quality degradation that maintains service availability despite network failures or resource constraints; (3) a comprehensive execution framework combining speculative execution for 10x latency reduction with parallel validation that ensures output safety without compromising responsiveness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0270#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "numbers", "security"]}
{"evidence_id": "E-P0270-7e781265c4", "paper_id": "P0270", "bibkey": "Yang2024Mvvm", "title": "MVVM: Deploy Your AI Agents-Securely, Efficiently, Everywhere", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our evaluation demonstrates that MVVM is validated on three separate devices across 18 workloads.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0270#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0271-897768f5f2", "paper_id": "P0271", "bibkey": "Tennant2024Moral", "title": "Moral Alignment for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, instead of relying on human feedback, we introduce the design of reward functions that explicitly and transparently encode core human values for Reinforcement Learning-based fine-tuning of foundation agent models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0271#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0271-54979d1734", "paper_id": "P0271", "bibkey": "Tennant2024Moral", "title": "Moral Alignment for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "As LLM-based systems become more agentic, their influence on human activity will grow and their transparency will decrease.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0271#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0271-820bbc36f5", "paper_id": "P0271", "bibkey": "Tennant2024Moral", "title": "Moral Alignment for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Decision-making agents based on pre-trained Large Language Models (LLMs) are increasingly being deployed across various domains of human activity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0271#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0271-f79fc25c23", "paper_id": "P0271", "bibkey": "Tennant2024Moral", "title": "Moral Alignment for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Decision-making agents based on pre-trained Large Language Models (LLMs) are increasingly being deployed across various domains of human activity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0271#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0271-cc33b151e2", "paper_id": "P0271", "bibkey": "Tennant2024Moral", "title": "Moral Alignment for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While their applications are currently rather specialized, several research efforts are underway to develop more generalist agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0271#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0271-506edbe053", "paper_id": "P0271", "bibkey": "Tennant2024Moral", "title": "Moral Alignment for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As LLM-based systems become more agentic, their influence on human activity will grow and their transparency will decrease.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0271#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0271-040a03f115", "paper_id": "P0271", "bibkey": "Tennant2024Moral", "title": "Moral Alignment for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Consequently, developing effective methods for aligning them to human values is vital.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0271#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0271-2a3bfe8f8f", "paper_id": "P0271", "bibkey": "Tennant2024Moral", "title": "Moral Alignment for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The prevailing practice in alignment often relies on human preference data (e.g., in RLHF or DPO), in which values are implicit, opaque and are essentially deduced from relative preferences over different model outputs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0271#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0272-d97f4bf12d", "paper_id": "P0272", "bibkey": "Lin2024Soen", "title": "SOEN-101: Code Generation by Emulating Software Process Models Using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Inspired by these software engineering practices, we present FlowGen - a code generation framework that emulates software process models based on multiple Large Language Model (LLM) agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0272#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0272-7df24b5b78", "paper_id": "P0272", "bibkey": "Lin2024Soen", "title": "SOEN-101: Code Generation by Emulating Software Process Models Using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We use GPT3.5 as our underlying LLM and several baselines (RawGPT, CodeT, Reflexion) to evaluate code generation on four benchmarks: HumanEval, HumanEval-ET, MBPP, and MBPP-ET.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0272#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0272-66a659a11c", "paper_id": "P0272", "bibkey": "Lin2024Soen", "title": "SOEN-101: Code Generation by Emulating Software Process Models Using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Compared with other state-of-the-art techniques, FlowGenScrum achieves a higher Pass@1 in MBPP compared to CodeT, with both outperforming Reflexion.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0272#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0272-c54e15f905", "paper_id": "P0272", "bibkey": "Lin2024Soen", "title": "SOEN-101: Code Generation by Emulating Software Process Models Using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Software process models are essential to facilitate collaboration and communication among software teams to solve complex development tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0272#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0272-8dcf723ac5", "paper_id": "P0272", "bibkey": "Lin2024Soen", "title": "SOEN-101: Code Generation by Emulating Software Process Models Using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Inspired by these software engineering practices, we present FlowGen - a code generation framework that emulates software process models based on multiple Large Language Model (LLM) agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0272#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0272-21cc1a55f7", "paper_id": "P0272", "bibkey": "Lin2024Soen", "title": "SOEN-101: Code Generation by Emulating Software Process Models Using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We emulate three process models, FlowGenWaterfall, FlowGenTDD, and FlowGenScrum, by assigning LLM agents to embody roles (i.e., requirement engineer, architect, developer, tester, and scrum master) that correspond to everyday development activities and organize their communication patterns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0272#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0272-e11d129321", "paper_id": "P0272", "bibkey": "Lin2024Soen", "title": "SOEN-101: Code Generation by Emulating Software Process Models Using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The agents work collaboratively using chain-of-thought and prompt composition with continuous self-refinement to improve the code quality.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0272#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0272-e3fa8a658e", "paper_id": "P0272", "bibkey": "Lin2024Soen", "title": "SOEN-101: Code Generation by Emulating Software Process Models Using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We use GPT3.5 as our underlying LLM and several baselines (RawGPT, CodeT, Reflexion) to evaluate code generation on four benchmarks: HumanEval, HumanEval-ET, MBPP, and MBPP-ET.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0272#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0273-f6fba56a1b", "paper_id": "P0273", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To overcome these challenges, we propose a novel approach that decomposes the aforementioned capabilities into a planner, caller, and summarizer.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0273#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0273-8158d9909c", "paper_id": "P0273", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "First, we fine-tune a backbone LLM on the entire dataset without discriminating sub-tasks, providing the model with a comprehensive understanding of the task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0273#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0273-9640816b42", "paper_id": "P0273", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluation across various tool-use benchmarks illustrates that our proposed multi-LLM framework surpasses the traditional single-LLM approach, highlighting its efficacy and advantages in tool learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0273#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0273-e8cc8a6f73", "paper_id": "P0273", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents significantly extend the capabilities of standalone LLMs, empowering them to interact with external tools (e.g., APIs, functions) and complete various tasks in a self-directed fashion.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0273#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0273-35a42b4664", "paper_id": "P0273", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The challenge of tool use demands that LLMs not only understand user queries and generate answers accurately but also excel in task planning, tool invocation, and result summarization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0273#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0273-9e83833f66", "paper_id": "P0273", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While traditional works focus on training a single LLM with all these capabilities, performance limitations become apparent, particularly with smaller models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0273#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0273-378c9f919c", "paper_id": "P0273", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To overcome these challenges, we propose a novel approach that decomposes the aforementioned capabilities into a planner, caller, and summarizer.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0273#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0273-0df71db19d", "paper_id": "P0273", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Each component is implemented by a single LLM that focuses on a specific capability and collaborates with others to accomplish the task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0273#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0273-c92ed293ba", "paper_id": "P0273", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "While traditional works focus on training a single LLM with all these capabilities, performance limitations become apparent, particularly with smaller models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0273#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0274-73dbd22d64", "paper_id": "P0274", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose PDoctor, a novel and automated approach to testing LLM agents and understanding their erroneous planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0274#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0274-c0a98eb625", "paper_id": "P0274", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate PDoctor with three mainstream agent frameworks and two powerful LLMs (GPT-3.5 and GPT-4).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0274#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0274-8d0f2cdb4c", "paper_id": "P0274", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agents based on large language models (LLMs) have demonstrated effectiveness in solving a wide range of tasks by integrating LLMs with key modules such as planning, memory, and tool usage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0274#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0274-2b0e1946ce", "paper_id": "P0274", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Increasingly, customers are adopting LLM agents across a variety of commercial applications critical to reliability, including support for mental well-being, chemical synthesis, and software development.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0274#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0274-dc0110cb08", "paper_id": "P0274", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Nevertheless, our observations and daily use of LLM agents indicate that they are prone to making erroneous plans, especially when the tasks are complex and require long-term planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0274#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0274-119e43ccdd", "paper_id": "P0274", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose PDoctor, a novel and automated approach to testing LLM agents and understanding their erroneous planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0274#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0274-b3e4aaa4b1", "paper_id": "P0274", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As the first work in this direction, we formulate the detection of erroneous planning as a constraint satisfiability problem: an LLM agent's plan is considered erroneous if its execution violates the constraints derived from the user inputs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0274#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0275-8a2d71b2f0", "paper_id": "P0275", "bibkey": "Du2024Text2Bim", "title": "Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To facilitate the expression of design intentions more intuitively, we propose Text2BIM, an LLM-based multi-agent framework that can generate 3D building models from natural language instructions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0275#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0275-a21c19010a", "paper_id": "P0275", "bibkey": "Du2024Text2Bim", "title": "Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The evaluation results demonstrate that our approach can effectively generate high-quality, structurally rational building models that are aligned with the abstract concepts specified by user input.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0275#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0275-390ef9bf09", "paper_id": "P0275", "bibkey": "Du2024Text2Bim", "title": "Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The conventional BIM authoring process typically requires designers to master complex and tedious modeling commands in order to materialize their design intentions within BIM authoring tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0275#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0275-6675d6f543", "paper_id": "P0275", "bibkey": "Du2024Text2Bim", "title": "Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This additional cognitive burden complicates the design process and hinders the adoption of BIM and model-based design in the AEC (Architecture, Engineering, and Construction) industry.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0275#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0275-a30cd07199", "paper_id": "P0275", "bibkey": "Du2024Text2Bim", "title": "Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To facilitate the expression of design intentions more intuitively, we propose Text2BIM, an LLM-based multi-agent framework that can generate 3D building models from natural language instructions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0275#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0275-6ef2e47e0a", "paper_id": "P0275", "bibkey": "Du2024Text2Bim", "title": "Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This framework orchestrates multiple LLM agents to collaborate and reason, transforming textual user input into imperative code that invokes the BIM authoring tool's APIs, thereby generating editable BIM models with internal layouts, external envelopes, and semantic information directly in the software.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0275#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0275-c79cbb3a4a", "paper_id": "P0275", "bibkey": "Du2024Text2Bim", "title": "Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Furthermore, a rule-based model checker is introduced into the agentic workflow, utilizing predefined domain knowledge to guide the LLM agents in resolving issues within the generated models and iteratively improving model quality.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0275#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0276-f9b2ea959c", "paper_id": "P0276", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce the Personal Health Insights Agent (PHIA), a system leveraging multistep reasoning with code generation and information retrieval to analyze and interpret behavioral health data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0276#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0276-0c25e2cfae", "paper_id": "P0276", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "To test its capabilities, we create and share two benchmark datasets with over 4000 health insights questions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0276#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0276-684ec790a0", "paper_id": "P0276", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "A 650-hour human expert evaluation shows that PHIA significantly outperforms a strong code generation baseline, achieving 84% accuracy on objective, numerical questions and, for open-ended ones, earning 83% favorable ratings while being twice as likely to achieve the highest quality rating.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0276#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0276-9cb70a9328", "paper_id": "P0276", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Deriving personalized insights from popular wearable trackers requires complex numerical reasoning that challenges standard LLMs, necessitating tool-based approaches like code generation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0276#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0276-6e25a922c0", "paper_id": "P0276", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents present a promising yet largely untapped solution for this analysis at scale.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0276#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0276-1dd8f714cc", "paper_id": "P0276", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce the Personal Health Insights Agent (PHIA), a system leveraging multistep reasoning with code generation and information retrieval to analyze and interpret behavioral health data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0276#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0276-dc6cfe64a6", "paper_id": "P0276", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To test its capabilities, we create and share two benchmark datasets with over 4000 health insights questions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0276#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0276-d8abf89037", "paper_id": "P0276", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A 650-hour human expert evaluation shows that PHIA significantly outperforms a strong code generation baseline, achieving 84% accuracy on objective, numerical questions and, for open-ended ones, earning 83% favorable ratings while being twice as likely to achieve the highest quality rating.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0276#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0277-f890e6a573", "paper_id": "P0277", "bibkey": "Ning2024Urbankgent", "title": "UrbanKGent: A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Moreover, we propose a tool-augmented iterative trajectory refinement module to enhance and refine the trajectories distilled from GPT-4.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0277#method"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0277-67eb7c9ffa", "paper_id": "P0277", "bibkey": "Ning2024Urbankgent", "title": "UrbanKGent: A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We perform a comprehensive evaluation on two real-world datasets using both human and GPT-4 self-evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0277#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0277-7842d2eb9a", "paper_id": "P0277", "bibkey": "Ning2024Urbankgent", "title": "UrbanKGent: A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The experimental results demonstrate that UrbanKGent family can not only significantly outperform 31 baselines in UrbanKGC tasks, but also surpass the state-of-the-art LLM, GPT-4, by more than 10% with approximately 20 times lower cost.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0277#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0277-cdaf65c17b", "paper_id": "P0277", "bibkey": "Ning2024Urbankgent", "title": "UrbanKGent: A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Urban knowledge graph has recently worked as an emerging building block to distill critical knowledge from multi-sourced urban data for diverse urban application scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0277#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0277-c793982fff", "paper_id": "P0277", "bibkey": "Ning2024Urbankgent", "title": "UrbanKGent: A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite its promising benefits, urban knowledge graph construction (UrbanKGC) still heavily relies on manual effort, hindering its potential advancement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0277#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0277-b40850e8cb", "paper_id": "P0277", "bibkey": "Ning2024Urbankgent", "title": "UrbanKGent: A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents UrbanKGent, a unified large language model agent framework, for urban knowledge graph construction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0277#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0277-347d539f7b", "paper_id": "P0277", "bibkey": "Ning2024Urbankgent", "title": "UrbanKGent: A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Specifically, we first construct the knowledgeable instruction set for UrbanKGC tasks (such as relational triplet extraction and knowledge graph completion) via heterogeneity-aware and geospatial-infused instruction generation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0277#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0277-2056d9097f", "paper_id": "P0277", "bibkey": "Ning2024Urbankgent", "title": "UrbanKGent: A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Moreover, we propose a tool-augmented iterative trajectory refinement module to enhance and refine the trajectories distilled from GPT-4.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0277#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0278-4af74d580f", "paper_id": "P0278", "bibkey": "Palavalli2024Using", "title": "Using a Feedback Loop for LLM-based Infrastructure as Code Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Code generation with Large Language Models (LLMs) has helped to increase software developer productivity in coding tasks, but has yet to have significant impact on the tasks of software developers that surround this code.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0278#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0278-672ef5cd73", "paper_id": "P0278", "bibkey": "Palavalli2024Using", "title": "Using a Feedback Loop for LLM-based Infrastructure as Code Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Code generation with Large Language Models (LLMs) has helped to increase software developer productivity in coding tasks, but has yet to have significant impact on the tasks of software developers that surround this code.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0278#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0278-3ea7fb3578", "paper_id": "P0278", "bibkey": "Palavalli2024Using", "title": "Using a Feedback Loop for LLM-based Infrastructure as Code Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Code generation with Large Language Models (LLMs) has helped to increase software developer productivity in coding tasks, but has yet to have significant impact on the tasks of software developers that surround this code.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0278#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0278-d1eb4dd2a4", "paper_id": "P0278", "bibkey": "Palavalli2024Using", "title": "Using a Feedback Loop for LLM-based Infrastructure as Code Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In particular, the challenge of infrastructure management remains an open question.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0278#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0278-e24f0bb37b", "paper_id": "P0278", "bibkey": "Palavalli2024Using", "title": "Using a Feedback Loop for LLM-based Infrastructure as Code Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We investigate the ability of an LLM agent to construct infrastructure using the Infrastructure as Code (IaC) paradigm.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0278#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0278-a8d1532084", "paper_id": "P0278", "bibkey": "Palavalli2024Using", "title": "Using a Feedback Loop for LLM-based Infrastructure as Code Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We particularly investigate the use of a feedback loop that returns errors and warnings on the generated IaC to allow the LLM agent to improve the code.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0278#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0278-44a0f0fcdf", "paper_id": "P0278", "bibkey": "Palavalli2024Using", "title": "Using a Feedback Loop for LLM-based Infrastructure as Code Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We find that, for each iteration of the loop, its effectiveness decreases exponentially until it plateaus at a certain point and becomes ineffective.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0278#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0278-5a6e0d520a", "paper_id": "P0278", "bibkey": "Palavalli2024Using", "title": "Using a Feedback Loop for LLM-based Infrastructure as Code Generation", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "In particular, the challenge of infrastructure management remains an open question.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0278#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0279-267fe9dae9", "paper_id": "P0279", "bibkey": "Bouzenia2024Name", "title": "You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Inspired by the way a human developer would address this task, our approach is a large language model (LLM)-based agent that autonomously executes commands and interacts with the host system.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0279#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0279-eeb8bd9c2f", "paper_id": "P0279", "bibkey": "Bouzenia2024Name", "title": "You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation applies ExecutionAgent to 50 open-source projects that use 14 different programming languages and many different build and testing tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0279#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0279-1d322735e7", "paper_id": "P0279", "bibkey": "Bouzenia2024Name", "title": "You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The approach successfully executes the test suites of 33/50 projects, while matching the test results of ground truth test suite executions with a deviation of only 7.5%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0279#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0279-54e2fc90f8", "paper_id": "P0279", "bibkey": "Bouzenia2024Name", "title": "You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The ability to execute the test suite of a project is essential in many scenarios, e.g., to assess code quality and code coverage, to validate code changes made by developers or automated tools, and to ensure compatibility with dependencies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0279#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0279-e724e9fb90", "paper_id": "P0279", "bibkey": "Bouzenia2024Name", "title": "You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite its importance, executing the test suite of a project can be challenging in practice because different projects use different programming languages, software ecosystems, build systems, testing frameworks, and other tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0279#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0279-de41a01125", "paper_id": "P0279", "bibkey": "Bouzenia2024Name", "title": "You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These challenges make it difficult to create a reliable, universal test execution method that works across different projects.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0279#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0279-e985f7c93b", "paper_id": "P0279", "bibkey": "Bouzenia2024Name", "title": "You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents ExecutionAgent, an automated technique that prepares scripts for building an arbitrary project from source code and running its test cases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0279#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0279-67e921a3fb", "paper_id": "P0279", "bibkey": "Bouzenia2024Name", "title": "You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Inspired by the way a human developer would address this task, our approach is a large language model (LLM)-based agent that autonomously executes commands and interacts with the host system.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0279#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0280-797ef5a0f7", "paper_id": "P0280", "bibkey": "Hu2023Avis", "title": "AVIS: Autonomous Visual Information Seeking with Large Language Model Agent", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose an autonomous information seeking visual question answering framework, AVIS.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0280#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0280-1c25e10ffc", "paper_id": "P0280", "bibkey": "Hu2023Avis", "title": "AVIS: Autonomous Visual Information Seeking with Large Language Model Agent", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "We show that AVIS achieves state-of-the-art results on knowledge-intensive visual question answering benchmarks such as Infoseek and OK-VQA.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0280#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0280-eed9b7dd15", "paper_id": "P0280", "bibkey": "Hu2023Avis", "title": "AVIS: Autonomous Visual Information Seeking with Large Language Model Agent", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "We conduct a user study to collect a variety of instances of human decision-making when faced with this task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0280#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0280-d9bf249cba", "paper_id": "P0280", "bibkey": "Hu2023Avis", "title": "AVIS: Autonomous Visual Information Seeking with Large Language Model Agent", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose an autonomous information seeking visual question answering framework, AVIS.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0280#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0280-bfa03921d1", "paper_id": "P0280", "bibkey": "Hu2023Avis", "title": "AVIS: Autonomous Visual Information Seeking with Large Language Model Agent", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our method leverages a Large Language Model (LLM) to dynamically strategize the utilization of external tools and to investigate their outputs, thereby acquiring the indispensable knowledge needed to provide answers to the posed questions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0280#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0280-0f08e41092", "paper_id": "P0280", "bibkey": "Hu2023Avis", "title": "AVIS: Autonomous Visual Information Seeking with Large Language Model Agent", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Responding to visual questions that necessitate external knowledge, such as \"What event is commemorated by the building depicted in this image?\", is a complex task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0280#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0280-1adc6e97d2", "paper_id": "P0280", "bibkey": "Hu2023Avis", "title": "AVIS: Autonomous Visual Information Seeking with Large Language Model Agent", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This task presents a combinatorial search space that demands a sequence of actions, including invoking APIs, analyzing their responses, and making informed decisions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0280#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0280-77f9e4a37b", "paper_id": "P0280", "bibkey": "Hu2023Avis", "title": "AVIS: Autonomous Visual Information Seeking with Large Language Model Agent", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We conduct a user study to collect a variety of instances of human decision-making when faced with this task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0280#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0281-486de51cf3", "paper_id": "P0281", "bibkey": "Zou2023Esgreveal", "title": "ESGReveal: An LLM-based approach for extracting structured data from ESG reports", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "ESGReveal is an innovative method proposed for efficiently extracting and analyzing Environmental, Social, and Governance (ESG) data from corporate reports, catering to the critical need for reliable ESG information retrieval.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0281#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0281-0e7ffab7a6", "paper_id": "P0281", "bibkey": "Zou2023Esgreveal", "title": "ESGReveal: An LLM-based approach for extracting structured data from ESG reports", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Utilizing ESGReveal unearthed significant insights into ESG reporting with GPT-4, demonstrating an accuracy of 76.9% in data extraction and 83.7% in disclosure analysis, which is an improvement over baseline models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0281#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0281-a0d1f8240f", "paper_id": "P0281", "bibkey": "Zou2023Esgreveal", "title": "ESGReveal: An LLM-based approach for extracting structured data from ESG reports", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Its efficacy was appraised using ESG reports from 166 companies across various sectors listed on the Hong Kong Stock Exchange in 2022, ensuring comprehensive industry and market capitalization representation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0281#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0281-bcd14e13f1", "paper_id": "P0281", "bibkey": "Zou2023Esgreveal", "title": "ESGReveal: An LLM-based approach for extracting structured data from ESG reports", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ESGReveal is an innovative method proposed for efficiently extracting and analyzing Environmental, Social, and Governance (ESG) data from corporate reports, catering to the critical need for reliable ESG information retrieval.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0281#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0281-921043fd90", "paper_id": "P0281", "bibkey": "Zou2023Esgreveal", "title": "ESGReveal: An LLM-based approach for extracting structured data from ESG reports", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This approach utilizes Large Language Models (LLM) enhanced with Retrieval Augmented Generation (RAG) techniques.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0281#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0281-a35a87800f", "paper_id": "P0281", "bibkey": "Zou2023Esgreveal", "title": "ESGReveal: An LLM-based approach for extracting structured data from ESG reports", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The ESGReveal system includes an ESG metadata module for targeted queries, a preprocessing module for assembling databases, and an LLM agent for data extraction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0281#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0281-79c9fe49ad", "paper_id": "P0281", "bibkey": "Zou2023Esgreveal", "title": "ESGReveal: An LLM-based approach for extracting structured data from ESG reports", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Its efficacy was appraised using ESG reports from 166 companies across various sectors listed on the Hong Kong Stock Exchange in 2022, ensuring comprehensive industry and market capitalization representation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0281#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0281-a4c6cb5fe3", "paper_id": "P0281", "bibkey": "Zou2023Esgreveal", "title": "ESGReveal: An LLM-based approach for extracting structured data from ESG reports", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Utilizing ESGReveal unearthed significant insights into ESG reporting with GPT-4, demonstrating an accuracy of 76.9% in data extraction and 83.7% in disclosure analysis, which is an improvement over baseline models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0281#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0282-99387b656a", "paper_id": "P0282", "bibkey": "Kim2023Language", "title": "Language Models can Solve Computer Tasks", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "Agents capable of carrying out general tasks on a computer can improve efficiency and productivity by automating repetitive tasks and assisting in complex problem-solving.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0282#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0282-1b120c685a", "paper_id": "P0282", "bibkey": "Kim2023Language", "title": "Language Models can Solve Computer Tasks", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "We compare multiple LLMs and find that RCI with the InstructGPT-3+RLHF LLM is state-of-the-art on MiniWoB++, using only a handful of demonstrations per task rather than tens of thousands, and without a task-specific reward function.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0282#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0282-594d198d52", "paper_id": "P0282", "bibkey": "Kim2023Language", "title": "Language Models can Solve Computer Tasks", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "The RCI approach significantly outperforms existing LLM methods for automating computer tasks and surpasses supervised learning (SL) and reinforcement learning (RL) approaches on the MiniWoB++ benchmark.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0282#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0282-051bd40121", "paper_id": "P0282", "bibkey": "Kim2023Language", "title": "Language Models can Solve Computer Tasks", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agents capable of carrying out general tasks on a computer can improve efficiency and productivity by automating repetitive tasks and assisting in complex problem-solving.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0282#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0282-e4d7718d8d", "paper_id": "P0282", "bibkey": "Kim2023Language", "title": "Language Models can Solve Computer Tasks", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Ideally, such agents should be able to solve new computer tasks presented to them through natural language commands.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0282#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0282-06d0b633b0", "paper_id": "P0282", "bibkey": "Kim2023Language", "title": "Language Models can Solve Computer Tasks", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, previous approaches to this problem require large amounts of expert demonstrations and task-specific reward functions, both of which are impractical for new tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0282#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0282-610d446f18", "paper_id": "P0282", "bibkey": "Kim2023Language", "title": "Language Models can Solve Computer Tasks", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we show that a pre-trained large language model (LLM) agent can execute computer tasks guided by natural language using a simple prompting scheme where the agent Recursively Criticizes and Improves its output (RCI).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0282#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0282-04340a0e60", "paper_id": "P0282", "bibkey": "Kim2023Language", "title": "Language Models can Solve Computer Tasks", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The RCI approach significantly outperforms existing LLM methods for automating computer tasks and surpasses supervised learning (SL) and reinforcement learning (RL) approaches on the MiniWoB++ benchmark.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0282#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0283-9f1b322ecd", "paper_id": "P0283", "bibkey": "Wu2023Mathchat", "title": "MathChat: Converse to Tackle Challenging Math Problems with LLM Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we study the effectiveness of utilizing LLM agents to solve math problems through conversations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0283#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0283-c4062ed891", "paper_id": "P0283", "bibkey": "Wu2023Mathchat", "title": "MathChat: Converse to Tackle Challenging Math Problems with LLM Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Utilizing Python, we show that MathChat can further improve previous tool-using prompting methods by 6%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0283#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0283-8b972f6293", "paper_id": "P0283", "bibkey": "Wu2023Mathchat", "title": "MathChat: Converse to Tackle Challenging Math Problems with LLM Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "We perform evaluation on difficult high school competition problems from the MATH dataset.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0283#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0283-334e770aa5", "paper_id": "P0283", "bibkey": "Wu2023Mathchat", "title": "MathChat: Converse to Tackle Challenging Math Problems with LLM Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Employing Large Language Models (LLMs) to address mathematical problems is an intriguing research endeavor, considering the abundance of math problems expressed in natural language across numerous science and engineering fields.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0283#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0283-d01226dced", "paper_id": "P0283", "bibkey": "Wu2023Mathchat", "title": "MathChat: Converse to Tackle Challenging Math Problems with LLM Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLMs, with their generalized ability, are used as a foundation model to build AI agents for different tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0283#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0283-ca2f4f693a", "paper_id": "P0283", "bibkey": "Wu2023Mathchat", "title": "MathChat: Converse to Tackle Challenging Math Problems with LLM Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we study the effectiveness of utilizing LLM agents to solve math problems through conversations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0283#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0283-9bff4e5885", "paper_id": "P0283", "bibkey": "Wu2023Mathchat", "title": "MathChat: Converse to Tackle Challenging Math Problems with LLM Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose MathChat, a conversational problem-solving framework designed for math problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0283#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0283-7fb7c2e2e1", "paper_id": "P0283", "bibkey": "Wu2023Mathchat", "title": "MathChat: Converse to Tackle Challenging Math Problems with LLM Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "MathChat consists of an LLM agent and a user proxy agent which is responsible for tool execution and additional guidance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0283#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0284-81118bdb35", "paper_id": "P0284", "bibkey": "Jin2023Surrealdriver", "title": "SurrealDriver: Designing LLM-powered Generative Driver Agent Framework based on Human Drivers' Driving-thinking Data", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce a framework for building human-like generative driving agents using post-driving self-report driving-thinking data from human drivers as both demonstration and feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0284#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0284-00d1e97539", "paper_id": "P0284", "bibkey": "Jin2023Surrealdriver", "title": "SurrealDriver: Designing LLM-powered Generative Driver Agent Framework based on Human Drivers' Driving-thinking Data", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Results indicate that incorporating expert demonstration data significantly reduced collision rates by 81.04\\% and increased human likeness by 50\\% compared to a baseline LLM-based agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0284#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0284-9252761657", "paper_id": "P0284", "bibkey": "Jin2023Surrealdriver", "title": "SurrealDriver: Designing LLM-powered Generative Driver Agent Framework based on Human Drivers' Driving-thinking Data", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "In this paper, we introduce a framework for building human-like generative driving agents using post-driving self-report driving-thinking data from human drivers as both demonstration and feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0284#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0284-6fbff020e7", "paper_id": "P0284", "bibkey": "Jin2023Surrealdriver", "title": "SurrealDriver: Designing LLM-powered Generative Driver Agent Framework based on Human Drivers' Driving-thinking Data", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Leveraging advanced reasoning capabilities and extensive world knowledge of large language models (LLMs) to construct generative agents for solving complex real-world problems is a major trend.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0284#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0284-8e2609eade", "paper_id": "P0284", "bibkey": "Jin2023Surrealdriver", "title": "SurrealDriver: Designing LLM-powered Generative Driver Agent Framework based on Human Drivers' Driving-thinking Data", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, LLMs inherently lack embodiment as humans, resulting in suboptimal performance in many embodied decision-making tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0284#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0284-6df521fff3", "paper_id": "P0284", "bibkey": "Jin2023Surrealdriver", "title": "SurrealDriver: Designing LLM-powered Generative Driver Agent Framework based on Human Drivers' Driving-thinking Data", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce a framework for building human-like generative driving agents using post-driving self-report driving-thinking data from human drivers as both demonstration and feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0284#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0284-d70f03631f", "paper_id": "P0284", "bibkey": "Jin2023Surrealdriver", "title": "SurrealDriver: Designing LLM-powered Generative Driver Agent Framework based on Human Drivers' Driving-thinking Data", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To capture high-quality, natural language data from drivers, we conducted urban driving experiments, recording drivers' verbalized thoughts under various conditions to serve as chain-of-thought prompts and demonstration examples for the LLM-Agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0284#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0284-ea47bf5cdd", "paper_id": "P0284", "bibkey": "Jin2023Surrealdriver", "title": "SurrealDriver: Designing LLM-powered Generative Driver Agent Framework based on Human Drivers' Driving-thinking Data", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The framework's effectiveness was evaluated through simulations and human assessments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0284#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0285-f5a3af0327", "paper_id": "P0285", "bibkey": "Naihin2023Testing", "title": "Testing Language Model Agents Safely in the Wild", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose a framework for conducting safe autonomous agent tests on the open internet: agent actions are audited by a context-sensitive monitor that enforces a stringent safety boundary to stop an unsafe test, with suspect behavior ranked and logged to be examined by humans.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0285#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0285-98539a45d7", "paper_id": "P0285", "bibkey": "Naihin2023Testing", "title": "Testing Language Model Agents Safely in the Wild", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Then we apply the AgentMonitor on a battery of real-world tests of AutoGPT, and we identify several limitations and challenges that will face the creation of safe in-the-wild tests as autonomous agents grow more capable.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0285#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0285-758f52608a", "paper_id": "P0285", "bibkey": "Naihin2023Testing", "title": "Testing Language Model Agents Safely in the Wild", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A prerequisite for safe autonomy-in-the-wild is safe testing-in-the-wild.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0285#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0285-d034513616", "paper_id": "P0285", "bibkey": "Naihin2023Testing", "title": "Testing Language Model Agents Safely in the Wild", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Yet real-world autonomous tests face several unique safety challenges, both due to the possibility of causing harm during a test, as well as the risk of encountering new unsafe agent behavior through interactions with real-world and potentially malicious actors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0285#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0285-287e035146", "paper_id": "P0285", "bibkey": "Naihin2023Testing", "title": "Testing Language Model Agents Safely in the Wild", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose a framework for conducting safe autonomous agent tests on the open internet: agent actions are audited by a context-sensitive monitor that enforces a stringent safety boundary to stop an unsafe test, with suspect behavior ranked and logged to be examined by humans.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0285#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0285-e1d695b19a", "paper_id": "P0285", "bibkey": "Naihin2023Testing", "title": "Testing Language Model Agents Safely in the Wild", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We design a basic safety monitor (AgentMonitor) that is flexible enough to monitor existing LLM agents, and, using an adversarial simulated agent, we measure its ability to identify and stop unsafe situations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0285#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0285-e666f48f0a", "paper_id": "P0285", "bibkey": "Naihin2023Testing", "title": "Testing Language Model Agents Safely in the Wild", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Then we apply the AgentMonitor on a battery of real-world tests of AutoGPT, and we identify several limitations and challenges that will face the creation of safe in-the-wild tests as autonomous agents grow more capable.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0285#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0285-32ecdd3309", "paper_id": "P0285", "bibkey": "Naihin2023Testing", "title": "Testing Language Model Agents Safely in the Wild", "year": 2023, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Then we apply the AgentMonitor on a battery of real-world tests of AutoGPT, and we identify several limitations and challenges that will face the creation of safe in-the-wild tests as autonomous agents grow more capable.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0285#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0286-acad68f9c9", "paper_id": "P0286", "bibkey": "Dong2023Philosopher", "title": "The Philosopher's Stone: Trojaning Plugins of Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "To train a Trojan adapter, we propose two novel attacks, POLISHED and FUSION, that improve over prior approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0286#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0286-039ca6c08c", "paper_id": "P0286", "bibkey": "Dong2023Philosopher", "title": "The Philosopher's Stone: Trojaning Plugins of Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, none proved entirely effective in safeguarding against our attacks, highlighting the need for more robust defenses supporting a secure LLM supply chain.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0286#key_results[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0286-a8a4b71acb", "paper_id": "P0286", "bibkey": "Dong2023Philosopher", "title": "The Philosopher's Stone: Trojaning Plugins of Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Open-source Large Language Models (LLMs) have recently gained popularity because of their comparable performance to proprietary LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0286#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0286-eeae20f16e", "paper_id": "P0286", "bibkey": "Dong2023Philosopher", "title": "The Philosopher's Stone: Trojaning Plugins of Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To efficiently fulfill domain-specialized tasks, open-source LLMs can be refined, without expensive accelerators, using low-rank adapters.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0286#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0286-bd74f3e77a", "paper_id": "P0286", "bibkey": "Dong2023Philosopher", "title": "The Philosopher's Stone: Trojaning Plugins of Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, it is still unknown whether low-rank adapters can be exploited to control LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0286#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0286-ecc0837997", "paper_id": "P0286", "bibkey": "Dong2023Philosopher", "title": "The Philosopher's Stone: Trojaning Plugins of Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, we demonstrate that an infected adapter can induce, on specific triggers,an LLM to output content defined by an adversary and to even maliciously use tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0286#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0286-9e039a5f1a", "paper_id": "P0286", "bibkey": "Dong2023Philosopher", "title": "The Philosopher's Stone: Trojaning Plugins of Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To train a Trojan adapter, we propose two novel attacks, POLISHED and FUSION, that improve over prior approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0286#summary_bullets[4]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0287-7c15c56e3a", "paper_id": "P0287", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Model (LLM) agents struggle with long-horizon software engineering tasks due to \"Context Bloat.\" As interaction history grows, computational costs explode, latency increases, and reasoning capabilities degrade due to distraction by irrelevant past errors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0287#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0287-c411c6caee", "paper_id": "P0287", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "With aggressive prompting that encourages frequent compression, Focus achieves 22.7% token reduction (14.9M -> 11.5M tokens) while maintaining identical accuracy (3/5 = 60% for both agents).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0287#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0287-9abcf1bf8a", "paper_id": "P0287", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0287#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0287-a0e592a756", "paper_id": "P0287", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents struggle with long-horizon software engineering tasks due to \"Context Bloat.\" As interaction history grows, computational costs explode, latency increases, and reasoning capabilities degrade due to distraction by irrelevant past errors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0287#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0287-5a68f5562b", "paper_id": "P0287", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing solutions often rely on passive, external summarization mechanisms that the agent cannot control.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0287#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0287-0323bf5e7e", "paper_id": "P0287", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper proposes Focus, an agent-centric architecture inspired by the biological exploration strategies of Physarum polycephalum (slime mold).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0287#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0287-12c12b308d", "paper_id": "P0287", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The Focus Agent autonomously decides when to consolidate key learnings into a persistent \"Knowledge\" block and actively withdraws (prunes) the raw interaction history.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0287#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0287-e866822df3", "paper_id": "P0287", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0287#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0288-45937036b0", "paper_id": "P0288", "bibkey": "V2026Agentic", "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0288#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0288-6c12fbfdd5", "paper_id": "P0288", "bibkey": "V2026Agentic", "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We also group the environments in which these agents operate, including digital operating systems, embodied robotics, and other specialized domains, and we review current evaluation practices.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0288#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0288-76f9d8f373", "paper_id": "P0288", "bibkey": "V2026Agentic", "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0288#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0288-a61436b261", "paper_id": "P0288", "bibkey": "V2026Agentic", "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0288#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0288-e8b8c3caa3", "paper_id": "P0288", "bibkey": "V2026Agentic", "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This shift already supports the automation of complex workflows in software engineering, scientific discovery, and web navigation, yet the variety of emerging designs, from simple single loop agents to hierarchical multi agent systems, makes the landscape hard to navigate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0288#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0288-6103fb8b23", "paper_id": "P0288", "bibkey": "V2026Agentic", "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we investigate architectures and propose a unified taxonomy that breaks agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0288#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0288-314b9feec6", "paper_id": "P0288", "bibkey": "V2026Agentic", "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We use this lens to describe the move from linear reasoning procedures to native inference time reasoning models, and the transition from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0288#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0289-6406f2cd0f", "paper_id": "P0289", "bibkey": "Li2026Agentic", "title": "Agentic LLMs as Powerful Deanonymizers: Re-identification of Participants in the Anthropic Interviewer Dataset", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "On December 4, 2025, Anthropic released Anthropic Interviewer, an AI tool for running qualitative interviews at scale, along with a public dataset of 1,250 interviews with professionals, including 125 scientists, about their use of AI for research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0289#method"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0289-1c5a0044aa", "paper_id": "P0289", "bibkey": "Li2026Agentic", "title": "Agentic LLMs as Powerful Deanonymizers: Re-identification of Participants in the Anthropic Interviewer Dataset", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "On December 4, 2025, Anthropic released Anthropic Interviewer, an AI tool for running qualitative interviews at scale, along with a public dataset of 1,250 interviews with professionals, including 125 scientists, about their use of AI for research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0289#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0289-7314ec23a4", "paper_id": "P0289", "bibkey": "Li2026Agentic", "title": "Agentic LLMs as Powerful Deanonymizers: Re-identification of Participants in the Anthropic Interviewer Dataset", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "On December 4, 2025, Anthropic released Anthropic Interviewer, an AI tool for running qualitative interviews at scale, along with a public dataset of 1,250 interviews with professionals, including 125 scientists, about their use of AI for research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0289#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0289-3d06145779", "paper_id": "P0289", "bibkey": "Li2026Agentic", "title": "Agentic LLMs as Powerful Deanonymizers: Re-identification of Participants in the Anthropic Interviewer Dataset", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Focusing on the scientist subset, I show that widely available LLMs with web search and agentic capabilities can link six out of twenty-four interviews to specific scientific works, recovering associated authors and, in some cases, uniquely identifying the interviewees.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0289#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0289-7498806f62", "paper_id": "P0289", "bibkey": "Li2026Agentic", "title": "Agentic LLMs as Powerful Deanonymizers: Re-identification of Participants in the Anthropic Interviewer Dataset", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "My contribution is to show that modern LLM-based agents make such re-identification attacks easy and low-effort: off-the-shelf tools can, with a few natural-language prompts, search the web, cross-reference details, and propose likely matches, effectively lowering the technical barrier.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0289#summary_bullets[2]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0289-4e8be0d34a", "paper_id": "P0289", "bibkey": "Li2026Agentic", "title": "Agentic LLMs as Powerful Deanonymizers: Re-identification of Participants in the Anthropic Interviewer Dataset", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing safeguards can be bypassed by breaking down the re-identification into benign tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0289#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0289-3e5d093739", "paper_id": "P0289", "bibkey": "Li2026Agentic", "title": "Agentic LLMs as Powerful Deanonymizers: Re-identification of Participants in the Anthropic Interviewer Dataset", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "I outline the attack at a high level, discuss implications for releasing rich qualitative data in the age of LLM agents, and propose mitigation recommendations and open problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0289#summary_bullets[4]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0289-95395d69d0", "paper_id": "P0289", "bibkey": "Li2026Agentic", "title": "Agentic LLMs as Powerful Deanonymizers: Re-identification of Participants in the Anthropic Interviewer Dataset", "year": 2026, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "I outline the attack at a high level, discuss implications for releasing rich qualitative data in the age of LLM agents, and propose mitigation recommendations and open problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0289#limitations[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0290-844ca49812", "paper_id": "P0290", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose Agentic Memory (AgeMem), a unified framework that integrates LTM and STM management directly into the agent's policy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0290#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0290-f0f0faaada", "paper_id": "P0290", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0290#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0290-ee162c208a", "paper_id": "P0290", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0290#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0290-47a5ff21e4", "paper_id": "P0290", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing methods typically handle long-term memory (LTM) and short-term memory (STM) as separate components, relying on heuristics or auxiliary controllers, which limits adaptability and end-to-end optimization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0290#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0290-d71204699d", "paper_id": "P0290", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose Agentic Memory (AgeMem), a unified framework that integrates LTM and STM management directly into the agent's policy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0290#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0290-cd59b0c4c0", "paper_id": "P0290", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "AgeMem exposes memory operations as tool-based actions, enabling the LLM agent to autonomously decide what and when to store, retrieve, update, summarize, or discard information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0290#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0290-2159f1a39a", "paper_id": "P0290", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To train such unified behaviors, we propose a three-stage progressive reinforcement learning strategy and design a step-wise GRPO to address sparse and discontinuous rewards induced by memory operations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0290#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0290-8b5ccf3d93", "paper_id": "P0290", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0290#limitations[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0291-5c6b0b6509", "paper_id": "P0291", "bibkey": "Miyamoto2026Agent", "title": "An LLM Agent-based Framework for Whaling Countermeasures", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this study, we propose a Whaling countermeasure framework for university faculty members that constructs personalized defense profiles and uses large language model (LLM)-based agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0291#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0291-3728b2e26e", "paper_id": "P0291", "bibkey": "Miyamoto2026Agent", "title": "An LLM Agent-based Framework for Whaling Countermeasures", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "The findings also highlight practical challenges and considerations for future operational deployment and systematic evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0291#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0291-f8c3cea1e2", "paper_id": "P0291", "bibkey": "Miyamoto2026Agent", "title": "An LLM Agent-based Framework for Whaling Countermeasures", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the spread of generative AI in recent years, attacks known as Whaling have become a serious threat.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0291#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0291-6bc9b16137", "paper_id": "P0291", "bibkey": "Miyamoto2026Agent", "title": "An LLM Agent-based Framework for Whaling Countermeasures", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Whaling is a form of social engineering that targets important high-authority individuals within organizations and uses sophisticated fraudulent emails.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0291#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0291-9bab239d5e", "paper_id": "P0291", "bibkey": "Miyamoto2026Agent", "title": "An LLM Agent-based Framework for Whaling Countermeasures", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In the context of Japanese universities, faculty members frequently hold positions that combine research leadership with authority within institutional workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0291#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0291-412c6737e1", "paper_id": "P0291", "bibkey": "Miyamoto2026Agent", "title": "An LLM Agent-based Framework for Whaling Countermeasures", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This structural characteristic leads to the wide public disclosure of high-value information such as publications, grants, and detailed researcher profiles.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0291#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0291-c98587297d", "paper_id": "P0291", "bibkey": "Miyamoto2026Agent", "title": "An LLM Agent-based Framework for Whaling Countermeasures", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Such extensive information exposure enables the construction of highly precise target profiles using generative AI.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0291#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0292-0aebb43b42", "paper_id": "P0292", "bibkey": "Milosevic2026Architecting", "title": "Architecting Agentic Communities using Design Patterns", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "The rapid evolution of Large Language Models (LLM) and subsequent Agentic AI technologies requires systematic architectural guidance for building sophisticated, production-grade systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0292#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0292-65da8a6bcd", "paper_id": "P0292", "bibkey": "Milosevic2026Architecting", "title": "Architecting Agentic Communities using Design Patterns", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We classify these patterns into three tiers: LLM Agents (task-specific automation), Agentic AI (adaptive goal-seekers), and Agentic Communities (organizational frameworks where AI agents and human participants coordinate through formal roles, protocols, and governance structures).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0292#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0292-4703a11e0a", "paper_id": "P0292", "bibkey": "Milosevic2026Architecting", "title": "Architecting Agentic Communities using Design Patterns", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid evolution of Large Language Models (LLM) and subsequent Agentic AI technologies requires systematic architectural guidance for building sophisticated, production-grade systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0292#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0292-950cb8187f", "paper_id": "P0292", "bibkey": "Milosevic2026Architecting", "title": "Architecting Agentic Communities using Design Patterns", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents an approach for architecting such systems using design patterns derived from enterprise distributed systems standards, formal methods, and industry practice.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0292#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0292-f0763dfe41", "paper_id": "P0292", "bibkey": "Milosevic2026Architecting", "title": "Architecting Agentic Communities using Design Patterns", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We classify these patterns into three tiers: LLM Agents (task-specific automation), Agentic AI (adaptive goal-seekers), and Agentic Communities (organizational frameworks where AI agents and human participants coordinate through formal roles, protocols, and governance structures).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0292#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0292-9e9725b2bf", "paper_id": "P0292", "bibkey": "Milosevic2026Architecting", "title": "Architecting Agentic Communities using Design Patterns", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We focus on Agentic Communities - coordination frameworks encompassing LLM Agents, Agentic AI entities, and humans - most relevant for enterprise and industrial applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0292#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0292-e78153218d", "paper_id": "P0292", "bibkey": "Milosevic2026Architecting", "title": "Architecting Agentic Communities using Design Patterns", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Drawing on established coordination principles from distributed systems, we ground these patterns in a formal framework that specifies collaboration agreements where AI agents and humans fill roles within governed ecosystems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0292#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0293-9a7d8f9aa3", "paper_id": "P0293", "bibkey": "Subaharan2026Controlling", "title": "Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce an agent-level affective subsystem that maintains a continuous Valence-Arousal-Dominance (VAD) state external to the language model and governed by first- and second-order update rules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0293#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0293-30e67523ee", "paper_id": "P0293", "bibkey": "Subaharan2026Controlling", "title": "Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Using a fixed 25-turn dialogue protocol, we compare stateless, first-order, and second-order affective dynamics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0293#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0293-8a55683a6a", "paper_id": "P0293", "bibkey": "Subaharan2026Controlling", "title": "Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Second-order dynamics introduce affective inertia and hysteresis that increase with momentum, revealing a trade-off between stability and responsiveness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0293#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0293-d336791e32", "paper_id": "P0293", "bibkey": "Subaharan2026Controlling", "title": "Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents often exhibit abrupt shifts in tone and persona during extended interaction, reflecting the absence of explicit temporal structure governing agent-level state.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0293#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0293-96751d566a", "paper_id": "P0293", "bibkey": "Subaharan2026Controlling", "title": "Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While prior work emphasizes turn-local sentiment or static emotion classification, the role of explicit affective dynamics in shaping long-horizon agent behavior remains underexplored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0293#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0293-f79ef2952a", "paper_id": "P0293", "bibkey": "Subaharan2026Controlling", "title": "Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This work investigates whether imposing dynamical structure on an external affective state can induce temporal coherence and controlled recovery in multi-turn dialogue.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0293#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0293-53e67219fc", "paper_id": "P0293", "bibkey": "Subaharan2026Controlling", "title": "Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce an agent-level affective subsystem that maintains a continuous Valence-Arousal-Dominance (VAD) state external to the language model and governed by first- and second-order update rules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0293#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0293-95259ce9ae", "paper_id": "P0293", "bibkey": "Subaharan2026Controlling", "title": "Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Instantaneous affective signals are extracted using a fixed, memoryless estimator and integrated over time via exponential smoothing or momentum-based dynamics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0293#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0294-c507882fa4", "paper_id": "P0294", "bibkey": "Shi2026Coordinated", "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this challenge, here we propose a large language model (LLM) multi-agent policymaking framework that supports coordinated and proactive pandemic control across regions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0294#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0294-b3c223d2ce", "paper_id": "P0294", "bibkey": "Shi2026Coordinated", "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We validate the proposed framework using state-level COVID-19 data from the United States between April and December 2020, together with real-world mobility records and observed policy interventions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0294#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0294-ce9f280af3", "paper_id": "P0294", "bibkey": "Shi2026Coordinated", "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Compared with real-world pandemic outcomes, our approach reduces cumulative infections and deaths by up to 63.7% and 40.1%, respectively, at the individual state level, and by 39.0% and 27.0%, respectively, when aggregated across states.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0294#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0294-eafc535ff9", "paper_id": "P0294", "bibkey": "Shi2026Coordinated", "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Effective pandemic control requires timely and coordinated policymaking across administrative regions that are intrinsically interdependent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0294#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0294-8c5cff0583", "paper_id": "P0294", "bibkey": "Shi2026Coordinated", "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, human-driven responses are often fragmented and reactive, with policies formulated in isolation and adjusted only after outbreaks escalate, undermining proactive intervention and global pandemic mitigation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0294#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0294-173e9a41ed", "paper_id": "P0294", "bibkey": "Shi2026Coordinated", "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this challenge, here we propose a large language model (LLM) multi-agent policymaking framework that supports coordinated and proactive pandemic control across regions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0294#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0294-5fbacdebb3", "paper_id": "P0294", "bibkey": "Shi2026Coordinated", "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Within our framework, each administrative region is assigned an LLM agent as an AI policymaking assistant.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0294#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0294-61d6db9254", "paper_id": "P0294", "bibkey": "Shi2026Coordinated", "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The agent reasons over region-specific epidemiological dynamics while communicating with other agents to account for cross-regional interdependencies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0294#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0295-b8e39e84d0", "paper_id": "P0295", "bibkey": "Song2026Envscaler", "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose EnvScaler, an automated framework for scalable tool-interaction environments via programmatic synthesis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0295#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0295-87a6cb3814", "paper_id": "P0295", "bibkey": "Song2026Envscaler", "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "With EnvScaler, we synthesize 191 environments and about 7K scenarios, and apply them to Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) for Qwen3 series models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0295#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0295-f1a25e82c1", "paper_id": "P0295", "bibkey": "Song2026Envscaler", "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "First, SkelBuilder constructs diverse environment skeletons through topic mining, logic modeling, and quality evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0295#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0295-7657af8284", "paper_id": "P0295", "bibkey": "Song2026Envscaler", "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are expected to be trained to act as agents in various real-world environments, but this process relies on rich and varied tool-interaction sandboxes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0295#summary_bullets[0]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0295-3dc68778a4", "paper_id": "P0295", "bibkey": "Song2026Envscaler", "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, access to real systems is often restricted; LLM-simulated environments are prone to hallucinations and inconsistencies; and manually built sandboxes are hard to scale.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0295#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0295-3cdfa39cc2", "paper_id": "P0295", "bibkey": "Song2026Envscaler", "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose EnvScaler, an automated framework for scalable tool-interaction environments via programmatic synthesis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0295#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0295-434cf01612", "paper_id": "P0295", "bibkey": "Song2026Envscaler", "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "EnvScaler comprises two components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0295#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0295-00d876acc0", "paper_id": "P0295", "bibkey": "Song2026Envscaler", "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "First, SkelBuilder constructs diverse environment skeletons through topic mining, logic modeling, and quality evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0295#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0296-5f287d2ae2", "paper_id": "P0296", "bibkey": "Xing2026Flashinfer", "title": "FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0296#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0296-2a0d336ba6", "paper_id": "P0296", "bibkey": "Xing2026Flashinfer", "title": "FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Built on real serving traces, FlashInfer-Bench includes a curated dataset, a robust correctness- and performance-aware benchmarking framework, a public leaderboard to track LLM agents' GPU programming capabilities, and a dynamic substitution mechanism (apply()) that seamlessly injects the best-performing kernels into production LLM engines such as SGLang and vLLM.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0296#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0296-5855278cae", "paper_id": "P0296", "bibkey": "Xing2026Flashinfer", "title": "FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0296#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0296-cab4d6b5dc", "paper_id": "P0296", "bibkey": "Xing2026Flashinfer", "title": "FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "FlashInfer-Bench addresses this gap by establishing a standardized, closed-loop framework that connects kernel generation, benchmarking, and deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0296#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0296-8a89414ffa", "paper_id": "P0296", "bibkey": "Xing2026Flashinfer", "title": "FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "At its core, FlashInfer Trace provides a unified schema describing kernel definitions, workloads, implementations, and evaluations, enabling consistent communication between agents and systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0296#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0296-2d3706acae", "paper_id": "P0296", "bibkey": "Xing2026Flashinfer", "title": "FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Built on real serving traces, FlashInfer-Bench includes a curated dataset, a robust correctness- and performance-aware benchmarking framework, a public leaderboard to track LLM agents' GPU programming capabilities, and a dynamic substitution mechanism (apply()) that seamlessly injects the best-performing kernels into production LLM engines such as SGLang and vLLM.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0296#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0296-5235e61345", "paper_id": "P0296", "bibkey": "Xing2026Flashinfer", "title": "FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Using FlashInfer-Bench, we further evaluate the performance and limitations of LLM agents, compare the trade-offs among different GPU programming languages, and provide insights for future agent design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0296#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0296-bc211d4128", "paper_id": "P0296", "bibkey": "Xing2026Flashinfer", "title": "FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Using FlashInfer-Bench, we further evaluate the performance and limitations of LLM agents, compare the trade-offs among different GPU programming languages, and provide insights for future agent design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0296#limitations[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0297-7d9c488c76", "paper_id": "P0297", "bibkey": "Hao2026From", "title": "From Failure to Mastery: Generating Hard Samples for Tool-use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To bridge this gap, we introduce HardGen, an automatic agentic pipeline designed to generate hard tool-use training samples with verifiable reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0297#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0297-7bed142d5c", "paper_id": "P0297", "bibkey": "Hao2026From", "title": "From Failure to Mastery: Generating Hard Samples for Tool-use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive evaluations demonstrate that a 4B parameter model trained with our curated dataset achieves superior performance compared to several leading open-source and closed-source competitors (e.g., GPT-5.2, Gemini-3-Pro and Claude-Opus-4.5).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0297#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0297-ed4427964c", "paper_id": "P0297", "bibkey": "Hao2026From", "title": "From Failure to Mastery: Generating Hard Samples for Tool-use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, the advanced tools and hard queries enable the generation of verifiable complex Chain-of-Thought (CoT), with a closed-loop evaluation feedback steering the continuous refinement of the process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0297#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0297-f00a187154", "paper_id": "P0297", "bibkey": "Hao2026From", "title": "From Failure to Mastery: Generating Hard Samples for Tool-use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The advancement of LLM agents with tool-use capabilities requires diverse and complex training corpora.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0297#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0297-c5dd6ade6c", "paper_id": "P0297", "bibkey": "Hao2026From", "title": "From Failure to Mastery: Generating Hard Samples for Tool-use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing data generation methods, which predominantly follow a paradigm of random sampling and shallow generation, often yield simple and homogeneous trajectories that fail to capture complex, implicit logical dependencies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0297#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0297-5f72d6dfad", "paper_id": "P0297", "bibkey": "Hao2026From", "title": "From Failure to Mastery: Generating Hard Samples for Tool-use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To bridge this gap, we introduce HardGen, an automatic agentic pipeline designed to generate hard tool-use training samples with verifiable reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0297#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0297-b7d2bed7df", "paper_id": "P0297", "bibkey": "Hao2026From", "title": "From Failure to Mastery: Generating Hard Samples for Tool-use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Firstly, HardGen establishes a dynamic API Graph built upon agent failure cases, from which it samples to synthesize hard traces.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0297#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0297-866abc60cf", "paper_id": "P0297", "bibkey": "Hao2026From", "title": "From Failure to Mastery: Generating Hard Samples for Tool-use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Secondly, these traces serve as conditional priors to guide the instantiation of modular, abstract advanced tools, which are subsequently leveraged to formulate hard queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0297#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0298-d5d54223d4", "paper_id": "P0298", "bibkey": "Quan2026Inferring", "title": "Inferring Latent Intentions: Attributional Natural Language Inference in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we introduce Attributional NLI (Att-NLI), a framework that extends NLI with principles from social psychology to assess an agent's capacity for abductive intentional inference (generating hypotheses about latent intentions), and subsequent deductive verification (drawing valid logical conclusions).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0298#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0298-c1df074e24", "paper_id": "P0298", "bibkey": "Quan2026Inferring", "title": "Inferring Latent Intentions: Attributional Natural Language Inference in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments demonstrate a clear hierarchy of attributional inference capabilities, with neuro-symbolic agents consistently outperforming others, achieving an average win rate of 17.08%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0298#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0298-16a8f0e24f", "paper_id": "P0298", "bibkey": "Quan2026Inferring", "title": "Inferring Latent Intentions: Attributional Natural Language Inference in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Attributional inference, the ability to predict latent intentions behind observed actions, is a critical yet underexplored capability for large language models (LLMs) operating in multi-agent environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0298#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0298-549f636257", "paper_id": "P0298", "bibkey": "Quan2026Inferring", "title": "Inferring Latent Intentions: Attributional Natural Language Inference in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional natural language inference (NLI), in fact, fails to capture the nuanced, intention-driven reasoning essential for complex interactive systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0298#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0298-0384a37514", "paper_id": "P0298", "bibkey": "Quan2026Inferring", "title": "Inferring Latent Intentions: Attributional Natural Language Inference in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, we introduce Attributional NLI (Att-NLI), a framework that extends NLI with principles from social psychology to assess an agent's capacity for abductive intentional inference (generating hypotheses about latent intentions), and subsequent deductive verification (drawing valid logical conclusions).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0298#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0298-2664265dbe", "paper_id": "P0298", "bibkey": "Quan2026Inferring", "title": "Inferring Latent Intentions: Attributional Natural Language Inference in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We instantiate Att-NLI via a textual game, Undercover-V, experimenting with three types of LLM agents with varying reasoning capabilities and access to external tools: a standard NLI agent using only deductive inference, an Att-NLI agent employing abductive-deductive inference, and a neuro-symbolic Att-NLI agent performing abductive-deductive inference with external theorem provers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0298#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0298-00bbfd6647", "paper_id": "P0298", "bibkey": "Quan2026Inferring", "title": "Inferring Latent Intentions: Attributional Natural Language Inference in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Extensive experiments demonstrate a clear hierarchy of attributional inference capabilities, with neuro-symbolic agents consistently outperforming others, achieving an average win rate of 17.08%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0298#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0299-8bff916590", "paper_id": "P0299", "bibkey": "Soliman2026Intagent", "title": "IntAgent: NWDAF-Based Intent LLM Agent Towards Advanced Next Generation Networks", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we introduce IntAgent, an intelligent intent LLM agent that integrates NWDAF analytics and tools to fulfill the network operator's intents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0299#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0299-e1300e60aa", "paper_id": "P0299", "bibkey": "Soliman2026Intagent", "title": "IntAgent: NWDAF-Based Intent LLM Agent Towards Advanced Next Generation Networks", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We demonstrate the efficacy of our framework through two practical use cases: ML-based traffic prediction and scheduled policy enforcement, which validate IntAgent's ability to autonomously fulfill complex network intents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0299#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0299-db89b745f3", "paper_id": "P0299", "bibkey": "Soliman2026Intagent", "title": "IntAgent: NWDAF-Based Intent LLM Agent Towards Advanced Next Generation Networks", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Intent-based networks (IBNs) are gaining prominence as an innovative technology that automates network operations through high-level request statements, defining what the network should achieve.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0299#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0299-3c56c4619b", "paper_id": "P0299", "bibkey": "Soliman2026Intagent", "title": "IntAgent: NWDAF-Based Intent LLM Agent Towards Advanced Next Generation Networks", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we introduce IntAgent, an intelligent intent LLM agent that integrates NWDAF analytics and tools to fulfill the network operator's intents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0299#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0299-14f08263fa", "paper_id": "P0299", "bibkey": "Soliman2026Intagent", "title": "IntAgent: NWDAF-Based Intent LLM Agent Towards Advanced Next Generation Networks", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike previous approaches, we develop an intent tools engine directly within the NWDAF analytics engine, allowing our agent to utilize live network analytics to inform its reasoning and tool selection.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0299#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0299-79ed9be52d", "paper_id": "P0299", "bibkey": "Soliman2026Intagent", "title": "IntAgent: NWDAF-Based Intent LLM Agent Towards Advanced Next Generation Networks", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We offer an enriched, 3GPP-compliant data source that enhances the dynamic, context-aware fulfillment of network operator goals, along with an MCP tools server for scheduling, monitoring, and analytics tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0299#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0299-ea7c5c2554", "paper_id": "P0299", "bibkey": "Soliman2026Intagent", "title": "IntAgent: NWDAF-Based Intent LLM Agent Towards Advanced Next Generation Networks", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We demonstrate the efficacy of our framework through two practical use cases: ML-based traffic prediction and scheduled policy enforcement, which validate IntAgent's ability to autonomously fulfill complex network intents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0299#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0300-952a3ec8a8", "paper_id": "P0300", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we present a comprehensive survey of LLM agents for legal tasks, analyzing how these architectures bridge the gap between technical capabilities and domain-specific needs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0300#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0300-8b56718f74", "paper_id": "P0300", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our major contributions include: (1) systematically analyzing the technical transition from standard legal LLMs to legal agents; (2) presenting a structured taxonomy of current agent applications across distinct legal practice areas; (3) discussing evaluation methodologies specifically for agentic performance in law; and (4) identifying open challenges and outlining future directions for developing robust and autonomous legal assistants.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0300#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0300-73192b14aa", "paper_id": "P0300", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have precipitated a dramatic improvement in the legal domain, yet the deployment of standalone models faces significant limitations regarding hallucination, outdated information, and verifiability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0300#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0300-536a01abb9", "paper_id": "P0300", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, LLM agents have attracted significant attention as a solution to these challenges, utilizing advanced capabilities such as planning, memory, and tool usage to meet the rigorous standards of legal practice.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0300#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0300-9e10275b89", "paper_id": "P0300", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we present a comprehensive survey of LLM agents for legal tasks, analyzing how these architectures bridge the gap between technical capabilities and domain-specific needs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0300#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0300-54e184e5e2", "paper_id": "P0300", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our major contributions include: (1) systematically analyzing the technical transition from standard legal LLMs to legal agents; (2) presenting a structured taxonomy of current agent applications across distinct legal practice areas; (3) discussing evaluation methodologies specifically for agentic performance in law; and (4) identifying open challenges and outlining future directions for developing robust and autonomous legal assistants.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0300#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0300-19ffd0c3ba", "paper_id": "P0300", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Large language models (LLMs) have precipitated a dramatic improvement in the legal domain, yet the deployment of standalone models faces significant limitations regarding hallucination, outdated information, and verifiability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0300#limitations[1]"}, "confidence": "medium", "tags": []}
