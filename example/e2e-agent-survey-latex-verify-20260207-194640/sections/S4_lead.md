Once interfaces define the action space, the next bottleneck is how agents choose actions over time under uncertainty and budget constraints. This chapter treats planning and memory as protocol-sensitive components: reported gains often depend as much on search breadth, tool-call scheduling, and termination rules as on the underlying model. Efficient variants therefore need to be interpreted jointly with the evaluation protocol (task format, step limits, latency/cost budgets) used to measure them. [@Yao2023Tree] [@Zhang2026Evoroute; @Mohammadi2025Evaluation]

The planning subsection emphasizes control loops and deliberation: when agents branch, how they score alternatives, and how plans are revised after tool feedback. The memory subsection focuses on what evidence the agent can condition on - retrieval policy, write/update rules, and how retrieved context is verified - because memory modules can shift both correctness and robustness without changing the nominal planner. Together, these components explain why "stronger reasoning" claims frequently hinge on grounded state and comparable protocols rather than prompt wording alone. [@Shi2025Progent] [@Abbineni2025Muallm; @Li2025Agentswift]
