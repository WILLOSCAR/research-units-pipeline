Evaluation determines which claims about agents are meaningful, and risk models determine which gains survive outside benign settings. This chapter connects benchmark design, protocol fields, and threat models so that reported numbers can be interpreted as statements about closed-loop systems rather than isolated model snapshots. In practice, differences in tool access, budgets, hidden prompts, and environment variability can dominate conclusions unless they are controlled or at least explicitly reported. [@Mohammadi2025Evaluation] [@Chowa2025From; @Fu2025Eval]

The benchmarks subsection surveys task suites and protocol conventions for tool-use and long-horizon evaluation, emphasizing how metrics interact with interaction formats and budgets. The risks subsection focuses on security and governance: prompt injection, tool abuse, and monitoring/guardrail strategies that trade off robustness with task utility under explicit adversarial assumptions. Together, they provide a protocol-aware lens for interpreting both performance improvements and safety claims in the rest of the paper. [@Zhang2025Security] [@Gasmi2025Bridging; @Mou2026Toolsafe]
