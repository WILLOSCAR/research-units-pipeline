# Evidence draft: 6.2 Safety, security, and governance

## Evidence snippets (with provenance)
- (E-P0186-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed attacks; (2) an evaluation harness that executes attacks by running real tools (both benign and malicious) via MCP rather than simulation; and (3) a robustness metric that quantifies the trade-off between security and performance: Net Resilient Performance (NRP). Zhang2025Security (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0186#key_results[0])
- (E-P0190-3c65d38a2a) Through extensive evaluation of leading LLMs, we find that even SOTA models such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit significant performance limitations. Luo2025Universe (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0190#limitations[1])
- (E-P0208-753416ce70) RAS-Eval comprises 80 test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration (CWE) categories, with tools implemented in JSON, LangGraph, and Model Context Protocol (MCP) formats. Fu2025Eval (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0208#key_results[1])
- (E-P0212-e0345118bc) To this end, we systematize a monitor red teaming (MRT) workflow that incorporates: (1) varying levels of agent and monitor situational awareness; (2) distinct adversarial strategies to evade the monitor, such as prompt injection; and (3) two datasets and environments -- SHADE-Arena for tool-calling agents and our new CUA-SHADE-Arena, which extends TheAgentCompany, for computer-use agents. Kale2025Reliable (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0212#key_results[0])
- (E-P0096-4fca49d200) We then systematically curate a high-quality dataset for function calling, which we use to fine-tune two small language models, TinyAgent-1.1B and 7B. Erdogan2024Tinyagent (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0096#key_results[0])
- (E-P0152-7edb91824f) Leveraging the ToolEmu framework, we conduct a systematic evaluation of quitting behavior across 12 state-of-the-art LLMs. Bonagiri2025Check (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0152#key_results[0])
- (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0109#key_results[0])
- (E-P0040-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0040#key_results[0])
- (E-P0136-a0b404d928) Extensive experiments across ten realistic, simulated tool-use scenarios and a range of popular LLM agents demonstrate consistently high attack success rates (81\%-95\%) and significant privacy leakage, with negligible impact on primary task execution. Mo2025Attractive (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0136#key_results[0])
- (E-P0101-a4ae2708e4) Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior. Balaji2026Beyond (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0101#key_results[1])
- (E-P0108-3e2edc05cd) However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings. Li2026Toolprmbench (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0108#key_results[0])
- (E-P0270-dda84e50a5) MVVM introduces two key innovations: (1) a two-way sandboxing framework leveraging hardware enclaves and accelerator extensions that protects both the agent from malicious hosts and the host from compromised agents; (2) an efficient cross platform migration mechanism using WebAssembly and WASI's platform-agnostic design, enabling seamless movement across ARM phones, RISC-V MCUs, x86 servers, and heterogeneous accelerators; and three astonishing use cases: (1) privacy-aware daemon that automatically determines whether to execute locally or remotely based on data sensitivity and resource availability; (2) multi-tier replication with intelligent quality degradation that maintains service availability despite network failures or resource constraints; (3) a comprehensive execution framework combining speculative execution for 10x latency reduction with parallel validation that ensures output safety without compromising responsiveness. Yang2024Mvvm (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0270#key_results[1])
- (E-P0163-84b88bc47a) Extensive evaluation using realistic 5G scenarios demonstrates that the edge framework achieves zero network outages under high-stress conditions, compared to 8.4% for traditional fixed-power networks and 3.3% for large language model (LLM) agent-based approaches, while maintaining near real-time responsiveness and consistent QoS. Salama2025Edge (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0163#key_results[0])
- (E-P0241-e26328e18c) Our evaluation of 16 popular LLM agents reveals a concerning result: none of the agents achieves a safety score above 60%. Zhang2024Agent (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0241#key_results[0])
- (E-P0113-a68f39bc04) This survey provides a comprehensive overview of foundation models, agentic systems, datasets, and computational tools supporting this growing field. Van2025Survey (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0113#key_results[0])
- (E-P0091-52fea1d199) We address research questions such as existing GUI agent frameworks, the collection and utilization of data for training specialized GUI agents, the development of large action models tailored for GUI tasks, and the evaluation metrics and benchmarks necessary to assess their effectiveness. Zhang2024Large (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0091#key_results[1])
- (E-P0236-3cd6217549) (2) We then conduct a series of pilot experiments to demonstrate the safety risks in MCP-powered agent systems is a real threat and its defense is not trivial. Fang2025Should (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0236#key_results[1])
- (E-P0122-20fed7f11c) Through extensive evaluations on public and self-built benchmarks, including Agent SafetyBench, InjecAgent, and BFCL, we demonstrate that our safety-aligned agents significantly improve resistance to security threats while preserving strong utility on benign tasks. Sha2025Agent (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0122#key_results[0])

## Definitions / setup

- Setup: Which design choices in Safety, security, and governance drive the major trade-offs, and how are those trade-offs measured? Scope: in-scope: Core topics directly relevant to 'Safety, security, and governance'.. Axes: evaluation protocol (datasets, metrics, human evaluation); compute and latency constraints; tool interface contract (schemas / protocols); tool selection / routing policy; sandboxing / permissions / observability. Balaji2026Beyond Li2026Toolprmbench Mou2026Toolsafe

## Claim candidates

- MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed attacks; (2) an evaluation harness that executes attacks by running real tools (both benign and malicious) via MCP Zhang2025Security
- Through extensive evaluation of leading LLMs, we find that even SOTA models such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit significant performance limitations. Luo2025Universe
- RAS-Eval comprises 80 test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration (CWE) categories, with tools implemented in JSON, LangGraph, and Model Context Protocol (MCP) formats. Fu2025Eval
- To this end, we systematize a monitor red teaming (MRT) workflow that incorporates: (1) varying levels of agent and monitor situational awareness; (2) distinct adversarial strategies to evade the monitor, such as prompt injection; and (3) two datasets and environments -- SHADE-Arena for tool-calling agents and our new CUA-SHADE-Arena, which extends TheAgentCompany, for computer-use agents. Kale2025Reliable
- We then systematically curate a high-quality dataset for function calling, which we use to fine-tune two small language models, TinyAgent-1.1B and 7B. Erdogan2024Tinyagent

## Concrete comparisons

- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Agent frameworks / architectures: `P0101`, `P0108`, `P0109`; B: Safety / security / guardrails: `P0109`, `P0029`, `P0040`. Balaji2026Beyond Gasmi2025Bridging Mou2026Toolsafe
  - A highlight: (E-P0101-a4ae2708e4) Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior. Balaji2026Beyond (pointer: papers/paper_notes.jsonl:paper_id=P0101#key_results[1])
  - A highlight: (E-P0040-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0040#key_results[0])
  - B highlight: (E-P0040-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0040#key_results[0])
  - B highlight: (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (pointer: papers/paper_notes.jsonl:paper_id=P0109#key_results[0])
- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Agent frameworks / architectures: `P0101`, `P0108`, `P0109`; B: Tool-use and function calling: `P0108`, `P0109`, `P0044`. Balaji2026Beyond Gasmi2025Bridging Zhang2025Security Van2025Survey
  - A highlight: (E-P0101-a4ae2708e4) Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior. Balaji2026Beyond (pointer: papers/paper_notes.jsonl:paper_id=P0101#key_results[1])
  - A highlight: (E-P0040-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0040#key_results[0])
  - B highlight: (E-P0186-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0186#key_results[0])
  - B highlight: (E-P0113-a68f39bc04) This survey provides a comprehensive overview of foundation models, agentic systems, datasets, and computational tools supporting this growing field. Van2025Survey (pointer: papers/paper_notes.jsonl:paper_id=P0113#key_results[0])
- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Safety / security / guardrails: `P0109`, `P0029`, `P0040`; B: Tool-use and function calling: `P0108`, `P0109`, `P0044`. Gasmi2025Bridging Mou2026Toolsafe Zhang2025Security Van2025Survey
  - A highlight: (E-P0040-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0040#key_results[0])
  - A highlight: (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (pointer: papers/paper_notes.jsonl:paper_id=P0109#key_results[0])
  - B highlight: (E-P0186-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0186#key_results[0])
  - B highlight: (E-P0113-a68f39bc04) This survey provides a comprehensive overview of foundation models, agentic systems, datasets, and computational tools supporting this growing field. Van2025Survey (pointer: papers/paper_notes.jsonl:paper_id=P0113#key_results[0])
- Axis: compute and latency constraints; A: Agent frameworks / architectures: `P0101`, `P0108`, `P0109`; B: Safety / security / guardrails: `P0109`, `P0029`, `P0040`. Mou2026Toolsafe Balaji2026Beyond Sha2025Agent
  - A highlight: (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (pointer: papers/paper_notes.jsonl:paper_id=P0109#key_results[0])
  - A highlight: (E-P0101-a4ae2708e4) Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior. Balaji2026Beyond (pointer: papers/paper_notes.jsonl:paper_id=P0101#key_results[1])
  - B highlight: (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (pointer: papers/paper_notes.jsonl:paper_id=P0109#key_results[0])
  - B highlight: (E-P0122-20fed7f11c) Through extensive evaluations on public and self-built benchmarks, including Agent SafetyBench, InjecAgent, and BFCL, we demonstrate that our safety-aligned agents significantly improve resistance to security threats while preserving strong utility on benign tasks. Sha2025Agent (pointer: papers/paper_notes.jsonl:paper_id=P0122#key_results[0])
- Axis: compute and latency constraints; A: Agent frameworks / architectures: `P0101`, `P0108`, `P0109`; B: Tool-use and function calling: `P0108`, `P0109`, `P0044`. Mou2026Toolsafe Balaji2026Beyond Zhang2025Security
  - A highlight: (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (pointer: papers/paper_notes.jsonl:paper_id=P0109#key_results[0])
  - A highlight: (E-P0101-a4ae2708e4) Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior. Balaji2026Beyond (pointer: papers/paper_notes.jsonl:paper_id=P0101#key_results[1])
  - B highlight: (E-P0186-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0186#key_results[0])
  - B highlight: (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (pointer: papers/paper_notes.jsonl:paper_id=P0109#key_results[0])
- Axis: compute and latency constraints; A: Safety / security / guardrails: `P0109`, `P0029`, `P0040`; B: Tool-use and function calling: `P0108`, `P0109`, `P0044`. Mou2026Toolsafe Sha2025Agent Zhang2025Security
  - A highlight: (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (pointer: papers/paper_notes.jsonl:paper_id=P0109#key_results[0])
  - A highlight: (E-P0122-20fed7f11c) Through extensive evaluations on public and self-built benchmarks, including Agent SafetyBench, InjecAgent, and BFCL, we demonstrate that our safety-aligned agents significantly improve resistance to security threats while preserving strong utility on benign tasks. Sha2025Agent (pointer: papers/paper_notes.jsonl:paper_id=P0122#key_results[0])
  - B highlight: (E-P0186-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0186#key_results[0])
  - B highlight: (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (pointer: papers/paper_notes.jsonl:paper_id=P0109#key_results[0])
- Axis: tool interface contract (schemas / protocols); A: Agent frameworks / architectures: `P0101`, `P0108`, `P0109`; B: Safety / security / guardrails: `P0109`, `P0029`, `P0040`. Gasmi2025Bridging Mou2026Toolsafe
  - A highlight: (E-P0040-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0040#key_results[0])
  - A highlight: (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (pointer: papers/paper_notes.jsonl:paper_id=P0109#key_results[0])
  - B highlight: (E-P0040-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0040#key_results[0])
  - B highlight: (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (pointer: papers/paper_notes.jsonl:paper_id=P0109#key_results[0])
- Axis: tool interface contract (schemas / protocols); A: Agent frameworks / architectures: `P0101`, `P0108`, `P0109`; B: Tool-use and function calling: `P0108`, `P0109`, `P0044`. Gasmi2025Bridging Mou2026Toolsafe Zhang2025Security
  - A highlight: (E-P0040-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0040#key_results[0])
  - A highlight: (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (pointer: papers/paper_notes.jsonl:paper_id=P0109#key_results[0])
  - B highlight: (E-P0186-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0186#key_results[0])
  - B highlight: (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (pointer: papers/paper_notes.jsonl:paper_id=P0109#key_results[0])
- Axis: tool interface contract (schemas / protocols); A: Safety / security / guardrails: `P0109`, `P0029`, `P0040`; B: Tool-use and function calling: `P0108`, `P0109`, `P0044`. Gasmi2025Bridging Mou2026Toolsafe Zhang2025Security
  - A highlight: (E-P0040-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0040#key_results[0])
  - A highlight: (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (pointer: papers/paper_notes.jsonl:paper_id=P0109#key_results[0])
  - B highlight: (E-P0186-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0186#key_results[0])
  - B highlight: (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (pointer: papers/paper_notes.jsonl:paper_id=P0109#key_results[0])
- Axis: tool selection / routing policy; A: Agent frameworks / architectures: `P0101`, `P0108`, `P0109`; B: Safety / security / guardrails: `P0109`, `P0029`, `P0040`. Gasmi2025Bridging Mou2026Toolsafe
  - A highlight: (E-P0040-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0040#key_results[0])
  - A highlight: (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (pointer: papers/paper_notes.jsonl:paper_id=P0109#key_results[0])
  - B highlight: (E-P0040-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0040#key_results[0])
  - B highlight: (E-P0109-c6a59efa61) Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks. Mou2026Toolsafe (pointer: papers/paper_notes.jsonl:paper_id=P0109#key_results[0])

## Evaluation protocol

- Evaluation mentions include: IVR, LLMs, SPA, DPA, GPT-4o-mini, GPT-4o, AI-driven, IVR-era, JourneyBench, PRMs. Balaji2026Beyond Li2026Toolprmbench Mou2026Toolsafe Zhou2025Reasoning
- When comparing results, anchor the paragraph with: task type + metric + constraint (budget, tool access, horizon, or threat model) when stated. Balaji2026Beyond Li2026Toolprmbench
- Prefer head-to-head comparisons only when benchmark/metric are shared; otherwise frame differences as protocol-driven rather than method superiority. Balaji2026Beyond Li2026Toolprmbench
- Avoid underspecified model/baseline naming; if abstracts omit details, state that the baseline is reported but underspecified instead of guessing. Balaji2026Beyond Li2026Toolprmbench
- If a claim relies on a single reported number, pair it with a limitation/caveat from the same evidence so the draft remains conservative. Balaji2026Beyond Li2026Toolprmbench
- If budgets or environments differ across papers, treat cross-paper numeric comparison as fragile and prefer qualitative contrasts aligned to the subsection axes. Balaji2026Beyond Li2026Toolprmbench

## Failures / limitations

- While large language model (LLM) agents offer a promising alternative, evaluating their ability to act in accordance with business rules and real-world support workflows remains an open challenge. Balaji2026Beyond
- Our findings demonstrate the importance of structured orchestration and establish JourneyBench as a critical resource to advance AI-driven customer support beyond IVR-era limitations. Balaji2026Beyond
- While LLM-based agents can interact with environments via invoking external tools, their expanded capabilities also amplify security risks. Mou2026Toolsafe
- Monitoring step-level tool invocation behaviors in real time and proactively intervening before unsafe execution is critical for agent deployment, yet remains under-explored. Mou2026Toolsafe
- The model proactively detects unsafe tool invocation actions before execution by reasoning over the interaction history. Mou2026Toolsafe
- It assesses request harmfulness and action-attack correlations, producing interpretable and generalizable safety judgments and feedback. Mou2026Toolsafe
- While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. Zhou2025Reasoning
- We introduce Generative Style Injection (GSI), an attack method that rewrites retrieved documents into pathological tones--specifically "analysis paralysis" or "cognitive haste"--without altering underlying facts or using explicit triggers. Zhou2025Reasoning

## Verify fields (non-blocking)

- named benchmarks/datasets used
- metrics/human-eval protocol
- compute/training/inference cost
- training data and supervision signal
- baseline choices and ablation evidence
