# Evidence draft: 4.1 Planning and reasoning loops

## Evidence snippets (with provenance)
- (E-P0243-38a26e4777) Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Shang2024Agentsquare (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0243#key_results[0])
- (E-P0190-84445d1a19) To address this critical gap, we introduce MCP-Universe, the first comprehensive benchmark specifically designed to evaluate LLMs in realistic and hard tasks through interaction with real-world MCP servers. Luo2025Universe (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0190#method)
- (E-P0046-741891e300) To evaluate our approach, we built an automated penetration testing LLM agent using three LLMs (Llama-3-8B, Gemini-1.5, and GPT-4) and applied it to navigate 10 HackTheBox cybersecurity exercises with 103 discrete subtasks representing real-world cyberattack scenarios. Nakano2025Guided (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0046#key_results[1])
- (E-P0215-0b753b9422) Across diverse evaluation agent settings, our seed test case generation approach yields 2 -- 2.5x boost to the coverage of risk outcomes and tool-calling trajectories. Zhou2025Siraj (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0215#key_results[0])
- (E-P0233-771620f84f) Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning tasks. Hu2025Training (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0233#key_results[0])
- (E-P0089-d36844b954) We investigate the performance of IoT across various datasets, spanning complex reasoning tasks from the GPQA dataset, explorative problem-solving in Game of 24, puzzle solving in Mini Crosswords, and multi-hop question answering from the HotpotQA dataset. Radha2024Iteration (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0089#key_results[0])
- (E-P0019-8517628bd0) While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. Zhou2025Reasoning (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[1])
- (E-P0086-a9c15ec0c8) LLM agents trained with our method also show more efficient tool use, with inference speed being on average ~1.4x faster than baseline tool-augmented LLMs. Gao2024Efficient (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0086#key_results[1])
- (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- (E-P0060-5377f4f9b7) To measure the performance of task-oriented agents comprehensively, we propose a two-level evaluation framework: (1) turn level and (2) end-to-end. Rawat2025Multi (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0060#key_results[0])
- (E-P0180-55a2731a38) We rigorously evaluate LARC on a carefully curated set of 48 constrained retrosynthesis planning tasks across 3 constraint types. Baker2025Larc (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0180#key_results[1])
- (E-P0254-2a7ea60588) Experiments on three real-world multi-tabular EHR datasets show that EHRAgent outperforms the strongest baseline by up to 29.6% in success rate. Shi2024Ehragent (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0254#key_results[0])
- (E-P0274-c0a98eb625) We evaluate PDoctor with three mainstream agent frameworks and two powerful LLMs (GPT-3.5 and GPT-4). Ji2024Testing (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0274#key_results[0])
- (E-P0199-9406c14ad1) Through comprehensive evaluation in both agent-versus-agent simulations and studies with human players, we demonstrate MultiMind's superior performance in gameplay. Zhang2025Multimind (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0199#key_results[0])
- (E-P0018-2bad4bca21) Using our proposed LLM agent to extract reasoning traces into ReJump format, we evaluate state-of-the-art LRMs on two tasks and find that models with similar accuracy can exhibit distinct reasoning behaviors, while different tasks favor different reasoning styles (e.g., varying balance between exploration and exploitation). Zeng2025Rejump (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0018#key_results[0])
- (E-P0145-c90a434db5) We introduce COMPASS (Constrained Optimization through Multi-turn Planning and Strategic Solutions), a benchmark that evaluates agents on realistic travel-planning scenarios. Qin2025Compass (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0145#key_results[1])
- (E-P0148-b35b53de13) We systematically evaluate their performance using a suite of coordination-sensitive metrics, including task success rate, redundant actions, room conflicts, and urgency-weighted efficiency. Silva2025Agents (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0148#key_results[0])
- (E-P0170-e4ac5005b3) Our best performing strategy generates executable API calls 88% of the time. Mudur2025Feabench (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0170#key_results[0])

## Definitions / setup

- Setup: Which design choices in Planning and reasoning loops drive the major trade-offs, and how are those trade-offs measured? Scope: in-scope: Core topics directly relevant to 'Planning and reasoning loops'.. Axes: evaluation protocol (datasets, metrics, human evaluation); compute and latency constraints; tool interface contract (schemas / protocols); tool selection / routing policy; sandboxing / permissions / observability. Zeng2025Rejump Zhou2025Reasoning Nakano2025Guided

## Claim candidates

- Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Shang2024Agentsquare
- To address this critical gap, we introduce MCP-Universe, the first comprehensive benchmark specifically designed to evaluate LLMs in realistic and hard tasks through interaction with real-world MCP servers. Luo2025Universe
- To evaluate our approach, we built an automated penetration testing LLM agent using three LLMs (Llama-3-8B, Gemini-1.5, and GPT-4) and applied it to navigate 10 HackTheBox cybersecurity exercises with 103 discrete subtasks representing real-world cyberattack scenarios. Nakano2025Guided
- Across diverse evaluation agent settings, our seed test case generation approach yields 2 -- 2.5x boost to the coverage of risk outcomes and tool-calling trajectories. Zhou2025Siraj
- Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning tasks. Hu2025Training

## Concrete comparisons

- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Planning / reasoning loops: `P0018`, `P0019`, `P0046`; B: Agent frameworks / architectures: `P0019`, `P0060`, `P0064`. Zeng2025Rejump Nakano2025Guided Silva2025Agents Zhou2025Reasoning
  - A highlight: (E-P0018-2bad4bca21) Using our proposed LLM agent to extract reasoning traces into ReJump format, we evaluate state-of-the-art LRMs on two tasks and find that models with similar accuracy can exhibit distinct reasoning behaviors, while different tasks favor different reasoning styles (e.g., varying Zeng2025Rejump (pointer: papers/paper_notes.jsonl:paper_id=P0018#key_results[0])
  - A highlight: (E-P0046-741891e300) To evaluate our approach, we built an automated penetration testing LLM agent using three LLMs (Llama-3-8B, Gemini-1.5, and GPT-4) and applied it to navigate 10 HackTheBox cybersecurity exercises with 103 discrete subtasks representing real-world cyberattack scenarios. Nakano2025Guided (pointer: papers/paper_notes.jsonl:paper_id=P0046#key_results[1])
  - B highlight: (E-P0148-b35b53de13) We systematically evaluate their performance using a suite of coordination-sensitive metrics, including task success rate, redundant actions, room conflicts, and urgency-weighted efficiency. Silva2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0148#key_results[0])
  - B highlight: (E-P0019-8517628bd0) While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. Zhou2025Reasoning (pointer: papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[1])
- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Planning / reasoning loops: `P0018`, `P0019`, `P0046`; B: Tool-use and function calling: `P0130`, `P0131`, `P0145`. Zeng2025Rejump Nakano2025Guided Luo2025Universe Qin2025Compass
  - A highlight: (E-P0018-2bad4bca21) Using our proposed LLM agent to extract reasoning traces into ReJump format, we evaluate state-of-the-art LRMs on two tasks and find that models with similar accuracy can exhibit distinct reasoning behaviors, while different tasks favor different reasoning styles (e.g., varying Zeng2025Rejump (pointer: papers/paper_notes.jsonl:paper_id=P0018#key_results[0])
  - A highlight: (E-P0046-741891e300) To evaluate our approach, we built an automated penetration testing LLM agent using three LLMs (Llama-3-8B, Gemini-1.5, and GPT-4) and applied it to navigate 10 HackTheBox cybersecurity exercises with 103 discrete subtasks representing real-world cyberattack scenarios. Nakano2025Guided (pointer: papers/paper_notes.jsonl:paper_id=P0046#key_results[1])
  - B highlight: (E-P0190-84445d1a19) To address this critical gap, we introduce MCP-Universe, the first comprehensive benchmark specifically designed to evaluate LLMs in realistic and hard tasks through interaction with real-world MCP servers. Luo2025Universe (pointer: papers/paper_notes.jsonl:paper_id=P0190#method)
  - B highlight: (E-P0145-c90a434db5) We introduce COMPASS (Constrained Optimization through Multi-turn Planning and Strategic Solutions), a benchmark that evaluates agents on realistic travel-planning scenarios. Qin2025Compass (pointer: papers/paper_notes.jsonl:paper_id=P0145#key_results[1])
- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Agent frameworks / architectures: `P0019`, `P0060`, `P0064`; B: Tool-use and function calling: `P0130`, `P0131`, `P0145`. Silva2025Agents Zhou2025Reasoning Luo2025Universe Qin2025Compass
  - A highlight: (E-P0148-b35b53de13) We systematically evaluate their performance using a suite of coordination-sensitive metrics, including task success rate, redundant actions, room conflicts, and urgency-weighted efficiency. Silva2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0148#key_results[0])
  - A highlight: (E-P0019-8517628bd0) While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. Zhou2025Reasoning (pointer: papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[1])
  - B highlight: (E-P0190-84445d1a19) To address this critical gap, we introduce MCP-Universe, the first comprehensive benchmark specifically designed to evaluate LLMs in realistic and hard tasks through interaction with real-world MCP servers. Luo2025Universe (pointer: papers/paper_notes.jsonl:paper_id=P0190#method)
  - B highlight: (E-P0145-c90a434db5) We introduce COMPASS (Constrained Optimization through Multi-turn Planning and Strategic Solutions), a benchmark that evaluates agents on realistic travel-planning scenarios. Qin2025Compass (pointer: papers/paper_notes.jsonl:paper_id=P0145#key_results[1])
- Axis: compute and latency constraints; A: Planning / reasoning loops: `P0018`, `P0019`, `P0046`; B: Agent frameworks / architectures: `P0019`, `P0060`, `P0064`. Zeng2025Rejump Nakano2025Guided Silva2025Agents Zhou2025Reasoning
  - A highlight: (E-P0018-2bad4bca21) Using our proposed LLM agent to extract reasoning traces into ReJump format, we evaluate state-of-the-art LRMs on two tasks and find that models with similar accuracy can exhibit distinct reasoning behaviors, while different tasks favor different reasoning styles (e.g., varying Zeng2025Rejump (pointer: papers/paper_notes.jsonl:paper_id=P0018#key_results[0])
  - A highlight: (E-P0046-741891e300) To evaluate our approach, we built an automated penetration testing LLM agent using three LLMs (Llama-3-8B, Gemini-1.5, and GPT-4) and applied it to navigate 10 HackTheBox cybersecurity exercises with 103 discrete subtasks representing real-world cyberattack scenarios. Nakano2025Guided (pointer: papers/paper_notes.jsonl:paper_id=P0046#key_results[1])
  - B highlight: (E-P0148-b35b53de13) We systematically evaluate their performance using a suite of coordination-sensitive metrics, including task success rate, redundant actions, room conflicts, and urgency-weighted efficiency. Silva2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0148#key_results[0])
  - B highlight: (E-P0019-8517628bd0) While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. Zhou2025Reasoning (pointer: papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[1])
- Axis: compute and latency constraints; A: Planning / reasoning loops: `P0018`, `P0019`, `P0046`; B: Tool-use and function calling: `P0130`, `P0131`, `P0145`. Zeng2025Rejump Nakano2025Guided Gao2024Efficient Qin2025Compass
  - A highlight: (E-P0018-2bad4bca21) Using our proposed LLM agent to extract reasoning traces into ReJump format, we evaluate state-of-the-art LRMs on two tasks and find that models with similar accuracy can exhibit distinct reasoning behaviors, while different tasks favor different reasoning styles (e.g., varying Zeng2025Rejump (pointer: papers/paper_notes.jsonl:paper_id=P0018#key_results[0])
  - A highlight: (E-P0046-741891e300) To evaluate our approach, we built an automated penetration testing LLM agent using three LLMs (Llama-3-8B, Gemini-1.5, and GPT-4) and applied it to navigate 10 HackTheBox cybersecurity exercises with 103 discrete subtasks representing real-world cyberattack scenarios. Nakano2025Guided (pointer: papers/paper_notes.jsonl:paper_id=P0046#key_results[1])
  - B highlight: (E-P0086-a9c15ec0c8) LLM agents trained with our method also show more efficient tool use, with inference speed being on average ~1.4x faster than baseline tool-augmented LLMs. Gao2024Efficient (pointer: papers/paper_notes.jsonl:paper_id=P0086#key_results[1])
  - B highlight: (E-P0145-c90a434db5) We introduce COMPASS (Constrained Optimization through Multi-turn Planning and Strategic Solutions), a benchmark that evaluates agents on realistic travel-planning scenarios. Qin2025Compass (pointer: papers/paper_notes.jsonl:paper_id=P0145#key_results[1])
- Axis: compute and latency constraints; A: Agent frameworks / architectures: `P0019`, `P0060`, `P0064`; B: Tool-use and function calling: `P0130`, `P0131`, `P0145`. Silva2025Agents Zhou2025Reasoning Gao2024Efficient Qin2025Compass
  - A highlight: (E-P0148-b35b53de13) We systematically evaluate their performance using a suite of coordination-sensitive metrics, including task success rate, redundant actions, room conflicts, and urgency-weighted efficiency. Silva2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0148#key_results[0])
  - A highlight: (E-P0019-8517628bd0) While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. Zhou2025Reasoning (pointer: papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[1])
  - B highlight: (E-P0086-a9c15ec0c8) LLM agents trained with our method also show more efficient tool use, with inference speed being on average ~1.4x faster than baseline tool-augmented LLMs. Gao2024Efficient (pointer: papers/paper_notes.jsonl:paper_id=P0086#key_results[1])
  - B highlight: (E-P0145-c90a434db5) We introduce COMPASS (Constrained Optimization through Multi-turn Planning and Strategic Solutions), a benchmark that evaluates agents on realistic travel-planning scenarios. Qin2025Compass (pointer: papers/paper_notes.jsonl:paper_id=P0145#key_results[1])
- Axis: tool interface contract (schemas / protocols); A: Planning / reasoning loops: `P0018`, `P0019`, `P0046`; B: Agent frameworks / architectures: `P0019`, `P0060`, `P0064`. Zeng2025Rejump Nakano2025Guided Silva2025Agents Zhou2025Reasoning
  - A highlight: (E-P0018-2bad4bca21) Using our proposed LLM agent to extract reasoning traces into ReJump format, we evaluate state-of-the-art LRMs on two tasks and find that models with similar accuracy can exhibit distinct reasoning behaviors, while different tasks favor different reasoning styles (e.g., varying Zeng2025Rejump (pointer: papers/paper_notes.jsonl:paper_id=P0018#key_results[0])
  - A highlight: (E-P0046-741891e300) To evaluate our approach, we built an automated penetration testing LLM agent using three LLMs (Llama-3-8B, Gemini-1.5, and GPT-4) and applied it to navigate 10 HackTheBox cybersecurity exercises with 103 discrete subtasks representing real-world cyberattack scenarios. Nakano2025Guided (pointer: papers/paper_notes.jsonl:paper_id=P0046#key_results[1])
  - B highlight: (E-P0148-b35b53de13) We systematically evaluate their performance using a suite of coordination-sensitive metrics, including task success rate, redundant actions, room conflicts, and urgency-weighted efficiency. Silva2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0148#key_results[0])
  - B highlight: (E-P0019-8517628bd0) While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. Zhou2025Reasoning (pointer: papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[1])
- Axis: tool interface contract (schemas / protocols); A: Planning / reasoning loops: `P0018`, `P0019`, `P0046`; B: Tool-use and function calling: `P0130`, `P0131`, `P0145`. Zeng2025Rejump Nakano2025Guided Luo2025Universe Gao2024Efficient
  - A highlight: (E-P0018-2bad4bca21) Using our proposed LLM agent to extract reasoning traces into ReJump format, we evaluate state-of-the-art LRMs on two tasks and find that models with similar accuracy can exhibit distinct reasoning behaviors, while different tasks favor different reasoning styles (e.g., varying Zeng2025Rejump (pointer: papers/paper_notes.jsonl:paper_id=P0018#key_results[0])
  - A highlight: (E-P0046-741891e300) To evaluate our approach, we built an automated penetration testing LLM agent using three LLMs (Llama-3-8B, Gemini-1.5, and GPT-4) and applied it to navigate 10 HackTheBox cybersecurity exercises with 103 discrete subtasks representing real-world cyberattack scenarios. Nakano2025Guided (pointer: papers/paper_notes.jsonl:paper_id=P0046#key_results[1])
  - B highlight: (E-P0190-84445d1a19) To address this critical gap, we introduce MCP-Universe, the first comprehensive benchmark specifically designed to evaluate LLMs in realistic and hard tasks through interaction with real-world MCP servers. Luo2025Universe (pointer: papers/paper_notes.jsonl:paper_id=P0190#method)
  - B highlight: (E-P0086-a9c15ec0c8) LLM agents trained with our method also show more efficient tool use, with inference speed being on average ~1.4x faster than baseline tool-augmented LLMs. Gao2024Efficient (pointer: papers/paper_notes.jsonl:paper_id=P0086#key_results[1])
- Axis: tool interface contract (schemas / protocols); A: Agent frameworks / architectures: `P0019`, `P0060`, `P0064`; B: Tool-use and function calling: `P0130`, `P0131`, `P0145`. Silva2025Agents Zhou2025Reasoning Luo2025Universe Gao2024Efficient
  - A highlight: (E-P0148-b35b53de13) We systematically evaluate their performance using a suite of coordination-sensitive metrics, including task success rate, redundant actions, room conflicts, and urgency-weighted efficiency. Silva2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0148#key_results[0])
  - A highlight: (E-P0019-8517628bd0) While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. Zhou2025Reasoning (pointer: papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[1])
  - B highlight: (E-P0190-84445d1a19) To address this critical gap, we introduce MCP-Universe, the first comprehensive benchmark specifically designed to evaluate LLMs in realistic and hard tasks through interaction with real-world MCP servers. Luo2025Universe (pointer: papers/paper_notes.jsonl:paper_id=P0190#method)
  - B highlight: (E-P0086-a9c15ec0c8) LLM agents trained with our method also show more efficient tool use, with inference speed being on average ~1.4x faster than baseline tool-augmented LLMs. Gao2024Efficient (pointer: papers/paper_notes.jsonl:paper_id=P0086#key_results[1])
- Axis: tool selection / routing policy; A: Planning / reasoning loops: `P0018`, `P0019`, `P0046`; B: Agent frameworks / architectures: `P0019`, `P0060`, `P0064`. Zeng2025Rejump Nakano2025Guided Silva2025Agents Zhou2025Reasoning
  - A highlight: (E-P0018-2bad4bca21) Using our proposed LLM agent to extract reasoning traces into ReJump format, we evaluate state-of-the-art LRMs on two tasks and find that models with similar accuracy can exhibit distinct reasoning behaviors, while different tasks favor different reasoning styles (e.g., varying Zeng2025Rejump (pointer: papers/paper_notes.jsonl:paper_id=P0018#key_results[0])
  - A highlight: (E-P0046-741891e300) To evaluate our approach, we built an automated penetration testing LLM agent using three LLMs (Llama-3-8B, Gemini-1.5, and GPT-4) and applied it to navigate 10 HackTheBox cybersecurity exercises with 103 discrete subtasks representing real-world cyberattack scenarios. Nakano2025Guided (pointer: papers/paper_notes.jsonl:paper_id=P0046#key_results[1])
  - B highlight: (E-P0148-b35b53de13) We systematically evaluate their performance using a suite of coordination-sensitive metrics, including task success rate, redundant actions, room conflicts, and urgency-weighted efficiency. Silva2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0148#key_results[0])
  - B highlight: (E-P0019-8517628bd0) While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. Zhou2025Reasoning (pointer: papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[1])

## Evaluation protocol

- Evaluation mentions include: LRMs, LLMs, UW-Madison-Lee-Lab, CoTs, ReJump, CoT-prompted, ReJump-guided, RSP, GSI, RSV. Zeng2025Rejump Zhou2025Reasoning Nakano2025Guided Rawat2025Multi
- When comparing results, anchor the paragraph with: task type + metric + constraint (budget, tool access, horizon, or threat model) when stated. Zeng2025Rejump Zhou2025Reasoning
- Prefer head-to-head comparisons only when benchmark/metric are shared; otherwise frame differences as protocol-driven rather than method superiority. Zeng2025Rejump Zhou2025Reasoning
- Avoid underspecified model/baseline naming; if abstracts omit details, state that the baseline is reported but underspecified instead of guessing. Zeng2025Rejump Zhou2025Reasoning
- If a claim relies on a single reported number, pair it with a limitation/caveat from the same evidence so the draft remains conservative. Zeng2025Rejump Zhou2025Reasoning
- If budgets or environments differ across papers, treat cross-paper numeric comparison as fragile and prefer qualitative contrasts aligned to the subsection axes. Zeng2025Rejump Zhou2025Reasoning

## Failures / limitations

- While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. Zhou2025Reasoning
- We introduce Generative Style Injection (GSI), an attack method that rewrites retrieved documents into pathological tones--specifically "analysis paralysis" or "cognitive haste"--without altering underlying facts or using explicit triggers. Zhou2025Reasoning
- This anchors reasoning in proven penetration testing methodologies and filters out ineffective actions by guiding the agent towards more productive attack procedures. Nakano2025Guided
- To address this limitation, we fine-tune relatively small models such as Llama 3.1 (8B & 70B) using the proposed Pre-Act approach. Rawat2025Multi
- Still, they face limitations in tasks requiring specific, structured knowledge, flexibility, or accountable decision-making. Hatalis2025Review
- Their dependence on rule-based control and narrow AI limits adaptability in dynamic and uncertain missions. Koubaa2025Agentic
- This study offers new insights into the strengths and failure modes of LLMs in physically grounded multi-agent collaboration tasks, contributing to future benchmarks and architectural improvements. Silva2025Agents
- Through extensive evaluation of leading LLMs, we find that even SOTA models such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit significant performance limitations. Luo2025Universe

## Verify fields (non-blocking)

- named benchmarks/datasets used
- metrics/human-eval protocol
- compute/training/inference cost
- training data and supervision signal
- baseline choices and ablation evidence
