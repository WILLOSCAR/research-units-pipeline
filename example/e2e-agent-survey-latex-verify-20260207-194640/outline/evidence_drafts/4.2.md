# Evidence draft: 4.2 Memory and retrieval (RAG)

## Evidence snippets (with provenance)
- (E-P0061-68db58914f) Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed. Shi2025Progent (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0061#key_results[0])
- (E-P0162-192e78b614) We introduce ETOM, a five-level benchmark for evaluating multi-hop, end-to-end tool orchestration by LLM agents within a hierarchical Model-Context Protocol (MCP) ecosystem. Dong2025Etom (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0162#method)
- (E-P0243-38a26e4777) Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Shang2024Agentsquare (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0243#key_results[0])
- (E-P0128-904ba35500) Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\% over both existing automated agent search methods and manually designed agents. Li2025Agentswift (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0128#key_results[0])
- (E-P0072-0301cf089d) The result is both a blueprint and an agenda: a blueprint that shows how memory-augmented, tool-using LLM agents can be composed into robust recommendation pipelines, and an agenda inviting the RecSys community to develop benchmarks, theoretical guarantees, and governance tools that keep pace with this new degree of autonomy. Maragheh2025Future (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0072#key_results[1])
- (E-P0197-e294aeefb5) To evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval and citation performance, and Reasoning-100 (Reas-100), focused on multistep reasoning in circuit design. Abbineni2025Muallm (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0197#key_results[1])
- (E-P0057-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0057#key_results[1])
- (E-P0102-98d4089bc9) While virtualization and resource pooling empower cloud networks with structural flexibility and elastic scalability, they inevitably expand the attack surface and challenge cyber resilience. Peng2026Enhancing (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0102#summary_bullets[0])
- (E-P0238-46914a4804) Yet their sophisticated architectures amplify vulnerability to cascading failures, where a single root-cause error propagates through subsequent decisions, leading to task failure. Zhu2025Where (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0238#summary_bullets[1])
- (E-P0054-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. In civil engineering, structural drawings serve as the main communication tool between architects, engineers, and builders to avoid conflicts, act as legal documentation, and provide a reference for future maintenance or evaluation needs. Zhang2025Large (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
- (E-P0234-4af0cf3c02) This study presents SAFE (system for accurate fact extraction and evaluation), an agent system that combines large language models with retrieval-augmented generation (RAG) to improve automated fact-checking of long-form COVID-19 misinformation. Huang2025Retrieval (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0234#key_results[1])
- (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- (E-P0007-dc2266b72d) Specifically, 1) the taxonomy defines environments/tasks, common LLM-profiled roles or LMPRs (policy models, evaluators, and dynamic models), and universally applicable workflows found in prior work, and 2) it enables a comparison of key perspectives on the implementations of LMPRs and workflow designs across different agent paradigms and frameworks. Li2024Review (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0007#key_results[0])
- (E-P0158-69c0aa3079) Experiments show that DSMentor using Claude-3.5-Sonnet improves the pass rate by up to 5.2% on DSEval and QRData compared to baseline agents. Wang2025Dsmentor (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0158#key_results[0])
- (E-P0287-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0287#key_results[1])
- (E-P0011-f0ea009256) Finally, we summarize the datasets and benchmarks used for evaluation and tuning, review key applications of LLM-based agents, and discuss major challenges and promising future directions. Du2025Survey (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0011#key_results[0])
- (E-P0091-52fea1d199) We address research questions such as existing GUI agent frameworks, the collection and utilization of data for training specialized GUI agents, the development of large action models tailored for GUI tasks, and the evaluation metrics and benchmarks necessary to assess their effectiveness. Zhang2024Large (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0091#key_results[1])
- (E-P0033-1b6fe3407a) To further accelerate research in this area for the community, we compile open-source training frameworks, training and evaluation datasets for developing agentic MLLMs. Yao2025Survey (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0033#key_results[0])

## Definitions / setup

- Setup: Which design choices in Memory and retrieval (RAG) drive the major trade-offs, and how are those trade-offs measured? Scope: in-scope: Core topics directly relevant to 'Memory and retrieval (RAG)'.. Axes: evaluation protocol (datasets, metrics, human evaluation); compute and latency constraints; tool interface contract (schemas / protocols); tool selection / routing policy; sandboxing / permissions / observability. Peng2026Enhancing Verma2026Active Yu2026Agentic

## Claim candidates

- Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed. Shi2025Progent
- We introduce ETOM, a five-level benchmark for evaluating multi-hop, end-to-end tool orchestration by LLM agents within a hierarchical Model-Context Protocol (MCP) ecosystem. Dong2025Etom
- Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Shang2024Agentsquare
- Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\% over both existing automated agent search methods and manually designed agents. Li2025Agentswift
- The result is both a blueprint and an agenda: a blueprint that shows how memory-augmented, tool-using LLM agents can be composed into robust recommendation pipelines, and an agenda inviting the RecSys community to develop benchmarks, theoretical guarantees, and governance tools that keep pace with this new degree of autonomy. Maragheh2025Future

## Concrete comparisons

- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Agent frameworks / architectures: `P0102`, `P0287`, `P0290`; B: Memory / retrieval augmentation: `P0287`, `P0290`, `P0054`. Du2025Survey Zhang2025Large Abbineni2025Muallm
  - A highlight: (E-P0011-f0ea009256) Finally, we summarize the datasets and benchmarks used for evaluation and tuning, review key applications of LLM-based agents, and discuss major challenges and promising future directions. Du2025Survey (pointer: papers/paper_notes.jsonl:paper_id=P0011#key_results[0])
  - A highlight: (E-P0054-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - B highlight: (E-P0054-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - B highlight: (E-P0197-e294aeefb5) To evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval and citation performance, and Reasoning-100 (Reas-100), focused on multistep reasoning in circuit design. Abbineni2025Muallm (pointer: papers/paper_notes.jsonl:paper_id=P0197#key_results[1])
- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Agent frameworks / architectures: `P0102`, `P0287`, `P0290`; B: Planning / reasoning loops: `P0041`, `P0128`, `P0205`. Du2025Survey Zhang2025Large Shang2024Agentsquare Li2025Agentswift
  - A highlight: (E-P0011-f0ea009256) Finally, we summarize the datasets and benchmarks used for evaluation and tuning, review key applications of LLM-based agents, and discuss major challenges and promising future directions. Du2025Survey (pointer: papers/paper_notes.jsonl:paper_id=P0011#key_results[0])
  - A highlight: (E-P0054-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - B highlight: (E-P0243-38a26e4777) Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Shang2024Agentsquare (pointer: papers/paper_notes.jsonl:paper_id=P0243#key_results[0])
  - B highlight: (E-P0128-904ba35500) Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\% over both existing automated agent search methods and manually designed agents. Li2025Agentswift (pointer: papers/paper_notes.jsonl:paper_id=P0128#key_results[0])
- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Memory / retrieval augmentation: `P0287`, `P0290`, `P0054`; B: Planning / reasoning loops: `P0041`, `P0128`, `P0205`. Zhang2025Large Abbineni2025Muallm Shang2024Agentsquare Li2025Agentswift
  - A highlight: (E-P0054-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - A highlight: (E-P0197-e294aeefb5) To evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval and citation performance, and Reasoning-100 (Reas-100), focused on multistep reasoning in circuit design. Abbineni2025Muallm (pointer: papers/paper_notes.jsonl:paper_id=P0197#key_results[1])
  - B highlight: (E-P0243-38a26e4777) Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Shang2024Agentsquare (pointer: papers/paper_notes.jsonl:paper_id=P0243#key_results[0])
  - B highlight: (E-P0128-904ba35500) Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\% over both existing automated agent search methods and manually designed agents. Li2025Agentswift (pointer: papers/paper_notes.jsonl:paper_id=P0128#key_results[0])
- Axis: compute and latency constraints; A: Agent frameworks / architectures: `P0102`, `P0287`, `P0290`; B: Memory / retrieval augmentation: `P0287`, `P0290`, `P0054`. Yao2025Survey Zhang2025Large Tawosi2025Meta
  - A highlight: (E-P0033-1b6fe3407a) To further accelerate research in this area for the community, we compile open-source training frameworks, training and evaluation datasets for developing agentic MLLMs. Yao2025Survey (pointer: papers/paper_notes.jsonl:paper_id=P0033#key_results[0])
  - A highlight: (E-P0054-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - B highlight: (E-P0054-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - B highlight: (E-P0057-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta (pointer: papers/paper_notes.jsonl:paper_id=P0057#key_results[1])
- Axis: compute and latency constraints; A: Agent frameworks / architectures: `P0102`, `P0287`, `P0290`; B: Planning / reasoning loops: `P0041`, `P0128`, `P0205`. Yao2025Survey Zhang2025Large Li2024Review Shang2024Agentsquare
  - A highlight: (E-P0033-1b6fe3407a) To further accelerate research in this area for the community, we compile open-source training frameworks, training and evaluation datasets for developing agentic MLLMs. Yao2025Survey (pointer: papers/paper_notes.jsonl:paper_id=P0033#key_results[0])
  - A highlight: (E-P0054-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - B highlight: (E-P0007-dc2266b72d) Specifically, 1) the taxonomy defines environments/tasks, common LLM-profiled roles or LMPRs (policy models, evaluators, and dynamic models), and universally applicable workflows found in prior work, and 2) it enables a comparison of key perspectives on the implementations of Li2024Review (pointer: papers/paper_notes.jsonl:paper_id=P0007#key_results[0])
  - B highlight: (E-P0243-38a26e4777) Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Shang2024Agentsquare (pointer: papers/paper_notes.jsonl:paper_id=P0243#key_results[0])
- Axis: compute and latency constraints; A: Memory / retrieval augmentation: `P0287`, `P0290`, `P0054`; B: Planning / reasoning loops: `P0041`, `P0128`, `P0205`. Zhang2025Large Tawosi2025Meta Li2024Review Shang2024Agentsquare
  - A highlight: (E-P0054-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - A highlight: (E-P0057-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta (pointer: papers/paper_notes.jsonl:paper_id=P0057#key_results[1])
  - B highlight: (E-P0007-dc2266b72d) Specifically, 1) the taxonomy defines environments/tasks, common LLM-profiled roles or LMPRs (policy models, evaluators, and dynamic models), and universally applicable workflows found in prior work, and 2) it enables a comparison of key perspectives on the implementations of Li2024Review (pointer: papers/paper_notes.jsonl:paper_id=P0007#key_results[0])
  - B highlight: (E-P0243-38a26e4777) Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Shang2024Agentsquare (pointer: papers/paper_notes.jsonl:paper_id=P0243#key_results[0])
- Axis: tool interface contract (schemas / protocols); A: Agent frameworks / architectures: `P0102`, `P0287`, `P0290`; B: Memory / retrieval augmentation: `P0287`, `P0290`, `P0054`. Zhang2025Large Verma2026Active Tawosi2025Meta
  - A highlight: (E-P0054-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - A highlight: (E-P0287-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (pointer: papers/paper_notes.jsonl:paper_id=P0287#key_results[1])
  - B highlight: (E-P0054-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - B highlight: (E-P0057-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta (pointer: papers/paper_notes.jsonl:paper_id=P0057#key_results[1])
- Axis: tool interface contract (schemas / protocols); A: Agent frameworks / architectures: `P0102`, `P0287`, `P0290`; B: Planning / reasoning loops: `P0041`, `P0128`, `P0205`. Zhang2025Large Verma2026Active Shang2024Agentsquare Li2025Agentswift
  - A highlight: (E-P0054-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - A highlight: (E-P0287-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (pointer: papers/paper_notes.jsonl:paper_id=P0287#key_results[1])
  - B highlight: (E-P0243-38a26e4777) Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Shang2024Agentsquare (pointer: papers/paper_notes.jsonl:paper_id=P0243#key_results[0])
  - B highlight: (E-P0128-904ba35500) Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\% over both existing automated agent search methods and manually designed agents. Li2025Agentswift (pointer: papers/paper_notes.jsonl:paper_id=P0128#key_results[0])
- Axis: tool interface contract (schemas / protocols); A: Memory / retrieval augmentation: `P0287`, `P0290`, `P0054`; B: Planning / reasoning loops: `P0041`, `P0128`, `P0205`. Zhang2025Large Tawosi2025Meta Shang2024Agentsquare Li2025Agentswift
  - A highlight: (E-P0054-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - A highlight: (E-P0057-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta (pointer: papers/paper_notes.jsonl:paper_id=P0057#key_results[1])
  - B highlight: (E-P0243-38a26e4777) Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Shang2024Agentsquare (pointer: papers/paper_notes.jsonl:paper_id=P0243#key_results[0])
  - B highlight: (E-P0128-904ba35500) Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\% over both existing automated agent search methods and manually designed agents. Li2025Agentswift (pointer: papers/paper_notes.jsonl:paper_id=P0128#key_results[0])
- Axis: tool selection / routing policy; A: Agent frameworks / architectures: `P0102`, `P0287`, `P0290`; B: Memory / retrieval augmentation: `P0287`, `P0290`, `P0054`. Zhang2025Large Verma2026Active Tawosi2025Meta
  - A highlight: (E-P0054-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - A highlight: (E-P0287-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (pointer: papers/paper_notes.jsonl:paper_id=P0287#key_results[1])
  - B highlight: (E-P0054-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - B highlight: (E-P0057-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta (pointer: papers/paper_notes.jsonl:paper_id=P0057#key_results[1])

## Evaluation protocol

- Evaluation mentions include: HITL, LLMs, MITRE, ATT, IPDRR-based, LLM-RL, CyberOps-Bots, ReAct, SWE-bench, LTM. Peng2026Enhancing Verma2026Active Yu2026Agentic Du2025Survey
- When comparing results, anchor the paragraph with: task type + metric + constraint (budget, tool access, horizon, or threat model) when stated. Peng2026Enhancing Verma2026Active
- Prefer head-to-head comparisons only when benchmark/metric are shared; otherwise frame differences as protocol-driven rather than method superiority. Peng2026Enhancing Verma2026Active
- Avoid underspecified model/baseline naming; if abstracts omit details, state that the baseline is reported but underspecified instead of guessing. Peng2026Enhancing Verma2026Active
- If a claim relies on a single reported number, pair it with a limitation/caveat from the same evidence so the draft remains conservative. Peng2026Enhancing Verma2026Active
- If budgets or environments differ across papers, treat cross-paper numeric comparison as fragile and prefer qualitative contrasts aligned to the subsection axes. Peng2026Enhancing Verma2026Active

## Failures / limitations

- To address these limitations, we propose CyberOps-Bots, a hierarchical multi-agent reinforcement learning framework empowered by Large Language Models (LLMs). Peng2026Enhancing
- While virtualization and resource pooling empower cloud networks with structural flexibility and elastic scalability, they inevitably expand the attack surface and challenge cyber resilience. Peng2026Enhancing
- However, existing approaches lack robustness as they require retraining to adapt to dynamic changes in network structure, node scale, attack strategies, and attack intensity. Peng2026Enhancing
- Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical. Yu2026Agentic
- This results in the failure to retrieve the relevant code of these fine-grained subtasks. Li2025Graphcodeagent
- To address this challenge, we propose GraphCodeAgent, a dual graph-guided LLM agent for retrieval-augmented repo-level code generation, bridging the gap between NL requirements and programming implementations. Li2025Graphcodeagent
- MPR (i) externalizes reusable corrective knowledge without model weight updates, (ii) enforces domain constraints to reduce unsafe or invalid actions, and (iii) retains the adaptability of language-based reflection. Wu2025Meta
- We analyze mechanisms that explain these gains, discuss scalability and failure modes, and outline future directions for multimodal and multi-agent extensions. Wu2025Meta

## Verify fields (non-blocking)

- named benchmarks/datasets used
- metrics/human-eval protocol
- compute/training/inference cost
- training data and supervision signal
- baseline choices and ablation evidence
