# Evidence draft: 4.2 Memory and retrieval (RAG)

## Evidence snippets (with provenance)
- (E-P0047-cb9370ac71) Comprehensive evaluations on multiple benchmarks show that A-MemGuard effectively cuts attack success rates by over 95% while incurring a minimal utility cost. Wei2025Memguard (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0047#key_results[0])
- (E-P0166-17fb12f5b7) In this work, we propose Agent Distillation, a framework for transferring not only reasoning capability but full task-solving behavior from LLM-based agents into sLMs with retrieval and code tools. Kang2025Distilling (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0166#method)
- (E-P0220-eedb53e99a) Despite the growing prominence of LLMs in this field, there is a scarcity of scholarly works that systematically synthesize how advanced enhancement techniques, specifically Retrieval-Augmented Generation (RAG) and Agentic systems, can be utilized to address these reliability and reasoning limitations. Ge2025Surveya (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0220#limitations[1])
- (E-P0189-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. In civil engineering, structural drawings serve as the main communication tool between architects, engineers, and builders to avoid conflicts, act as legal documentation, and provide a reference for future maintenance or evaluation needs. Zhang2025Largea (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0189#key_results[0])
- (E-P0200-1b99de5317) From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap tracker that explicitly renders the answering process transparent and tracks the evidence collection process. Du2025Memr (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0200#key_results[1])
- (E-P0173-06e45507a7) We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets. Wei2025Memory (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0173#key_results[0])
- (E-P0235-4af0cf3c02) This study presents SAFE (system for accurate fact extraction and evaluation), an agent system that combines large language models with retrieval-augmented generation (RAG) to improve automated fact-checking of long-form COVID-19 misinformation. Huang2025Retrieval (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0235#key_results[1])
- (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- (E-P0033-46914a4804) Yet their sophisticated architectures amplify vulnerability to cascading failures, where a single root-cause error propagates through subsequent decisions, leading to task failure. Zhu2025Where (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0033#summary_bullets[1])
- (E-P0016-62b8101d4e) Tool use, planning, and feedback learning are currently three prominent paradigms for developing Large Language Model (LLM)-based agents across various tasks. Li2024Review (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0016#method)
- (E-P0120-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0120#key_results[1])
- (E-P0026-f0ea009256) Finally, we summarize the datasets and benchmarks used for evaluation and tuning, review key applications of LLM-based agents, and discuss major challenges and promising future directions. Du2025Survey (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0026#key_results[0])
- (E-P0062-86184d0d44) Existing benchmarks either rely on limited context lengths or are tailored for static, long-context settings like book-based QA, which do not reflect the interactive, multi-turn nature of memory agents that incrementally accumulate information. Hu2025Evaluating (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0062#key_results[1])
- (E-P0011-1b6fe3407a) To further accelerate research in this area for the community, we compile open-source training frameworks, training and evaluation datasets for developing agentic MLLMs. Yao2025Survey (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0011#key_results[0])
- (E-P0121-f0f0faaada) Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage. Yu2026Agentic (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0121#key_results[0])
- (E-P0169-0a0006ef38) The EM-Test assesses performance across various time spans and difficulty levels, providing a comprehensive evaluation of multi-turn episodic memory dialogues. Liu2025Echo (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0169#key_results[1])
- (E-P0032-53536132a8) We release TME's codebase, benchmarks, and components as open-source resources, enabling researchers to develop reliable LLM agents. Ye2025Task (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0032#key_results[1])
- (E-P0064-d568c53e1d) We evaluated GraphCodeAgent on three advanced LLMs with the two widely-used repo-level code generation benchmarks DevEval and CoderEval. Li2025Graphcodeagent (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0064#key_results[0])

## Definitions / setup

- Setup: Which design choices in Memory and retrieval (RAG) drive the major trade-offs, and how are those trade-offs measured? Scope: in-scope: Core topics directly relevant to 'Memory and retrieval (RAG)'.. Axes: evaluation protocol (datasets, metrics, human evaluation); compute and latency constraints; tool interface contract (schemas / protocols); tool selection / routing policy; sandboxing / permissions / observability. Verma2026Active Yu2026Agentic Tao2026Membox

## Claim candidates

- Comprehensive evaluations on multiple benchmarks show that A-MemGuard effectively cuts attack success rates by over 95% while incurring a minimal utility cost. Wei2025Memguard
- In this work, we propose Agent Distillation, a framework for transferring not only reasoning capability but full task-solving behavior from LLM-based agents into sLMs with retrieval and code tools. Kang2025Distilling
- Despite the growing prominence of LLMs in this field, there is a scarcity of scholarly works that systematically synthesize how advanced enhancement techniques, specifically Retrieval-Augmented Generation (RAG) and Agentic systems, can be utilized to address these reliability and reasoning limitations. Ge2025Surveya
- Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Largea
- From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap tracker that explicitly renders the answering process transparent and tracks the evidence collection process. Du2025Memr

## Concrete comparisons

- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Agent frameworks / architectures: `P0120`, `P0121`, `P0128`; B: Memory / retrieval augmentation: `P0120`, `P0121`, `P0128`. Du2025Survey Yu2026Agentic Hu2025Evaluating
  - A highlight: (E-P0026-f0ea009256) Finally, we summarize the datasets and benchmarks used for evaluation and tuning, review key applications of LLM-based agents, and discuss major challenges and promising future directions. Du2025Survey (pointer: papers/paper_notes.jsonl:paper_id=P0026#key_results[0])
  - A highlight: (E-P0121-f0f0faaada) Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage. Yu2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0121#key_results[0])
  - B highlight: (E-P0121-f0f0faaada) Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage. Yu2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0121#key_results[0])
  - B highlight: (E-P0062-86184d0d44) Existing benchmarks either rely on limited context lengths or are tailored for static, long-context settings like book-based QA, which do not reflect the interactive, multi-turn nature of memory agents that incrementally accumulate information. Hu2025Evaluating (pointer: papers/paper_notes.jsonl:paper_id=P0062#key_results[1])
- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Agent frameworks / architectures: `P0120`, `P0121`, `P0128`; B: Planning / reasoning loops: `P0200`, `P0016`, `P0118`. Du2025Survey Yu2026Agentic Du2025Memr Yao2022React
  - A highlight: (E-P0026-f0ea009256) Finally, we summarize the datasets and benchmarks used for evaluation and tuning, review key applications of LLM-based agents, and discuss major challenges and promising future directions. Du2025Survey (pointer: papers/paper_notes.jsonl:paper_id=P0026#key_results[0])
  - A highlight: (E-P0121-f0f0faaada) Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage. Yu2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0121#key_results[0])
  - B highlight: (E-P0200-1b99de5317) From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap Du2025Memr (pointer: papers/paper_notes.jsonl:paper_id=P0200#key_results[1])
  - B highlight: (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (pointer: papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Memory / retrieval augmentation: `P0120`, `P0121`, `P0128`; B: Planning / reasoning loops: `P0200`, `P0016`, `P0118`. Yu2026Agentic Hu2025Evaluating Du2025Memr Yao2022React
  - A highlight: (E-P0121-f0f0faaada) Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage. Yu2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0121#key_results[0])
  - A highlight: (E-P0062-86184d0d44) Existing benchmarks either rely on limited context lengths or are tailored for static, long-context settings like book-based QA, which do not reflect the interactive, multi-turn nature of memory agents that incrementally accumulate information. Hu2025Evaluating (pointer: papers/paper_notes.jsonl:paper_id=P0062#key_results[1])
  - B highlight: (E-P0200-1b99de5317) From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap Du2025Memr (pointer: papers/paper_notes.jsonl:paper_id=P0200#key_results[1])
  - B highlight: (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (pointer: papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- Axis: compute and latency constraints; A: Agent frameworks / architectures: `P0120`, `P0121`, `P0128`; B: Memory / retrieval augmentation: `P0120`, `P0121`, `P0128`. Yao2025Survey Yu2026Agentic Wei2025Memguard
  - A highlight: (E-P0011-1b6fe3407a) To further accelerate research in this area for the community, we compile open-source training frameworks, training and evaluation datasets for developing agentic MLLMs. Yao2025Survey (pointer: papers/paper_notes.jsonl:paper_id=P0011#key_results[0])
  - A highlight: (E-P0121-f0f0faaada) Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage. Yu2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0121#key_results[0])
  - B highlight: (E-P0121-f0f0faaada) Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage. Yu2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0121#key_results[0])
  - B highlight: (E-P0047-cb9370ac71) Comprehensive evaluations on multiple benchmarks show that A-MemGuard effectively cuts attack success rates by over 95% while incurring a minimal utility cost. Wei2025Memguard (pointer: papers/paper_notes.jsonl:paper_id=P0047#key_results[0])
- Axis: compute and latency constraints; A: Agent frameworks / architectures: `P0120`, `P0121`, `P0128`; B: Planning / reasoning loops: `P0200`, `P0016`, `P0118`. Yao2025Survey Yu2026Agentic Du2025Memr Yao2022React
  - A highlight: (E-P0011-1b6fe3407a) To further accelerate research in this area for the community, we compile open-source training frameworks, training and evaluation datasets for developing agentic MLLMs. Yao2025Survey (pointer: papers/paper_notes.jsonl:paper_id=P0011#key_results[0])
  - A highlight: (E-P0121-f0f0faaada) Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage. Yu2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0121#key_results[0])
  - B highlight: (E-P0200-1b99de5317) From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap Du2025Memr (pointer: papers/paper_notes.jsonl:paper_id=P0200#key_results[1])
  - B highlight: (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (pointer: papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- Axis: compute and latency constraints; A: Memory / retrieval augmentation: `P0120`, `P0121`, `P0128`; B: Planning / reasoning loops: `P0200`, `P0016`, `P0118`. Yu2026Agentic Wei2025Memguard Du2025Memr Yao2022React
  - A highlight: (E-P0121-f0f0faaada) Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage. Yu2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0121#key_results[0])
  - A highlight: (E-P0047-cb9370ac71) Comprehensive evaluations on multiple benchmarks show that A-MemGuard effectively cuts attack success rates by over 95% while incurring a minimal utility cost. Wei2025Memguard (pointer: papers/paper_notes.jsonl:paper_id=P0047#key_results[0])
  - B highlight: (E-P0200-1b99de5317) From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap Du2025Memr (pointer: papers/paper_notes.jsonl:paper_id=P0200#key_results[1])
  - B highlight: (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (pointer: papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- Axis: tool interface contract (schemas / protocols); A: Agent frameworks / architectures: `P0120`, `P0121`, `P0128`; B: Memory / retrieval augmentation: `P0120`, `P0121`, `P0128`. Yu2026Agentic Verma2026Active Kang2025Distilling
  - A highlight: (E-P0121-f0f0faaada) Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage. Yu2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0121#key_results[0])
  - A highlight: (E-P0120-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (pointer: papers/paper_notes.jsonl:paper_id=P0120#key_results[1])
  - B highlight: (E-P0166-17fb12f5b7) In this work, we propose Agent Distillation, a framework for transferring not only reasoning capability but full task-solving behavior from LLM-based agents into sLMs with retrieval and code tools. Kang2025Distilling (pointer: papers/paper_notes.jsonl:paper_id=P0166#method)
  - B highlight: (E-P0121-f0f0faaada) Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage. Yu2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0121#key_results[0])
- Axis: tool interface contract (schemas / protocols); A: Agent frameworks / architectures: `P0120`, `P0121`, `P0128`; B: Planning / reasoning loops: `P0200`, `P0016`, `P0118`. Yu2026Agentic Verma2026Active Du2025Memr Li2024Review
  - A highlight: (E-P0121-f0f0faaada) Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage. Yu2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0121#key_results[0])
  - A highlight: (E-P0120-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (pointer: papers/paper_notes.jsonl:paper_id=P0120#key_results[1])
  - B highlight: (E-P0200-1b99de5317) From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap Du2025Memr (pointer: papers/paper_notes.jsonl:paper_id=P0200#key_results[1])
  - B highlight: (E-P0016-62b8101d4e) Tool use, planning, and feedback learning are currently three prominent paradigms for developing Large Language Model (LLM)-based agents across various tasks. Li2024Review (pointer: papers/paper_notes.jsonl:paper_id=P0016#method)
- Axis: tool interface contract (schemas / protocols); A: Memory / retrieval augmentation: `P0120`, `P0121`, `P0128`; B: Planning / reasoning loops: `P0200`, `P0016`, `P0118`. Kang2025Distilling Yu2026Agentic Du2025Memr Li2024Review
  - A highlight: (E-P0166-17fb12f5b7) In this work, we propose Agent Distillation, a framework for transferring not only reasoning capability but full task-solving behavior from LLM-based agents into sLMs with retrieval and code tools. Kang2025Distilling (pointer: papers/paper_notes.jsonl:paper_id=P0166#method)
  - A highlight: (E-P0121-f0f0faaada) Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage. Yu2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0121#key_results[0])
  - B highlight: (E-P0200-1b99de5317) From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap Du2025Memr (pointer: papers/paper_notes.jsonl:paper_id=P0200#key_results[1])
  - B highlight: (E-P0016-62b8101d4e) Tool use, planning, and feedback learning are currently three prominent paradigms for developing Large Language Model (LLM)-based agents across various tasks. Li2024Review (pointer: papers/paper_notes.jsonl:paper_id=P0016#method)
- Axis: tool selection / routing policy; A: Agent frameworks / architectures: `P0120`, `P0121`, `P0128`; B: Memory / retrieval augmentation: `P0120`, `P0121`, `P0128`. Yu2026Agentic Verma2026Active Kang2025Distilling
  - A highlight: (E-P0121-f0f0faaada) Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage. Yu2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0121#key_results[0])
  - A highlight: (E-P0120-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (pointer: papers/paper_notes.jsonl:paper_id=P0120#key_results[1])
  - B highlight: (E-P0166-17fb12f5b7) In this work, we propose Agent Distillation, a framework for transferring not only reasoning capability but full task-solving behavior from LLM-based agents into sLMs with retrieval and code tools. Kang2025Distilling (pointer: papers/paper_notes.jsonl:paper_id=P0166#method)
  - B highlight: (E-P0121-f0f0faaada) Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage. Yu2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0121#key_results[0])

## Evaluation protocol

- Evaluation mentions include: SWE-bench, LTM, STM, GRPO, AgeMem, MEM, LoCoMo, AGI, MLLMs, MLLM-based. Verma2026Active Yu2026Agentic Tao2026Membox Yao2025Survey
- When comparing results, anchor the paragraph with: task type + metric + constraint (budget, tool access, horizon, or threat model) when stated. Verma2026Active Yu2026Agentic
- Prefer head-to-head comparisons only when benchmark/metric are shared; otherwise frame differences as protocol-driven rather than method superiority. Verma2026Active Yu2026Agentic
- Avoid underspecified model/baseline naming; if abstracts omit details, state that the baseline is reported but underspecified instead of guessing. Verma2026Active Yu2026Agentic
- If a claim relies on a single reported number, pair it with a limitation/caveat from the same evidence so the draft remains conservative. Verma2026Active Yu2026Agentic
- If budgets or environments differ across papers, treat cross-paper numeric comparison as fragile and prefer qualitative contrasts aligned to the subsection axes. Verma2026Active Yu2026Agentic

## Failures / limitations

- Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical. Yu2026Agentic
- Yet their sophisticated architectures amplify vulnerability to cascading failures, where a single root-cause error propagates through subsequent decisions, leading to task failure. Zhu2025Where
- First, we introduce the AgentErrorTaxonomy, a modular classification of failure modes spanning memory, reflection, planning, action, and system-level operations. Zhu2025Where
- Second, we construct AgentErrorBench, the first dataset of systematically annotated failure trajectories from ALFWorld, GAIA, and WebShop, grounding error analysis in real-world agent rollouts. Zhu2025Where
- However, this reliance on memory introduces a critical security risk: an adversary can inject seemingly harmless records into an agent's memory to manipulate its future behavior. Wei2025Memguard
- Comprehensive evaluations on multiple benchmarks show that A-MemGuard effectively cuts attack success rates by over 95% while incurring a minimal utility cost. Wei2025Memguard
- This work shifts LLM memory security from static filtering to a proactive, experience-driven model where defenses strengthen over time. Wei2025Memguard
- This results in the failure to retrieve the relevant code of these fine-grained subtasks. Li2025Graphcodeagent

## Verify fields (non-blocking)

- named benchmarks/datasets used
- metrics/human-eval protocol
- compute/training/inference cost
- training data and supervision signal
- baseline choices and ablation evidence
