{"evidence_id": "E-P0001-43f54265e8", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "method", "snippet": "We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0001-ca4a00b5cf", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "result", "snippet": "On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0001-604e8557e1", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "result", "snippet": "We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0001-8d0b22fef5", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0001-4f8536e0c6", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0001-d0f1113f52", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0001-1ac73ff02d", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0001-f18242e304", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "summary", "snippet": "On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0002-a8cd1f03c8", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0002-67875fd02f", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0002-9c4c3d45ac", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0002-f1f4c8649c", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller models excel.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0002-a58d26cb94", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0002-8f44086775", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0002-19f40531ed", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0003-b0fdbdd3a5", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose Reflexion, a novel framework to reinforce language agents not by updating weights, but instead through linguistic feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0003-a402af154b", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "For example, Reflexion achieves a 91% pass@1 accuracy on the HumanEval coding benchmark, surpassing the previous state-of-the-art GPT-4 that achieves 80%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0003-fb3046de14", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have been increasingly used to interact with external environments (e.g., games, compilers, APIs) as goal-driven agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0003-6c4bb4831c", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, it remains challenging for these language agents to quickly and efficiently learn from trial-and-error as traditional reinforcement learning methods require extensive training samples and expensive model fine-tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0003-901b0c3e29", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose Reflexion, a novel framework to reinforce language agents not by updating weights, but instead through linguistic feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0003-3f6b365112", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Concretely, Reflexion agents verbally reflect on task feedback signals, then maintain their own reflective text in an episodic memory buffer to induce better decision-making in subsequent trials.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0003-50d96acd26", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reflexion is flexible enough to incorporate various types (scalar values or free-form language) and sources (external or internally simulated) of feedback signals, and obtains significant improvements over a baseline agent across diverse tasks (sequential decision-making, coding, language reasoning).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0004-83af02f575", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0004-b9cd4289ed", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4% of tasks, our method achieved a success rate of 74%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0004-110ba95352", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0004-e9d0fe92c8", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0004-f64609094e", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0004-de6a7d0720", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0004-abde03b1c3", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0004-676a7be5f2", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0005-c57fee9291", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0005-b2eceb5b30", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "It obtains 3.3x more unique items, travels 2.3x longer distances, and unlocks key tech tree milestones up to 15.3x faster than prior SOTA.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0005-506120a6cd", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0005-e65ddaea31", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0005-c5ade9e083", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0005-51338842b2", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Voyager interacts with GPT-4 via blackbox queries, which bypasses the need for model parameter fine-tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0005-cc1ce5543d", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The skills developed by Voyager are temporally extended, interpretable, and compositional, which compounds the agent's abilities rapidly and alleviates catastrophic forgetting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0005-437d13c92d", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Empirically, Voyager shows strong in-context lifelong learning capability and exhibits exceptional proficiency in playing Minecraft.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0006-e4eb139524", "paper_id": "P0006", "bibkey": "Tang2025Empowering", "title": "Empowering Real-World: A Survey on the Technology, Practice, and Evaluation of LLM-driven Industry Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "With the rise of large language models (LLMs), LLM agents capable of autonomous reasoning, planning, and executing complex tasks have become a frontier in artificial intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0006-756bec09e8", "paper_id": "P0006", "bibkey": "Tang2025Empowering", "title": "Empowering Real-World: A Survey on the Technology, Practice, and Evaluation of LLM-driven Industry Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To address this, this paper systematically reviews the technologies, applications, and evaluation methods of industry agents based on LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0006-3f9a43a03b", "paper_id": "P0006", "bibkey": "Tang2025Empowering", "title": "Empowering Real-World: A Survey on the Technology, Practice, and Evaluation of LLM-driven Industry Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Additionally, this paper reviews the evaluation benchmarks and methods for both fundamental and specialized capabilities, identifying the challenges existing evaluation systems face regarding authenticity, safety, and industry specificity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0006-5338e8f844", "paper_id": "P0006", "bibkey": "Tang2025Empowering", "title": "Empowering Real-World: A Survey on the Technology, Practice, and Evaluation of LLM-driven Industry Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the rise of large language models (LLMs), LLM agents capable of autonomous reasoning, planning, and executing complex tasks have become a frontier in artificial intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0006-c284eff9f9", "paper_id": "P0006", "bibkey": "Tang2025Empowering", "title": "Empowering Real-World: A Survey on the Technology, Practice, and Evaluation of LLM-driven Industry Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, how to translate the research on general agents into productivity that drives industry transformations remains a significant challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0006-5e1f9679b5", "paper_id": "P0006", "bibkey": "Tang2025Empowering", "title": "Empowering Real-World: A Survey on the Technology, Practice, and Evaluation of LLM-driven Industry Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this, this paper systematically reviews the technologies, applications, and evaluation methods of industry agents based on LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0007-c1fe05ae37", "paper_id": "P0007", "bibkey": "Zhao2023Depth", "title": "An In-depth Survey of Large Language Model-based Artificial Intelligence Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "Due to the powerful capabilities demonstrated by large language model (LLM), there has been a recent surge in efforts to integrate them with AI agents to enhance their performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0007-c64b50e9b0", "paper_id": "P0007", "bibkey": "Zhao2023Depth", "title": "An In-depth Survey of Large Language Model-based Artificial Intelligence Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "At the end of the paper, we provide directional suggestions for further research in this field, with the hope of offering valuable insights to scholars and researchers in the field.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0007-528052f943", "paper_id": "P0007", "bibkey": "Zhao2023Depth", "title": "An In-depth Survey of Large Language Model-based Artificial Intelligence Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Due to the powerful capabilities demonstrated by large language model (LLM), there has been a recent surge in efforts to integrate them with AI agents to enhance their performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0007-964992cb0f", "paper_id": "P0007", "bibkey": "Zhao2023Depth", "title": "An In-depth Survey of Large Language Model-based Artificial Intelligence Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we have explored the core differences and characteristics between LLM-based AI agents and traditional AI agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0007-8739fe80a7", "paper_id": "P0007", "bibkey": "Zhao2023Depth", "title": "An In-depth Survey of Large Language Model-based Artificial Intelligence Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Specifically, we first compare the fundamental characteristics of these two types of agents, clarifying the significant advantages of LLM-based agents in handling natural language, knowledge storage, and reasoning capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0008-ce3104c142", "paper_id": "P0008", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Background: There is great interest in agentic LLMs, large language models that act as agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0008-2fb0b1b9ae", "paper_id": "P0008", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Methods: Agentic LLMs are LLMs that (1) reason, (2) act, and (3) interact.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0008-a1fb101bda", "paper_id": "P0008", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Further, agentic LLMs provide a solution for the problem of LLMs running out of training data: inference-time behavior generates new training states, such that LLMs can keep learning without needing ever larger datasets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0008-c14b84b190", "paper_id": "P0008", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Background: There is great interest in agentic LLMs, large language models that act as agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0008-0ffaa050ce", "paper_id": "P0008", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Objectives: We review the growing body of work in this area and provide a research agenda.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0008-4f05d5ff66", "paper_id": "P0008", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Methods: Agentic LLMs are LLMs that (1) reason, (2) act, and (3) interact.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0008-e688e4a34e", "paper_id": "P0008", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "We note that there is risk associated with LLM assistants taking action in the real world-safety, liability and security are open problems-while agentic LLMs are also likely to benefit society.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0009-9de2760a61", "paper_id": "P0009", "bibkey": "Chowa2025From", "title": "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The pursuit of human-level artificial intelligence (AI) has significantly advanced the development of autonomous agents and Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0009-e0bcca0d9e", "paper_id": "P0009", "bibkey": "Chowa2025From", "title": "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Furthermore, we evaluated current benchmarks and assessment protocols and have provided an analysis of 68 publicly available datasets to assess the performance of LLM-based agents in various tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0009-a0fdb95626", "paper_id": "P0009", "bibkey": "Chowa2025From", "title": "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We only used the papers published between 2023 and 2025 in conferences of the A* and A rank and Q1 journals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0009-e0d8a082bf", "paper_id": "P0009", "bibkey": "Chowa2025From", "title": "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The pursuit of human-level artificial intelligence (AI) has significantly advanced the development of autonomous agents and Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0009-9ba636b243", "paper_id": "P0009", "bibkey": "Chowa2025From", "title": "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLMs are now widely utilized as decision-making agents for their ability to interpret instructions, manage sequential tasks, and adapt through feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0009-eede1b39a1", "paper_id": "P0009", "bibkey": "Chowa2025From", "title": "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This review examines recent developments in employing LLMs as autonomous agents and tool users and comprises seven research questions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0010-7abf599636", "paper_id": "P0010", "bibkey": "Zhang2025Generalizability", "title": "Generalizability of Large Language Model-Based Agents: A Comprehensive Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Moreover, we introduce the distinction between generalizable frameworks and generalizable agents and outline how generalizable frameworks can be translated into agent-level generalizability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0010-793979aed4", "paper_id": "P0010", "bibkey": "Zhang2025Generalizability", "title": "Generalizability of Large Language Model-Based Agents: A Comprehensive Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We then review datasets, evaluation dimensions, and metrics, highlighting their limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0010-a8cee0e5b6", "paper_id": "P0010", "bibkey": "Zhang2025Generalizability", "title": "Generalizability of Large Language Model-Based Agents: A Comprehensive Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we identify critical challenges and future directions, including developing standardized frameworks, variance- and cost-based metrics, and approaches that integrate methodological innovations with architecture-level designs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0010-d6ee4024f1", "paper_id": "P0010", "bibkey": "Zhang2025Generalizability", "title": "Generalizability of Large Language Model-Based Agents: A Comprehensive Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM)-based agents have emerged as a new paradigm that extends LLMs' capabilities beyond text generation to dynamic interaction with external environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0010-1d8b751ec5", "paper_id": "P0010", "bibkey": "Zhang2025Generalizability", "title": "Generalizability of Large Language Model-Based Agents: A Comprehensive Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By integrating reasoning with perception, memory, and tool use, agents are increasingly deployed in diverse domains like web navigation and household robotics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0010-ba3c3cd86d", "paper_id": "P0010", "bibkey": "Zhang2025Generalizability", "title": "Generalizability of Large Language Model-Based Agents: A Comprehensive Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A critical challenge, however, lies in ensuring agent generalizability - the ability to maintain consistent performance across varied instructions, tasks, environments, and domains, especially those beyond agents' fine-tuning data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0010-ebf42b933d", "paper_id": "P0010", "bibkey": "Zhang2025Generalizability", "title": "Generalizability of Large Language Model-Based Agents: A Comprehensive Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite growing interest, the concept of generalizability in LLM-based agents remains underdefined, and systematic approaches to measure and improve it are lacking.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0010-4597b4d93a", "paper_id": "P0010", "bibkey": "Zhang2025Generalizability", "title": "Generalizability of Large Language Model-Based Agents: A Comprehensive Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this survey, we provide the first comprehensive review of generalizability in LLM-based agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0010-285b02539b", "paper_id": "P0010", "bibkey": "Zhang2025Generalizability", "title": "Generalizability of Large Language Model-Based Agents: A Comprehensive Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "We then review datasets, evaluation dimensions, and metrics, highlighting their limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#limitations[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0011-43b3136b8c", "paper_id": "P0011", "bibkey": "Yao2025Survey", "title": "A Survey on Agentic Multimodal Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Motivated by the growing interest in agentic AI and its potential trajectory toward AGI, we present a comprehensive survey on Agentic Multimodal Large Language Models (Agentic MLLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0011-1b6fe3407a", "paper_id": "P0011", "bibkey": "Yao2025Survey", "title": "A Survey on Agentic Multimodal Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To further accelerate research in this area for the community, we compile open-source training frameworks, training and evaluation datasets for developing agentic MLLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0011-5cb27c72cf", "paper_id": "P0011", "bibkey": "Yao2025Survey", "title": "A Survey on Agentic Multimodal Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the recent emergence of revolutionary autonomous agentic systems, research community is witnessing a significant shift from traditional static, passive, and domain-specific AI agents toward more dynamic, proactive, and generalizable agentic AI.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0011-3ab24ac75f", "paper_id": "P0011", "bibkey": "Yao2025Survey", "title": "A Survey on Agentic Multimodal Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Motivated by the growing interest in agentic AI and its potential trajectory toward AGI, we present a comprehensive survey on Agentic Multimodal Large Language Models (Agentic MLLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0011-9f159848e7", "paper_id": "P0011", "bibkey": "Yao2025Survey", "title": "A Survey on Agentic Multimodal Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this survey, we explore the emerging paradigm of agentic MLLMs, delineating their conceptual foundations and distinguishing characteristics from conventional MLLM-based agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0012-6a96bfb7fd", "paper_id": "P0012", "bibkey": "Aratchige2025Llms", "title": "LLMs Working in Harmony: A Survey on the Technological Aspects of Building Effective LLM-Based Multi Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "This survey investigates foundational technologies essential for developing effective Large Language Model (LLM)-based multi-agent systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0012-f7c86693ee", "paper_id": "P0012", "bibkey": "Aratchige2025Llms", "title": "LLMs Working in Harmony: A Survey on the Technological Aspects of Building Effective LLM-Based Multi Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our findings provide a roadmap for future research, supporting the creation of robust, efficient multi-agent systems that advance both individual agent performance and collective system resilience.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0012-e0316a9571", "paper_id": "P0012", "bibkey": "Aratchige2025Llms", "title": "LLMs Working in Harmony: A Survey on the Technological Aspects of Building Effective LLM-Based Multi Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey investigates foundational technologies essential for developing effective Large Language Model (LLM)-based multi-agent systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0012-de0a341174", "paper_id": "P0012", "bibkey": "Aratchige2025Llms", "title": "LLMs Working in Harmony: A Survey on the Technological Aspects of Building Effective LLM-Based Multi Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Aiming to answer how best to optimize these systems for collaborative, dynamic environments, we focus on four critical areas: Architecture, Memory, Planning, and Technologies/Frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0012-8ad93c90f3", "paper_id": "P0012", "bibkey": "Aratchige2025Llms", "title": "LLMs Working in Harmony: A Survey on the Technological Aspects of Building Effective LLM-Based Multi Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By analyzing recent advancements and their limitations - such as scalability, real-time response challenges, and agent coordination constraints, we provide a detailed view of the technological landscape.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0012-7cac5db9a9", "paper_id": "P0012", "bibkey": "Aratchige2025Llms", "title": "LLMs Working in Harmony: A Survey on the Technological Aspects of Building Effective LLM-Based Multi Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "By analyzing recent advancements and their limitations - such as scalability, real-time response challenges, and agent coordination constraints, we provide a detailed view of the technological landscape.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0013-9d9d60644a", "paper_id": "P0013", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0013-04c60086db", "paper_id": "P0013", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design principles for trustworthy agents: modular decomposition, adaptive symbolic governance, and transparent state management.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0013-17d092450a", "paper_id": "P0013", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model agents suffer from fundamental architectural problems: entangled reasoning and execution, memory volatility, and uncontrolled action sequences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0013-10950917a3", "paper_id": "P0013", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0013-1dbc5333ba", "paper_id": "P0013", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "At the core of SCL is Soft Symbolic Control, an adaptive governance mechanism that applies symbolic constraints to probabilistic inference, preserving neural flexibility while restoring the explainability and controllability of classical symbolic systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0013-79a2100d6b", "paper_id": "P0013", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Through empirical validation on multi-step conditional reasoning tasks, we demonstrate that SCL achieves zero policy violations, eliminates redundant tool calls, and maintains complete decision traceability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0013-54c9afde38", "paper_id": "P0013", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These results address critical gaps in existing frameworks such as ReAct, AutoGPT, and memory-augmented approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0014-6e4feb950e", "paper_id": "P0014", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this limitation, we propose ReAcTree, a hierarchical task-planning method that decomposes a complex goal into more manageable subgoals within a dynamically constructed agent tree.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0014-800068dfc6", "paper_id": "P0014", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Notably, on WAH-NL, ReAcTree achieves a 61% goal success rate with Qwen 2.5 72B, nearly doubling ReAct's 31%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0014-4bcafdb221", "paper_id": "P0014", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on the WAH-NL and ALFRED datasets demonstrate that ReAcTree consistently outperforms strong task-planning baselines such as ReAct across diverse LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0014-27052609b0", "paper_id": "P0014", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in large language models (LLMs) have enabled significant progress in decision-making and task planning for embodied autonomous agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0014-19186aab0d", "paper_id": "P0014", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, most existing methods still struggle with complex, long-horizon tasks because they rely on a monolithic trajectory that entangles all past decisions and observations, attempting to solve the entire task in a single unified process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0014-5e26d15f21", "paper_id": "P0014", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this limitation, we propose ReAcTree, a hierarchical task-planning method that decomposes a complex goal into more manageable subgoals within a dynamically constructed agent tree.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0014-c782275d8d", "paper_id": "P0014", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address this limitation, we propose ReAcTree, a hierarchical task-planning method that decomposes a complex goal into more manageable subgoals within a dynamically constructed agent tree.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0015-ec05e3ea6f", "paper_id": "P0015", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Agents powered by Large Language Models (LLMs) have recently demonstrated impressive capabilities in various tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0015-b5f497408b", "paper_id": "P0015", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Contributing to the ongoing research on neuro-symbolic hybrid systems, this work posits CBR as a viable technique for enhancing the reasoning skills and cognitive aspects of autonomous LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0015-fce48c710d", "paper_id": "P0015", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agents powered by Large Language Models (LLMs) have recently demonstrated impressive capabilities in various tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0015-45b7c47edc", "paper_id": "P0015", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Still, they face limitations in tasks requiring specific, structured knowledge, flexibility, or accountable decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0015-9d7bd89b61", "paper_id": "P0015", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While agents are capable of perceiving their environments, forming inferences, planning, and executing actions towards goals, they often face issues such as hallucinations and lack of contextual memory across interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0015-90c64203f8", "paper_id": "P0015", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Still, they face limitations in tasks requiring specific, structured knowledge, flexibility, or accountable decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0016-62b8101d4e", "paper_id": "P0016", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Tool use, planning, and feedback learning are currently three prominent paradigms for developing Large Language Model (LLM)-based agents across various tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0016-dc2266b72d", "paper_id": "P0016", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Specifically, 1) the taxonomy defines environments/tasks, common LLM-profiled roles or LMPRs (policy models, evaluators, and dynamic models), and universally applicable workflows found in prior work, and 2) it enables a comparison of key perspectives on the implementations of LMPRs and workflow designs across different agent paradigms and frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0016-81a4fb82d1", "paper_id": "P0016", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "3) Finally, we identify three limitations in existing workflow designs and systematically discuss the future work.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0016-a25d9c6a6c", "paper_id": "P0016", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tool use, planning, and feedback learning are currently three prominent paradigms for developing Large Language Model (LLM)-based agents across various tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0016-7f05d2fa5c", "paper_id": "P0016", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Although numerous frameworks have been devised for each paradigm, their intricate workflows and inconsistent taxonomy create challenges in understanding and reviewing the frameworks across different paradigms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0016-8d4ea17e2b", "paper_id": "P0016", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey introduces a unified taxonomy to systematically review and discuss these frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0016-480e7513c3", "paper_id": "P0016", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Specifically, 1) the taxonomy defines environments/tasks, common LLM-profiled roles or LMPRs (policy models, evaluators, and dynamic models), and universally applicable workflows found in prior work, and 2) it enables a comparison of key perspectives on the implementations of LMPRs and workflow designs across different agent paradigms and frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0016-f122d06471", "paper_id": "P0016", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "3) Finally, we identify three limitations in existing workflow designs and systematically discuss the future work.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0016-3c57288d9a", "paper_id": "P0016", "bibkey": "Li2024Review", "title": "A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "3) Finally, we identify three limitations in existing workflow designs and systematically discuss the future work.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#limitations[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0017-6ec00ea923", "paper_id": "P0017", "bibkey": "Han2024Causal", "title": "Causal Agent based on Large Language Model", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "The large language model (LLM) has achieved significant success across various domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0017-3a83961f70", "paper_id": "P0017", "bibkey": "Han2024Causal", "title": "Causal Agent based on Large Language Model", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through verification on the real-world dataset QRData, the causal agent is 6\\% higher than the original SOTA.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0017-bc65ad829f", "paper_id": "P0017", "bibkey": "Han2024Causal", "title": "Causal Agent based on Large Language Model", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Causal agent demonstrates remarkable efficacy on the four-level causal problems, with accuracy rates all above 80\\%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0017-2f19d94848", "paper_id": "P0017", "bibkey": "Han2024Causal", "title": "Causal Agent based on Large Language Model", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The large language model (LLM) has achieved significant success across various domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0017-370e28b536", "paper_id": "P0017", "bibkey": "Han2024Causal", "title": "Causal Agent based on Large Language Model", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the inherent complexity of causal problems and causal theory poses challenges in accurately describing them in natural language, making it difficult for LLM to comprehend and use them effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0017-24c082efcf", "paper_id": "P0017", "bibkey": "Han2024Causal", "title": "Causal Agent based on Large Language Model", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Causal methods are not easily conveyed through natural language, which hinders LLM's ability to apply them accurately.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0018-cc39d97e63", "paper_id": "P0018", "bibkey": "Guo2024Large", "title": "Large Language Model based Multi-Agents: A Survey of Progress and Challenges", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To provide the community with an overview of this dynamic field, we present this survey to offer an in-depth discussion on the essential aspects of multi-agent systems based on LLMs, as well as the challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0018-c345f8f82d", "paper_id": "P0018", "bibkey": "Guo2024Large", "title": "Large Language Model based Multi-Agents: A Survey of Progress and Challenges", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0018-8f3fe29d06", "paper_id": "P0018", "bibkey": "Guo2024Large", "title": "Large Language Model based Multi-Agents: A Survey of Progress and Challenges", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "For those interested in delving into this field of study, we also summarize the commonly used datasets or benchmarks for them to have convenient access.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0018-70e170551d", "paper_id": "P0018", "bibkey": "Guo2024Large", "title": "Large Language Model based Multi-Agents: A Survey of Progress and Challenges", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0018-b886524eff", "paper_id": "P0018", "bibkey": "Guo2024Large", "title": "Large Language Model based Multi-Agents: A Survey of Progress and Challenges", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Due to the impressive planning and reasoning abilities of LLMs, they have been used as autonomous agents to do many tasks automatically.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0018-c079095d3b", "paper_id": "P0018", "bibkey": "Guo2024Large", "title": "Large Language Model based Multi-Agents: A Survey of Progress and Challenges", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, based on the development of using one LLM as a single planning or decision-making agent, LLM-based multi-agent systems have achieved considerable progress in complex problem-solving and world simulation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0019-afe907256b", "paper_id": "P0019", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Since the advent of personal computing devices, intelligent personal assistants (IPAs) have been one of the key technologies that researchers and engineers have focused on, aiming to help users efficiently obtain information and execute tasks, and provide users with more intelligent, convenient, and rich interaction experiences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0019-063c3b3128", "paper_id": "P0019", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Next, we discuss several key challenges to achieve intelligent, efficient and secure Personal LLM Agents, followed by a comprehensive survey of representative solutions to address these challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0019-8179d149f9", "paper_id": "P0019", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Since the advent of personal computing devices, intelligent personal assistants (IPAs) have been one of the key technologies that researchers and engineers have focused on, aiming to help users efficiently obtain information and execute tasks, and provide users with more intelligent, convenient, and rich interaction experiences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0019-b0726cba84", "paper_id": "P0019", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the development of smartphones and IoT, computing and sensing devices have become ubiquitous, greatly expanding the boundaries of IPAs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0019-716c8ba772", "paper_id": "P0019", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, due to the lack of capabilities such as user intent understanding, task planning, tool using, and personal data management etc., existing IPAs still have limited practicality and scalability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0019-01651dbee4", "paper_id": "P0019", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, the emergence of foundation models, represented by large language models (LLMs), brings new opportunities for the development of IPAs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0019-e3be73b8f9", "paper_id": "P0019", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the powerful semantic understanding and reasoning capabilities, LLM can enable intelligent agents to solve complex problems autonomously.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0020-7be3711e86", "paper_id": "P0020", "bibkey": "Pternea2024Taxonomy", "title": "The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement Learning and Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose a novel taxonomy of three main classes based on the way that the two model types interact with each other.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0020-a888e1ae05", "paper_id": "P0020", "bibkey": "Pternea2024Taxonomy", "title": "The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement Learning and Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We use this taxonomy to explore the motivations behind the synergy of LLMs and RL and explain the reasons for its success, while pinpointing potential shortcomings and areas where further research is needed, as well as alternative methodologies that serve the same goal.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0020-27e5b83e43", "paper_id": "P0020", "bibkey": "Pternea2024Taxonomy", "title": "The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement Learning and Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we review research studies that combine Reinforcement Learning (RL) and Large Language Models (LLMs), two areas that owe their momentum to the development of deep neural networks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0020-33dfc14d04", "paper_id": "P0020", "bibkey": "Pternea2024Taxonomy", "title": "The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement Learning and Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose a novel taxonomy of three main classes based on the way that the two model types interact with each other.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0020-2deacb5db7", "paper_id": "P0020", "bibkey": "Pternea2024Taxonomy", "title": "The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement Learning and Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The first class, RL4LLM, includes studies where RL is leveraged to improve the performance of LLMs on tasks related to Natural Language Processing.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0021-01839baf55", "paper_id": "P0021", "bibkey": "Feng2026Backdooragent", "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To fill this gap, we propose \\textbf{BackdoorAgent}, a modular and stage-aware framework that provides a unified, agent-centric view of backdoor threats in LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0021-d296f8966d", "paper_id": "P0021", "bibkey": "Feng2026Backdooragent", "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our empirical analysis shows that \\textit{triggers implanted at a single stage can persist across multiple steps and propagate through intermediate states.} For instance, when using a GPT-based backbone, we observe trigger persistence in 43.58\\% of planning attacks, 77.97\\% of memory attacks, and 60.28\\% of tool-stage attacks, highlighting the vulnerabilities of the agentic workflow itself to backdoor threats.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0021-fbbcda4f8d", "paper_id": "P0021", "bibkey": "Feng2026Backdooragent", "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Building on this framework, we construct a standardized benchmark spanning four representative agent applications: \\textbf{Agent QA}, \\textbf{Agent Code}, \\textbf{Agent Web}, and \\textbf{Agent Drive}, covering both language-only and multimodal settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0021-dee1747966", "paper_id": "P0021", "bibkey": "Feng2026Backdooragent", "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents execute tasks through multi-step workflows that combine planning, memory, and tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0021-669d5f908a", "paper_id": "P0021", "bibkey": "Feng2026Backdooragent", "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While this design enables autonomy, it also expands the attack surface for backdoor threats.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0021-345d91afb8", "paper_id": "P0021", "bibkey": "Feng2026Backdooragent", "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Backdoor triggers injected into specific stages of an agent workflow can persist through multiple intermediate states and adversely influence downstream outputs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0022-1564795a81", "paper_id": "P0022", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a stealthy, multi-turn economic DoS attack that operates at the tool layer under the guise of a correctly completed task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#method"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0022-b6b7af5a81", "paper_id": "P0022", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across six LLMs on the ToolBench and BFCL benchmarks, our attack expands tasks into trajectories exceeding 60,000 tokens, inflates costs by up to 658x, and raises energy by 100-560x.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0022-0e9bf4bf0b", "paper_id": "P0022", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "It drives GPU KV cache occupancy from <1% to 35-74% and cuts co-running throughput by approximately 50%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0022-09300516c9", "paper_id": "P0022", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The agent-tool communication loop is a critical attack surface in modern Large Language Model (LLM) agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#summary_bullets[0]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0022-eb0bf8bedb", "paper_id": "P0022", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing Denial-of-Service (DoS) attacks, primarily triggered via user prompts or injected retrieval-augmented generation (RAG) context, are ineffective for this new paradigm.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "security"]}
{"evidence_id": "E-P0022-62b0277ae2", "paper_id": "P0022", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "They are fundamentally single-turn and often lack a task-oriented approach, making them conspicuous in goal-oriented workflows and unable to exploit the compounding costs of multi-turn agent-tool interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0023-c63f9e7a62", "paper_id": "P0023", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we explore the Large Language Model (LLM) agent reviewer dynamics in an Elo-ranked review system using real-world conference paper submissions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0023-a11e93b0b9", "paper_id": "P0023", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our simulation results showcase several interesting findings, including how incorporating Elo improves Area Chair decision accuracy, as well as reviewers' adaptive review strategy that exploits our Elo system without improving review effort.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0023-7a3393ef27", "paper_id": "P0023", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we explore the Large Language Model (LLM) agent reviewer dynamics in an Elo-ranked review system using real-world conference paper submissions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0023-ff3cba1c44", "paper_id": "P0023", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Multiple LLM agent reviewers with different personas are engage in multi round review interactions moderated by an Area Chair.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0023-82b5ed27f7", "paper_id": "P0023", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We compare a baseline setting with conditions that incorporate Elo ratings and reviewer memory.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0024-7b3ec45781", "paper_id": "P0024", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "This paper surveys the development of large language model (LLM)-based agents for question answering (QA).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0024-48f5050e3c", "paper_id": "P0024", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Additionally, this paper identifies ongoing challenges and explores future research directions to enhance the performance of LLM agent QA systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0024-c4dbb5a1b4", "paper_id": "P0024", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper surveys the development of large language model (LLM)-based agents for question answering (QA).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0024-d923fcecb6", "paper_id": "P0024", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional agents face significant limitations, including substantial data requirements and difficulty in generalizing to new environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0024-59428e8083", "paper_id": "P0024", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM-based agents address these challenges by leveraging LLMs as their core reasoning engine.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0024-014d5f7597", "paper_id": "P0024", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Traditional agents face significant limitations, including substantial data requirements and difficulty in generalizing to new environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0025-b75c597e91", "paper_id": "P0025", "bibkey": "Yu2025Survey", "title": "A Survey on Trustworthy LLM Agents: Threats and Countermeasures", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this survey, we propose the TrustAgent framework, a comprehensive study on the trustworthiness of agents, characterized by modular taxonomy, multi-dimensional connotations, and technical implementation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0025-74b194488e", "paper_id": "P0025", "bibkey": "Yu2025Survey", "title": "A Survey on Trustworthy LLM Agents: Threats and Countermeasures", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "By thoroughly investigating and summarizing newly emerged attacks, defenses, and evaluation methods for agents and MAS, we extend the concept of Trustworthy LLM to the emerging paradigm of Trustworthy Agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "security"]}
{"evidence_id": "E-P0025-fd7a72d3e0", "paper_id": "P0025", "bibkey": "Yu2025Survey", "title": "A Survey on Trustworthy LLM Agents: Threats and Countermeasures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the rapid evolution of Large Language Models (LLMs), LLM-based agents and Multi-agent Systems (MAS) have significantly expanded the capabilities of LLM ecosystems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0025-db39332e77", "paper_id": "P0025", "bibkey": "Yu2025Survey", "title": "A Survey on Trustworthy LLM Agents: Threats and Countermeasures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This evolution stems from empowering LLMs with additional modules such as memory, tools, environment, and even other agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0025-3538f5d0b1", "paper_id": "P0025", "bibkey": "Yu2025Survey", "title": "A Survey on Trustworthy LLM Agents: Threats and Countermeasures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, this advancement has also introduced more complex issues of trustworthiness, which previous research focused solely on LLMs could not cover.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0026-455a6721bd", "paper_id": "P0026", "bibkey": "Du2025Survey", "title": "A Survey on the Optimization of Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "With the rapid development of Large Language Models (LLMs), LLM-based agents have been widely adopted in various fields, becoming essential for autonomous decision-making and interactive tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0026-f0ea009256", "paper_id": "P0026", "bibkey": "Du2025Survey", "title": "A Survey on the Optimization of Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we summarize the datasets and benchmarks used for evaluation and tuning, review key applications of LLM-based agents, and discuss major challenges and promising future directions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0026-87f9935f5e", "paper_id": "P0026", "bibkey": "Du2025Survey", "title": "A Survey on the Optimization of Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the rapid development of Large Language Models (LLMs), LLM-based agents have been widely adopted in various fields, becoming essential for autonomous decision-making and interactive tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0026-26210903cc", "paper_id": "P0026", "bibkey": "Du2025Survey", "title": "A Survey on the Optimization of Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, current work typically relies on prompt design or fine-tuning strategies applied to vanilla LLMs, which often leads to limited effectiveness or suboptimal performance in complex agent-related environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0026-08efa921ed", "paper_id": "P0026", "bibkey": "Du2025Survey", "title": "A Survey on the Optimization of Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Although LLM optimization techniques can improve model performance across many general tasks, they lack specialized optimization towards critical agent functionalities such as long-term planning, dynamic environmental interaction, and complex decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0026-e4d5a179c9", "paper_id": "P0026", "bibkey": "Du2025Survey", "title": "A Survey on the Optimization of Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Although numerous recent studies have explored various strategies to optimize LLM-based agents for complex agent tasks, a systematic review summarizing and comparing these methods from a holistic perspective is still lacking.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0026-21d42345ac", "paper_id": "P0026", "bibkey": "Du2025Survey", "title": "A Survey on the Optimization of Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this survey, we provide a comprehensive review of LLM-based agent optimization approaches, categorizing them into parameter-driven and parameter-free methods.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0027-dac95cdbce", "paper_id": "P0027", "bibkey": "Wu2025Agentic", "title": "Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Agentic Reasoning, a framework that enhances large language model (LLM) reasoning by integrating external tool-using agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0027-d25c02babe", "paper_id": "P0027", "bibkey": "Wu2025Agentic", "title": "Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "When deployed on DeepSeek-R1, our method achieves a new state-of-the-art (SOTA) among public models and delivers performance comparable to OpenAI Deep Research, the leading proprietary model in this domain.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0027-4096e01329", "paper_id": "P0027", "bibkey": "Wu2025Agentic", "title": "Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Agentic Reasoning, a framework that enhances large language model (LLM) reasoning by integrating external tool-using agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0027-3afec4c535", "paper_id": "P0027", "bibkey": "Wu2025Agentic", "title": "Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agentic Reasoning dynamically leverages web search, code execution, and structured memory to address complex problems requiring deep research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0027-055fef6a8b", "paper_id": "P0027", "bibkey": "Wu2025Agentic", "title": "Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A key innovation in our framework is the Mind-Map agent, which constructs a structured knowledge graph to store reasoning context and track logical relationships, ensuring coherence in long reasoning chains with extensive tool usage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0028-e7d6d55617", "paper_id": "P0028", "bibkey": "Dong2025Compressed", "title": "Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic Capabilities in LLM Compression", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce the Agent Compression Benchmark (ACBench), the first comprehensive benchmark for evaluating how compression impacts LLMs' agentic abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0028-a2fc746ea1", "paper_id": "P0028", "bibkey": "Dong2025Compressed", "title": "Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic Capabilities in LLM Compression", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments reveal compression tradeoffs: 4-bit quantization preserves workflow generation and tool use (1%-3% drop) but degrades real-world application accuracy by 10%-15%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0028-08c43ee74b", "paper_id": "P0028", "bibkey": "Dong2025Compressed", "title": "Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic Capabilities in LLM Compression", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "ACBench spans (1) 12 tasks across 4 capabilities (e.g., WorfBench for workflow generation, Needle-in-Haystack for long-context retrieval), (2) quantization (GPTQ, AWQ) and pruning (Wanda, SparseGPT), and (3) 15 models, including small (Gemma-2B), standard (Qwen2.5 7B-32B), and distilled reasoning LLMs (DeepSeek-R1-Distill).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0028-53eed949dc", "paper_id": "P0028", "bibkey": "Dong2025Compressed", "title": "Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic Capabilities in LLM Compression", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Post-training compression reduces the computational and memory costs of large language models (LLMs), enabling resource-efficient deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0028-9c4969a3a5", "paper_id": "P0028", "bibkey": "Dong2025Compressed", "title": "Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic Capabilities in LLM Compression", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing compression benchmarks only focus on language modeling (e.g., perplexity) and natural language understanding tasks (e.g., GLUE accuracy), ignoring the agentic capabilities - workflow, tool use/function call, long-context understanding and real-world application.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0028-8dc334b831", "paper_id": "P0028", "bibkey": "Dong2025Compressed", "title": "Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic Capabilities in LLM Compression", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce the Agent Compression Benchmark (ACBench), the first comprehensive benchmark for evaluating how compression impacts LLMs' agentic abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0029-2c3b7eae80", "paper_id": "P0029", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose Group-in-Group Policy Optimization (GiGPO), a novel RL algorithm that achieves fine-grained credit assignment for LLM agents while preserving the appealing properties of group-based RL: critic-free, low memory, and stable convergence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0029-4b027dfb27", "paper_id": "P0029", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate GiGPO on challenging agent benchmarks, including ALFWorld and WebShop, as well as tool-integrated reasoning on search-augmented QA tasks, using Qwen2.5-1.5B/3B/7B-Instruct.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0029-af024eea6f", "paper_id": "P0029", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Crucially, GiGPO delivers fine-grained per-step credit signals, achieves performance gains of > 12% on ALFWorld and > 9% on WebShop over GRPO, and obtains superior performance on QA tasks (42.1% on 3B and 47.2% on 7B): all while maintaining the same GPU memory overhead, identical LLM rollout, and incurring little to no additional time cost.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0029-dccace20fe", "paper_id": "P0029", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in group-based reinforcement learning (RL) have driven frontier large language models (LLMs) in single-turn tasks like mathematical reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0029-4c1e30b52c", "paper_id": "P0029", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, their scalability to multi-turn LLM agent training remains limited.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0029-930a33b2d7", "paper_id": "P0029", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike static tasks, agent-environment interactions unfold over many steps and often yield sparse or delayed rewards, making credit assignment across individual steps significantly more challenging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0030-cb7c521301", "paper_id": "P0030", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose Reasoning-Style Poisoning (RSP), a paradigm that manipulates how agents process information rather than what they process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0030-c17bcfb7d4", "paper_id": "P0030", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "It increases reasoning steps by up to 4.4 times or induces premature errors, successfully bypassing state-of-the-art content filters.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0030-e38b4bdff3", "paper_id": "P0030", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To quantify these shifts, we develop the Reasoning Style Vector (RSV), a metric tracking Verification depth, Self-confidence, and Attention focus.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0030-dac2089fae", "paper_id": "P0030", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents relying on external retrieval are increasingly deployed in high-stakes environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0030-8517628bd0", "paper_id": "P0030", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0030-8a9233d368", "paper_id": "P0030", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose Reasoning-Style Poisoning (RSP), a paradigm that manipulates how agents process information rather than what they process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0030-058627ec30", "paper_id": "P0030", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Generative Style Injection (GSI), an attack method that rewrites retrieved documents into pathological tones--specifically \"analysis paralysis\" or \"cognitive haste\"--without altering underlying facts or using explicit triggers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#summary_bullets[3]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0030-954eb74a81", "paper_id": "P0030", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To quantify these shifts, we develop the Reasoning Style Vector (RSV), a metric tracking Verification depth, Self-confidence, and Attention focus.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0031-48068017a1", "paper_id": "P0031", "bibkey": "Ruangtanusak2025Talk", "title": "Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "This report investigates approaches for prompting a tool-augmented large language model (LLM) to act as a role-playing dialogue agent in the API track of the Commonsense Persona-grounded Dialogue Challenge (CPDC) 2025.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#method"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0031-dee89cf74c", "paper_id": "P0031", "bibkey": "Ruangtanusak2025Talk", "title": "Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This report investigates approaches for prompting a tool-augmented large language model (LLM) to act as a role-playing dialogue agent in the API track of the Commonsense Persona-grounded Dialogue Challenge (CPDC) 2025.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0031-6820c1de30", "paper_id": "P0031", "bibkey": "Ruangtanusak2025Talk", "title": "Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We explore four prompting approaches to address these issues: 1) basic role prompting, 2) improved role prompting, 3) automatic prompt optimization (APO), and 4) rule-based role prompting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0031-7f918d46cc", "paper_id": "P0031", "bibkey": "Ruangtanusak2025Talk", "title": "Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This report investigates approaches for prompting a tool-augmented large language model (LLM) to act as a role-playing dialogue agent in the API track of the Commonsense Persona-grounded Dialogue Challenge (CPDC) 2025.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#summary_bullets[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0031-c56aceb7cc", "paper_id": "P0031", "bibkey": "Ruangtanusak2025Talk", "title": "Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this setting, dialogue agents often produce overly long in-character responses (over-speaking) while failing to use tools effectively according to the persona (under-acting), such as generating function calls that do not exist or making unnecessary tool calls before answering.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0031-a2c80b9c6c", "paper_id": "P0031", "bibkey": "Ruangtanusak2025Talk", "title": "Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We explore four prompting approaches to address these issues: 1) basic role prompting, 2) improved role prompting, 3) automatic prompt optimization (APO), and 4) rule-based role prompting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0032-a0fe046ece", "paper_id": "P0032", "bibkey": "Ye2025Task", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce the Task Memory Engine (TME), a modular memory controller that transforms existing LLMs into robust, revision-aware agents without fine-tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0032-3bf4dab38c", "paper_id": "P0032", "bibkey": "Ye2025Task", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns, outperforming ReAct.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0032-53536132a8", "paper_id": "P0032", "bibkey": "Ye2025Task", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We release TME's codebase, benchmarks, and components as open-source resources, enabling researchers to develop reliable LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0032-d509f280df", "paper_id": "P0032", "bibkey": "Ye2025Task", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) falter in multi-step interactions -- often hallucinating, repeating actions, or misinterpreting user corrections -- due to reliance on linear, unstructured context.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0032-5997082b9f", "paper_id": "P0032", "bibkey": "Ye2025Task", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This fragility stems from the lack of persistent memory to track evolving goals and task dependencies, undermining trust in autonomous agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0032-5da3033ff7", "paper_id": "P0032", "bibkey": "Ye2025Task", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce the Task Memory Engine (TME), a modular memory controller that transforms existing LLMs into robust, revision-aware agents without fine-tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0033-32516d8b0b", "paper_id": "P0033", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "First, we introduce the AgentErrorTaxonomy, a modular classification of failure modes spanning memory, reflection, planning, action, and system-level operations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0033-3a24449737", "paper_id": "P0033", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on AgentErrorBench show that AgentDebug achieves 24% higher all-correct accuracy and 17% higher step accuracy compared to the strongest baseline.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0033-cb04969cfe", "paper_id": "P0033", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Beyond detection, the targeted feedback generated by AgentDebug enables LLM agents to iteratively recover from failures, yielding up to 26% relative improvements in task success across ALFWorld, GAIA, and WebShop.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0033-085ad78ac8", "paper_id": "P0033", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents, which integrate planning, memory, reflection, and tool-use modules, have shown promise in solving complex, multi-step tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0033-46914a4804", "paper_id": "P0033", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Yet their sophisticated architectures amplify vulnerability to cascading failures, where a single root-cause error propagates through subsequent decisions, leading to task failure.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0033-f1dcce8f4d", "paper_id": "P0033", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current systems lack a framework that can comprehensively understand agent error in a modular and systemic way, and therefore fail to detect these errors accordingly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0033-cfb691cbc4", "paper_id": "P0033", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We address this gap with three contributions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0033-0d0d8bae59", "paper_id": "P0033", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "First, we introduce the AgentErrorTaxonomy, a modular classification of failure modes spanning memory, reflection, planning, action, and system-level operations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0034-373b648756", "paper_id": "P0034", "bibkey": "Lu2025Youtu", "title": "Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Youtu-LLM, a lightweight yet powerful language model that harmonizes high computational efficiency with native agentic intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0034-a332ff9b04", "paper_id": "P0034", "bibkey": "Lu2025Youtu", "title": "Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Unlike typical small models that rely on distillation, Youtu-LLM (1.96B) is pre-trained from scratch to systematically cultivate reasoning and planning capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0034-0f3e2d76f4", "paper_id": "P0034", "bibkey": "Lu2025Youtu", "title": "Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The key technical advancements are as follows: (1) Compact Architecture with Long-Context Support: Built on a dense Multi-Latent Attention (MLA) architecture with a novel STEM-oriented vocabulary, Youtu-LLM supports a 128k context window.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0034-91d5d7cdf0", "paper_id": "P0034", "bibkey": "Lu2025Youtu", "title": "Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Youtu-LLM, a lightweight yet powerful language model that harmonizes high computational efficiency with native agentic intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0034-ffac4f76a1", "paper_id": "P0034", "bibkey": "Lu2025Youtu", "title": "Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike typical small models that rely on distillation, Youtu-LLM (1.96B) is pre-trained from scratch to systematically cultivate reasoning and planning capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0034-9523a82188", "paper_id": "P0034", "bibkey": "Lu2025Youtu", "title": "Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The key technical advancements are as follows: (1) Compact Architecture with Long-Context Support: Built on a dense Multi-Latent Attention (MLA) architecture with a novel STEM-oriented vocabulary, Youtu-LLM supports a 128k context window.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0035-792b859ee4", "paper_id": "P0035", "bibkey": "Hu2024Survey", "title": "A Survey on Large Language Model-Based Game Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To contextualize these designs, we introduce a challenge-centered taxonomy linking six major game genres to their dominant agent requirements, from low-latency control in action games to open-ended goal formation in sandbox worlds.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0035-b0569dc894", "paper_id": "P0035", "bibkey": "Hu2024Survey", "title": "A Survey on Large Language Model-Based Game Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "A curated list of related papers is available at https://github.com/git-disl/awesome-LLM-game-agent-papers", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0035-38160fb4f4", "paper_id": "P0035", "bibkey": "Hu2024Survey", "title": "A Survey on Large Language Model-Based Game Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Game environments provide rich, controllable settings that stimulate many aspects of real-world complexity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0035-3e127f25b2", "paper_id": "P0035", "bibkey": "Hu2024Survey", "title": "A Survey on Large Language Model-Based Game Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As such, game agents offer a valuable testbed for exploring capabilities relevant to Artificial General Intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0035-f1fa9a9543", "paper_id": "P0035", "bibkey": "Hu2024Survey", "title": "A Survey on Large Language Model-Based Game Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, the emergence of Large Language Models (LLMs) provides new opportunities to endow these agents with generalizable reasoning, memory, and adaptability in complex game environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0036-f33521dfc7", "paper_id": "P0036", "bibkey": "Sun2024Survey", "title": "A Survey on Large Language Model-based Agents for Statistics and Data Science", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Furthermore, we analyze several case studies to demonstrate the practical applications of various data agents in real-world scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0036-0569f0f81b", "paper_id": "P0036", "bibkey": "Sun2024Survey", "title": "A Survey on Large Language Model-based Agents for Statistics and Data Science", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We explore current trends in the design of LLM-based frameworks, detailing essential features such as planning, reasoning, reflection, multi-agent collaboration, user interface, knowledge integration, and system design, which enable agents to address data-centric problems with minimal human intervention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0036-b7bacd5397", "paper_id": "P0036", "bibkey": "Sun2024Survey", "title": "A Survey on Large Language Model-based Agents for Statistics and Data Science", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In recent years, data science agents powered by Large Language Models (LLMs), known as \"data agents,\" have shown significant potential to transform the traditional data analysis paradigm.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0036-9c05254191", "paper_id": "P0036", "bibkey": "Sun2024Survey", "title": "A Survey on Large Language Model-based Agents for Statistics and Data Science", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey provides an overview of the evolution, capabilities, and applications of LLM-based data agents, highlighting their role in simplifying complex data tasks and lowering the entry barrier for users without related expertise.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0036-c38fb74862", "paper_id": "P0036", "bibkey": "Sun2024Survey", "title": "A Survey on Large Language Model-based Agents for Statistics and Data Science", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We explore current trends in the design of LLM-based frameworks, detailing essential features such as planning, reasoning, reflection, multi-agent collaboration, user interface, knowledge integration, and system design, which enable agents to address data-centric problems with minimal human intervention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0037-f37cede190", "paper_id": "P0037", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce a new research problem: Modularized LLM Agent Search (MoLAS).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0037-38a26e4777", "paper_id": "P0037", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0037-dca71a3ca8", "paper_id": "P0037", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in Large Language Models (LLMs) have led to a rapid growth of agentic systems capable of handling a wide range of complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0037-9dc7792507", "paper_id": "P0037", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, current research largely relies on manual, task-specific design, limiting their adaptability to novel tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0037-df54024240", "paper_id": "P0037", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce a new research problem: Modularized LLM Agent Search (MoLAS).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0037-d863729a45", "paper_id": "P0037", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose a modular design space that abstracts existing LLM agent designs into four fundamental modules with uniform IO interface: Planning, Reasoning, Tool Use, and Memory.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0037-33a25da160", "paper_id": "P0037", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Building on this design space, we present a novel LLM agent search framework called AgentSquare, which introduces two core mechanisms, i.e., module evolution and recombination, to efficiently search for optimized LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0038-2aaf9d7fde", "paper_id": "P0038", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose EHRAgent, an LLM agent empowered with a code interface, to autonomously generate and execute code for multi-tabular reasoning within electronic health records (EHRs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0038-2a7ea60588", "paper_id": "P0038", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on three real-world multi-tabular EHR datasets show that EHRAgent outperforms the strongest baseline by up to 29.6% in success rate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0038-3fd4eb3e47", "paper_id": "P0038", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have demonstrated exceptional capabilities in planning and tool utilization as autonomous agents, but few have been developed for medical problem-solving.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0038-04a0a547bf", "paper_id": "P0038", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose EHRAgent, an LLM agent empowered with a code interface, to autonomously generate and execute code for multi-tabular reasoning within electronic health records (EHRs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0038-bb81f94c2f", "paper_id": "P0038", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "First, we formulate an EHR question-answering task into a tool-use planning process, efficiently decomposing a complicated task into a sequence of manageable actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0039-c42cf712f3", "paper_id": "P0039", "bibkey": "Huang2024Understanding", "title": "Understanding the planning of LLM agents: A survey", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "As Large Language Models (LLMs) have shown significant intelligence, the progress to leverage LLMs as planning modules of autonomous agents has attracted more attention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0039-ba968b6b32", "paper_id": "P0039", "bibkey": "Huang2024Understanding", "title": "Understanding the planning of LLM agents: A survey", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Comprehensive analyses are conducted for each direction, and further challenges for the field of research are discussed.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0039-4f5a103381", "paper_id": "P0039", "bibkey": "Huang2024Understanding", "title": "Understanding the planning of LLM agents: A survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As Large Language Models (LLMs) have shown significant intelligence, the progress to leverage LLMs as planning modules of autonomous agents has attracted more attention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0039-eb9c9a3564", "paper_id": "P0039", "bibkey": "Huang2024Understanding", "title": "Understanding the planning of LLM agents: A survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey provides the first systematic view of LLM-based agents planning, covering recent works aiming to improve planning ability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0039-124466c3d9", "paper_id": "P0039", "bibkey": "Huang2024Understanding", "title": "Understanding the planning of LLM agents: A survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We provide a taxonomy of existing works on LLM-Agent planning, which can be categorized into Task Decomposition, Plan Selection, External Module, Reflection and Memory.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0040-d7953c6245", "paper_id": "P0040", "bibkey": "Jiang2023Large", "title": "Large Language Model Enhanced Multi-Agent Systems for 6G Communications", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "To this end, we propose a multi-agent system with customized communication knowledge and tools for solving communication related tasks using natural language, comprising three components: (1) Multi-agent Data Retrieval (MDR), which employs the condensate and inference agents to refine and summarize communication knowledge from the knowledge base, expanding the knowledge boundaries of LLMs in 6G communications; (2) Multi-agent Collaborative Planning (MCP), which utilizes multiple planning agents to generate feasible solutions for the communication related task from different perspectives based on the retrieved knowledge; (3) Multi-agent Evaluation and Reflecxion (MER), which utilizes the evaluation agent to assess the solutions, and applies the reflexion agent and refinement agent to provide improvement suggestions for current solutions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#method"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0040-96b056b80b", "paper_id": "P0040", "bibkey": "Jiang2023Large", "title": "Large Language Model Enhanced Multi-Agent Systems for 6G Communications", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "To this end, we propose a multi-agent system with customized communication knowledge and tools for solving communication related tasks using natural language, comprising three components: (1) Multi-agent Data Retrieval (MDR), which employs the condensate and inference agents to refine and summarize communication knowledge from the knowledge base, expanding the knowledge boundaries of LLMs in 6G communications; (2) Multi-agent Collaborative Planning (MCP), which utilizes multiple planning agents to generate feasible solutions for the communication related task from different perspectives based on the retrieved knowledge; (3) Multi-agent Evaluation and Reflecxion (MER), which utilizes the evaluation agent to assess the solutions, and applies the reflexion agent and refinement agent to provide improvement suggestions for current solutions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0040-81f2cb6ba8", "paper_id": "P0040", "bibkey": "Jiang2023Large", "title": "Large Language Model Enhanced Multi-Agent Systems for 6G Communications", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, directly applying native LLMs in 6G encounters various challenges, such as a lack of private communication data and knowledge, limited logical reasoning, evaluation, and refinement abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0040-2933ac7223", "paper_id": "P0040", "bibkey": "Jiang2023Large", "title": "Large Language Model Enhanced Multi-Agent Systems for 6G Communications", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid development of the Large Language Model (LLM) presents huge opportunities for 6G communications, e.g., network optimization and management by allowing users to input task requirements to LLMs by nature language.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0040-5b5b4bb619", "paper_id": "P0040", "bibkey": "Jiang2023Large", "title": "Large Language Model Enhanced Multi-Agent Systems for 6G Communications", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, directly applying native LLMs in 6G encounters various challenges, such as a lack of private communication data and knowledge, limited logical reasoning, evaluation, and refinement abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0040-8108211b12", "paper_id": "P0040", "bibkey": "Jiang2023Large", "title": "Large Language Model Enhanced Multi-Agent Systems for 6G Communications", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Integrating LLMs with the capabilities of retrieval, planning, memory, evaluation and reflection in agents can greatly enhance the potential of LLMs for 6G communications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0041-45937036b0", "paper_id": "P0041", "bibkey": "V2026Agentic", "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0041-6c12fbfdd5", "paper_id": "P0041", "bibkey": "V2026Agentic", "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We also group the environments in which these agents operate, including digital operating systems, embodied robotics, and other specialized domains, and we review current evaluation practices.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0041-76f9d8f373", "paper_id": "P0041", "bibkey": "V2026Agentic", "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0041-a61436b261", "paper_id": "P0041", "bibkey": "V2026Agentic", "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0041-e8b8c3caa3", "paper_id": "P0041", "bibkey": "V2026Agentic", "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This shift already supports the automation of complex workflows in software engineering, scientific discovery, and web navigation, yet the variety of emerging designs, from simple single loop agents to hierarchical multi agent systems, makes the landscape hard to navigate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0042-713156a9fe", "paper_id": "P0042", "bibkey": "Wei2026Agentic", "title": "Agentic Reasoning for Large Language Models", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0042-44dce85d3e", "paper_id": "P0042", "bibkey": "Wei2026Agentic", "title": "Agentic Reasoning for Large Language Models", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0042-32486db825", "paper_id": "P0042", "bibkey": "Wei2026Agentic", "title": "Agentic Reasoning for Large Language Models", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0042-e46bae3b74", "paper_id": "P0042", "bibkey": "Wei2026Agentic", "title": "Agentic Reasoning for Large Language Models", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0042-e6fb4c4a12", "paper_id": "P0042", "bibkey": "Wei2026Agentic", "title": "Agentic Reasoning for Large Language Models", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agentic reasoning marks a paradigm shift by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0042-c9daa66e88", "paper_id": "P0042", "bibkey": "Wei2026Agentic", "title": "Agentic Reasoning for Large Language Models", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this survey, we organize agentic reasoning along three complementary dimensions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0042-8ac0b5a370", "paper_id": "P0042", "bibkey": "Wei2026Agentic", "title": "Agentic Reasoning for Large Language Models", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "First, we characterize environmental dynamics through three layers: foundational agentic reasoning, which establishes core single-agent capabilities including planning, tool use, and search in stable environments; self-evolving agentic reasoning, which studies how agents refine these capabilities through feedback, memory, and adaptation; and collective multi-agent reasoning, which extends intelligence to collaborative settings involving coordination, knowledge sharing, and shared goals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0043-c73ca8fd16", "paper_id": "P0043", "bibkey": "Mei2025Survey", "title": "A Survey of Context Engineering for Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present a comprehensive taxonomy decomposing Context Engineering into its foundational components and the sophisticated implementations that integrate them into intelligent systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0043-79128fd675", "paper_id": "P0043", "bibkey": "Mei2025Survey", "title": "A Survey of Context Engineering for Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through this systematic analysis of over 1400 research papers, our survey not only establishes a technical roadmap for the field but also reveals a critical research gap: a fundamental asymmetry exists between model capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0043-bcd2fca24a", "paper_id": "P0043", "bibkey": "Mei2025Survey", "title": "A Survey of Context Engineering for Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The performance of Large Language Models (LLMs) is fundamentally determined by the contextual information provided during inference.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0043-e07466304c", "paper_id": "P0043", "bibkey": "Mei2025Survey", "title": "A Survey of Context Engineering for Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey introduces Context Engineering, a formal discipline that transcends simple prompt design to encompass the systematic optimization of information payloads for LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0043-6a969fec61", "paper_id": "P0043", "bibkey": "Mei2025Survey", "title": "A Survey of Context Engineering for Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present a comprehensive taxonomy decomposing Context Engineering into its foundational components and the sophisticated implementations that integrate them into intelligent systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0043-d024f02ffc", "paper_id": "P0043", "bibkey": "Mei2025Survey", "title": "A Survey of Context Engineering for Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "While current models, augmented by advanced context engineering, demonstrate remarkable proficiency in understanding complex contexts, they exhibit pronounced limitations in generating equally sophisticated, long-form outputs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0044-bd9b2efeac", "paper_id": "P0044", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Information technology has profoundly altered the way humans interact with information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0044-698effea8f", "paper_id": "P0044", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Recent advances in large language models (LLMs) have demonstrated capabilities that surpass human performance in various language-related tasks and exhibit general understanding, reasoning, and decision-making abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0044-8587764f76", "paper_id": "P0044", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Information technology has profoundly altered the way humans interact with information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0044-24e201f889", "paper_id": "P0044", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The vast amount of content created, shared, and disseminated online has made it increasingly difficult to access relevant information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0044-61fda627ce", "paper_id": "P0044", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Over the past two decades, recommender systems and search (collectively referred to as information retrieval systems) have evolved significantly to address these challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0045-b5ff728ba2", "paper_id": "P0045", "bibkey": "Hu2025Survey", "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Scientific Large Language Models (Sci-LLMs) are transforming how knowledge is represented, integrated, and applied in scientific research, yet their progress is shaped by the complex nature of scientific data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0045-af349d7214", "paper_id": "P0045", "bibkey": "Hu2025Survey", "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We systematically review recent Sci-LLMs, from general-purpose foundations to specialized models across diverse scientific disciplines, alongside an extensive analysis of over 270 pre-/post-training datasets, showing why Sci-LLMs pose distinct demands -- heterogeneous, multi-scale, uncertainty-laden corpora that require representations preserving domain invariance and enabling cross-modal reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0045-7219ca15f4", "paper_id": "P0045", "bibkey": "Hu2025Survey", "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On evaluation, we examine over 190 benchmark datasets and trace a shift from static exams toward process- and discovery-oriented assessments with advanced evaluation protocols.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0045-37b961ca17", "paper_id": "P0045", "bibkey": "Hu2025Survey", "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Scientific Large Language Models (Sci-LLMs) are transforming how knowledge is represented, integrated, and applied in scientific research, yet their progress is shaped by the complex nature of scientific data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0045-f92a970f7b", "paper_id": "P0045", "bibkey": "Hu2025Survey", "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey presents a comprehensive, data-centric synthesis that reframes the development of Sci-LLMs as a co-evolution between models and their underlying data substrate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0045-7ad9d04f00", "paper_id": "P0045", "bibkey": "Hu2025Survey", "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We formulate a unified taxonomy of scientific data and a hierarchical model of scientific knowledge, emphasizing the multimodal, cross-scale, and domain-specific challenges that differentiate scientific corpora from general natural language processing datasets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0046-a22a3fa59f", "paper_id": "P0046", "bibkey": "Park2025Survey", "title": "A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large language models (LLMs) are widely applied in chatbots, code generators, and search engines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0046-688e98b8b8", "paper_id": "P0046", "bibkey": "Park2025Survey", "title": "A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, a systematic study on inference engines is still lacking.This paper provides a comprehensive evaluation of 25 open-source and commercial inference engines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0046-93647ec277", "paper_id": "P0046", "bibkey": "Park2025Survey", "title": "A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Workload such as chain-of-throught, complex reasoning, agent services significantly increase the inference cost by invoke the model repeatedly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0046-fd384e17a9", "paper_id": "P0046", "bibkey": "Park2025Survey", "title": "A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are widely applied in chatbots, code generators, and search engines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0046-7a5e2890a8", "paper_id": "P0046", "bibkey": "Park2025Survey", "title": "A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Workload such as chain-of-throught, complex reasoning, agent services significantly increase the inference cost by invoke the model repeatedly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0046-35e2e00767", "paper_id": "P0046", "bibkey": "Park2025Survey", "title": "A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Optimization methods such as parallelism, compression, and caching have been adopted to reduce costs, but the diverse service requirements make it hard to select the right method.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0047-677bf02a8c", "paper_id": "P0047", "bibkey": "Wei2025Memguard", "title": "A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we introduce A-MemGuard (Agent-Memory Guard), the first proactive defense framework for LLM agent memory.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0047-cb9370ac71", "paper_id": "P0047", "bibkey": "Wei2025Memguard", "title": "A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Comprehensive evaluations on multiple benchmarks show that A-MemGuard effectively cuts attack success rates by over 95% while incurring a minimal utility cost.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0047-a4dcbe4147", "paper_id": "P0047", "bibkey": "Wei2025Memguard", "title": "A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Without modifying the agent's core architecture, A-MemGuard combines two mechanisms: (1) consensus-based validation, which detects anomalies by comparing reasoning paths derived from multiple related memories and (2) a dual-memory structure, where detected failures are distilled into ``lessons'' stored separately and consulted before future actions, breaking error cycles and enabling adaptation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0047-2a6e17232c", "paper_id": "P0047", "bibkey": "Wei2025Memguard", "title": "A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents use memory to learn from past interactions, enabling autonomous planning and decision-making in complex environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0047-0ec0a6c770", "paper_id": "P0047", "bibkey": "Wei2025Memguard", "title": "A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, this reliance on memory introduces a critical security risk: an adversary can inject seemingly harmless records into an agent's memory to manipulate its future behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0047-7bca145f4a", "paper_id": "P0047", "bibkey": "Wei2025Memguard", "title": "A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This vulnerability is characterized by two core aspects: First, the malicious effect of injected records is only activated within a specific context, making them hard to detect when individual memory entries are audited in isolation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "security"]}
{"evidence_id": "E-P0047-04160b253c", "paper_id": "P0047", "bibkey": "Wei2025Memguard", "title": "A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Second, once triggered, the manipulation can initiate a self-reinforcing error cycle: the corrupted outcome is stored as precedent, which not only amplifies the initial error but also progressively lowers the threshold for similar attacks in the future.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#summary_bullets[3]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0047-2454a3dbdf", "paper_id": "P0047", "bibkey": "Wei2025Memguard", "title": "A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these challenges, we introduce A-MemGuard (Agent-Memory Guard), the first proactive defense framework for LLM agent memory.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0048-7165555871", "paper_id": "P0048", "bibkey": "Kang2025Acon", "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Agent Context Optimization (ACON), a unified framework that optimally compresses both environment observations and interaction histories into concise yet informative condensations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0048-8628272498", "paper_id": "P0048", "bibkey": "Kang2025Acon", "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on AppWorld, OfficeBench, and Multi-objective QA show that ACON reduces memory usage by 26-54% (peak tokens) while largely preserving task performance, preserves over 95% of accuracy when distilled into smaller compressors, and enhances smaller LMs as long-horizon agents with up to 46% performance improvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0048-108346ac22", "paper_id": "P0048", "bibkey": "Kang2025Acon", "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large language models (LLMs) are increasingly deployed as agents in dynamic, real-world environments, where success requires both reasoning and effective tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#key_results[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0048-f12a5fafca", "paper_id": "P0048", "bibkey": "Kang2025Acon", "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are increasingly deployed as agents in dynamic, real-world environments, where success requires both reasoning and effective tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0048-5d195eea5e", "paper_id": "P0048", "bibkey": "Kang2025Acon", "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A central challenge for agentic tasks is the growing context length, as agents must accumulate long histories of actions and observations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0048-7f5cd00b5a", "paper_id": "P0048", "bibkey": "Kang2025Acon", "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This expansion raises costs and reduces efficiency in long-horizon tasks, yet prior work on context compression has mostly focused on single-step tasks or narrow applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0049-a565550b5e", "paper_id": "P0049", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we propose AgentSwift, a novel framework for automated agent design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0049-904ba35500", "paper_id": "P0049", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\\% over both existing automated agent search methods and manually designed agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0049-9d669c9af7", "paper_id": "P0049", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Current automated agent design approaches are often constrained by limited search spaces that primarily optimize workflows but fail to integrate crucial human-designed components like memory, planning, and tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#key_results[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0049-3b666704bd", "paper_id": "P0049", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents have demonstrated strong capabilities across diverse domains, yet automated agent design remains a significant challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0049-5631a9e933", "paper_id": "P0049", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current automated agent design approaches are often constrained by limited search spaces that primarily optimize workflows but fail to integrate crucial human-designed components like memory, planning, and tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0049-7fa82de592", "paper_id": "P0049", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Furthermore, these methods are hampered by high evaluation costs, as evaluating even a single new agent on a benchmark can require tens of dollars.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0050-4a05e5c477", "paper_id": "P0050", "bibkey": "Jiang2025Agentic", "title": "Agentic Software Issue Resolution with Large Language Models: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Software issue resolution aims to address real-world issues in software repositories (e.g., bug fixing and efficiency optimization) based on natural language descriptions provided by users, representing a key aspect of software maintenance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0050-5f1fb8803e", "paper_id": "P0050", "bibkey": "Jiang2025Agentic", "title": "Agentic Software Issue Resolution with Large Language Models: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This work presents a systematic survey of 126 recent studies at the forefront of LLM-based agentic software issue resolution research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0050-f38be5e04b", "paper_id": "P0050", "bibkey": "Jiang2025Agentic", "title": "Agentic Software Issue Resolution with Large Language Models: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "It outlines the general workflow of the task and establishes a taxonomy across three dimensions: benchmarks, techniques, and empirical studies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0050-b6b65960a3", "paper_id": "P0050", "bibkey": "Jiang2025Agentic", "title": "Agentic Software Issue Resolution with Large Language Models: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Software issue resolution aims to address real-world issues in software repositories (e.g., bug fixing and efficiency optimization) based on natural language descriptions provided by users, representing a key aspect of software maintenance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0050-570b4cedd6", "paper_id": "P0050", "bibkey": "Jiang2025Agentic", "title": "Agentic Software Issue Resolution with Large Language Models: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the rapid development of large language models (LLMs) in reasoning and generative capabilities, LLM-based approaches have made significant progress in automated software issue resolution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0050-abef316504", "paper_id": "P0050", "bibkey": "Jiang2025Agentic", "title": "Agentic Software Issue Resolution with Large Language Models: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, real-world software issue resolution is inherently complex and requires long-horizon reasoning, iterative exploration, and feedback-driven decision making, which demand agentic capabilities beyond conventional single-step approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0051-4ef4e06ede", "paper_id": "P0051", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose HexMachina, a continual learning multi-agent system that separates environment discovery (inducing an adapter layer without documentation) from strategy improvement (evolving a compiled player through code refinement and simulation).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0051-7929ef7a56", "paper_id": "P0051", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In controlled Catanatron experiments, HexMachina learns from scratch and evolves players that outperform the strongest human-crafted baseline (AlphaBeta), achieving a 54% win rate and surpassing prompt-driven and no-discovery baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0051-eae2720c71", "paper_id": "P0051", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Settlers of Catan provides a challenging benchmark: success depends on balancing short- and long-term goals amid randomness, trading, expansion, and blocking.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0051-c9e00a13bf", "paper_id": "P0051", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We address the long-horizon gap in large language model (LLM) agents by enabling them to sustain coherent strategies in adversarial, stochastic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0051-cecd47b994", "paper_id": "P0051", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Settlers of Catan provides a challenging benchmark: success depends on balancing short- and long-term goals amid randomness, trading, expansion, and blocking.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0051-ab714c0ab3", "paper_id": "P0051", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Prompt-centric LLM agents (e.g., ReAct, Reflexion) must re-interpret large, evolving game states each turn, quickly saturating context windows and losing strategic consistency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0052-003a387b7d", "paper_id": "P0052", "bibkey": "Liu2025Aligning", "title": "Aligning LLM agents with human learning and adjustment behavior: a dual agent approach", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Building on this, we introduce a novel dual-agent framework that enables continuous learning and alignment between LLM agents and human travelers on learning and adaptation behavior from online data streams.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0052-17093ccc31", "paper_id": "P0052", "bibkey": "Liu2025Aligning", "title": "Aligning LLM agents with human learning and adjustment behavior: a dual agent approach", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Effective modeling of how human travelers learn and adjust their travel behavior from interacting with transportation systems is critical for system assessment and planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0052-96cf9ff5bf", "paper_id": "P0052", "bibkey": "Liu2025Aligning", "title": "Aligning LLM agents with human learning and adjustment behavior: a dual agent approach", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Building on this, we introduce a novel dual-agent framework that enables continuous learning and alignment between LLM agents and human travelers on learning and adaptation behavior from online data streams.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0052-b3a6043ca0", "paper_id": "P0052", "bibkey": "Liu2025Aligning", "title": "Aligning LLM agents with human learning and adjustment behavior: a dual agent approach", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Effective modeling of how human travelers learn and adjust their travel behavior from interacting with transportation systems is critical for system assessment and planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0052-24355878fd", "paper_id": "P0052", "bibkey": "Liu2025Aligning", "title": "Aligning LLM agents with human learning and adjustment behavior: a dual agent approach", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, this task is also difficult due to the complex cognition and decision-making involved in such behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0052-5a2846c2f9", "paper_id": "P0052", "bibkey": "Liu2025Aligning", "title": "Aligning LLM agents with human learning and adjustment behavior: a dual agent approach", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent research has begun to leverage Large Language Model (LLM) agents for this task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0053-f5791417c7", "paper_id": "P0053", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Audio-Language Models (LALMs) perform well on audio understanding tasks but lack multi-step reasoning and tool-calling found in recent Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0053-e31e41085b", "paper_id": "P0053", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments with MMAU, MMAR, and MMAU-Pro show state-of-the-art accuracy: up to 74.10% on MMAU, 68.80% on MMAR, and 57.96% on MMAU-Pro.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0053-de509152db", "paper_id": "P0053", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Monte Carlo sampling for shapley values across 374 configurations identifies effective agent-tool combinations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0053-3c246cb9dc", "paper_id": "P0053", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Audio-Language Models (LALMs) perform well on audio understanding tasks but lack multi-step reasoning and tool-calling found in recent Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0053-eefd7f1aeb", "paper_id": "P0053", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents AudioToolAgent, a framework that coordinates audio-language models as tools via a central LLM agent that accesses tool adapters for audio question answering and speech-to-text.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0053-9505dec385", "paper_id": "P0053", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The agent selects tools, asks follow-up questions, and compares outputs for verification.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0054-682a68866c", "paper_id": "P0054", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose AutoTool, a novel graph-based framework that bypasses repeated LLM inference by exploiting a key empirical observation: tool usage inertia - the tendency of tool invocations to follow predictable sequential patterns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0054-d3344c79dc", "paper_id": "P0054", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments across diverse agent tasks demonstrate that AutoTool reduces inference costs by up to 30% while maintaining competitive task completion rates, offering a practical and scalable enhancement for inference-heavy frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0054-3f62ff9f3a", "paper_id": "P0054", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents have emerged as powerful tools for automating complex tasks by leveraging the reasoning and decision-making abilities of LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0054-7674242cfe", "paper_id": "P0054", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, a major bottleneck in current agent frameworks lies in the high inference cost of tool selection, especially in approaches like ReAct that repeatedly invoke the LLM to determine which tool to use at each step.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0054-7a8afd3d87", "paper_id": "P0054", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we propose AutoTool, a novel graph-based framework that bypasses repeated LLM inference by exploiting a key empirical observation: tool usage inertia - the tendency of tool invocations to follow predictable sequential patterns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0055-09f2e56422", "paper_id": "P0055", "bibkey": "Nusrat2025Automated", "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0055-c6c63e4ab5", "paper_id": "P0055", "bibkey": "Nusrat2025Automated", "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) while reducing cochlear dose below human baselines (p = 0.022).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0055-71f2629f1b", "paper_id": "P0055", "bibkey": "Nusrat2025Automated", "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0055-a1ae33c16c", "paper_id": "P0055", "bibkey": "Nusrat2025Automated", "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0055-98affd04d7", "paper_id": "P0055", "bibkey": "Nusrat2025Automated", "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0055-0f1a9aa069", "paper_id": "P0055", "bibkey": "Nusrat2025Automated", "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0055-2a7f633cbb", "paper_id": "P0055", "bibkey": "Nusrat2025Automated", "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Two variants generated plans for each case: one using a non-reasoning model, one using a reasoning model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0055-75d4571f3c", "paper_id": "P0055", "bibkey": "Nusrat2025Automated", "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) while reducing cochlear dose below human baselines (p = 0.022).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0056-4b1ab22641", "paper_id": "P0056", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Second, we propose GradleFixer, an LLM agent with domain-specific tools for inspecting and manipulating the Gradle build environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0056-858f86ac9c", "paper_id": "P0056", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To address this gap, we first introduce AndroidBuildBench, a benchmark of 1,019 build failures curated from the commit histories of 43 open-source Android projects.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0056-852023ec1e", "paper_id": "P0056", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "GradleFixer achieves a resolve rate of 81.4% (pass@1), significantly outperforming a state-of-the-art coding agent that relies on a general-purpose shell.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0056-f3d4ecad3b", "paper_id": "P0056", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Android is the largest mobile platform, yet automatically building applications remains a practical challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0056-cb5f194b20", "paper_id": "P0056", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While Large Language Models (LLMs) show promise for code repair, their use for fixing Android build errors remains underexplored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0056-7686ac87f9", "paper_id": "P0056", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, we first introduce AndroidBuildBench, a benchmark of 1,019 build failures curated from the commit histories of 43 open-source Android projects.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0057-ff86c61e7c", "paper_id": "P0057", "bibkey": "Nusrat2025Autonomous", "title": "Autonomous Radiotherapy Treatment Planning Using DOLA: A Privacy-Preserving, LLM-Based Optimization Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we introduce Dose Optimization Language Agent (DOLA), an autonomous large language model (LLM)-based agent designed for optimizing radiotherapy treatment plans while rigorously protecting patient privacy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0057-ab51cf100e", "paper_id": "P0057", "bibkey": "Nusrat2025Autonomous", "title": "Autonomous Radiotherapy Treatment Planning Using DOLA: A Privacy-Preserving, LLM-Based Optimization Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "DOLA integrates the LLaMa3.1 LLM directly with a commercial treatment planning system, utilizing chain-of-thought prompting, retrieval-augmented generation (RAG), and reinforcement learning (RL).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0057-69aac09ee4", "paper_id": "P0057", "bibkey": "Nusrat2025Autonomous", "title": "Autonomous Radiotherapy Treatment Planning Using DOLA: A Privacy-Preserving, LLM-Based Optimization Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluated DOLA using a retrospective cohort of 18 prostate cancer patients prescribed 60 Gy in 20 fractions, comparing model sizes (8 billion vs. 70 billion parameters) and optimization strategies (No-RAG, RAG, and RAG+RL) over 10 planning iterations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0057-982a1814a7", "paper_id": "P0057", "bibkey": "Nusrat2025Autonomous", "title": "Autonomous Radiotherapy Treatment Planning Using DOLA: A Privacy-Preserving, LLM-Based Optimization Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Radiotherapy treatment planning is a complex and time-intensive process, often impacted by inter-planner variability and subjective decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0057-257a956b71", "paper_id": "P0057", "bibkey": "Nusrat2025Autonomous", "title": "Autonomous Radiotherapy Treatment Planning Using DOLA: A Privacy-Preserving, LLM-Based Optimization Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these challenges, we introduce Dose Optimization Language Agent (DOLA), an autonomous large language model (LLM)-based agent designed for optimizing radiotherapy treatment plans while rigorously protecting patient privacy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0057-dd275d9979", "paper_id": "P0057", "bibkey": "Nusrat2025Autonomous", "title": "Autonomous Radiotherapy Treatment Planning Using DOLA: A Privacy-Preserving, LLM-Based Optimization Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "DOLA integrates the LLaMa3.1 LLM directly with a commercial treatment planning system, utilizing chain-of-thought prompting, retrieval-augmented generation (RAG), and reinforcement learning (RL).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0058-c8895eaeab", "paper_id": "P0058", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Model (LLM) agents face security vulnerabilities spanning AI-specific and traditional software domains, yet current research addresses these separately.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0058-8e34a29629", "paper_id": "P0058", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "security", "tooling"]}
{"evidence_id": "E-P0058-8a2c2e2291", "paper_id": "P0058", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Attack complexity dramatically amplified effectiveness, with chained attacks achieving 91-96% success rates.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "security"]}
{"evidence_id": "E-P0058-2a59b6d5bc", "paper_id": "P0058", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents face security vulnerabilities spanning AI-specific and traditional software domains, yet current research addresses these separately.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0058-2333abf508", "paper_id": "P0058", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study bridges this gap through comparative evaluation of Function Calling architecture and Model Context Protocol (MCP) deployment paradigms using a unified threat classification framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0058-26646f7a50", "paper_id": "P0058", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We tested 3,250 attack scenarios across seven language models, evaluating simple, composed, and chained attacks targeting both AI-specific threats (prompt injection) and software vulnerabilities (JSON injection, denial-of-service).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0058-c6d60c7b44", "paper_id": "P0058", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers", "security", "tooling"]}
{"evidence_id": "E-P0058-a96843d7f0", "paper_id": "P0058", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Attack complexity dramatically amplified effectiveness, with chained attacks achieving 91-96% success rates.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers", "security"]}
{"evidence_id": "E-P0059-6716c8d937", "paper_id": "P0059", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The ability to coordinate actions across multiple agents is critical for solving complex, real-world problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0059-b35b53de13", "paper_id": "P0059", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We systematically evaluate their performance using a suite of coordination-sensitive metrics, including task success rate, redundant actions, room conflicts, and urgency-weighted efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0059-baa622fa7f", "paper_id": "P0059", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This study offers new insights into the strengths and failure modes of LLMs in physically grounded multi-agent collaboration tasks, contributing to future benchmarks and architectural improvements.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0059-2dfd2491a4", "paper_id": "P0059", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The ability to coordinate actions across multiple agents is critical for solving complex, real-world problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0059-66af67b58a", "paper_id": "P0059", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have shown strong capabilities in communication, planning, and reasoning, raising the question of whether they can also support effective collaboration in multi-agent settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0059-e886e27049", "paper_id": "P0059", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we investigate the use of LLM agents to solve a structured victim rescue task that requires division of labor, prioritization, and cooperative planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0060-4702cb10b5", "paper_id": "P0060", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we present a novel diagnostic framework that integrates Knowledge Graphs (KGs) and Large Language Models (LLMs) to support system diagnostics in high-reliability systems such as nuclear power plants.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0060-f10376c14d", "paper_id": "P0060", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "A case study on an auxiliary feedwater system demonstrated the framework's effectiveness, with over 90% accuracy in key elements and consistent tool and argument extraction, supporting its use in safety-critical diagnostics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0060-434724f85d", "paper_id": "P0060", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we present a novel diagnostic framework that integrates Knowledge Graphs (KGs) and Large Language Models (LLMs) to support system diagnostics in high-reliability systems such as nuclear power plants.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0060-67e23ab509", "paper_id": "P0060", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional diagnostic modeling struggles when systems become too complex, making functional modeling a more attractive approach.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0060-ffc84de302", "paper_id": "P0060", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our approach introduces a diagnostic framework grounded in the functional modeling principles of the Dynamic Master Logic (DML) model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0061-3c9791fc6e", "paper_id": "P0061", "bibkey": "Zhao2025Connecting", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we propose Cochain, a collaboration prompting framework that effectively solves business workflow collaboration problem by combining knowledge and prompts at a reduced cost.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0061-5621a1353b", "paper_id": "P0061", "bibkey": "Zhao2025Connecting", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Additionally, expert evaluation results indicate that the use of a small model in combination with Cochain outperforms GPT-4.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0061-0f7f5c9804", "paper_id": "P0061", "bibkey": "Zhao2025Connecting", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We perform extensive evaluations of Cochain across multiple datasets, demonstrating that Cochain outperforms all baselines in both prompt engineering and multi-agent LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0061-82fa8c4398", "paper_id": "P0061", "bibkey": "Zhao2025Connecting", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have demonstrated impressive performance in executing complex reasoning tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0061-ff6062abed", "paper_id": "P0061", "bibkey": "Zhao2025Connecting", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Chain-of-thought effectively enhances reasoning capabilities by unlocking the potential of large models, while multi-agent systems provide more comprehensive solutions by integrating collective intelligence of multiple agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0061-fea88e9b0c", "paper_id": "P0061", "bibkey": "Zhao2025Connecting", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, both approaches face significant limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0061-f5921ca1c2", "paper_id": "P0061", "bibkey": "Zhao2025Connecting", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "However, both approaches face significant limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0062-a31f0ec9cd", "paper_id": "P0062", "bibkey": "Hu2025Evaluating", "title": "Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce MemoryAgentBench, a new benchmark specifically designed for memory agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0062-0d56c76ce0", "paper_id": "P0062", "bibkey": "Hu2025Evaluating", "title": "Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Recent benchmarks for Large Language Model (LLM) agents primarily focus on evaluating reasoning, planning, and execution capabilities, while another critical component-memory, encompassing how agents memorize, update, and retrieve long-term information-is under-evaluated due to the lack of benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0062-86184d0d44", "paper_id": "P0062", "bibkey": "Hu2025Evaluating", "title": "Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Existing benchmarks either rely on limited context lengths or are tailored for static, long-context settings like book-based QA, which do not reflect the interactive, multi-turn nature of memory agents that incrementally accumulate information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0062-609d2e78aa", "paper_id": "P0062", "bibkey": "Hu2025Evaluating", "title": "Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent benchmarks for Large Language Model (LLM) agents primarily focus on evaluating reasoning, planning, and execution capabilities, while another critical component-memory, encompassing how agents memorize, update, and retrieve long-term information-is under-evaluated due to the lack of benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0062-1d6a285239", "paper_id": "P0062", "bibkey": "Hu2025Evaluating", "title": "Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We term agents with memory mechanisms as memory agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0062-5c2be3ecb2", "paper_id": "P0062", "bibkey": "Hu2025Evaluating", "title": "Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, based on classic theories from memory science and cognitive science, we identify four core competencies essential for memory agents: accurate retrieval, test-time learning, long-range understanding, and selective forgetting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0063-dfa68f923b", "paper_id": "P0063", "bibkey": "Xu2025Forewarned", "title": "Forewarned is Forearmed: A Survey on Large Language Model-based Agents in Autonomous Cyberattacks", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Firstly, we present the capabilities of LLM-based cyberattack agents, which include executing autonomous attack strategies, comprising scouting, memory, reasoning, and action, and facilitating collaborative operations with other agents or human operators.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#method"}, "confidence": "medium", "tags": ["memory", "security"]}
{"evidence_id": "E-P0063-8b2f45e170", "paper_id": "P0063", "bibkey": "Xu2025Forewarned", "title": "Forewarned is Forearmed: A Survey on Large Language Model-based Agents in Autonomous Cyberattacks", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Firstly, we present the capabilities of LLM-based cyberattack agents, which include executing autonomous attack strategies, comprising scouting, memory, reasoning, and action, and facilitating collaborative operations with other agents or human operators.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#key_results[0]"}, "confidence": "medium", "tags": ["memory", "security"]}
{"evidence_id": "E-P0063-54f2631ac3", "paper_id": "P0063", "bibkey": "Xu2025Forewarned", "title": "Forewarned is Forearmed: A Survey on Large Language Model-based Agents in Autonomous Cyberattacks", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "By significantly reducing the time, expertise, and resources, AI-assisted cyberattacks orchestrated by LLM-based agents have led to a phenomenon termed Cyber Threat Inflation, characterized by a significant reduction in attack costs and a tremendous increase in attack scale.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#key_results[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0063-b3163a68d4", "paper_id": "P0063", "bibkey": "Xu2025Forewarned", "title": "Forewarned is Forearmed: A Survey on Large Language Model-based Agents in Autonomous Cyberattacks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the continuous evolution of Large Language Models (LLMs), LLM-based agents have advanced beyond passive chatbots to become autonomous cyber entities capable of performing complex tasks, including web browsing, malicious code and deceptive content generation, and decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0063-ee0fc406e3", "paper_id": "P0063", "bibkey": "Xu2025Forewarned", "title": "Forewarned is Forearmed: A Survey on Large Language Model-based Agents in Autonomous Cyberattacks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By significantly reducing the time, expertise, and resources, AI-assisted cyberattacks orchestrated by LLM-based agents have led to a phenomenon termed Cyber Threat Inflation, characterized by a significant reduction in attack costs and a tremendous increase in attack scale.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0063-8170e33deb", "paper_id": "P0063", "bibkey": "Xu2025Forewarned", "title": "Forewarned is Forearmed: A Survey on Large Language Model-based Agents in Autonomous Cyberattacks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To provide actionable defensive insights, in this survey, we focus on the potential cyber threats posed by LLM-based agents across diverse network systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0064-ba2296b38e", "paper_id": "P0064", "bibkey": "Li2025Graphcodeagent", "title": "GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this challenge, we propose GraphCodeAgent, a dual graph-guided LLM agent for retrieval-augmented repo-level code generation, bridging the gap between NL requirements and programming implementations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0064-d568c53e1d", "paper_id": "P0064", "bibkey": "Li2025Graphcodeagent", "title": "GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluated GraphCodeAgent on three advanced LLMs with the two widely-used repo-level code generation benchmarks DevEval and CoderEval.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0064-b4ffe74009", "paper_id": "P0064", "bibkey": "Li2025Graphcodeagent", "title": "GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiment results show that GraphCodeAgent significantly outperforms state-of-the-art baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0064-e124a9d46d", "paper_id": "P0064", "bibkey": "Li2025Graphcodeagent", "title": "GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Writing code requires significant time and effort in software development.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0064-2b0173ae88", "paper_id": "P0064", "bibkey": "Li2025Graphcodeagent", "title": "GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To automate this process, researchers have made substantial progress for code generation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0064-72b6664644", "paper_id": "P0064", "bibkey": "Li2025Graphcodeagent", "title": "GraphCodeAgent: Dual Graph-Guided LLM Agent for Retrieval-Augmented Repo-Level Code Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, large language models (LLMs) have demonstrated remarkable proficiency in function-level code generation, yet their performance significantly degrades in the real-world software development process, where coding tasks are deeply embedded within specific repository contexts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0065-5a596646fe", "paper_id": "P0065", "bibkey": "Gupta2025Hierrouter", "title": "HierRouter: Coordinated Routing of Specialized Large Language Models via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this, we propose HierRouter, a hierarchical routing approach that dynamically assembles inference pipelines from a pool of specialized, lightweight language models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0065-25aedb5918", "paper_id": "P0065", "bibkey": "Gupta2025Hierrouter", "title": "HierRouter: Coordinated Routing of Specialized Large Language Models via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments with three open-source candidate LLMs across six benchmarks, including QA, code generation, and mathematical reasoning, show that HierRouter improves response quality by up to 2.4x compared to using individual models independently, while incurring only a minimal additional inference cost on average.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0065-37cd1bf602", "paper_id": "P0065", "bibkey": "Gupta2025Hierrouter", "title": "HierRouter: Coordinated Routing of Specialized Large Language Models via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large Language Models (LLMs) deliver state-of-the-art performance across many tasks but impose high computational and memory costs, limiting their deployment in resource-constrained or real-time settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#key_results[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0065-8439ef589d", "paper_id": "P0065", "bibkey": "Gupta2025Hierrouter", "title": "HierRouter: Coordinated Routing of Specialized Large Language Models via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) deliver state-of-the-art performance across many tasks but impose high computational and memory costs, limiting their deployment in resource-constrained or real-time settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0065-45423781b6", "paper_id": "P0065", "bibkey": "Gupta2025Hierrouter", "title": "HierRouter: Coordinated Routing of Specialized Large Language Models via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this, we propose HierRouter, a hierarchical routing approach that dynamically assembles inference pipelines from a pool of specialized, lightweight language models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0065-b874828f39", "paper_id": "P0065", "bibkey": "Gupta2025Hierrouter", "title": "HierRouter: Coordinated Routing of Specialized Large Language Models via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Formulated as a finite-horizon Markov Decision Process (MDP), our approach trains a Proximal Policy Optimization (PPO)-based reinforcement learning agent to iteratively select which models to invoke at each stage of multi-hop inference.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0066-b034d6bcfb", "paper_id": "P0066", "bibkey": "Yin2025Infobid", "title": "InfoBid: A Simulation Framework for Studying Information Disclosure in Auctions with Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we introduce InfoBid, a flexible simulation framework that leverages LLM agents to examine the effects of information disclosure strategies in multi-agent auction settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0066-719c0f09ca", "paper_id": "P0066", "bibkey": "Yin2025Infobid", "title": "InfoBid: A Simulation Framework for Studying Information Disclosure in Auctions with Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The recent emergence of large language models (LLMs) offers a novel approach to simulations, providing human-like reasoning and adaptability without necessarily relying on explicit assumptions about agent behavior modeling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0066-238795b88e", "paper_id": "P0066", "bibkey": "Yin2025Infobid", "title": "InfoBid: A Simulation Framework for Studying Information Disclosure in Auctions with Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through InfoBid, we hope to foster the use of LLMs as proxies for human economic and social agents in empirical studies, enhancing our understanding of their capabilities and limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0066-5a4ac1a732", "paper_id": "P0066", "bibkey": "Yin2025Infobid", "title": "InfoBid: A Simulation Framework for Studying Information Disclosure in Auctions with Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In online advertising systems, publishers often face a trade-off in information disclosure strategies: while disclosing more information can enhance efficiency by enabling optimal allocation of ad impressions, it may lose revenue potential by decreasing uncertainty among competing advertisers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0066-778d58bd1c", "paper_id": "P0066", "bibkey": "Yin2025Infobid", "title": "InfoBid: A Simulation Framework for Studying Information Disclosure in Auctions with Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Similar to other challenges in market design, understanding this trade-off is constrained by limited access to real-world data, leading researchers and practitioners to turn to simulation frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0066-22d346a018", "paper_id": "P0066", "bibkey": "Yin2025Infobid", "title": "InfoBid: A Simulation Framework for Studying Information Disclosure in Auctions with Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The recent emergence of large language models (LLMs) offers a novel approach to simulations, providing human-like reasoning and adaptability without necessarily relying on explicit assumptions about agent behavior modeling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0066-fd6f502318", "paper_id": "P0066", "bibkey": "Yin2025Infobid", "title": "InfoBid: A Simulation Framework for Studying Information Disclosure in Auctions with Large Language Model-based Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Through InfoBid, we hope to foster the use of LLMs as proxies for human economic and social agents in empirical studies, enhancing our understanding of their capabilities and limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0067-a265c55160", "paper_id": "P0067", "bibkey": "Geng2025Insuragent", "title": "InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Flood insurance is an effective strategy for individuals to mitigate disaster-related losses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0067-fb2f69c292", "paper_id": "P0067", "bibkey": "Geng2025Insuragent", "title": "InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large language models (LLMs) have recently exhibited human-like intelligence across wide-ranging tasks, offering promising tools for simulating human decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0067-97906ac93c", "paper_id": "P0067", "bibkey": "Geng2025Insuragent", "title": "InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This study constructs a benchmark dataset to capture insurance purchase probabilities across factors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0067-1013d8ead3", "paper_id": "P0067", "bibkey": "Geng2025Insuragent", "title": "InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Flood insurance is an effective strategy for individuals to mitigate disaster-related losses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0067-83421b91b2", "paper_id": "P0067", "bibkey": "Geng2025Insuragent", "title": "InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, participation rates among at-risk populations in the United States remain strikingly low.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0067-cf1544526f", "paper_id": "P0067", "bibkey": "Geng2025Insuragent", "title": "InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This gap underscores the need to understand and model the behavioral mechanisms underlying insurance decisions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0067-635c896bcd", "paper_id": "P0067", "bibkey": "Geng2025Insuragent", "title": "InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address this limitation, InsurAgent, an LLM-empowered agent comprising five modules including perception, retrieval, reasoning, action, and memory, is proposed.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#limitations[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0068-044d4e6a4e", "paper_id": "P0068", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We study the resulting open-ended agent qualitatively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0068-b3caa17225", "paper_id": "P0068", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "These findings illustrate both the promise and current limits of adapting pretrained LLMs toward open-endedness, and point to future directions for training agents to manage memory, explore productively, and pursue abstract long-term goals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#key_results[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0068-a49a564488", "paper_id": "P0068", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent LLM agents have made great use of chain of thought reasoning and function calling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0068-eff3ad7b6b", "paper_id": "P0068", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As their capabilities grow, an important question arises: can this software represent not only a smart problem-solving tool, but an entity in its own right, that can plan, design immediate tasks, and reason toward broader, more ambiguous goals?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0068-cebb3ed2a1", "paper_id": "P0068", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To study this question, we adopt an open-ended experimental setting where we augment a pretrained LLM agent with the ability to generate its own tasks, accumulate knowledge, and interact extensively with its environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0069-e8a109886f", "paper_id": "P0069", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Models (LLMs) have garnered significant attention for several years now.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0069-597439cd1d", "paper_id": "P0069", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We then apply the same strategy to show that LLM agents can explore, discover, and exploit diverse chemical interactions in an advanced Atomic Layer Processing reactor simulation using intentionally limited probe capabilities without explicit instructions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0069-38aee336c0", "paper_id": "P0069", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have garnered significant attention for several years now.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0069-359710b235", "paper_id": "P0069", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, their use as independently reasoning agents has been proposed.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0069-65afe8ae85", "paper_id": "P0069", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we test the potential of such agents for knowledge discovery in materials science.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0070-70e34320d5", "paper_id": "P0070", "bibkey": "Zahedifar2025Agent", "title": "LLM-Agent-Controller: A Universal Multi-Agent Large Language Model System as a Control Engineer", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To evaluate the system, we propose new performance metrics assessing both individual agents and the system as a whole.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0070-ebcb5ebf6c", "paper_id": "P0070", "bibkey": "Zahedifar2025Agent", "title": "LLM-Agent-Controller: A Universal Multi-Agent Large Language Model System as a Control Engineer", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Results show that the LLM-Agent-Controller successfully solved 83% of general tasks, with individual agents achieving an average success rate of 87%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0070-0f34c44fa9", "paper_id": "P0070", "bibkey": "Zahedifar2025Agent", "title": "LLM-Agent-Controller: A Universal Multi-Agent Large Language Model System as a Control Engineer", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To evaluate the system, we propose new performance metrics assessing both individual agents and the system as a whole.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0070-4ac460f4f6", "paper_id": "P0070", "bibkey": "Zahedifar2025Agent", "title": "LLM-Agent-Controller: A Universal Multi-Agent Large Language Model System as a Control Engineer", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study presents the LLM-Agent-Controller, a multi-agent large language model (LLM) system developed to address a wide range of problems in control engineering (Control Theory).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0070-6841fa5358", "paper_id": "P0070", "bibkey": "Zahedifar2025Agent", "title": "LLM-Agent-Controller: A Universal Multi-Agent Large Language Model System as a Control Engineer", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The system integrates a central controller agent with multiple specialized auxiliary agents, responsible for tasks such as controller design, model representation, control analysis, time-domain response, and simulation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0070-56bdb2a4c3", "paper_id": "P0070", "bibkey": "Zahedifar2025Agent", "title": "LLM-Agent-Controller: A Universal Multi-Agent Large Language Model System as a Control Engineer", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A supervisor oversees high-level decision-making and workflow coordination, enhancing the system's reliability and efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0071-ee97f26020", "paper_id": "P0071", "bibkey": "Zou2025Based", "title": "LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Recent advances in large language models (LLMs) have sparked growing interest in building fully autonomous agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0071-2bdfa7c6c0", "paper_id": "P0071", "bibkey": "Zou2025Based", "title": "LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To overcome these limitations, LLM-based human-agent systems (LLM-HAS) incorporate human-provided information, feedback, or control into the agent system to enhance system performance, reliability and safety.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0071-dda50c4c55", "paper_id": "P0071", "bibkey": "Zou2025Based", "title": "LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "These human-agent collaboration systems enable humans and LLM-based agents to collaborate effectively by leveraging their complementary strengths.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#key_results[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0071-fc199ca512", "paper_id": "P0071", "bibkey": "Zou2025Based", "title": "LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in large language models (LLMs) have sparked growing interest in building fully autonomous agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0071-e2db62cf57", "paper_id": "P0071", "bibkey": "Zou2025Based", "title": "LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, fully autonomous LLM-based agents still face significant challenges, including limited reliability due to hallucinations, difficulty in handling complex tasks, and substantial safety and ethical risks, all of which limit their feasibility and trustworthiness in real-world applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0071-8b8906016a", "paper_id": "P0071", "bibkey": "Zou2025Based", "title": "LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To overcome these limitations, LLM-based human-agent systems (LLM-HAS) incorporate human-provided information, feedback, or control into the agent system to enhance system performance, reliability and safety.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0071-9a8a480e9c", "paper_id": "P0071", "bibkey": "Zou2025Based", "title": "LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To overcome these limitations, LLM-based human-agent systems (LLM-HAS) incorporate human-provided information, feedback, or control into the agent system to enhance system performance, reliability and safety.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0072-49822b305c", "paper_id": "P0072", "bibkey": "Sun2025Guided", "title": "LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we propose to model each homogeneous traveler group facing the same decision context with a single representative LLM agent who behaves like the population's average, maintaining and updating a mixed strategy over routes that coincides with the group's aggregate flow proportions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0072-298fc52f21", "paper_id": "P0072", "bibkey": "Sun2025Guided", "title": "LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In richer settings with income heterogeneity, multi-criteria costs, and multi-modal choices, the generated dynamics remain stable and interpretable, reproducing plausible behavioral patterns well-documented in psychology and economics, for example, the decoy effect in toll versus non-toll road selection, and higher willingness-to-pay for convenience among higher-income travelers when choosing between driving, transit, and park-and-ride options.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0072-9b739854f0", "paper_id": "P0072", "bibkey": "Sun2025Guided", "title": "LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are increasingly used as behavioral proxies for self-interested travelers in agent-based traffic models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0072-c629bfddf4", "paper_id": "P0072", "bibkey": "Sun2025Guided", "title": "LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Although more flexible and generalizable than conventional models, the practical use of these approaches remains limited by scalability due to the cost of calling one LLM for every traveler.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0072-2fc33d0e5c", "paper_id": "P0072", "bibkey": "Sun2025Guided", "title": "LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Moreover, it has been found that LLM agents often make opaque choices and produce unstable day-to-day dynamics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0073-bbaca264f1", "paper_id": "P0073", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large language models (LLMs) and agent techniques have brought a fundamental shift in the functionality and development paradigm of data analysis tasks (a.k.a LLM/Agent-as-Data-Analyst), demonstrating substantial impact across both academia and industry.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0073-db233dcd06", "paper_id": "P0073", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we outline the remaining challenges and propose several insights and practical directions for advancing LLM/Agent-powered data analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0073-4e35a5103c", "paper_id": "P0073", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) and agent techniques have brought a fundamental shift in the functionality and development paradigm of data analysis tasks (a.k.a LLM/Agent-as-Data-Analyst), demonstrating substantial impact across both academia and industry.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0073-d66e2031cc", "paper_id": "P0073", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In comparison with traditional rule or small-model based approaches, (agentic) LLMs enable complex data understanding, natural language interfaces, semantic analysis functions, and autonomous pipeline orchestration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0073-a4245dcbb7", "paper_id": "P0073", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "From a modality perspective, we review LLM-based techniques for (i) structured data (e.g., NL2SQL, NL2GQL, ModelQA), (ii) semi-structured data (e.g., markup languages understanding, semi-structured table question answering), (iii) unstructured data (e.g., chart understanding, text/image document understanding), and (iv) heterogeneous data (e.g., data retrieval and modality alignment in data lakes).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0074-7cdfbf595a", "paper_id": "P0074", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The era of intelligent agents is upon us, driven by revolutionary advancements in large language models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0074#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0074-62cd0c501b", "paper_id": "P0074", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our work provides a unified architectural perspective, examining how agents are constructed, how they collaborate, and how they evolve over time, while also addressing evaluation methodologies, tool applications, practical challenges, and diverse application domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0074#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0074-65aa5a8555", "paper_id": "P0074", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The era of intelligent agents is upon us, driven by revolutionary advancements in large language models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0074#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0074-8447fe66ad", "paper_id": "P0074", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents, with goal-driven behaviors and dynamic adaptation capabilities, potentially represent a critical pathway toward artificial general intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0074#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0074-a47c55035c", "paper_id": "P0074", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey systematically deconstructs LLM agent systems through a methodology-centered taxonomy, linking architectural foundations, collaboration mechanisms, and evolutionary pathways.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0074#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0075-36d25f4f71", "paper_id": "P0075", "bibkey": "Han2025Large", "title": "Large Language Model Powered Intelligent Urban Agents: Concepts, Capabilities, and Applications", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "First, we introduce the concept of urban LLM agents, discussing their unique capabilities and features.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0075-fedc33d121", "paper_id": "P0075", "bibkey": "Han2025Large", "title": "Large Language Model Powered Intelligent Urban Agents: Concepts, Capabilities, and Applications", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we discuss trustworthiness and evaluation issues that are critical for real-world deployment, and identify several open problems for future research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0075-f7e72b349b", "paper_id": "P0075", "bibkey": "Han2025Large", "title": "Large Language Model Powered Intelligent Urban Agents: Concepts, Capabilities, and Applications", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The long-standing vision of intelligent cities is to create efficient, livable, and sustainable urban environments using big data and artificial intelligence technologies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0075-9012ecb8ba", "paper_id": "P0075", "bibkey": "Han2025Large", "title": "Large Language Model Powered Intelligent Urban Agents: Concepts, Capabilities, and Applications", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, the advent of Large Language Models (LLMs) has opened new ways toward realizing this vision.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0075-7392482756", "paper_id": "P0075", "bibkey": "Han2025Large", "title": "Large Language Model Powered Intelligent Urban Agents: Concepts, Capabilities, and Applications", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With powerful semantic understanding and reasoning capabilities, LLMs can be deployed as intelligent agents capable of autonomously solving complex problems across domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0075-cceb414c8a", "paper_id": "P0075", "bibkey": "Han2025Large", "title": "Large Language Model Powered Intelligent Urban Agents: Concepts, Capabilities, and Applications", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Finally, we discuss trustworthiness and evaluation issues that are critical for real-world deployment, and identify several open problems for future research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#limitations[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0076-90f2081037", "paper_id": "P0076", "bibkey": "Zhang2025Large", "title": "Large Language Model enabled Mathematical Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The integration of Large Language Models (LLMs) with optimization modeling offers a promising avenue for advancing decision-making in operations research (OR).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0076-56300e9d4f", "paper_id": "P0076", "bibkey": "Zhang2025Large", "title": "Large Language Model enabled Mathematical Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Despite its success in benchmarks such as LiveCodeBench and Math-500, its effectiveness in applied OR scenarios remains under explored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0076-c26b63d8be", "paper_id": "P0076", "bibkey": "Zhang2025Large", "title": "Large Language Model enabled Mathematical Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Although prior models like GPT-4, Claude, and Bard have shown strong performance in NLP and reasoning tasks, their high token costs and tendency toward hallucinations limit real-world applicability in supply chain contexts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0076-bb6f8c91d1", "paper_id": "P0076", "bibkey": "Zhang2025Large", "title": "Large Language Model enabled Mathematical Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The integration of Large Language Models (LLMs) with optimization modeling offers a promising avenue for advancing decision-making in operations research (OR).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0076-2735856d5c", "paper_id": "P0076", "bibkey": "Zhang2025Large", "title": "Large Language Model enabled Mathematical Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional optimization methods,such as linear programming, mixed integer programming, and simulation depend heavily on domain expertise to translate real-world problems into solvable mathematical models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0076-fc2c3f86dd", "paper_id": "P0076", "bibkey": "Zhang2025Large", "title": "Large Language Model enabled Mathematical Modeling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While solvers like Gurobi and COPT are powerful, expert input remains essential for defining objectives, constraints, and variables.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0077-ca612dd4ac", "paper_id": "P0077", "bibkey": "Cao2025Large", "title": "Large Language Models for Planning: A Comprehensive and Systematic Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Planning represents a fundamental capability of intelligent agents, requiring comprehensive environmental understanding, rigorous logical reasoning, and effective sequential decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0077-91eca0d007", "paper_id": "P0077", "bibkey": "Cao2025Large", "title": "Large Language Models for Planning: A Comprehensive and Systematic Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Next, we provide a detailed taxonomy and analysis of contemporary LLM-based planning methodologies, categorizing them into three principal approaches: 1) External Module Augmented Methods that combine LLMs with additional components for planning, 2) Finetuning-based Methods that involve using trajectory data and feedback signals to adjust LLMs in order to improve their planning abilities, and 3) Searching-based Methods that break down complex tasks into simpler components, navigate the planning space, or enhance decoding strategies to find the best solutions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0077-23a1945a58", "paper_id": "P0077", "bibkey": "Cao2025Large", "title": "Large Language Models for Planning: A Comprehensive and Systematic Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Subsequently, we systematically summarize existing evaluation frameworks, including benchmark datasets, evaluation metrics and performance comparisons between representative planning methods.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0077-c7754056c9", "paper_id": "P0077", "bibkey": "Cao2025Large", "title": "Large Language Models for Planning: A Comprehensive and Systematic Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Planning represents a fundamental capability of intelligent agents, requiring comprehensive environmental understanding, rigorous logical reasoning, and effective sequential decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0077-fe785958fb", "paper_id": "P0077", "bibkey": "Cao2025Large", "title": "Large Language Models for Planning: A Comprehensive and Systematic Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While Large Language Models (LLMs) have demonstrated remarkable performance on certain planning tasks, their broader application in this domain warrants systematic investigation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0077-35045cc8f4", "paper_id": "P0077", "bibkey": "Cao2025Large", "title": "Large Language Models for Planning: A Comprehensive and Systematic Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents a comprehensive review of LLM-based planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0078-541015e540", "paper_id": "P0078", "bibkey": "Rouzrokh2025Lattereview", "title": "LatteReview: A Multi-Agent Framework for Systematic Review Automation Using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Systematic literature reviews and meta-analyses are essential for synthesizing research insights, but they remain time-intensive and labor-intensive due to the iterative processes of screening, evaluation, and data extraction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0078-fa4336d046", "paper_id": "P0078", "bibkey": "Rouzrokh2025Lattereview", "title": "LatteReview: A Multi-Agent Framework for Systematic Review Automation Using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Systematic literature reviews and meta-analyses are essential for synthesizing research insights, but they remain time-intensive and labor-intensive due to the iterative processes of screening, evaluation, and data extraction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0078-6a2dac4bfa", "paper_id": "P0078", "bibkey": "Rouzrokh2025Lattereview", "title": "LatteReview: A Multi-Agent Framework for Systematic Review Automation Using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The framework supports features such as Retrieval-Augmented Generation (RAG) for incorporating external context, multimodal reviews, Pydantic-based validation for structured inputs and outputs, and asynchronous programming for handling large-scale datasets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0078-4ce8fda1dc", "paper_id": "P0078", "bibkey": "Rouzrokh2025Lattereview", "title": "LatteReview: A Multi-Agent Framework for Systematic Review Automation Using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Systematic literature reviews and meta-analyses are essential for synthesizing research insights, but they remain time-intensive and labor-intensive due to the iterative processes of screening, evaluation, and data extraction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0078-e45dffe4b6", "paper_id": "P0078", "bibkey": "Rouzrokh2025Lattereview", "title": "LatteReview: A Multi-Agent Framework for Systematic Review Automation Using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper introduces and evaluates LatteReview, a Python-based framework that leverages large language models (LLMs) and multi-agent systems to automate key elements of the systematic review process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0078-8df5c76e99", "paper_id": "P0078", "bibkey": "Rouzrokh2025Lattereview", "title": "LatteReview: A Multi-Agent Framework for Systematic Review Automation Using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Designed to streamline workflows while maintaining rigor, LatteReview utilizes modular agents for tasks such as title and abstract screening, relevance scoring, and structured data extraction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0079-cdec58bfbb", "paper_id": "P0079", "bibkey": "Li2025Learn", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Inspired by centralized training with decentralized execution in multi-agent reinforcement learning, we propose a \\textit{Learn as Individuals, Evolve as a Team (LIET)} paradigm for multi-agent LLMs adaptation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0079-d19d8e1143", "paper_id": "P0079", "bibkey": "Li2025Learn", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "At the individual level, LLM agents learn a local utility function from exploratory datasets to better comprehend the embodied environment, which is then queried during test time to support informed decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0079-1dd544863c", "paper_id": "P0079", "bibkey": "Li2025Learn", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments on Communicative Watch-And-Help and ThreeD-World Multi-Agent Transport benchmarks demonstrate that LIET, instantiated with both LLaMA and GPT-4o, outperforms existing baselines and exhibits strong cooperative planning abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0079-c4c7a48c82", "paper_id": "P0079", "bibkey": "Li2025Learn", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) possess extensive knowledge bases and strong reasoning capabilities, making them promising tools for complex, multi-agent planning in embodied environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0079-da8f148a2b", "paper_id": "P0079", "bibkey": "Li2025Learn", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, despite LLMs' advanced abilities and the sophisticated modular design of agentic methods, existing LLM-based planning algorithms remain limited by weak adaptation capabilities to multi-agent embodied scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0079-d9a6ff4c1a", "paper_id": "P0079", "bibkey": "Li2025Learn", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We address this limitation by introducing a framework that enables LLM agents to learn and evolve both before and during test time, equipping them with environment-relevant knowledge for better planning and enhanced communication for improved cooperation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0079-01f439b837", "paper_id": "P0079", "bibkey": "Li2025Learn", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "We address this limitation by introducing a framework that enables LLM agents to learn and evolve both before and during test time, equipping them with environment-relevant knowledge for better planning and enhanced communication for improved cooperation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0080-d2bd627b74", "paper_id": "P0080", "bibkey": "Collini2025Marvel", "title": "MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We test our approach on a known buggy SoC based on OpenTitan from the Hack@DATE competition.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0080-0e82f75090", "paper_id": "P0080", "bibkey": "Collini2025Marvel", "title": "MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We find that 20 of the 48 issues reported by MARVEL pose security vulnerabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "security"]}
{"evidence_id": "E-P0080-6701c90e15", "paper_id": "P0080", "bibkey": "Collini2025Marvel", "title": "MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We improve the state of the art by proposing MARVEL, a multi-agent LLM framework for a unified approach to decision-making, tool use, and reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#key_results[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0080-99988922bf", "paper_id": "P0080", "bibkey": "Collini2025Marvel", "title": "MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Hardware security verification is a challenging and time-consuming task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0080-d78a5b6d39", "paper_id": "P0080", "bibkey": "Collini2025Marvel", "title": "MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "For this purpose, design engineers may utilize tools such as formal verification, linters, and functional simulation tests, coupled with analysis and a deep understanding of the hardware design being inspected.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0080-9b26f7c826", "paper_id": "P0080", "bibkey": "Collini2025Marvel", "title": "MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have been used to assist during this task, either directly or in conjunction with existing tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0081-155255a855", "paper_id": "P0081", "bibkey": "Gao2025Radar", "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "As Large Language Models (LLMs) evolve from passive text generators to active reasoning agents capable of interacting with external tools, the Model Context Protocol (MCP) has emerged as a key standardized framework for dynamic tool discovery and orchestration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0081-419e1464da", "paper_id": "P0081", "bibkey": "Gao2025Radar", "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "MCP-RADAR features a challenging dataset of 507 tasks spanning six domains: mathematical reasoning, web search, email, calendar, file management, and terminal operations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0081-55cf3ec701", "paper_id": "P0081", "bibkey": "Gao2025Radar", "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Despite its widespread industry adoption, existing evaluation methods do not adequately assess tool utilization capabilities under this new paradigm.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0081-f3b1559bcc", "paper_id": "P0081", "bibkey": "Gao2025Radar", "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As Large Language Models (LLMs) evolve from passive text generators to active reasoning agents capable of interacting with external tools, the Model Context Protocol (MCP) has emerged as a key standardized framework for dynamic tool discovery and orchestration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0081-daf259cf01", "paper_id": "P0081", "bibkey": "Gao2025Radar", "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite its widespread industry adoption, existing evaluation methods do not adequately assess tool utilization capabilities under this new paradigm.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0081-ca089d06c0", "paper_id": "P0081", "bibkey": "Gao2025Radar", "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, this paper introduces MCP-RADAR, the first comprehensive benchmark specifically designed to evaluate LLM performance within the MCP framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0082-79603dbb38", "paper_id": "P0082", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Temporal progression is an integral part of knowledge accumulation and update.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0082-bc9f2f2374", "paper_id": "P0082", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results indicate that agent design and evaluations should take a dynamical view and implement measures to account for the temporal influence of external resources to ensure reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0082-ccb6112830", "paper_id": "P0082", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Temporal progression is an integral part of knowledge accumulation and update.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0082-bbd77bc2b8", "paper_id": "P0082", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Web search is frequently adopted as grounding for agent knowledge, yet an improper configuration affects the quality of the agent's responses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0082-355d9ee68b", "paper_id": "P0082", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Here, we assess the agent behavior using distinct date-controlled tools (DCTs) as stress test to measure the knowledge variability of large language model (LLM) agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0083-d4a4183b68", "paper_id": "P0083", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce MemTool, a short-term memory framework enabling LLM agents to dynamically manage tools or MCP server contexts across multi-turn conversations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#method"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0083-35271418ac", "paper_id": "P0083", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0083-38dc800de9", "paper_id": "P0083", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "MemTool offers three agentic architectures: 1) Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow Mode, providing deterministic control without autonomy, and 3) Hybrid Mode, combining autonomous and deterministic control.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0083-64ae1a2cfc", "paper_id": "P0083", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents have shown significant autonomous capabilities in dynamically searching and incorporating relevant tools or Model Context Protocol (MCP) servers for individual queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0083-6243350e0e", "paper_id": "P0083", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, fixed context windows limit effectiveness in multi-turn interactions requiring repeated, independent tool usage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0083-50ae553d5f", "paper_id": "P0083", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce MemTool, a short-term memory framework enabling LLM agents to dynamically manage tools or MCP server contexts across multi-turn conversations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0084-32dbb4aa87", "paper_id": "P0084", "bibkey": "Bilal2025Meta", "title": "Meta-Thinking in LLMs via Multi-Agent Reinforcement Learning: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "This survey explores the development of meta-thinking capabilities in Large Language Models (LLMs) from a Multi-Agent Reinforcement Learning (MARL) perspective.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-61917beed9", "paper_id": "P0084", "bibkey": "Bilal2025Meta", "title": "Meta-Thinking in LLMs via Multi-Agent Reinforcement Learning: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "It then talks about newer methods, including RL from human feedback (RLHF), self-distillation, and chain-of-thought prompting, and each of their limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-ffbc3301be", "paper_id": "P0084", "bibkey": "Bilal2025Meta", "title": "Meta-Thinking in LLMs via Multi-Agent Reinforcement Learning: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The crux of the survey is to talk about how multi-agent architectures, namely supervisor-agent hierarchies, agent debates, and theory of mind frameworks, can emulate human-like introspective behavior and enhance LLM robustness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-cae29a52de", "paper_id": "P0084", "bibkey": "Bilal2025Meta", "title": "Meta-Thinking in LLMs via Multi-Agent Reinforcement Learning: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey explores the development of meta-thinking capabilities in Large Language Models (LLMs) from a Multi-Agent Reinforcement Learning (MARL) perspective.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-84f02fc28e", "paper_id": "P0084", "bibkey": "Bilal2025Meta", "title": "Meta-Thinking in LLMs via Multi-Agent Reinforcement Learning: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Meta-thinking self-reflection, assessment, and control of thinking processes is an important next step in enhancing LLM reliability, flexibility, and performance, particularly for complex or high-stakes tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-11ced1c1bb", "paper_id": "P0084", "bibkey": "Bilal2025Meta", "title": "Meta-Thinking in LLMs via Multi-Agent Reinforcement Learning: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The survey begins by analyzing current LLM limitations, such as hallucinations and the lack of internal self-assessment mechanisms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-56dde8f302", "paper_id": "P0084", "bibkey": "Bilal2025Meta", "title": "Meta-Thinking in LLMs via Multi-Agent Reinforcement Learning: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "The survey begins by analyzing current LLM limitations, such as hallucinations and the lack of internal self-assessment mechanisms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0085-215d773329", "paper_id": "P0085", "bibkey": "Wu2025Multi", "title": "Multi-Agent Autonomous Driving Systems with Large Language Models: A Survey of Recent Advances", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Autonomous Driving Systems (ADSs) are revolutionizing transportation by reducing human intervention, improving operational efficiency, and enhancing safety.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0085-f822751d71", "paper_id": "P0085", "bibkey": "Wu2025Multi", "title": "Multi-Agent Autonomous Driving Systems with Large Language Models: A Survey of Recent Advances", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Autonomous Driving Systems (ADSs) are revolutionizing transportation by reducing human intervention, improving operational efficiency, and enhancing safety.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0085-f7ab9ec390", "paper_id": "P0085", "bibkey": "Wu2025Multi", "title": "Multi-Agent Autonomous Driving Systems with Large Language Models: A Survey of Recent Advances", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We then discuss agent-human interactions in scenarios where LLM-based agents engage with humans.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0085-26047d61a6", "paper_id": "P0085", "bibkey": "Wu2025Multi", "title": "Multi-Agent Autonomous Driving Systems with Large Language Models: A Survey of Recent Advances", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Autonomous Driving Systems (ADSs) are revolutionizing transportation by reducing human intervention, improving operational efficiency, and enhancing safety.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0085-b56e8ca609", "paper_id": "P0085", "bibkey": "Wu2025Multi", "title": "Multi-Agent Autonomous Driving Systems with Large Language Models: A Survey of Recent Advances", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have been integrated into ADSs to support high-level decision-making through their powerful reasoning, instruction-following, and communication abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0085-b98147dea9", "paper_id": "P0085", "bibkey": "Wu2025Multi", "title": "Multi-Agent Autonomous Driving Systems with Large Language Models: A Survey of Recent Advances", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, LLM-based single-agent ADSs face three major challenges: limited perception, insufficient collaboration, and high computational demands.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0086-27b24bfa54", "paper_id": "P0086", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Progent, the first privilege control framework to secure LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0086-68db58914f", "paper_id": "P0086", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0086-e6b786dc5e", "paper_id": "P0086", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM agents utilize Large Language Models as central components with diverse tools to complete various user tasks, but face significant security risks when interacting with external environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0086-52976e4dfa", "paper_id": "P0086", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Attackers can exploit these agents through various vectors, including indirect prompt injection, memory/knowledge base poisoning, and malicious tools, tricking agents into performing dangerous actions such as unauthorized financial transactions or data leakage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "security", "tooling"]}
{"evidence_id": "E-P0086-4792fb4704", "paper_id": "P0086", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The core problem that enables attacks to succeed lies in over-privileged tool access.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#summary_bullets[2]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0086-6829c8b583", "paper_id": "P0086", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Thanks to our modular design, integrating Progent does not alter agent internals and only requires minimal changes to the existing agent implementation, enhancing its practicality and potential for widespread adoption.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0087-18e9d83661", "paper_id": "P0087", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this, in this paper we propose Self-taught ActioN Deliberation (SAND) framework, enabling LLM agents to explicitly deliberate over candidate actions before committing to one.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0087-6273763a98", "paper_id": "P0087", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluating on two representative interactive agent tasks, SAND achieves an average 20% improvement over initial supervised finetuning and also outperforms state-of-the-art agent tuning approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0087-c32e04ef1b", "paper_id": "P0087", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To tackle the challenges of when and what to deliberate given large action space and step-level action evaluation, we incorporate self-consistency action sampling and execution-guided action critique to help synthesize step-wise action deliberation thoughts using the base model of the LLM agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0087-7aa323548c", "paper_id": "P0087", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents are commonly tuned with supervised finetuning on ReAct-style expert trajectories or preference optimization over pairwise rollouts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0087-8dfc3945ee", "paper_id": "P0087", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Most of these methods focus on imitating specific expert behaviors or promoting chosen reasoning thoughts and actions over rejected ones.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0087-a482c4692d", "paper_id": "P0087", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, without reasoning and comparing over alternatives actions, LLM agents finetuned with these methods may over-commit towards seemingly plausible but suboptimal actions due to limited action space exploration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0088-0fe6ee607e", "paper_id": "P0088", "bibkey": "Sun2025Search", "title": "Search-on-Graph: Iterative Informed Navigation for Large Language Model Reasoning on Knowledge Graphs", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these limitations, we propose Search-on-Graph (SoG), a simple yet effective framework that enables LLMs to perform iterative informed graph navigation using a single, carefully designed \\textsc{Search} function.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0088-4ae722da57", "paper_id": "P0088", "bibkey": "Sun2025Search", "title": "Search-on-Graph: Iterative Informed Navigation for Large Language Model Reasoning on Knowledge Graphs", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We demonstrate particularly strong gains on Wikidata benchmarks (+16\\% improvement over previous best methods) alongside consistent improvements on Freebase benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0088-f30a9c2992", "paper_id": "P0088", "bibkey": "Sun2025Search", "title": "Search-on-Graph: Iterative Informed Navigation for Large Language Model Reasoning on Knowledge Graphs", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across six KGQA benchmarks spanning Freebase and Wikidata, SoG achieves state-of-the-art performance without fine-tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0088-a5367bd2f1", "paper_id": "P0088", "bibkey": "Sun2025Search", "title": "Search-on-Graph: Iterative Informed Navigation for Large Language Model Reasoning on Knowledge Graphs", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have demonstrated impressive reasoning abilities yet remain unreliable on knowledge-intensive, multi-hop questions -- they miss long-tail facts, hallucinate when uncertain, and their internal knowledge lags behind real-world change.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0088-94560c6012", "paper_id": "P0088", "bibkey": "Sun2025Search", "title": "Search-on-Graph: Iterative Informed Navigation for Large Language Model Reasoning on Knowledge Graphs", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Knowledge graphs (KGs) offer a structured source of relational evidence, but existing KGQA methods face fundamental trade-offs: compiling complete SPARQL queries without knowing available relations proves brittle, retrieving large subgraphs introduces noise, and complex agent frameworks with parallel exploration exponentially expand search spaces.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0088-d510c2942f", "paper_id": "P0088", "bibkey": "Sun2025Search", "title": "Search-on-Graph: Iterative Informed Navigation for Large Language Model Reasoning on Knowledge Graphs", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these limitations, we propose Search-on-Graph (SoG), a simple yet effective framework that enables LLMs to perform iterative informed graph navigation using a single, carefully designed \\textsc{Search} function.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0088-9ab78c15e3", "paper_id": "P0088", "bibkey": "Sun2025Search", "title": "Search-on-Graph: Iterative Informed Navigation for Large Language Model Reasoning on Knowledge Graphs", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address these limitations, we propose Search-on-Graph (SoG), a simple yet effective framework that enables LLMs to perform iterative informed graph navigation using a single, carefully designed \\textsc{Search} function.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0089-f4d80ca542", "paper_id": "P0089", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Models (LLMs) have demonstrated remarkable capabilities in knowledge acquisition, reasoning, and tool use, making them promising candidates for autonomous agent applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0089-771620f84f", "paper_id": "P0089", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0089-5a257bd496", "paper_id": "P0089", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our theoretical analysis shows that GRPO improvement on single-turn task reasoning results in a lower bound of the multi-turn success probability under the minimal turns, as well as the generalization to subtasks with shorter horizons.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0089-efac948251", "paper_id": "P0089", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have demonstrated remarkable capabilities in knowledge acquisition, reasoning, and tool use, making them promising candidates for autonomous agent applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0089-291455ba2c", "paper_id": "P0089", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, training LLM agents for complex multi-turn task planning faces significant challenges, including sparse episode-wise rewards, credit assignment across long horizons, and the computational overhead of reinforcement learning in multi-turn interaction settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0089-ac96b98574", "paper_id": "P0089", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To this end, this paper introduces a novel approach that transforms multi-turn task planning into single-turn task reasoning problems, enabling efficient policy optimization through Group Relative Policy Optimization (GRPO) with dense and verifiable reward from expert trajectories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0090-e8fe93d5a3", "paper_id": "P0090", "bibkey": "Feng2024Survey", "title": "A Survey on Large Language Model-Based Social Agents in Game-Theoretic Scenarios", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Additionally, we analyze the performance of current social agents across various game scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0090-2bc2266ae0", "paper_id": "P0090", "bibkey": "Feng2024Survey", "title": "A Survey on Large Language Model-Based Social Agents in Game-Theoretic Scenarios", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our survey organizes the findings into three core components: Game Framework, Social Agent, and Evaluation Protocol.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0090-8cf874b8f8", "paper_id": "P0090", "bibkey": "Feng2024Survey", "title": "A Survey on Large Language Model-Based Social Agents in Game-Theoretic Scenarios", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The evaluation protocol covers both game-agnostic and game-specific metrics for assessing agent performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0090-163c710097", "paper_id": "P0090", "bibkey": "Feng2024Survey", "title": "A Survey on Large Language Model-Based Social Agents in Game-Theoretic Scenarios", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Game-theoretic scenarios have become pivotal in evaluating the social intelligence of Large Language Model (LLM)-based social agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0090-1cdff0af64", "paper_id": "P0090", "bibkey": "Feng2024Survey", "title": "A Survey on Large Language Model-Based Social Agents in Game-Theoretic Scenarios", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While numerous studies have explored these agents in such settings, there is a lack of a comprehensive survey summarizing the current progress.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0090-f6e3774cab", "paper_id": "P0090", "bibkey": "Feng2024Survey", "title": "A Survey on Large Language Model-Based Social Agents in Game-Theoretic Scenarios", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, we systematically review existing research on LLM-based social agents within game-theoretic scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0091-293082398e", "paper_id": "P0091", "bibkey": "Zhang2024Survey", "title": "A Survey on the Memory Mechanism of Large Language Model based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To bridge this gap, in this paper, we propose a comprehensive survey on the memory mechanism of LLM-based agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0091-8ac991f4ab", "paper_id": "P0091", "bibkey": "Zhang2024Survey", "title": "A Survey on the Memory Mechanism of Large Language Model based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "To keep up with the latest advances in this field, we create a repository at \\url{https://github.com/nuster1128/LLM_Agent_Memory_Survey}.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#key_results[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0091-1cd1b11e8a", "paper_id": "P0091", "bibkey": "Zhang2024Survey", "title": "A Survey on the Memory Mechanism of Large Language Model based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) based agents have recently attracted much attention from the research and industry communities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0091-1415f0c982", "paper_id": "P0091", "bibkey": "Zhang2024Survey", "title": "A Survey on the Memory Mechanism of Large Language Model based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Compared with original LLMs, LLM-based agents are featured in their self-evolving capability, which is the basis for solving real-world problems that need long-term and complex agent-environment interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0091-edd62fb3d6", "paper_id": "P0091", "bibkey": "Zhang2024Survey", "title": "A Survey on the Memory Mechanism of Large Language Model based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The key component to support agent-environment interactions is the memory of the agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0091-a79af4d2cc", "paper_id": "P0091", "bibkey": "Zhang2024Survey", "title": "A Survey on the Memory Mechanism of Large Language Model based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "At last, we analyze the limitations of existing work and show important future directions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0092-c5ce408c6b", "paper_id": "P0092", "bibkey": "Chen2024Architectural", "title": "APT: Architectural Planning and Text-to-Blueprint Construction Using Large Language Models for Open-World Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present APT, an advanced Large Language Model (LLM)-driven framework that enables autonomous agents to construct complex and creative structures within the Minecraft environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0092-d1af7d9a55", "paper_id": "P0092", "bibkey": "Chen2024Architectural", "title": "APT: Architectural Planning and Text-to-Blueprint Construction Using Large Language Models for Open-World Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "To rigorously evaluate the agent's performance in this emerging research area, we introduce a comprehensive benchmark consisting of diverse construction tasks designed to test creativity, spatial reasoning, adherence to in-game rules, and the effective integration of multimodal instructions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0092-60a8b19a3f", "paper_id": "P0092", "bibkey": "Chen2024Architectural", "title": "APT: Architectural Planning and Text-to-Blueprint Construction Using Large Language Models for Open-World Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Additionally, the agent's unexpected emergence of scaffolding behavior highlights the potential of future LLM-driven agents to utilize subroutine planning and leverage the emergence ability of LLMs to autonomously develop human-like problem-solving techniques.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#key_results[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0092-b501172c02", "paper_id": "P0092", "bibkey": "Chen2024Architectural", "title": "APT: Architectural Planning and Text-to-Blueprint Construction Using Large Language Models for Open-World Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present APT, an advanced Large Language Model (LLM)-driven framework that enables autonomous agents to construct complex and creative structures within the Minecraft environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0092-1220504a37", "paper_id": "P0092", "bibkey": "Chen2024Architectural", "title": "APT: Architectural Planning and Text-to-Blueprint Construction Using Large Language Models for Open-World Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike previous approaches that primarily concentrate on skill-based open-world tasks or rely on image-based diffusion models for generating voxel-based structures, our method leverages the intrinsic spatial reasoning capabilities of LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0092-653c2aa7bc", "paper_id": "P0092", "bibkey": "Chen2024Architectural", "title": "APT: Architectural Planning and Text-to-Blueprint Construction Using Large Language Models for Open-World Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By employing chain-of-thought decomposition along with multimodal inputs, the framework generates detailed architectural layouts and blueprints that the agent can execute under zero-shot or few-shot learning scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0093-16bbf8a0a5", "paper_id": "P0093", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we develop a framework for building multi-turn RL algorithms for fine-tuning LLMs, that preserves the flexibility of existing single-turn RL methods for LLMs (e.g., proximal policy optimization), while accommodating multiple turns, long horizons, and delayed rewards effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0093-faa3d4c9ee", "paper_id": "P0093", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Empirically, we find that ArCHer significantly improves efficiency and performance on agent tasks, attaining a sample efficiency of about 100x over existing methods, while also improving with larger model capacity (upto the 7 billion scale that we tested on).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0093-6f94b5dd68", "paper_id": "P0093", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A broad use case of large language models (LLMs) is in goal-directed decision-making tasks (or \"agent\" tasks), where an LLM needs to not just generate completions for a given prompt, but rather make intelligent decisions over a multi-turn interaction to accomplish a task (e.g., when interacting with the web, using tools, or providing customer support).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0093-d7f0bcbe26", "paper_id": "P0093", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reinforcement learning (RL) provides a general paradigm to address such agent tasks, but current RL methods for LLMs largely focus on optimizing single-turn rewards.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0093-05ea8dd729", "paper_id": "P0093", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By construction, most single-turn RL methods cannot endow LLMs with the ability to intelligently seek information over multiple turns, perform credit assignment, or reason about their past actions -- all of which are critical in agent tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0094-43287d5458", "paper_id": "P0094", "bibkey": "Anokhin2024Arigraph", "title": "AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In our study, we introduce AriGraph, a novel method wherein the agent constructs and updates a memory graph that integrates semantic and episodic memories while exploring the environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0094-e499ec8b67", "paper_id": "P0094", "bibkey": "Anokhin2024Arigraph", "title": "AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We demonstrate that our Ariadne LLM agent, consisting of the proposed memory architecture augmented with planning and decision-making, effectively handles complex tasks within interactive text game environments difficult even for human players.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#key_results[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0094-72413e634e", "paper_id": "P0094", "bibkey": "Anokhin2024Arigraph", "title": "AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Advancements in the capabilities of Large Language Models (LLMs) have created a promising foundation for developing autonomous agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0094-76ed436af0", "paper_id": "P0094", "bibkey": "Anokhin2024Arigraph", "title": "AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the right tools, these agents could learn to solve tasks in new environments by accumulating and updating their knowledge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0094-d2796732a0", "paper_id": "P0094", "bibkey": "Anokhin2024Arigraph", "title": "AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current LLM-based agents process past experiences using a full history of observations, summarization, retrieval augmentation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0095-d2b990fb32", "paper_id": "P0095", "bibkey": "Andriukeviius2024Automatic", "title": "Automatic Control With Human-Like Reasoning: Exploring Language Model Embodied Air Traffic Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Recent developments in language models have created new opportunities in air traffic control studies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0095-b79927b14d", "paper_id": "P0095", "bibkey": "Andriukeviius2024Automatic", "title": "Automatic Control With Human-Like Reasoning: Exploring Language Model Embodied Air Traffic Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The best-performing configuration was able to solve almost all 120 but one imminent conflict scenarios, including up to four aircraft at the same time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0095-0295af613c", "paper_id": "P0095", "bibkey": "Andriukeviius2024Automatic", "title": "Automatic Control With Human-Like Reasoning: Exploring Language Model Embodied Air Traffic Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "This paper investigates the application of a language model-based agent with function-calling and learning capabilities to resolve air traffic conflicts without human intervention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#key_results[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0095-7ace2fc5d7", "paper_id": "P0095", "bibkey": "Andriukeviius2024Automatic", "title": "Automatic Control With Human-Like Reasoning: Exploring Language Model Embodied Air Traffic Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent developments in language models have created new opportunities in air traffic control studies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0095-b59bb8eab3", "paper_id": "P0095", "bibkey": "Andriukeviius2024Automatic", "title": "Automatic Control With Human-Like Reasoning: Exploring Language Model Embodied Air Traffic Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The current focus is primarily on text and language-based use cases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0095-72fd5f1601", "paper_id": "P0095", "bibkey": "Andriukeviius2024Automatic", "title": "Automatic Control With Human-Like Reasoning: Exploring Language Model Embodied Air Traffic Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, these language models may offer a higher potential impact in the air traffic control domain, thanks to their ability to interact with air traffic environments in an embodied agent form.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0096-9effa35196", "paper_id": "P0096", "bibkey": "Wu2024Avatar", "title": "AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Here, we introduce AvaTaR, a novel and automated framework that optimizes an LLM agent to effectively leverage provided tools, improving performance on a given task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#method"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0096-3575a7c673", "paper_id": "P0096", "bibkey": "Wu2024Avatar", "title": "AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We find AvaTaR consistently outperforms state-of-the-art approaches across all seven tasks, exhibiting strong generalization ability when applied to novel cases and achieving an average relative improvement of 14% on the Hit@1 metric for the retrieval datasets and 13% for the QA datasets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0096-2032a098fd", "paper_id": "P0096", "bibkey": "Wu2024Avatar", "title": "AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large language model (LLM) agents have demonstrated impressive capabilities in utilizing external tools and knowledge to boost accuracy and reduce hallucinations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#key_results[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0096-9d487b28b3", "paper_id": "P0096", "bibkey": "Wu2024Avatar", "title": "AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents have demonstrated impressive capabilities in utilizing external tools and knowledge to boost accuracy and reduce hallucinations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0096-89c6a36649", "paper_id": "P0096", "bibkey": "Wu2024Avatar", "title": "AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, developing prompting techniques that enable LLM agents to effectively use these tools and knowledge remains a heuristic and labor-intensive task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0096-c8fa7cd7e1", "paper_id": "P0096", "bibkey": "Wu2024Avatar", "title": "AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Here, we introduce AvaTaR, a novel and automated framework that optimizes an LLM agent to effectively leverage provided tools, improving performance on a given task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0097-a61ac123d5", "paper_id": "P0097", "bibkey": "Piatti2024Cooperate", "title": "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce the Governance of the Commons Simulation (GovSim), a generative simulation platform designed to study strategic interactions and cooperative decision-making in LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0097-ce1001aef8", "paper_id": "P0097", "bibkey": "Piatti2024Cooperate", "title": "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We find that all but the most powerful LLM agents fail to achieve a sustainable equilibrium in GovSim, with the highest survival rate below 54%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0097-449aa6c093", "paper_id": "P0097", "bibkey": "Piatti2024Cooperate", "title": "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "As AI systems pervade human life, ensuring that large language models (LLMs) make safe decisions remains a significant challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0097-2cabe8a540", "paper_id": "P0097", "bibkey": "Piatti2024Cooperate", "title": "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As AI systems pervade human life, ensuring that large language models (LLMs) make safe decisions remains a significant challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0097-32383c5c7c", "paper_id": "P0097", "bibkey": "Piatti2024Cooperate", "title": "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce the Governance of the Commons Simulation (GovSim), a generative simulation platform designed to study strategic interactions and cooperative decision-making in LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0097-6e5ff9acf1", "paper_id": "P0097", "bibkey": "Piatti2024Cooperate", "title": "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In GovSim, a society of AI agents must collectively balance exploiting a common resource with sustaining it for future use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0098-a69e9aa428", "paper_id": "P0098", "bibkey": "Zala2024Envgen", "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose EnvGen, a novel framework to address this question.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0098-d8cf871a34", "paper_id": "P0098", "bibkey": "Zala2024Envgen", "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We find that a small RL agent trained with EnvGen can outperform SOTA methods, including a GPT-4 agent, and learns long-horizon tasks significantly faster.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0098-81909db190", "paper_id": "P0098", "bibkey": "Zala2024Envgen", "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Additionally, EnvGen is substantially more efficient as it only uses a small number of LLM calls (e.g., 4 in total), whereas LLM agents require thousands of calls.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0098-f1b7423b17", "paper_id": "P0098", "bibkey": "Zala2024Envgen", "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent SOTA approaches for embodied learning via interaction directly employ large language models (LLMs) as agents to determine the next steps in an environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0098-ba2342bd3d", "paper_id": "P0098", "bibkey": "Zala2024Envgen", "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Due to their world knowledge and reasoning capabilities, LLM agents achieve stronger performance than previous smaller agents based on reinforcement learning (RL); however, frequently calling LLMs is slow and expensive.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0098-f6b1a51dc0", "paper_id": "P0098", "bibkey": "Zala2024Envgen", "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Instead of directly employing LLMs as agents, can we use LLMs' reasoning capabilities to adaptively create training environments to help smaller RL agents learn useful skills that they are weak at?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0099-2c60278a81", "paper_id": "P0099", "bibkey": "Jin2024From", "title": "From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "With the rise of large language models (LLMs), researchers are increasingly exploring their applications in var ious vertical domains, such as software engineering.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0099-e5a6d61afc", "paper_id": "P0099", "bibkey": "Jin2024From", "title": "From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "LLMs have achieved remarkable success in areas including code generation and vulnerability detection.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#key_results[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0099-33c7e5174b", "paper_id": "P0099", "bibkey": "Jin2024From", "title": "From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We review and differentiate the work of LLMs and LLM-based agents from these six topics, examining their differences and similarities in tasks, benchmarks, and evaluation metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0099-68252f25ba", "paper_id": "P0099", "bibkey": "Jin2024From", "title": "From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the rise of large language models (LLMs), researchers are increasingly exploring their applications in var ious vertical domains, such as software engineering.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0099-9182f7f691", "paper_id": "P0099", "bibkey": "Jin2024From", "title": "From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLMs have achieved remarkable success in areas including code generation and vulnerability detection.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0099-42bb415982", "paper_id": "P0099", "bibkey": "Jin2024From", "title": "From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, they also exhibit numerous limitations and shortcomings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0099-1d7bf9a1c9", "paper_id": "P0099", "bibkey": "Jin2024From", "title": "From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "However, they also exhibit numerous limitations and shortcomings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0100-b03aabc027", "paper_id": "P0100", "bibkey": "Yang2024Wizard", "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this survey, we present an overview of the various benefits of integrating code into LLMs' training data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0100-56e73314cf", "paper_id": "P0100", "bibkey": "Yang2024Wizard", "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "In addition, we trace how these profound capabilities of LLMs, brought by code, have led to their emergence as intelligent agents (IAs) in situations where the ability to understand instructions, decompose goals, plan and execute actions, and refine from feedback are crucial to their success on downstream tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0100-44e4eb7252", "paper_id": "P0100", "bibkey": "Yang2024Wizard", "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The prominent large language models (LLMs) of today differ from past language models not only in size, but also in the fact that they are trained on a combination of natural language and formal language (code).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0100-477b67503e", "paper_id": "P0100", "bibkey": "Yang2024Wizard", "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As a medium between humans and computers, code translates high-level goals into executable steps, featuring standard syntax, logical consistency, abstraction, and modularity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0100-72205763ae", "paper_id": "P0100", "bibkey": "Yang2024Wizard", "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this survey, we present an overview of the various benefits of integrating code into LLMs' training data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0101-ef2df859e5", "paper_id": "P0101", "bibkey": "Radha2024Iteration", "title": "Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Motivated by this insight, we propose the Iteration of Thought (IoT) framework for enhancing LLM responses by generating \"thought\"-provoking prompts vis a vis an input query and the current iteration of an LLM's response.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0101-d36844b954", "paper_id": "P0101", "bibkey": "Radha2024Iteration", "title": "Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We investigate the performance of IoT across various datasets, spanning complex reasoning tasks from the GPQA dataset, explorative problem-solving in Game of 24, puzzle solving in Mini Crosswords, and multi-hop question answering from the HotpotQA dataset.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0101-dc268ffd9e", "paper_id": "P0101", "bibkey": "Radha2024Iteration", "title": "Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The three components of the IoT framework are (1) an Inner Dialogue Agent (IDA) responsible for generating instructive, context-specific prompts; (2) an LLM Agent (LLMA) that processes these prompts to refine its responses; and (3) an iterative prompting loop that implements a conversation between the former two components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0101-8767ae0705", "paper_id": "P0101", "bibkey": "Radha2024Iteration", "title": "Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Iterative human engagement is a common and effective means of leveraging the advanced language processing power of large language models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0101-ceea4956ca", "paper_id": "P0101", "bibkey": "Radha2024Iteration", "title": "Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Using well-structured prompts in a conversational manner, human users can effectively influence an LLM to develop more thoughtful and accurate responses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0101-f490fd9fb7", "paper_id": "P0101", "bibkey": "Radha2024Iteration", "title": "Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Motivated by this insight, we propose the Iteration of Thought (IoT) framework for enhancing LLM responses by generating \"thought\"-provoking prompts vis a vis an input query and the current iteration of an LLM's response.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0102-bef44e3be3", "paper_id": "P0102", "bibkey": "Jiang2024Agent", "title": "KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Inspired by existing methods that design the interaction strategy between LLMs and KG, we propose an autonomous LLM-based agent framework, called KG-Agent, which enables a small LLM to actively make decisions until finishing the reasoning process over KGs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0102-0cc318c2c4", "paper_id": "P0102", "bibkey": "Jiang2024Agent", "title": "KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments demonstrate that only using 10K samples for tuning LLaMA-7B can outperform state-of-the-art methods using larger LLMs or more data, on both in-domain and out-domain datasets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0102-066b5d9b0b", "paper_id": "P0102", "bibkey": "Jiang2024Agent", "title": "KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "To guarantee the effectiveness, we leverage program language to formulate the multi-hop reasoning process over the KG, and synthesize a code-based instruction dataset to fine-tune the base LLM.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0102-fbeabd0056", "paper_id": "P0102", "bibkey": "Jiang2024Agent", "title": "KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we aim to improve the reasoning ability of large language models (LLMs) over knowledge graphs (KGs) to answer complex questions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0102-9ffd75deb3", "paper_id": "P0102", "bibkey": "Jiang2024Agent", "title": "KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Inspired by existing methods that design the interaction strategy between LLMs and KG, we propose an autonomous LLM-based agent framework, called KG-Agent, which enables a small LLM to actively make decisions until finishing the reasoning process over KGs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0102-90b7c86c22", "paper_id": "P0102", "bibkey": "Jiang2024Agent", "title": "KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In KG-Agent, we integrate the LLM, multifunctional toolbox, KG-based executor, and knowledge memory, and develop an iteration mechanism that autonomously selects the tool then updates the memory for reasoning over KG.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0103-f9b592f5a7", "paper_id": "P0103", "bibkey": "Maranto2024Llmsat", "title": "LLMSat: A Large Language Model-Based Goal-Oriented Agent for Autonomous Space Exploration", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "As spacecraft journey further from Earth with more complex missions, systems of greater autonomy and onboard intelligence are called for.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0103-fbf9c0802f", "paper_id": "P0103", "bibkey": "Maranto2024Llmsat", "title": "LLMSat: A Large Language Model-Based Goal-Oriented Agent for Autonomous Space Exploration", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Reducing reliance on human-based mission control becomes increasingly critical if we are to increase our rate of solar-system-wide exploration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0103-6f520fb252", "paper_id": "P0103", "bibkey": "Maranto2024Llmsat", "title": "LLMSat: A Large Language Model-Based Goal-Oriented Agent for Autonomous Space Exploration", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Such systems have proven to be successful in controlled cases, but they are difficult to implement as they require human-crafted ontological models to allow the spacecraft to understand the world.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0103-8dc88a3be9", "paper_id": "P0103", "bibkey": "Maranto2024Llmsat", "title": "LLMSat: A Large Language Model-Based Goal-Oriented Agent for Autonomous Space Exploration", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As spacecraft journey further from Earth with more complex missions, systems of greater autonomy and onboard intelligence are called for.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0103-50e791afe1", "paper_id": "P0103", "bibkey": "Maranto2024Llmsat", "title": "LLMSat: A Large Language Model-Based Goal-Oriented Agent for Autonomous Space Exploration", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reducing reliance on human-based mission control becomes increasingly critical if we are to increase our rate of solar-system-wide exploration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0103-99a2b15826", "paper_id": "P0103", "bibkey": "Maranto2024Llmsat", "title": "LLMSat: A Large Language Model-Based Goal-Oriented Agent for Autonomous Space Exploration", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent work has explored AI-based goal-oriented systems to increase the level of autonomy in mission execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0104-8cbda2aeca", "paper_id": "P0104", "bibkey": "Chiang2024Llamp", "title": "LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Here we introduce LLaMP, a multimodal retrieval-augmented generation (RAG) framework of hierarchical reasoning-and-acting (ReAct) agents that can dynamically and recursively interact with computational and experimental data on Materials Project (MP) and run atomistic simulations via high-throughput workflow interface.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0104-c8b3e662a6", "paper_id": "P0104", "bibkey": "Chiang2024Llamp", "title": "LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We propose a simple metric combining uncertainty and confidence estimates to evaluate the self-consistency of responses by LLaMP and vanilla LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0104-7b7a296576", "paper_id": "P0104", "bibkey": "Chiang2024Llamp", "title": "LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our benchmark shows that LLaMP effectively mitigates the intrinsic bias in LLMs, counteracting the errors on bulk moduli, electronic bandgaps, and formation energies that seem to derive from mixed data sources.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0104-3ff4190d67", "paper_id": "P0104", "bibkey": "Chiang2024Llamp", "title": "LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reducing hallucination of Large Language Models (LLMs) is imperative for use in the sciences, where reliability and reproducibility are crucial.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0104-b19251a981", "paper_id": "P0104", "bibkey": "Chiang2024Llamp", "title": "LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, LLMs inherently lack long-term memory, making it a nontrivial, ad hoc, and inevitably biased task to fine-tune them on domain-specific literature and data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0104-d5a675c344", "paper_id": "P0104", "bibkey": "Chiang2024Llamp", "title": "LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Here we introduce LLaMP, a multimodal retrieval-augmented generation (RAG) framework of hierarchical reasoning-and-acting (ReAct) agents that can dynamically and recursively interact with computational and experimental data on Materials Project (MP) and run atomistic simulations via high-throughput workflow interface.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0105-110de36ea8", "paper_id": "P0105", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Trading is a highly competitive task that requires a combination of strategy, knowledge, and psychological fortitude.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0105-909ff3f218", "paper_id": "P0105", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "With the recent success of large language models(LLMs), it is appealing to apply the emerging intelligence of LLM agents in this competitive arena and understanding if they can outperform professional traders.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0105-27ff3101b9", "paper_id": "P0105", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Trading is a highly competitive task that requires a combination of strategy, knowledge, and psychological fortitude.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0105-c1377776f8", "paper_id": "P0105", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the recent success of large language models(LLMs), it is appealing to apply the emerging intelligence of LLM agents in this competitive arena and understanding if they can outperform professional traders.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0105-d40fcae00e", "paper_id": "P0105", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this survey, we provide a comprehensive review of the current research on using LLMs as agents in financial trading.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0106-49c9d6301a", "paper_id": "P0106", "bibkey": "Zeng2024Perceive", "title": "Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "This paper considers a scenario in city navigation: an AI agent is provided with language descriptions of the goal location with respect to some well-known landmarks; By only observing the scene around, including recognizing landmarks and road network connections, the agent has to make decisions to navigate to the goal location without instructions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0106-0cffb6b607", "paper_id": "P0106", "bibkey": "Zeng2024Perceive", "title": "Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Specifically, we find LLaVA-7B can be fine-tuned to perceive the direction and distance of landmarks with sufficient accuracy for city navigation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0106-b09614c48f", "paper_id": "P0106", "bibkey": "Zeng2024Perceive", "title": "Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We show the designed workflow significantly improves navigation ability of the LLM agent compared with the state-of-the-art baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0106-aaa095d3dd", "paper_id": "P0106", "bibkey": "Zeng2024Perceive", "title": "Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper considers a scenario in city navigation: an AI agent is provided with language descriptions of the goal location with respect to some well-known landmarks; By only observing the scene around, including recognizing landmarks and road network connections, the agent has to make decisions to navigate to the goal location without instructions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0106-f04cb8a1ca", "paper_id": "P0106", "bibkey": "Zeng2024Perceive", "title": "Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This problem is very challenging, because it requires agent to establish self-position and acquire spatial representation of complex urban environment, where landmarks are often invisible.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0106-bc094963f9", "paper_id": "P0106", "bibkey": "Zeng2024Perceive", "title": "Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In the absence of navigation instructions, such abilities are vital for the agent to make high-quality decisions in long-range city navigation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0107-3a0f9ff646", "paper_id": "P0107", "bibkey": "Li2024Stride", "title": "STRIDE: A Tool-Assisted LLM Agent Framework for Strategic and Interactive Decision-Making", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Models (LLMs) like GPT-4 have revolutionized natural language processing, showing remarkable linguistic proficiency and reasoning capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#method"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0107-4211050ad9", "paper_id": "P0107", "bibkey": "Li2024Stride", "title": "STRIDE: A Tool-Assisted LLM Agent Framework for Strategic and Interactive Decision-Making", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large Language Models (LLMs) like GPT-4 have revolutionized natural language processing, showing remarkable linguistic proficiency and reasoning capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0107-e483f51daa", "paper_id": "P0107", "bibkey": "Li2024Stride", "title": "STRIDE: A Tool-Assisted LLM Agent Framework for Strategic and Interactive Decision-Making", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We employ quantitative metrics to assess the framework's performance in various strategic decision-making problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0107-35c6a18467", "paper_id": "P0107", "bibkey": "Li2024Stride", "title": "STRIDE: A Tool-Assisted LLM Agent Framework for Strategic and Interactive Decision-Making", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) like GPT-4 have revolutionized natural language processing, showing remarkable linguistic proficiency and reasoning capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#summary_bullets[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0107-78175c54ff", "paper_id": "P0107", "bibkey": "Li2024Stride", "title": "STRIDE: A Tool-Assisted LLM Agent Framework for Strategic and Interactive Decision-Making", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, their application in strategic multi-agent decision-making environments is hampered by significant limitations including poor mathematical reasoning, difficulty in following instructions, and a tendency to generate incorrect information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0107-7526f3c188", "paper_id": "P0107", "bibkey": "Li2024Stride", "title": "STRIDE: A Tool-Assisted LLM Agent Framework for Strategic and Interactive Decision-Making", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These deficiencies hinder their performance in strategic and interactive tasks that demand adherence to nuanced game rules, long-term planning, exploration in unknown environments, and anticipation of opponents' moves.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0107-9764768d4a", "paper_id": "P0107", "bibkey": "Li2024Stride", "title": "STRIDE: A Tool-Assisted LLM Agent Framework for Strategic and Interactive Decision-Making", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "However, their application in strategic multi-agent decision-making environments is hampered by significant limitations including poor mathematical reasoning, difficulty in following instructions, and a tendency to generate incorrect information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0108-f6fba56a1b", "paper_id": "P0108", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To overcome these challenges, we propose a novel approach that decomposes the aforementioned capabilities into a planner, caller, and summarizer.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0108-8158d9909c", "paper_id": "P0108", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "First, we fine-tune a backbone LLM on the entire dataset without discriminating sub-tasks, providing the model with a comprehensive understanding of the task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0108-9640816b42", "paper_id": "P0108", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluation across various tool-use benchmarks illustrates that our proposed multi-LLM framework surpasses the traditional single-LLM approach, highlighting its efficacy and advantages in tool learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0108-e8cc8a6f73", "paper_id": "P0108", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents significantly extend the capabilities of standalone LLMs, empowering them to interact with external tools (e.g., APIs, functions) and complete various tasks in a self-directed fashion.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0108-35a42b4664", "paper_id": "P0108", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The challenge of tool use demands that LLMs not only understand user queries and generate answers accurately but also excel in task planning, tool invocation, and result summarization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0108-9e83833f66", "paper_id": "P0108", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While traditional works focus on training a single LLM with all these capabilities, performance limitations become apparent, particularly with smaller models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0108-c92ed293ba", "paper_id": "P0108", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "While traditional works focus on training a single LLM with all these capabilities, performance limitations become apparent, particularly with smaller models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0109-93e3a73313", "paper_id": "P0109", "bibkey": "Chen2024Steering", "title": "Steering Large Language Models between Code Execution and Textual Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To mitigate the above issues, we propose three methods to better steer LLM code/text generation and achieve a notable improvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0109-c0a4d47a26", "paper_id": "P0109", "bibkey": "Chen2024Steering", "title": "Steering Large Language Models between Code Execution and Textual Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "While a lot of recent research focuses on enhancing the textual reasoning capabilities of Large Language Models (LLMs) by optimizing the multi-agent framework or reasoning chains, several benchmark tasks can be solved with 100\\% success through direct coding, which is more scalable and avoids the computational overhead associated with textual iterating and searching.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0109-b76a8bfc16", "paper_id": "P0109", "bibkey": "Chen2024Steering", "title": "Steering Large Language Models between Code Execution and Textual Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, based on our experiments on 7 existing popular methods for steering code/text generation in both single- and multi-turn settings with 14 tasks and 6 types of LLMs (including the new O1-preview), currently there is no optimal method to correctly steer LLMs to write code when needed.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0109-62bb19cecf", "paper_id": "P0109", "bibkey": "Chen2024Steering", "title": "Steering Large Language Models between Code Execution and Textual Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While a lot of recent research focuses on enhancing the textual reasoning capabilities of Large Language Models (LLMs) by optimizing the multi-agent framework or reasoning chains, several benchmark tasks can be solved with 100\\% success through direct coding, which is more scalable and avoids the computational overhead associated with textual iterating and searching.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0109-c78e0feccb", "paper_id": "P0109", "bibkey": "Chen2024Steering", "title": "Steering Large Language Models between Code Execution and Textual Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Textual reasoning has inherent limitations in solving tasks with challenges in math, logics, optimization, and searching, which is unlikely to be solved by simply scaling up the model and data size.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0109-a97e02c12e", "paper_id": "P0109", "bibkey": "Chen2024Steering", "title": "Steering Large Language Models between Code Execution and Textual Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The recently released OpenAI GPT Code Interpreter and multi-agent frameworks such as AutoGen have demonstrated remarkable proficiency of integrating code generation and execution to solve complex tasks using LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0109-44300117fc", "paper_id": "P0109", "bibkey": "Chen2024Steering", "title": "Steering Large Language Models between Code Execution and Textual Reasoning", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Textual reasoning has inherent limitations in solving tasks with challenges in math, logics, optimization, and searching, which is unlikely to be solved by simply scaling up the model and data size.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0110-73dbd22d64", "paper_id": "P0110", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose PDoctor, a novel and automated approach to testing LLM agents and understanding their erroneous planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0110-c0a98eb625", "paper_id": "P0110", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate PDoctor with three mainstream agent frameworks and two powerful LLMs (GPT-3.5 and GPT-4).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0110-8d0f2cdb4c", "paper_id": "P0110", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agents based on large language models (LLMs) have demonstrated effectiveness in solving a wide range of tasks by integrating LLMs with key modules such as planning, memory, and tool usage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0110-2b0e1946ce", "paper_id": "P0110", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Increasingly, customers are adopting LLM agents across a variety of commercial applications critical to reliability, including support for mental well-being, chemical synthesis, and software development.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0110-dc0110cb08", "paper_id": "P0110", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Nevertheless, our observations and daily use of LLM agents indicate that they are prone to making erroneous plans, especially when the tasks are complex and require long-term planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0111-822f022b13", "paper_id": "P0111", "bibkey": "Mao2023Language", "title": "A Language Agent for Autonomous Driving", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose a fundamental paradigm shift from current pipelines, exploiting Large Language Models (LLMs) as a cognitive agent to integrate human-like intelligence into autonomous driving systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0111-d9668f576d", "paper_id": "P0111", "bibkey": "Mao2023Language", "title": "A Language Agent for Autonomous Driving", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate our approach on the large-scale nuScenes benchmark, and extensive experiments substantiate that our Agent-Driver significantly outperforms the state-of-the-art driving methods by a large margin.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0111-2c0845aed1", "paper_id": "P0111", "bibkey": "Mao2023Language", "title": "A Language Agent for Autonomous Driving", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Human-level driving is an ultimate goal of autonomous driving.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0111-df01fbc25c", "paper_id": "P0111", "bibkey": "Mao2023Language", "title": "A Language Agent for Autonomous Driving", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Human-level driving is an ultimate goal of autonomous driving.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0111-1638e97eab", "paper_id": "P0111", "bibkey": "Mao2023Language", "title": "A Language Agent for Autonomous Driving", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Conventional approaches formulate autonomous driving as a perception-prediction-planning framework, yet their systems do not capitalize on the inherent reasoning ability and experiential knowledge of humans.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0111-d55a54e531", "paper_id": "P0111", "bibkey": "Mao2023Language", "title": "A Language Agent for Autonomous Driving", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose a fundamental paradigm shift from current pipelines, exploiting Large Language Models (LLMs) as a cognitive agent to integrate human-like intelligence into autonomous driving systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0112-38a252fae6", "paper_id": "P0112", "bibkey": "Chang2023Survey", "title": "A Survey on Evaluation of Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0112-fb83b7aa2b", "paper_id": "P0112", "bibkey": "Chang2023Survey", "title": "A Survey on Evaluation of Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0112-8f668d83bf", "paper_id": "P0112", "bibkey": "Chang2023Survey", "title": "A Survey on Evaluation of Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0112-c6352be2d8", "paper_id": "P0112", "bibkey": "Chang2023Survey", "title": "A Survey on Evaluation of Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0112-72ea044b37", "paper_id": "P0112", "bibkey": "Chang2023Survey", "title": "A Survey on Evaluation of Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0112-7b67a87007", "paper_id": "P0112", "bibkey": "Chang2023Survey", "title": "A Survey on Evaluation of Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Over the past years, significant efforts have been made to examine LLMs from various perspectives.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0113-24c8a8f93a", "paper_id": "P0113", "bibkey": "Lin2023Agentsims", "title": "AgentSims: An Open-Source Sandbox for Large Language Model Evaluation", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present AgentSims, an easy-to-use infrastructure for researchers from all disciplines to test the specific capacities they are interested in.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0113-152d1ce5af", "paper_id": "P0113", "bibkey": "Lin2023Agentsims", "title": "AgentSims: An Open-Source Sandbox for Large Language Model Evaluation", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Existing evaluation methods suffer from following shortcomings: (1) constrained evaluation abilities, (2) vulnerable benchmarks, (3) unobjective metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0113-f38c4a86a1", "paper_id": "P0113", "bibkey": "Lin2023Agentsims", "title": "AgentSims: An Open-Source Sandbox for Large Language Model Evaluation", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "We suggest that task-based evaluation, where LLM agents complete tasks in a simulated environment, is a one-for-all solution to solve above problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0113-4a7ae5c98e", "paper_id": "P0113", "bibkey": "Lin2023Agentsims", "title": "AgentSims: An Open-Source Sandbox for Large Language Model Evaluation", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With ChatGPT-like large language models (LLM) prevailing in the community, how to evaluate the ability of LLMs is an open question.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0113-c45e932d73", "paper_id": "P0113", "bibkey": "Lin2023Agentsims", "title": "AgentSims: An Open-Source Sandbox for Large Language Model Evaluation", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing evaluation methods suffer from following shortcomings: (1) constrained evaluation abilities, (2) vulnerable benchmarks, (3) unobjective metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0113-4a4db01d53", "paper_id": "P0113", "bibkey": "Lin2023Agentsims", "title": "AgentSims: An Open-Source Sandbox for Large Language Model Evaluation", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We suggest that task-based evaluation, where LLM agents complete tasks in a simulated environment, is a one-for-all solution to solve above problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0114-6e573db11b", "paper_id": "P0114", "bibkey": "Webb2023Improving", "title": "Improving Planning with Large Language Models: A Modular Agentic Architecture", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "To improve planning with LLMs, we propose an agentic architecture, the Modular Agentic Planner (MAP), in which planning is accomplished via the recurrent interaction of the specialized modules mentioned above, each implemented using an LLM.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0114-373af18bcc", "paper_id": "P0114", "bibkey": "Webb2023Improving", "title": "Improving Planning with Large Language Models: A Modular Agentic Architecture", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Both cognitive neuroscience and reinforcement learning (RL) have proposed a number of interacting functional components that together implement search and evaluation in multi-step decision making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0114-ac2b4d69bb", "paper_id": "P0114", "bibkey": "Webb2023Improving", "title": "Improving Planning with Large Language Models: A Modular Agentic Architecture", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "These components include conflict monitoring, state prediction, state evaluation, task decomposition, and orchestration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0114-a3d019c3ec", "paper_id": "P0114", "bibkey": "Webb2023Improving", "title": "Improving Planning with Large Language Models: A Modular Agentic Architecture", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) demonstrate impressive performance on a wide variety of tasks, but they often struggle with tasks that require multi-step reasoning or goal-directed planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0114-2e335917a9", "paper_id": "P0114", "bibkey": "Webb2023Improving", "title": "Improving Planning with Large Language Models: A Modular Agentic Architecture", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Both cognitive neuroscience and reinforcement learning (RL) have proposed a number of interacting functional components that together implement search and evaluation in multi-step decision making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0114-186166fd28", "paper_id": "P0114", "bibkey": "Webb2023Improving", "title": "Improving Planning with Large Language Models: A Modular Agentic Architecture", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These components include conflict monitoring, state prediction, state evaluation, task decomposition, and orchestration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0115-1e5fa00b20", "paper_id": "P0115", "bibkey": "Xu2023Magic", "title": "MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Models (LLMs) have significantly advanced natural language processing, demonstrating exceptional reasoning, tool usage, and memory capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#method"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0115-af857798be", "paper_id": "P0115", "bibkey": "Xu2023Magic", "title": "MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate seven LLMs, quantitatively highlighting a significant capability gap of over threefold between the strongest, GPT o1, and the weakest, Llama-2-70B.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0115-4bfcf0838d", "paper_id": "P0115", "bibkey": "Xu2023Magic", "title": "MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "It also confirms that our PGM enhancement boosts the abilities of all selected models by an average of 37%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0115-5f2bff37b3", "paper_id": "P0115", "bibkey": "Xu2023Magic", "title": "MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have significantly advanced natural language processing, demonstrating exceptional reasoning, tool usage, and memory capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0115-41ec3b7160", "paper_id": "P0115", "bibkey": "Xu2023Magic", "title": "MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As their applications expand into multi-agent environments, there arises a need for a comprehensive evaluation framework that captures LLMs' reasoning, planning, collaboration, and other social abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0115-feda9db147", "paper_id": "P0115", "bibkey": "Xu2023Magic", "title": "MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This work introduces a novel competition-based benchmark framework specifically designed to assess LLMs within multi-agent settings, providing quantitative metrics to evaluate their judgment, reasoning, deception, self-awareness, cooperation, coordination, and rationality.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0116-5eda4a7824", "paper_id": "P0116", "bibkey": "Li2023Modelscope", "title": "ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we introduce ModelScope-Agent, a general and customizable agent framework for real-world applications, based on open-source LLMs as controllers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0116-7a2e32f4bc", "paper_id": "P0116", "bibkey": "Li2023Modelscope", "title": "ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we showcase ModelScopeGPT, a real-world intelligent assistant of ModelScope Community based on the ModelScope-Agent framework, which is able to connect open-source LLMs with more than 1000 public AI models and localized community knowledge in ModelScope.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0116-a4d153adbf", "paper_id": "P0116", "bibkey": "Li2023Modelscope", "title": "ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large language models (LLMs) have recently demonstrated remarkable capabilities to comprehend human intentions, engage in reasoning, and design planning-like behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0116-5214d9aa74", "paper_id": "P0116", "bibkey": "Li2023Modelscope", "title": "ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have recently demonstrated remarkable capabilities to comprehend human intentions, engage in reasoning, and design planning-like behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0116-3d092eb5f4", "paper_id": "P0116", "bibkey": "Li2023Modelscope", "title": "ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To further unleash the power of LLMs to accomplish complex tasks, there is a growing trend to build agent framework that equips LLMs, such as ChatGPT, with tool-use abilities to connect with massive external APIs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0116-5ce038b37f", "paper_id": "P0116", "bibkey": "Li2023Modelscope", "title": "ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we introduce ModelScope-Agent, a general and customizable agent framework for real-world applications, based on open-source LLMs as controllers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0116-fca9acf3f7", "paper_id": "P0116", "bibkey": "Li2023Modelscope", "title": "ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It provides a user-friendly system library, with customizable engine design to support model training on multiple open-source LLMs, while also enabling seamless integration with both model APIs and common APIs in a unified way.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0116-8713cff493", "paper_id": "P0116", "bibkey": "Li2023Modelscope", "title": "ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To equip the LLMs with tool-use abilities, a comprehensive framework has been proposed spanning over tool-use data collection, tool retrieval, tool registration, memory control, customized model training, and evaluation for practical real-world applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0117-de716a2f6c", "paper_id": "P0117", "bibkey": "Zhou2023Navgpt", "title": "NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we introduce the NavGPT, a purely LLM-based instruction-following navigation agent, to reveal the reasoning capability of GPT models in complex embodied scenes by performing zero-shot sequential action prediction for vision-and-language navigation (VLN).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0117-ebbc83e2c7", "paper_id": "P0117", "bibkey": "Zhou2023Navgpt", "title": "NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Trained with an unprecedented scale of data, large language models (LLMs) like ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilities from model scaling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0117-2c12f2ff60", "paper_id": "P0117", "bibkey": "Zhou2023Navgpt", "title": "NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Furthermore, we show that LLMs is capable of generating high-quality navigational instructions from observations and actions along a path, as well as drawing accurate top-down metric trajectory given the agent's navigation history.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0117-bebfbd0edb", "paper_id": "P0117", "bibkey": "Zhou2023Navgpt", "title": "NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Trained with an unprecedented scale of data, large language models (LLMs) like ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilities from model scaling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#summary_bullets[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0117-480890f6c9", "paper_id": "P0117", "bibkey": "Zhou2023Navgpt", "title": "NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Such a trend underscored the potential of training LLMs with unlimited language data, advancing the development of a universal embodied agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0117-1b0b4abbad", "paper_id": "P0117", "bibkey": "Zhou2023Navgpt", "title": "NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we introduce the NavGPT, a purely LLM-based instruction-following navigation agent, to reveal the reasoning capability of GPT models in complex embodied scenes by performing zero-shot sequential action prediction for vision-and-language navigation (VLN).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0118-4e24b07c1a", "paper_id": "P0118", "bibkey": "Liu2023Reason", "title": "Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "To this end, we propose a principled framework with provable regret guarantees to orchestrate reasoning and acting, which we call \"reason for future, act for now\" (\\texttt{RAFA}).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0118-fa466c449b", "paper_id": "P0118", "bibkey": "Liu2023Reason", "title": "Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our empirical validation shows that it outperforms various existing frameworks and achieves nearly perfect scores on a few benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0118-8b07795a97", "paper_id": "P0118", "bibkey": "Liu2023Reason", "title": "Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) demonstrate impressive reasoning abilities, but translating reasoning into actions in the real world remains challenging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0118-7e1879d3c7", "paper_id": "P0118", "bibkey": "Liu2023Reason", "title": "Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In particular, it remains unclear how to complete a given task provably within a minimum number of interactions with the external environment, e.g., through an internal mechanism of reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0118-cc013ccd03", "paper_id": "P0118", "bibkey": "Liu2023Reason", "title": "Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To this end, we propose a principled framework with provable regret guarantees to orchestrate reasoning and acting, which we call \"reason for future, act for now\" (\\texttt{RAFA}).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0119-0c80b4dcde", "paper_id": "P0119", "bibkey": "Xu2023Towards", "title": "Towards Reasoning in Large Language Models via Multi-Agent Peer Review Collaboration", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a multi-agent collaboration strategy that emulates the academic peer review process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0119-e39a48f0d6", "paper_id": "P0119", "bibkey": "Xu2023Towards", "title": "Towards Reasoning in Large Language Models via Multi-Agent Peer Review Collaboration", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Recent studies have explored human-like problem-solving strategies, such as self-correct, to push further the boundary of single-model reasoning ability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0119-02f16b54ff", "paper_id": "P0119", "bibkey": "Xu2023Towards", "title": "Towards Reasoning in Large Language Models via Multi-Agent Peer Review Collaboration", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments on three different types of reasoning tasks show that our collaboration approach delivers superior accuracy across all ten datasets compared to existing methods.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0119-50461fd9fc", "paper_id": "P0119", "bibkey": "Xu2023Towards", "title": "Towards Reasoning in Large Language Models via Multi-Agent Peer Review Collaboration", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have shown remarkable capabilities in general natural language processing tasks but often fall short in complex reasoning tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0119-dab2f6b183", "paper_id": "P0119", "bibkey": "Xu2023Towards", "title": "Towards Reasoning in Large Language Models via Multi-Agent Peer Review Collaboration", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent studies have explored human-like problem-solving strategies, such as self-correct, to push further the boundary of single-model reasoning ability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0119-cbc19a9d04", "paper_id": "P0119", "bibkey": "Xu2023Towards", "title": "Towards Reasoning in Large Language Models via Multi-Agent Peer Review Collaboration", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we let a single model \"step outside the box\" by engaging multiple models to correct each other.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0120-7c15c56e3a", "paper_id": "P0120", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Model (LLM) agents struggle with long-horizon software engineering tasks due to \"Context Bloat.\" As interaction history grows, computational costs explode, latency increases, and reasoning capabilities degrade due to distraction by irrelevant past errors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0120-c411c6caee", "paper_id": "P0120", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "With aggressive prompting that encourages frequent compression, Focus achieves 22.7% token reduction (14.9M -> 11.5M tokens) while maintaining identical accuracy (3/5 = 60% for both agents).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0120-9abcf1bf8a", "paper_id": "P0120", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0120-a0e592a756", "paper_id": "P0120", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents struggle with long-horizon software engineering tasks due to \"Context Bloat.\" As interaction history grows, computational costs explode, latency increases, and reasoning capabilities degrade due to distraction by irrelevant past errors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0120-5a68f5562b", "paper_id": "P0120", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing solutions often rely on passive, external summarization mechanisms that the agent cannot control.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0120-0323bf5e7e", "paper_id": "P0120", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper proposes Focus, an agent-centric architecture inspired by the biological exploration strategies of Physarum polycephalum (slime mold).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0121-844ca49812", "paper_id": "P0121", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose Agentic Memory (AgeMem), a unified framework that integrates LTM and STM management directly into the agent's policy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0121-f0f0faaada", "paper_id": "P0121", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0121-ee162c208a", "paper_id": "P0121", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0121-47a5ff21e4", "paper_id": "P0121", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing methods typically handle long-term memory (LTM) and short-term memory (STM) as separate components, relying on heuristics or auxiliary controllers, which limits adaptability and end-to-end optimization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0121-d71204699d", "paper_id": "P0121", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose Agentic Memory (AgeMem), a unified framework that integrates LTM and STM management directly into the agent's policy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0121-8b5ccf3d93", "paper_id": "P0121", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#limitations[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0122-ef4cf62416", "paper_id": "P0122", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0122-79f88927fa", "paper_id": "P0122", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0122-593af2dd94", "paper_id": "P0122", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "API specification, which includes detailed documentation and usage constraints, and 2.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0122-f99e220a0c", "paper_id": "P0122", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0122-2b1181bd3f", "paper_id": "P0122", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0122-cdecc79d54", "paper_id": "P0122", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "API specification, which includes detailed documentation and usage constraints, and 2.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0123-a5a67dec94", "paper_id": "P0123", "bibkey": "Zhao2026Ecomstage", "title": "EComStage: Stage-wise and Orientation-specific Benchmarking for Large Language Models in E-commerce", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we propose EComStage, a unified benchmark for evaluating agent-capable LLMs across the comprehensive stage-wise reasoning process: Perception (understanding user intent), Planning (formulating an action plan), and Action (executing the decision).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0123-ccb925a417", "paper_id": "P0123", "bibkey": "Zhao2026Ecomstage", "title": "EComStage: Stage-wise and Orientation-specific Benchmarking for Large Language Models in E-commerce", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate a wide range of over 30 LLMs, spanning from 1B to over 200B parameters, including open-source models and closed-source APIs, revealing stage/orientation-specific strengths and weaknesses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0123-a288c0a652", "paper_id": "P0123", "bibkey": "Zhao2026Ecomstage", "title": "EComStage: Stage-wise and Orientation-specific Benchmarking for Large Language Models in E-commerce", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Existing benchmarks primarily evaluate whether these agents successfully complete the final task, overlooking the intermediate reasoning stages that are crucial for effective decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0123-6d1a52e99f", "paper_id": "P0123", "bibkey": "Zhao2026Ecomstage", "title": "EComStage: Stage-wise and Orientation-specific Benchmarking for Large Language Models in E-commerce", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM)-based agents are increasingly deployed in e-commerce applications to assist customer services in tasks such as product inquiries, recommendations, and order management.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0123-6f8bd97b77", "paper_id": "P0123", "bibkey": "Zhao2026Ecomstage", "title": "EComStage: Stage-wise and Orientation-specific Benchmarking for Large Language Models in E-commerce", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing benchmarks primarily evaluate whether these agents successfully complete the final task, overlooking the intermediate reasoning stages that are crucial for effective decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0123-d815d5ca55", "paper_id": "P0123", "bibkey": "Zhao2026Ecomstage", "title": "EComStage: Stage-wise and Orientation-specific Benchmarking for Large Language Models in E-commerce", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, we propose EComStage, a unified benchmark for evaluating agent-capable LLMs across the comprehensive stage-wise reasoning process: Perception (understanding user intent), Planning (formulating an action plan), and Action (executing the decision).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0124-df142ee3e5", "paper_id": "P0124", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To dismantle this trilemma, we introduce EvoRoute, a self-evolving model routing paradigm that transcends static, pre-defined model assignments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0124-60cc0d458f", "paper_id": "P0124", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\\%$ and latency by over $70\\%$.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0124-d550725f5f", "paper_id": "P0124", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, this success is shadowed by prohibitive economic costs and severe latency, exposing a critical, yet underexplored, trade-off.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0124-f5b4e3fb6c", "paper_id": "P0124", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Complex agentic AI systems, powered by a coordinated ensemble of Large Language Models (LLMs), tool and memory modules, have demonstrated remarkable capabilities on intricate, multi-turn tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0124-229019434c", "paper_id": "P0124", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, this success is shadowed by prohibitive economic costs and severe latency, exposing a critical, yet underexplored, trade-off.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0124-6b1976d308", "paper_id": "P0124", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We formalize this challenge as the \\textbf{Agent System Trilemma}: the inherent tension among achieving state-of-the-art performance, minimizing monetary cost, and ensuring rapid task completion.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0125-cfd50d8597", "paper_id": "P0125", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "Existing change detection methods often lack the versatility to handle diverse real-world queries and the intelligence for comprehensive analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0125-a8702dce10", "paper_id": "P0125", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "The agent was evaluated on a curated dataset of 140 questions categorized by real-world scenarios, encompassing various question types (e.g., Size, Class, Number) and complexities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0125-deabf13faf", "paper_id": "P0125", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "ChangeGPT, especially with a GPT-4-turbo backend, demonstrated superior performance, achieving a 90.71 % Match rate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0125-c4ff905064", "paper_id": "P0125", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing change detection methods often lack the versatility to handle diverse real-world queries and the intelligence for comprehensive analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0125-0afbc558b7", "paper_id": "P0125", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents a general agent framework, integrating Large Language Models (LLM) with vision foundation models to form ChangeGPT.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0125-24d3c2a530", "paper_id": "P0125", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A hierarchical structure is employed to mitigate hallucination.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0126-952a3ec8a8", "paper_id": "P0126", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we present a comprehensive survey of LLM agents for legal tasks, analyzing how these architectures bridge the gap between technical capabilities and domain-specific needs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0126-8b56718f74", "paper_id": "P0126", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our major contributions include: (1) systematically analyzing the technical transition from standard legal LLMs to legal agents; (2) presenting a structured taxonomy of current agent applications across distinct legal practice areas; (3) discussing evaluation methodologies specifically for agentic performance in law; and (4) identifying open challenges and outlining future directions for developing robust and autonomous legal assistants.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0126-73192b14aa", "paper_id": "P0126", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have precipitated a dramatic improvement in the legal domain, yet the deployment of standalone models faces significant limitations regarding hallucination, outdated information, and verifiability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0126-536a01abb9", "paper_id": "P0126", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, LLM agents have attracted significant attention as a solution to these challenges, utilizing advanced capabilities such as planning, memory, and tool usage to meet the rigorous standards of legal practice.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0126-9e10275b89", "paper_id": "P0126", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we present a comprehensive survey of LLM agents for legal tasks, analyzing how these architectures bridge the gap between technical capabilities and domain-specific needs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0126-19ffd0c3ba", "paper_id": "P0126", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Large language models (LLMs) have precipitated a dramatic improvement in the legal domain, yet the deployment of standalone models faces significant limitations regarding hallucination, outdated information, and verifiability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0127-607a67cf41", "paper_id": "P0127", "bibkey": "Zhang2026Maxs", "title": "MAXS: Meta-Adaptive Exploration with LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these two issues, we propose meta-adaptive exploration with LLM agents https://github.com/exoskeletonzj/MAXS, a meta-adaptive reasoning framework based on LLM Agents that flexibly integrates tool execution and reasoning planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0127-6d8c7a2ee9", "paper_id": "P0127", "bibkey": "Zhang2026Maxs", "title": "MAXS: Meta-Adaptive Exploration with LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We conduct extensive empirical studies across three base models (MiMo-VL-7B, Qwen2.5-VL-7B, Qwen2.5-VL-32B) and five datasets, demonstrating that MAXS consistently outperforms existing methods in both performance and inference efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0127-6224623a18", "paper_id": "P0127", "bibkey": "Zhang2026Maxs", "title": "MAXS: Meta-Adaptive Exploration with LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) Agents exhibit inherent reasoning abilities through the collaboration of multiple tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0127-aa9d142037", "paper_id": "P0127", "bibkey": "Zhang2026Maxs", "title": "MAXS: Meta-Adaptive Exploration with LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, during agent inference, existing methods often suffer from (i) locally myopic generation, due to the absence of lookahead, and (ii) trajectory instability, where minor early errors can escalate into divergent reasoning paths.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0127-b8b3947292", "paper_id": "P0127", "bibkey": "Zhang2026Maxs", "title": "MAXS: Meta-Adaptive Exploration with LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These issues make it difficult to balance global effectiveness and computational efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0128-5471e4157d", "paper_id": "P0128", "bibkey": "Tao2026Membox", "title": "Membox: Weaving Topic Continuity into Long-Range Memory for LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce membox, a hierarchical memory architecture centered on a Topic Loom that continuously monitors dialogue in a sliding-window fashion, grouping consecutive same-topic turns into coherent \"memory boxes\" at storage time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0128-d8feedefd0", "paper_id": "P0128", "bibkey": "Tao2026Membox", "title": "Membox: Weaving Topic Continuity into Long-Range Memory for LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on LoCoMo demonstrate that Membox achieves up to 68% F1 improvement on temporal reasoning tasks, outperforming competitive baselines (e.g., Mem0, A-MEM).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0128-32c1e1ef43", "paper_id": "P0128", "bibkey": "Tao2026Membox", "title": "Membox: Weaving Topic Continuity into Long-Range Memory for LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Human-agent dialogues often exhibit topic continuity-a stable thematic frame that evolves through temporally adjacent exchanges-yet most large language model (LLM) agent memory systems fail to preserve it.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#key_results[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0128-b2d6a7fb76", "paper_id": "P0128", "bibkey": "Tao2026Membox", "title": "Membox: Weaving Topic Continuity into Long-Range Memory for LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Human-agent dialogues often exhibit topic continuity-a stable thematic frame that evolves through temporally adjacent exchanges-yet most large language model (LLM) agent memory systems fail to preserve it.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0128-f399cff144", "paper_id": "P0128", "bibkey": "Tao2026Membox", "title": "Membox: Weaving Topic Continuity into Long-Range Memory for LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing designs follow a fragmentation-compensation paradigm: they first break dialogue streams into isolated utterances for storage, then attempt to restore coherence via embedding-based retrieval.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0128-3c5fb24095", "paper_id": "P0128", "bibkey": "Tao2026Membox", "title": "Membox: Weaving Topic Continuity into Long-Range Memory for LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This process irreversibly damages narrative and causal flow, while biasing retrieval towards lexical similarity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0129-fd1c020725", "paper_id": "P0129", "bibkey": "Wang2025Comprehensive", "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The remarkable success of Large Language Models (LLMs) has illuminated a promising pathway toward achieving Artificial General Intelligence for both academic and industrial communities, owing to their unprecedented performance across various applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0129-d541ee15e3", "paper_id": "P0129", "bibkey": "Wang2025Comprehensive", "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our research is grounded in an exhaustive review of over 800+ papers, ensuring comprehensive coverage and systematic organization of security issues within a more holistic understanding.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0129-fb0d5b7ae0", "paper_id": "P0129", "bibkey": "Wang2025Comprehensive", "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The remarkable success of Large Language Models (LLMs) has illuminated a promising pathway toward achieving Artificial General Intelligence for both academic and industrial communities, owing to their unprecedented performance across various applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0129-122ed19ba9", "paper_id": "P0129", "bibkey": "Wang2025Comprehensive", "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The remarkable success of Large Language Models (LLMs) has illuminated a promising pathway toward achieving Artificial General Intelligence for both academic and industrial communities, owing to their unprecedented performance across various applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0129-1222ae6189", "paper_id": "P0129", "bibkey": "Wang2025Comprehensive", "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As LLMs continue to gain prominence in both research and commercial domains, their security and safety implications have become a growing concern, not only for researchers and corporations but also for every nation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0129-ab9bde5a7c", "paper_id": "P0129", "bibkey": "Wang2025Comprehensive", "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Currently, existing surveys on LLM safety primarily focus on specific stages of the LLM lifecycle, e.g., deployment phase or fine-tuning phase, lacking a comprehensive understanding of the entire \"lifechain\" of LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0129-6a2ccc17c0", "paper_id": "P0129", "bibkey": "Wang2025Comprehensive", "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "These insights provide valuable guidance for researchers pursuing future work in this field.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0130-91a81fe89a", "paper_id": "P0130", "bibkey": "Aljohani2025Comprehensive", "title": "A Comprehensive Survey on the Trustworthiness of Large Language Models in Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We analyze how each dimension affects the reliability and ethical deployment of healthcare LLMs, synthesize ongoing research efforts, and identify critical gaps in existing approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0130-76cd732d10", "paper_id": "P0130", "bibkey": "Aljohani2025Comprehensive", "title": "A Comprehensive Survey on the Trustworthiness of Large Language Models in Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "While researchers have recently begun developing benchmarks and evaluation frameworks to assess LLM trustworthiness, the trustworthiness of LLMs in healthcare remains underexplored, lacking a systematic review that provides a comprehensive understanding and future insights.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0130-abd03ca815", "paper_id": "P0130", "bibkey": "Aljohani2025Comprehensive", "title": "A Comprehensive Survey on the Trustworthiness of Large Language Models in Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The application of large language models (LLMs) in healthcare holds significant promise for enhancing clinical decision-making, medical research, and patient care.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0130-37e7bec4dc", "paper_id": "P0130", "bibkey": "Aljohani2025Comprehensive", "title": "A Comprehensive Survey on the Trustworthiness of Large Language Models in Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, their integration into real-world clinical settings raises critical concerns around trustworthiness, particularly around dimensions of truthfulness, privacy, safety, robustness, fairness, and explainability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0130-b430ccbc59", "paper_id": "P0130", "bibkey": "Aljohani2025Comprehensive", "title": "A Comprehensive Survey on the Trustworthiness of Large Language Models in Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These dimensions are essential for ensuring that LLMs generate reliable, unbiased, and ethically sound outputs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0131-dda4615952", "paper_id": "P0131", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this issue, we propose a multi-modal and automated scale bar detection and extraction framework that provides concurrent object detection, text detection and text recognition with a Large Language Model (LLM) agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0131-1b9b514b0a", "paper_id": "P0131", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The hybrid OCR system achieved 89% precision, 65% recall, and a 75% F1 score on the Auto-DG dataset, significantly outperforming several mainstream standalone engines, highlighting its reliability for scientific image analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0131-065ba24ce9", "paper_id": "P0131", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The proposed model demonstrates a strong performance in object detection and accurate localization with a precision of 100%, recall of 95.8%, and a mean Average Precision (mAP) of 99.2% at IoU=0.5 and 69.1% at IoU=0.5:0.95.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0131-a1b1baea2e", "paper_id": "P0131", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Microscopic characterizations, such as Scanning Electron Microscopy (SEM), are widely used in scientific research for visualizing and analyzing microstructures.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0131-b0095e0371", "paper_id": "P0131", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Determining the scale bars is an important first step of accurate SEM analysis; however, currently, it mainly relies on manual operations, which is both time-consuming and prone to errors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0131-c7a327bc99", "paper_id": "P0131", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this issue, we propose a multi-modal and automated scale bar detection and extraction framework that provides concurrent object detection, text detection and text recognition with a Large Language Model (LLM) agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0132-2a5fc497d0", "paper_id": "P0132", "bibkey": "Kiruluta2025Novel", "title": "A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose a hybrid architecture that integrates decision tree-based symbolic reasoning with the generative capabilities of large language models (LLMs) within a coordinated multi-agent framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0132-a666552417", "paper_id": "P0132", "bibkey": "Kiruluta2025Novel", "title": "A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On GSM8k, it achieves +5.3\\% accuracy gains in multistep mathematical problems via symbolic augmentation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0132-c7423180cf", "paper_id": "P0132", "bibkey": "Kiruluta2025Novel", "title": "A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On \\textit{ARC}, it boosts abstraction accuracy by +6.0\\% through integration of symbolic oracles.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0132-178473e844", "paper_id": "P0132", "bibkey": "Kiruluta2025Novel", "title": "A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose a hybrid architecture that integrates decision tree-based symbolic reasoning with the generative capabilities of large language models (LLMs) within a coordinated multi-agent framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0132-a1a6f9479c", "paper_id": "P0132", "bibkey": "Kiruluta2025Novel", "title": "A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike prior approaches that loosely couple symbolic and neural modules, our design embeds decision trees and random forests as callable oracles within a unified reasoning system.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0132-4b4ea26f38", "paper_id": "P0132", "bibkey": "Kiruluta2025Novel", "title": "A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tree-based modules enable interpretable rule inference and causal logic, while LLM agents handle abductive reasoning, generalization, and interactive planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0133-e2d0085f84", "paper_id": "P0133", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a task-driven taxonomy encompassing six broad application areas: data extraction, interpretation and Q\\&A; atomistic simulation; property prediction; materials structure, design and discovery; process planning, discovery, and optimization; and multiscale modeling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0133-a68f39bc04", "paper_id": "P0133", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This survey provides a comprehensive overview of foundation models, agentic systems, datasets, and computational tools supporting this growing field.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0133-e012f792c6", "paper_id": "P0133", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Furthermore, we review standardized datasets, open-source tools, and autonomous experimental platforms that collectively fuel the development and integration of FMs into research workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0133-34dbc1be9b", "paper_id": "P0133", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Foundation models (FMs) are catalyzing a transformative shift in materials science (MatSci) by enabling scalable, general-purpose, and multimodal AI systems for scientific discovery.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0133-099d1eaa8f", "paper_id": "P0133", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike traditional machine learning models, which are typically narrow in scope and require task-specific engineering, FMs offer cross-domain generalization and exhibit emergent capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0133-80a53d8d03", "paper_id": "P0133", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Their versatility is especially well-suited to materials science, where research challenges span diverse data types and scales.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0133-7acf4de689", "paper_id": "P0133", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "We assess the early successes of foundation models and identify persistent limitations, including challenges in generalizability, interpretability, data imbalance, safety concerns, and limited multimodal fusion.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0134-17a1bb587f", "paper_id": "P0134", "bibkey": "Zhou2025Survey", "title": "A Survey of LLM $\\times$ DATA", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The integration of large language model (LLM) and data management (DATA) is rapidly redefining both domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0134-89d169bb51", "paper_id": "P0134", "bibkey": "Zhou2025Survey", "title": "A Survey of LLM $\\times$ DATA", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We review recent advances in (i) data manipulation, including automatic data cleaning, integration, discovery; (ii) data analysis, covering reasoning over structured, semi-structured, and unstructured data, and (iii) system optimization (e.g., configuration tuning, query rewriting, anomaly diagnosis), powered by LLM techniques like retrieval-augmented prompting, task-specialized fine-tuning, and multi-agent collaboration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0134-cfcf55250d", "paper_id": "P0134", "bibkey": "Zhou2025Survey", "title": "A Survey of LLM $\\times$ DATA", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The integration of large language model (LLM) and data management (DATA) is rapidly redefining both domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0134-3658645525", "paper_id": "P0134", "bibkey": "Zhou2025Survey", "title": "A Survey of LLM $\\times$ DATA", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this survey, we comprehensively review the bidirectional relationships.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0134-ff23838bdc", "paper_id": "P0134", "bibkey": "Zhou2025Survey", "title": "A Survey of LLM $\\times$ DATA", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "On the one hand, DATA4LLM, spanning large-scale data processing, storage, and serving, feeds LLMs with high quality, diversity, and timeliness of data required for stages like pre-training, post-training, retrieval-augmented generation, and agentic workflows: (i) Data processing for LLMs includes scalable acquisition, deduplication, filtering, selection, domain mixing, and synthetic augmentation; (ii) Data Storage for LLMs focuses on efficient data and model formats, distributed and heterogeneous storage hierarchies, KV-cache management, and fault-tolerant checkpointing; (iii) Data serving for LLMs tackles challenges in RAG (e.g., knowledge post-processing), LLM inference (e.g., prompt compression, data provenance), and training strategies (e.g., data packing and shuffling).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0135-c92fa98a3c", "paper_id": "P0135", "bibkey": "Xiang2025Survey", "title": "A Survey of Large Language Models in Discipline-specific Research: Challenges, Methods and Opportunities", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Models (LLMs) have demonstrated their transformative potential across numerous disciplinary studies, reshaping the existing research methodologies and fostering interdisciplinary collaboration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0135-0dbab9c009", "paper_id": "P0135", "bibkey": "Xiang2025Survey", "title": "A Survey of Large Language Models in Discipline-specific Research: Challenges, Methods and Opportunities", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "By providing a comprehensive overview of the technical developments and applications in this field, this survey aims to serve as an invaluable resource for the researchers who are navigating the complex landscape of LLMs in the context of interdisciplinary studies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0135-96dd5b94ce", "paper_id": "P0135", "bibkey": "Xiang2025Survey", "title": "A Survey of Large Language Models in Discipline-specific Research: Challenges, Methods and Opportunities", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have demonstrated their transformative potential across numerous disciplinary studies, reshaping the existing research methodologies and fostering interdisciplinary collaboration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0135-1c83932247", "paper_id": "P0135", "bibkey": "Xiang2025Survey", "title": "A Survey of Large Language Models in Discipline-specific Research: Challenges, Methods and Opportunities", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, a systematic understanding of their integration into diverse disciplines remains underexplored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0135-830ab73195", "paper_id": "P0135", "bibkey": "Xiang2025Survey", "title": "A Survey of Large Language Models in Discipline-specific Research: Challenges, Methods and Opportunities", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey paper provides a comprehensive overview of the application of LLMs in interdisciplinary studies, categorising research efforts from both a technical perspective and with regard to their applicability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0136-dc3d2a7752", "paper_id": "P0136", "bibkey": "Chen2025Survey", "title": "A Survey of Scaling in Large Language Model Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Next, we analyze scaling in reasoning steps that improves multi-step inference and logical consistency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0136-aa64e614e6", "paper_id": "P0136", "bibkey": "Chen2025Survey", "title": "A Survey of Scaling in Large Language Model Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "By synthesizing these diverse perspectives, this survey aims to provide insights into how scaling strategies fundamentally enhance the reasoning capabilities of LLMs and further guide the development of next-generation AI systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0136-507eec7fb0", "paper_id": "P0136", "bibkey": "Chen2025Survey", "title": "A Survey of Scaling in Large Language Model Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid advancements in large Language models (LLMs) have significantly enhanced their reasoning capabilities, driven by various strategies such as multi-agent collaboration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0136-08815c7c8e", "paper_id": "P0136", "bibkey": "Chen2025Survey", "title": "A Survey of Scaling in Large Language Model Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, unlike the well-established performance improvements achieved through scaling data and model size, the scaling of reasoning in LLMs is more complex and can even negatively impact reasoning performance, introducing new challenges in model alignment and robustness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0136-1a94d9a901", "paper_id": "P0136", "bibkey": "Chen2025Survey", "title": "A Survey of Scaling in Large Language Model Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this survey, we provide a comprehensive examination of scaling in LLM reasoning, categorizing it into multiple dimensions and analyzing how and to what extent different scaling strategies contribute to improving reasoning capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0137-2a1951092e", "paper_id": "P0137", "bibkey": "Ge2025Survey", "title": "A Survey of Vibe Coding with Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The advancement of large language models (LLMs) has catalyzed a paradigm shift from code generation assistance to autonomous coding agents, enabling a novel development methodology termed \"Vibe Coding\" where developers validate AI-generated implementations through outcome observation rather than line-by-line code comprehension.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0137-d70a67b3d0", "paper_id": "P0137", "bibkey": "Ge2025Survey", "title": "A Survey of Vibe Coding with Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Drawing from systematic analysis of over 1000 research papers, we survey the entire vibe coding ecosystem, examining critical infrastructure components including LLMs for coding, LLM-based coding agent, development environment of coding agent, and feedback mechanisms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0137-79dc0cfe22", "paper_id": "P0137", "bibkey": "Ge2025Survey", "title": "A Survey of Vibe Coding with Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Despite its transformative potential, the effectiveness of this emergent paradigm remains under-explored, with empirical evidence revealing unexpected productivity losses and fundamental challenges in human-AI collaboration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0137-858db2644b", "paper_id": "P0137", "bibkey": "Ge2025Survey", "title": "A Survey of Vibe Coding with Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The advancement of large language models (LLMs) has catalyzed a paradigm shift from code generation assistance to autonomous coding agents, enabling a novel development methodology termed \"Vibe Coding\" where developers validate AI-generated implementations through outcome observation rather than line-by-line code comprehension.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0137-d968dfc590", "paper_id": "P0137", "bibkey": "Ge2025Survey", "title": "A Survey of Vibe Coding with Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite its transformative potential, the effectiveness of this emergent paradigm remains under-explored, with empirical evidence revealing unexpected productivity losses and fundamental challenges in human-AI collaboration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0137-bb8f55912a", "paper_id": "P0137", "bibkey": "Ge2025Survey", "title": "A Survey of Vibe Coding with Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, this survey provides the first comprehensive and systematic review of Vibe Coding with large language models, establishing both theoretical foundations and practical frameworks for this transformative development approach.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0138-c0ee6eb9df", "paper_id": "P0138", "bibkey": "Samplawski2025Agent", "title": "AGENT: An Aerial Vehicle Generation and Design Tool Using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Following the recent success of large language models (LLMs), we propose AGENT (Aircraft GENeraTor).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0138-da6dd163cf", "paper_id": "P0138", "bibkey": "Samplawski2025Agent", "title": "AGENT: An Aerial Vehicle Generation and Design Tool Using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We use the recently released AircraftVerse dataset, which is especially suited for developing and evaluating large language models for designs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0138-0e1a1ca884", "paper_id": "P0138", "bibkey": "Samplawski2025Agent", "title": "AGENT: An Aerial Vehicle Generation and Design Tool Using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Following the recent success of large language models (LLMs), we propose AGENT (Aircraft GENeraTor).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0138-f84e8f8d7c", "paper_id": "P0138", "bibkey": "Samplawski2025Agent", "title": "AGENT: An Aerial Vehicle Generation and Design Tool Using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Computer-aided design (CAD) is a promising application area for emerging artificial intelligence methods.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0138-2e0aa19a7f", "paper_id": "P0138", "bibkey": "Samplawski2025Agent", "title": "AGENT: An Aerial Vehicle Generation and Design Tool Using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional workflows for cyberphysical systems create detailed digital models which can be evaluated by physics simulators in order to narrow the search space before creating physical prototypes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0138-04e25baa0c", "paper_id": "P0138", "bibkey": "Samplawski2025Agent", "title": "AGENT: An Aerial Vehicle Generation and Design Tool Using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A major bottleneck of this approach is that the simulators are often computationally expensive and slow.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0139-87532cd300", "paper_id": "P0139", "bibkey": "Masters2025Arcane", "title": "ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce ARCANE, a framework that frames alignment as a multi-agent collaboration problem that dynamically represents stakeholder preferences as natural-language rubrics: weighted sets of verifiable criteria that can be generated on-the-fly from task context.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0139-8eb9ff221b", "paper_id": "P0139", "bibkey": "Masters2025Arcane", "title": "ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Using a corpus of 219 labeled rubrics derived from the GDPVal benchmark, we evaluate ARCANE on challenging tasks requiring multi-step reasoning and tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0139-526e5fa507", "paper_id": "P0139", "bibkey": "Masters2025Arcane", "title": "ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As agents based on large language models are increasingly deployed to long-horizon tasks, maintaining their alignment with stakeholder preferences becomes critical.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0139-66f80bef80", "paper_id": "P0139", "bibkey": "Masters2025Arcane", "title": "ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Effective alignment in such settings requires reward models that are interpretable so that stakeholders can understand and audit model objectives.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0139-1b5c90617c", "paper_id": "P0139", "bibkey": "Masters2025Arcane", "title": "ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Moreover, reward models must be capable of steering agents at interaction time, allowing preference shifts to be incorporated without retraining.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0140-9aa1481722", "paper_id": "P0140", "bibkey": "Chen2025Atlas", "title": "ATLaS: Agent Tuning via Learning Critical Steps", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "For more effective and efficient agent tuning, we propose ATLaS that identifies the critical steps in expert trajectories and finetunes LLMs solely on these steps with reduced costs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0140-4ec8ccd2d2", "paper_id": "P0140", "bibkey": "Chen2025Atlas", "title": "ATLaS: Agent Tuning via Learning Critical Steps", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In extensive experiments, an LLM finetuned on only 30% critical steps selected by ATLaS outperforms the LLM finetuned on all steps and recent open-source LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0140-f1fb21d6a3", "paper_id": "P0140", "bibkey": "Chen2025Atlas", "title": "ATLaS: Agent Tuning via Learning Critical Steps", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Additionally, critical steps, such as planning, complex reasoning for intermediate subtasks, and strategic decision-making, are essential to success in agent tasks, so learning these steps is the key to improving LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0140-85ab7f7050", "paper_id": "P0140", "bibkey": "Chen2025Atlas", "title": "ATLaS: Agent Tuning via Learning Critical Steps", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents have demonstrated remarkable generalization capabilities across multi-domain tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0140-b9667a9147", "paper_id": "P0140", "bibkey": "Chen2025Atlas", "title": "ATLaS: Agent Tuning via Learning Critical Steps", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing agent tuning approaches typically employ supervised finetuning on entire expert trajectories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0140-446240671c", "paper_id": "P0140", "bibkey": "Chen2025Atlas", "title": "ATLaS: Agent Tuning via Learning Critical Steps", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, behavior-cloning of full trajectories can introduce expert bias and weaken generalization to states not covered by the expert data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0141-bd4c2a4c01", "paper_id": "P0141", "bibkey": "Kulkarni2025Agent", "title": "Agent-S: LLM Agentic workflow to automate Standard Operating Procedures", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose an LLM-based agentic workflow for automating Standard Operating Procedures (SOP).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0141-6dec6b27ee", "paper_id": "P0141", "bibkey": "Kulkarni2025Agent", "title": "Agent-S: LLM Agentic workflow to automate Standard Operating Procedures", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "For customer care operations, an SOP defines a logical step-by-step process for human agents to resolve customer issues.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0141-933d480ea0", "paper_id": "P0141", "bibkey": "Kulkarni2025Agent", "title": "Agent-S: LLM Agentic workflow to automate Standard Operating Procedures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "AI agents using Large Language Models (LLMs) as foundations have shown promise in solving complex real-world tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0141-283b27c846", "paper_id": "P0141", "bibkey": "Kulkarni2025Agent", "title": "Agent-S: LLM Agentic workflow to automate Standard Operating Procedures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose an LLM-based agentic workflow for automating Standard Operating Procedures (SOP).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0141-e4485f250b", "paper_id": "P0141", "bibkey": "Kulkarni2025Agent", "title": "Agent-S: LLM Agentic workflow to automate Standard Operating Procedures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "For customer care operations, an SOP defines a logical step-by-step process for human agents to resolve customer issues.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0142-7a4b1d1117", "paper_id": "P0142", "bibkey": "Wang2025Agentvigil", "title": "AgentVigil: Generic Black-Box Red-teaming for Indirect Prompt Injection against LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose a generic black-box fuzzing framework, AgentVigil, designed to automatically discover and exploit indirect prompt injection vulnerabilities across diverse LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0142-03ed8e82d6", "paper_id": "P0142", "bibkey": "Wang2025Agentvigil", "title": "AgentVigil: Generic Black-Box Red-teaming for Indirect Prompt Injection against LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate AgentVigil on two public benchmarks, AgentDojo and VWA-adv, where it achieves 71% and 70% success rates against agents based on o3-mini and GPT-4o, respectively, nearly doubling the performance of baseline attacks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0142-f4f37d874a", "paper_id": "P0142", "bibkey": "Wang2025Agentvigil", "title": "AgentVigil: Generic Black-Box Red-teaming for Indirect Prompt Injection against LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Beyond benchmark evaluations, we apply our attacks in real-world environments, successfully misleading agents to navigate to arbitrary URLs, including malicious sites.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "security"]}
{"evidence_id": "E-P0142-1e6424e090", "paper_id": "P0142", "bibkey": "Wang2025Agentvigil", "title": "AgentVigil: Generic Black-Box Red-teaming for Indirect Prompt Injection against LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The strong planning and reasoning capabilities of Large Language Models (LLMs) have fostered the development of agent-based systems capable of leveraging external tools and interacting with increasingly complex environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0142-ba2c8b6097", "paper_id": "P0142", "bibkey": "Wang2025Agentvigil", "title": "AgentVigil: Generic Black-Box Red-teaming for Indirect Prompt Injection against LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, these powerful features also introduce a critical security risk: indirect prompt injection, a sophisticated attack vector that compromises the core of these agents, the LLM, by manipulating contextual information rather than direct user prompts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0142-1740a8e576", "paper_id": "P0142", "bibkey": "Wang2025Agentvigil", "title": "AgentVigil: Generic Black-Box Red-teaming for Indirect Prompt Injection against LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we propose a generic black-box fuzzing framework, AgentVigil, designed to automatically discover and exploit indirect prompt injection vulnerabilities across diverse LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0143-cc24fcd59a", "paper_id": "P0143", "bibkey": "Makroum2025Agentic", "title": "Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The electricity sector transition requires substantial increases in residential demand response capacity, yet Home Energy Management Systems (HEMS) adoption remains limited by user interaction barriers requiring translation of everyday preferences into technical parameters.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0143-e66cebb352", "paper_id": "P0143", "bibkey": "Makroum2025Agentic", "title": "Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Llama-3.3-70B successfully coordinates all appliances across all scenarios to match cost-optimal benchmarks computed via mixed-integer linear programming, while other models achieve perfect single-appliance performance but struggle to coordinate all appliances simultaneously.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0143-eedd780494", "paper_id": "P0143", "bibkey": "Makroum2025Agentic", "title": "Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluation across three open-source models using real Austrian day-ahead electricity prices reveals substantial capability differences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0143-d46cf43adc", "paper_id": "P0143", "bibkey": "Makroum2025Agentic", "title": "Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The electricity sector transition requires substantial increases in residential demand response capacity, yet Home Energy Management Systems (HEMS) adoption remains limited by user interaction barriers requiring translation of everyday preferences into technical parameters.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0143-225455735b", "paper_id": "P0143", "bibkey": "Makroum2025Agentic", "title": "Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While large language models have been applied to energy systems as code generators and parameter extractors, no existing implementation deploys LLMs as autonomous coordinators managing the complete workflow from natural language input to multi-appliance scheduling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0143-69ba1cc610", "paper_id": "P0143", "bibkey": "Makroum2025Agentic", "title": "Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents an agentic AI HEMS where LLMs autonomously coordinate multi-appliance scheduling from natural language requests to device control, achieving optimal scheduling without example demonstrations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0144-1b9be222c7", "paper_id": "P0144", "bibkey": "Zhang2025Agentic", "title": "Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Building on the adaptive memory introduced by Dynamic Cheatsheet, we introduce ACE (Agentic Context Engineering), a framework that treats contexts as evolving playbooks that accumulate, refine, and organize strategies through a modular process of generation, reflection, and curation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0144-7d85a7241d", "paper_id": "P0144", "bibkey": "Zhang2025Agentic", "title": "Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across agent and domain-specific benchmarks, ACE optimizes contexts both offline (e.g., system prompts) and online (e.g., agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while significantly reducing adaptation latency and rollout cost.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0144-10cd693d7a", "paper_id": "P0144", "bibkey": "Zhang2025Agentic", "title": "Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) applications such as agents and domain-specific reasoning increasingly rely on context adaptation -- modifying inputs with instructions, strategies, or evidence, rather than weight updates.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0144-8852e175b0", "paper_id": "P0144", "bibkey": "Zhang2025Agentic", "title": "Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Prior approaches improve usability but often suffer from brevity bias, which drops domain insights for concise summaries, and from context collapse, where iterative rewriting erodes details over time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0144-0ab2093458", "paper_id": "P0144", "bibkey": "Zhang2025Agentic", "title": "Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Building on the adaptive memory introduced by Dynamic Cheatsheet, we introduce ACE (Agentic Context Engineering), a framework that treats contexts as evolving playbooks that accumulate, refine, and organize strategies through a modular process of generation, reflection, and curation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0145-9062fd18ff", "paper_id": "P0145", "bibkey": "Rosario2025Architecting", "title": "Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "As Large Language Model (LLM) agents become increasingly capable of automating complex, multi-step tasks, the need for robust, secure, and predictable architectural patterns is paramount.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0145-0590337b16", "paper_id": "P0145", "bibkey": "Rosario2025Architecting", "title": "Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we discuss advanced patterns, including dynamic re-planning loops, parallel execution with Directed Acyclic Graphs (DAGs), and the critical role of Human-in-the-Loop (HITL) verification, to offer a complete strategic blueprint for architects, developers, and security engineers aiming to build production-grade, resilient, and trustworthy LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0145-857ffd5d59", "paper_id": "P0145", "bibkey": "Rosario2025Architecting", "title": "Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As Large Language Model (LLM) agents become increasingly capable of automating complex, multi-step tasks, the need for robust, secure, and predictable architectural patterns is paramount.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0145-cee871a1fb", "paper_id": "P0145", "bibkey": "Rosario2025Architecting", "title": "Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper provides a comprehensive guide to the ``Plan-then-Execute'' (P-t-E) pattern, an agentic design that separates strategic planning from tactical execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0145-2cb857d77b", "paper_id": "P0145", "bibkey": "Rosario2025Architecting", "title": "Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We explore the foundational principles of P-t-E, detailing its core components - the Planner and the Executor - and its architectural advantages in predictability, cost-efficiency, and reasoning quality over reactive patterns like ReAct (Reason + Act).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0146-a40f113c0a", "paper_id": "P0146", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To demonstrate and exploit this vulnerability, we propose the Attractive Metadata Attack (AMA), a black-box in-context learning framework that generates highly attractive but syntactically and semantically valid tool metadata through iterative optimization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#method"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0146-a0b404d928", "paper_id": "P0146", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments across ten realistic, simulated tool-use scenarios and a range of popular LLM agents demonstrate consistently high attack success rates (81\\%-95\\%) and significant privacy leakage, with negligible impact on primary task execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "security", "tooling"]}
{"evidence_id": "E-P0146-00dc8ff622", "paper_id": "P0146", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents have demonstrated remarkable capabilities in complex reasoning and decision-making by leveraging external tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0146-38b7cc5d37", "paper_id": "P0146", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, this tool-centric paradigm introduces a previously underexplored attack surface, where adversaries can manipulate tool metadata -- such as names, descriptions, and parameter schemas -- to influence agent behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#summary_bullets[1]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0146-b47df2ba00", "paper_id": "P0146", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We identify this as a new and stealthy threat surface that allows malicious tools to be preferentially selected by LLM agents, without requiring prompt injection or access to model internals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#summary_bullets[2]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0147-54aa7c79f9", "paper_id": "P0147", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a library implementing common prompting patterns using the PDL prompt programming language.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0147-1c2ad83594", "paper_id": "P0147", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluations across three tasks and seven LLMs (ranging from 3B to 70B parameters) show consistent accuracy gains ($9.21\\pm15.46$ percentage points), up to 67.5pp, and reveal that selected prompting strategies vary across models and tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0147-b3f5346012", "paper_id": "P0147", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "AutoPDL solutions are human-readable, editable, and executable PDL programs that use this library.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0147-5bd886ea4a", "paper_id": "P0147", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The performance of large language models (LLMs) depends on how they are prompted, with choices spanning both the high-level prompting pattern (e.g., Zero-Shot, CoT, ReAct, ReWOO) and the specific prompt content (instructions and few-shot demonstrations).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0147-05fc2ccbd6", "paper_id": "P0147", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Manually tuning this combination is tedious, error-prone, and specific to a given LLM and task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0147-658a4af4bb", "paper_id": "P0147", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Therefore, this paper proposes AutoPDL, an automated approach to discovering good LLM agent configurations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0148-f6681abfd4", "paper_id": "P0148", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "A recent area of increasing research is the use of Large Language Models (LLMs) in penetration testing, which promises to reduce costs and thus allow for higher frequency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0148-7e9d7616ab", "paper_id": "P0148", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Both approaches are able to complete 15-25 % of the subtasks on the HTB machines, with AutoPentest slightly outperforming ChatGPT.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0148-89865e4c80", "paper_id": "P0148", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We measure a total cost of \\$96.20 US when using AutoPentest across all experiments, while a one-month subscription to ChatGPT Plus costs \\$20.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0148-b543eff594", "paper_id": "P0148", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A recent area of increasing research is the use of Large Language Models (LLMs) in penetration testing, which promises to reduce costs and thus allow for higher frequency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0148-3dc72e8dbb", "paper_id": "P0148", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We conduct a review of related work, identifying best practices and common evaluation issues.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0148-4d926d8b04", "paper_id": "P0148", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We then present AutoPentest, an application for performing black-box penetration tests with a high degree of autonomy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0149-b572dab874", "paper_id": "P0149", "bibkey": "Wang2025Autoscore", "title": "AutoSCORE: Enhancing Automated Scoring with Multi-Agent Large Language Models via Structured Component Recognition", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address the limitations, we propose AutoSCORE, a multi-agent LLM framework enhancing automated scoring via rubric-aligned Structured COmponent REcognition.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0149-42512d3cac", "paper_id": "P0149", "bibkey": "Wang2025Autoscore", "title": "AutoSCORE: Enhancing Automated Scoring with Multi-Agent Large Language Models via Structured Component Recognition", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate AutoSCORE on four benchmark datasets from the ASAP benchmark, using both proprietary and open-source LLMs (GPT-4o, LLaMA-3.1-8B, and LLaMA-3.1-70B).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0149-d956dcaf4c", "paper_id": "P0149", "bibkey": "Wang2025Autoscore", "title": "AutoSCORE: Enhancing Automated Scoring with Multi-Agent Large Language Models via Structured Component Recognition", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Automated scoring plays a crucial role in education by reducing the reliance on human raters, offering scalable and immediate evaluation of student work.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0149-63226f7eaf", "paper_id": "P0149", "bibkey": "Wang2025Autoscore", "title": "AutoSCORE: Enhancing Automated Scoring with Multi-Agent Large Language Models via Structured Component Recognition", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Automated scoring plays a crucial role in education by reducing the reliance on human raters, offering scalable and immediate evaluation of student work.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0149-d72f4142e3", "paper_id": "P0149", "bibkey": "Wang2025Autoscore", "title": "AutoSCORE: Enhancing Automated Scoring with Multi-Agent Large Language Models via Structured Component Recognition", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While large language models (LLMs) have shown strong potential in this task, their use as end-to-end raters faces challenges such as low accuracy, prompt sensitivity, limited interpretability, and rubric misalignment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0149-c508fd1ac7", "paper_id": "P0149", "bibkey": "Wang2025Autoscore", "title": "AutoSCORE: Enhancing Automated Scoring with Multi-Agent Large Language Models via Structured Component Recognition", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These issues hinder the implementation of LLM-based automated scoring in assessment practice.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0149-061c06683a", "paper_id": "P0149", "bibkey": "Wang2025Autoscore", "title": "AutoSCORE: Enhancing Automated Scoring with Multi-Agent Large Language Models via Structured Component Recognition", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address the limitations, we propose AutoSCORE, a multi-agent LLM framework enhancing automated scoring via rubric-aligned Structured COmponent REcognition.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0150-f91113514e", "paper_id": "P0150", "bibkey": "Wang2025Automated", "title": "Automated Penetration Testing with LLM Agents and Classical Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce the \"Planner-Executor-Perceptor (PEP)\" design paradigm and use it to systematically review existing work and identify the key challenges in this area.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0150-32aec6c669", "paper_id": "P0150", "bibkey": "Wang2025Automated", "title": "Automated Penetration Testing with LLM Agents and Classical Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation shows that CHECKMATE outperforms the state-of-the-art system (Claude Code) in penetration capability, improving benchmark success rates by over 20%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0150-fe9d3fbb2c", "paper_id": "P0150", "bibkey": "Wang2025Automated", "title": "Automated Penetration Testing with LLM Agents and Classical Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The results show that the out-of-the-box Claude Code and Sonnet 4.5 exhibit superior penetration capabilities observed to date, substantially outperforming all prior systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0150-d75f33bc1c", "paper_id": "P0150", "bibkey": "Wang2025Automated", "title": "Automated Penetration Testing with LLM Agents and Classical Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While penetration testing plays a vital role in cybersecurity, achieving fully automated, hands-off-the-keyboard execution remains a significant research challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0150-b67604206c", "paper_id": "P0150", "bibkey": "Wang2025Automated", "title": "Automated Penetration Testing with LLM Agents and Classical Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce the \"Planner-Executor-Perceptor (PEP)\" design paradigm and use it to systematically review existing work and identify the key challenges in this area.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0150-b0076c372a", "paper_id": "P0150", "bibkey": "Wang2025Automated", "title": "Automated Penetration Testing with LLM Agents and Classical Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We also evaluate existing penetration testing systems, with a particular focus on the use of Large Language Model (LLM) agents for this task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0150-4a55873ef2", "paper_id": "P0150", "bibkey": "Wang2025Automated", "title": "Automated Penetration Testing with LLM Agents and Classical Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "However, a detailed analysis of their testing processes reveals specific strengths and limitations; notably, LLM agents struggle with maintaining coherent long-horizon plans, performing complex reasoning, and effectively utilizing specialized tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#limitations[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0151-1e710dda72", "paper_id": "P0151", "bibkey": "Kaiyrbekov2025Automated", "title": "Automated Survey Collection with LLM-based Conversational Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To overcome these limitations, we propose an end-to-end survey collection framework driven by conversational Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0151-0e1917aa86", "paper_id": "P0151", "bibkey": "Kaiyrbekov2025Automated", "title": "Automated Survey Collection with LLM-based Conversational Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Results: Survey responses were successfully extracted by GPT-4o from conversation transcripts with an average accuracy of 98% despite transcripts exhibiting an average per-line word error rate of 7.7%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0151-1d486fa6b3", "paper_id": "P0151", "bibkey": "Kaiyrbekov2025Automated", "title": "Automated Survey Collection with LLM-based Conversational Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To test our framework, we recruited 8 participants consisting of 5 native and 3 non-native english speakers and administered 40 surveys.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0151-2a9c5c4a1e", "paper_id": "P0151", "bibkey": "Kaiyrbekov2025Automated", "title": "Automated Survey Collection with LLM-based Conversational Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Objective: Traditional phone-based surveys are among the most accessible and widely used methods to collect biomedical and healthcare data, however, they are often costly, labor intensive, and difficult to scale effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0151-153e11fcaa", "paper_id": "P0151", "bibkey": "Kaiyrbekov2025Automated", "title": "Automated Survey Collection with LLM-based Conversational Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To overcome these limitations, we propose an end-to-end survey collection framework driven by conversational Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0151-720f536fcc", "paper_id": "P0151", "bibkey": "Kaiyrbekov2025Automated", "title": "Automated Survey Collection with LLM-based Conversational Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Materials and Methods: Our framework consists of a researcher responsible for designing the survey and recruiting participants, a conversational phone agent powered by an LLM that calls participants and administers the survey, a second LLM (GPT-4o) that analyzes the conversation transcripts generated during the surveys, and a database for storing and organizing the results.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0151-143b85da69", "paper_id": "P0151", "bibkey": "Kaiyrbekov2025Automated", "title": "Automated Survey Collection with LLM-based Conversational Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To overcome these limitations, we propose an end-to-end survey collection framework driven by conversational Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0152-0a6bcfbb77", "paper_id": "P0152", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this study, we propose an innovative pipeline utilizing Large Language Model (LLM) agents to automate data-driven modeling and analysis, with a particular emphasis on regression tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0152-5da77482d9", "paper_id": "P0152", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We validate our approach using a critical heat flux (CHF) prediction benchmark, involving approximately 25,000 experimental data points from the OECD/NEA benchmark dataset.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0152-c2a5689efc", "paper_id": "P0152", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Results indicate that our LLM-agent-developed model surpasses traditional CHF lookup tables and delivers predictive accuracy and UQ on par with state-of-the-art Bayesian optimized deep neural network models developed by human experts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0152-5a5e822b1f", "paper_id": "P0152", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Modern engineering increasingly relies on vast datasets generated by experiments and simulations, driving a growing demand for efficient, reliable, and broadly applicable modeling strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0152-c68a10fc29", "paper_id": "P0152", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "There is also heightened interest in developing data-driven approaches, particularly neural network models, for effective prediction and analysis of scientific datasets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0152-4ac701e24b", "paper_id": "P0152", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional data-driven methods frequently involve extensive manual intervention, limiting their ability to scale effectively and generalize to diverse applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0153-4a0bbc45f7", "paper_id": "P0153", "bibkey": "Liang2025Automating", "title": "Automating Structural Engineering Workflows with Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce $\\textbf{MASSE}$, the first Multi-Agent System for Structural Engineering, effectively integrating large language model (LLM)-based agents with real-world engineering workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0153-ee541a7864", "paper_id": "P0153", "bibkey": "Liang2025Automating", "title": "Automating Structural Engineering Workflows with Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "MASSE enables immediate deployment in professional environments, and our comprehensive validation on real-world case studies demonstrates that it can reduce expert workload from approximately two hours to mere minutes, while enhancing both reliability and accuracy in practical engineering scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0153-0c6a94f89e", "paper_id": "P0153", "bibkey": "Liang2025Automating", "title": "Automating Structural Engineering Workflows with Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce $\\textbf{MASSE}$, the first Multi-Agent System for Structural Engineering, effectively integrating large language model (LLM)-based agents with real-world engineering workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0153-54b5c0b56d", "paper_id": "P0153", "bibkey": "Liang2025Automating", "title": "Automating Structural Engineering Workflows with Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Structural engineering is a fundamental yet traditionally stagnant domain, with core workflows remaining largely unchanged for decades despite its substantial economic impact and global market size.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0153-c6549fdf06", "paper_id": "P0153", "bibkey": "Liang2025Automating", "title": "Automating Structural Engineering Workflows with Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in LLMs have significantly enhanced their ability to perform complex reasoning, long-horizon planning, and precise tool utilization -- capabilities well aligned with structural engineering tasks such as interpreting design codes, executing load calculations, and verifying structural capacities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0154-a138e19bd2", "paper_id": "P0154", "bibkey": "Jacob2025Beyond", "title": "Beyond Protein Language Models: An Agentic LLM Framework for Mechanistic Enzyme Design", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present Genie-CAT, a tool-augmented large-language-model (LLM) system designed to accelerate scientific hypothesis generation in protein design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0154-937d4936e4", "paper_id": "P0154", "bibkey": "Jacob2025Beyond", "title": "Beyond Protein Language Models: An Agentic LLM Framework for Mechanistic Enzyme Design", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The framework highlights how AI agents combining language models with domain-specific tools can bridge symbolic reasoning and numerical simulation, transforming LLMs from conversational assistants into partners for computational discovery.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0154-89ed928844", "paper_id": "P0154", "bibkey": "Jacob2025Beyond", "title": "Beyond Protein Language Models: An Agentic LLM Framework for Mechanistic Enzyme Design", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present Genie-CAT, a tool-augmented large-language-model (LLM) system designed to accelerate scientific hypothesis generation in protein design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0154-88c5d5cc97", "paper_id": "P0154", "bibkey": "Jacob2025Beyond", "title": "Beyond Protein Language Models: An Agentic LLM Framework for Mechanistic Enzyme Design", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Using metalloproteins (e.g., ferredoxins) as a case study, Genie-CAT integrates four capabilities -- literature-grounded reasoning through retrieval-augmented generation (RAG), structural parsing of Protein Data Bank files, electrostatic potential calculations, and machine-learning prediction of redox properties -- into a unified agentic workflow.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0154-4843e3ed5e", "paper_id": "P0154", "bibkey": "Jacob2025Beyond", "title": "Beyond Protein Language Models: An Agentic LLM Framework for Mechanistic Enzyme Design", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By coupling natural-language reasoning with data-driven and physics-based computation, the system generates mechanistically interpretable, testable hypotheses linking sequence, structure, and function.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0155-d846bdc3d8", "paper_id": "P0155", "bibkey": "Weng2025Bridgescope", "title": "BridgeScope: A Universal Toolkit for Bridging Large Language Models and Databases", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To resolve these challenges, we introduce BridgeScope, a universal toolkit bridging LLMs and databases through three key innovations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0155-e4be1f69f1", "paper_id": "P0155", "bibkey": "Weng2025Bridgescope", "title": "BridgeScope: A Universal Toolkit for Bridging Large Language Models and Databases", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluations on two novel benchmarks demonstrate that BridgeScope enables LLM agents to operate databases more effectively, reduces token usage by up to 80% through improved security awareness, and uniquely supports data-intensive workflows beyond existing toolkits, establishing BridgeScope as a robust foundation for next-generation intelligent data automation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0155-6842c1dfbc", "paper_id": "P0155", "bibkey": "Weng2025Bridgescope", "title": "BridgeScope: A Universal Toolkit for Bridging Large Language Models and Databases", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As large language models (LLMs) demonstrate increasingly powerful reasoning and orchestration capabilities, LLM-based agents are rapidly proliferating for complex data-related tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0155-4ea5a63da9", "paper_id": "P0155", "bibkey": "Weng2025Bridgescope", "title": "BridgeScope: A Universal Toolkit for Bridging Large Language Models and Databases", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite this progress, the current design of how LLMs interact with databases exhibits critical limitations in usability, security, privilege management, and data transmission efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0155-235490a55a", "paper_id": "P0155", "bibkey": "Weng2025Bridgescope", "title": "BridgeScope: A Universal Toolkit for Bridging Large Language Models and Databases", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To resolve these challenges, we introduce BridgeScope, a universal toolkit bridging LLMs and databases through three key innovations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0155-8b4b8f6bb0", "paper_id": "P0155", "bibkey": "Weng2025Bridgescope", "title": "BridgeScope: A Universal Toolkit for Bridging Large Language Models and Databases", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Despite this progress, the current design of how LLMs interact with databases exhibits critical limitations in usability, security, privilege management, and data transmission efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0156-2c183561ec", "paper_id": "P0156", "bibkey": "Bazgir2025Causal", "title": "Causal MAS: A Survey of Large Language Model Architectures for Discovery and Effect Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Models (LLMs) have demonstrated remarkable capabilities in various reasoning and generation tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0156-c7c6b9b562", "paper_id": "P0156", "bibkey": "Bazgir2025Causal", "title": "Causal MAS: A Survey of Large Language Model Architectures for Discovery and Effect Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Furthermore, we discuss the evaluation methodologies, benchmarks, and diverse application domains where causal multi-agent LLMs are making an impact, including scientific discovery, healthcare, fact-checking, and personalized systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0156-c303b8e455", "paper_id": "P0156", "bibkey": "Bazgir2025Causal", "title": "Causal MAS: A Survey of Large Language Model Architectures for Discovery and Effect Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have demonstrated remarkable capabilities in various reasoning and generation tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0156-33c06c1599", "paper_id": "P0156", "bibkey": "Bazgir2025Causal", "title": "Causal MAS: A Survey of Large Language Model Architectures for Discovery and Effect Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, their proficiency in complex causal reasoning, discovery, and estimation remains an area of active development, often hindered by issues like hallucination, reliance on spurious correlations, and difficulties in handling nuanced, domain-specific, or personalized causal relationships.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0156-1cead11641", "paper_id": "P0156", "bibkey": "Bazgir2025Causal", "title": "Causal MAS: A Survey of Large Language Model Architectures for Discovery and Effect Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Multi-agent systems, leveraging the collaborative or specialized abilities of multiple LLM-based agents, are emerging as a powerful paradigm to address these limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0156-d1ff886fab", "paper_id": "P0156", "bibkey": "Bazgir2025Causal", "title": "Causal MAS: A Survey of Large Language Model Architectures for Discovery and Effect Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Multi-agent systems, leveraging the collaborative or specialized abilities of multiple LLM-based agents, are emerging as a powerful paradigm to address these limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#limitations[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0157-959fb538d9", "paper_id": "P0157", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present an LLM assistant, ChatVis, that aids the LLM to generate Python code for ParaView scientific visualization tasks, without the need for retraining or fine-tuning the LLM.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0157-4af4bd8bf3", "paper_id": "P0157", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "An integral part of our approach is a benchmark suite of canonical visualization tasks, ParaView regression tests, and scientific use cases that includes comprehensive evaluation metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0157-825bc530a5", "paper_id": "P0157", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We find that all the metrics are significantly improved with ChatVis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0157-fa0414ceff", "paper_id": "P0157", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are rapidly increasing in capability, but they still struggle with highly specialized programming tasks such as scientific visualization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0157-6af97a93b1", "paper_id": "P0157", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present an LLM assistant, ChatVis, that aids the LLM to generate Python code for ParaView scientific visualization tasks, without the need for retraining or fine-tuning the LLM.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0157-38ab24096b", "paper_id": "P0157", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ChatVis employs chain-of-thought prompt simplification, retrieval-augmented prompt generation using a vector database of documentation and code examples, and error checking with iterative prompt feedback to correct errors until a visualization is produced.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0158-ea4ec898b8", "paper_id": "P0158", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose using \"quitting\" as a simple yet effective behavioral mechanism for LLM agents to recognize and withdraw from situations where they lack confidence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0158-7edb91824f", "paper_id": "P0158", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Leveraging the ToolEmu framework, we conduct a systematic evaluation of quitting behavior across 12 state-of-the-art LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0158-0550cab83d", "paper_id": "P0158", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results demonstrate a highly favorable safety-helpfulness trade-off: agents prompted to quit with explicit instructions improve safety by an average of +0.39 on a 0-3 scale across all models (+0.64 for proprietary models), while maintaining a negligible average decrease of -0.03 in helpfulness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0158-ed9d5a5002", "paper_id": "P0158", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As Large Language Model (LLM) agents increasingly operate in complex environments with real-world consequences, their safety becomes critical.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0158-fcdca39700", "paper_id": "P0158", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While uncertainty quantification is well-studied for single-turn tasks, multi-turn agentic scenarios with real-world tool access present unique challenges where uncertainties and ambiguities compound, leading to severe or catastrophic risks beyond traditional text generation failures.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0158-53dd169482", "paper_id": "P0158", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose using \"quitting\" as a simple yet effective behavioral mechanism for LLM agents to recognize and withdraw from situations where they lack confidence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0159-8d11489f3e", "paper_id": "P0159", "bibkey": "Ye2025Cognipair", "title": "CogniPair: From LLM Chatbots to Conscious AI Agents -- GNWT-Based Multi-Agent Digital Twins for Social Pairing -- Dating & Hiring Applications", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this limitation, we present a computational implementation of Global Workspace Theory (GNWT) that integrates human cognitive architecture principles into LLM agents, creating specialized sub-agents for emotion, memory, social norms, planning, and goal-tracking coordinated through a global workspace mechanism.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0159-1ea69fbec3", "paper_id": "P0159", "bibkey": "Ye2025Cognipair", "title": "CogniPair: From LLM Chatbots to Conscious AI Agents -- GNWT-Based Multi-Agent Digital Twins for Social Pairing -- Dating & Hiring Applications", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Validation using 551 GNWT-Agents and Columbia University Speed Dating dataset demonstrates 72% correlation with human attraction patterns, 77.8% match prediction accuracy, and 74% agreement in human validation studies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0159-cd7c778e13", "paper_id": "P0159", "bibkey": "Ye2025Cognipair", "title": "CogniPair: From LLM Chatbots to Conscious AI Agents -- GNWT-Based Multi-Agent Digital Twins for Social Pairing -- Dating & Hiring Applications", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Current large language model (LLM) agents lack authentic human psychological processes necessary for genuine digital twins and social AI applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0159-747e0c9697", "paper_id": "P0159", "bibkey": "Ye2025Cognipair", "title": "CogniPair: From LLM Chatbots to Conscious AI Agents -- GNWT-Based Multi-Agent Digital Twins for Social Pairing -- Dating & Hiring Applications", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current large language model (LLM) agents lack authentic human psychological processes necessary for genuine digital twins and social AI applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0159-90b8fb8540", "paper_id": "P0159", "bibkey": "Ye2025Cognipair", "title": "CogniPair: From LLM Chatbots to Conscious AI Agents -- GNWT-Based Multi-Agent Digital Twins for Social Pairing -- Dating & Hiring Applications", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this limitation, we present a computational implementation of Global Workspace Theory (GNWT) that integrates human cognitive architecture principles into LLM agents, creating specialized sub-agents for emotion, memory, social norms, planning, and goal-tracking coordinated through a global workspace mechanism.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0159-ee2acf965e", "paper_id": "P0159", "bibkey": "Ye2025Cognipair", "title": "CogniPair: From LLM Chatbots to Conscious AI Agents -- GNWT-Based Multi-Agent Digital Twins for Social Pairing -- Dating & Hiring Applications", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, authentic digital twins require accurate personality initialization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0159-02c16751d9", "paper_id": "P0159", "bibkey": "Ye2025Cognipair", "title": "CogniPair: From LLM Chatbots to Conscious AI Agents -- GNWT-Based Multi-Agent Digital Twins for Social Pairing -- Dating & Hiring Applications", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address this limitation, we present a computational implementation of Global Workspace Theory (GNWT) that integrates human cognitive architecture principles into LLM agents, creating specialized sub-agents for emotion, memory, social norms, planning, and goal-tracking coordinated through a global workspace mechanism.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#limitations[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0160-b3d97b8b63", "paper_id": "P0160", "bibkey": "Liu2025Costbench", "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To bridge this gap, we introduce CostBench, a scalable, cost-centric benchmark designed to evaluate agents' economic reasoning and replanning abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0160-32d61c8fae", "paper_id": "P0160", "bibkey": "Liu2025Costbench", "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and performance further dropping by around 40% under dynamic conditions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0160-17133c2d5e", "paper_id": "P0160", "bibkey": "Liu2025Costbench", "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To bridge this gap, we introduce CostBench, a scalable, cost-centric benchmark designed to evaluate agents' economic reasoning and replanning abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0160-8ccf29128f", "paper_id": "P0160", "bibkey": "Liu2025Costbench", "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current evaluations of Large Language Model (LLM) agents primarily emphasize task completion, often overlooking resource efficiency and adaptability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0160-77980b824c", "paper_id": "P0160", "bibkey": "Liu2025Costbench", "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This neglects a crucial capability: agents' ability to devise and adjust cost-optimal plans in response to changing environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0160-a2a7dcee0c", "paper_id": "P0160", "bibkey": "Liu2025Costbench", "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To bridge this gap, we introduce CostBench, a scalable, cost-centric benchmark designed to evaluate agents' economic reasoning and replanning abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0161-5fe6dbb13b", "paper_id": "P0161", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Our approach decomposes demonstration knowledge into transferable and non-transferable components through a causal lens, showing how the latter can introduce spurious dependencies that impair generalization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0161-384d450350", "paper_id": "P0161", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments across diverse domains demonstrate our method's effectiveness and generality, highlighting the importance of principled, context-aware demo selection for robust and efficient LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0161-56b0c62e72", "paper_id": "P0161", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model-based agents, empowered by in-context learning (ICL), have demonstrated strong capabilities in complex reasoning and tool-use tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0161-83df58a7e9", "paper_id": "P0161", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing works have shown that the effectiveness of ICL is highly sensitive to the choice of demonstrations, with suboptimal examples often leading to unstable or degraded performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0161-e88cf45af9", "paper_id": "P0161", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While prior work has explored example selection, including in some agentic or multi-step settings, existing approaches typically rely on heuristics or task-specific designs and lack a general, theoretically grounded criterion for what constitutes an effective demonstration across reasoning steps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0162-b9e7423acc", "paper_id": "P0162", "bibkey": "Zhang2025Datascibench", "title": "DataSciBench: An LLM Agent Benchmark for Data Science", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We develop a semi-automated pipeline for generating ground truth (GT) and validating evaluation metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0162-ee6e0931f8", "paper_id": "P0162", "bibkey": "Zhang2025Datascibench", "title": "DataSciBench: An LLM Agent Benchmark for Data Science", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experimental framework involves testing 6 API-based models, 8 open-source general models, and 9 open-source code generation models using the diverse set of prompts we have gathered.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0162-39281e5083", "paper_id": "P0162", "bibkey": "Zhang2025Datascibench", "title": "DataSciBench: An LLM Agent Benchmark for Data Science", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experimental results demonstrate that API-based models outperform open-sourced models on all metrics and Deepseek-Coder-33B-Instruct achieves the highest score among open-sourced models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0162-db3ee8cd01", "paper_id": "P0162", "bibkey": "Zhang2025Datascibench", "title": "DataSciBench: An LLM Agent Benchmark for Data Science", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents DataSciBench, a comprehensive benchmark for evaluating Large Language Model (LLM) capabilities in data science.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0162-d60d3c7269", "paper_id": "P0162", "bibkey": "Zhang2025Datascibench", "title": "DataSciBench: An LLM Agent Benchmark for Data Science", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent related benchmarks have primarily focused on single tasks, easily obtainable ground truth, and straightforward evaluation metrics, which limits the scope of tasks that can be evaluated.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0162-647bee3494", "paper_id": "P0162", "bibkey": "Zhang2025Datascibench", "title": "DataSciBench: An LLM Agent Benchmark for Data Science", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In contrast, DataSciBench is constructed based on a more comprehensive and curated collection of natural and challenging prompts for uncertain ground truth and evaluation metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0163-46c10190bc", "paper_id": "P0163", "bibkey": "Ismayilov2025Decentralized", "title": "Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Coordinating multiple autonomous agents in shared environments under decentralized conditions is a long-standing challenge in robotics and artificial intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0163-f2954cacc1", "paper_id": "P0163", "bibkey": "Ismayilov2025Decentralized", "title": "Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results show that LLM-based agents, when provided with well-designed prompts and relevant quantitative information, can achieve near-optimal makespans and consistently outperform traditional heuristics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0163-727313439f", "paper_id": "P0163", "bibkey": "Ismayilov2025Decentralized", "title": "Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Coordinating multiple autonomous agents in shared environments under decentralized conditions is a long-standing challenge in robotics and artificial intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0163-7ca544040d", "paper_id": "P0163", "bibkey": "Ismayilov2025Decentralized", "title": "Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This work addresses the problem of decentralized goal assignment for multi-agent path planning, where agents independently generate ranked preferences over goals based on structured representations of the environment, including grid visualizations and scenario data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0163-eec9e86b3d", "paper_id": "P0163", "bibkey": "Ismayilov2025Decentralized", "title": "Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "After this reasoning phase, agents exchange their goal rankings, and assignments are determined by a fixed, deterministic conflict-resolution rule (e.g., agent index ordering), without negotiation or iterative coordination.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0164-8a3360fc95", "paper_id": "P0164", "bibkey": "Zhang2025Deepseek", "title": "DeepSeek performs better than other Large Language Models in Dental Cases", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large language models (LLMs) hold transformative potential in healthcare, yet their capacity to interpret longitudinal patient narratives remains inadequately explored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0164-fef28e5f67", "paper_id": "P0164", "bibkey": "Zhang2025Deepseek", "title": "DeepSeek performs better than other Large Language Models in Dental Cases", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Using 34 standardized longitudinal periodontal cases (comprising 258 question-answer pairs), we assessed model performance via automated metrics and blinded evaluations by licensed dentists.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0164-8b736d164c", "paper_id": "P0164", "bibkey": "Zhang2025Deepseek", "title": "DeepSeek performs better than other Large Language Models in Dental Cases", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This study evaluated four state-of-the-art LLMs (GPT-4o, Gemini 2.0 Flash, Copilot, and DeepSeek V3) on their ability to analyze longitudinal dental case vignettes through open-ended clinical tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0164-4bfd5842ec", "paper_id": "P0164", "bibkey": "Zhang2025Deepseek", "title": "DeepSeek performs better than other Large Language Models in Dental Cases", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) hold transformative potential in healthcare, yet their capacity to interpret longitudinal patient narratives remains inadequately explored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0164-e27e615aaf", "paper_id": "P0164", "bibkey": "Zhang2025Deepseek", "title": "DeepSeek performs better than other Large Language Models in Dental Cases", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Dentistry, with its rich repository of structured clinical data, presents a unique opportunity to rigorously assess LLMs' reasoning abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0164-4668a3fb81", "paper_id": "P0164", "bibkey": "Zhang2025Deepseek", "title": "DeepSeek performs better than other Large Language Models in Dental Cases", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While several commercial LLMs already exist, DeepSeek, a model that gained significant attention earlier this year, has also joined the competition.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0165-2405651751", "paper_id": "P0165", "bibkey": "Wang2025Digital", "title": "Digital Player: Evaluating Large Language Models based Human-like Agent in Games", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we develop an application-level testbed based on the open-source strategy game \"Unciv\", which has millions of active players, to enable researchers to build a \"data flywheel\" for studying human-like agents in the \"digital players\" task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0165-20cf93b026", "paper_id": "P0165", "bibkey": "Wang2025Digital", "title": "Digital Player: Evaluating Large Language Models based Human-like Agent in Games", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In this paper, we develop an application-level testbed based on the open-source strategy game \"Unciv\", which has millions of active players, to enable researchers to build a \"data flywheel\" for studying human-like agents in the \"digital players\" task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0165-ae7af6cacf", "paper_id": "P0165", "bibkey": "Wang2025Digital", "title": "Digital Player: Evaluating Large Language Models based Human-like Agent in Games", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Another challenge for \"digital players\" is to generate human-like responses for social interaction, collaboration, and negotiation with human players.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0165-c31ea994f7", "paper_id": "P0165", "bibkey": "Wang2025Digital", "title": "Digital Player: Evaluating Large Language Models based Human-like Agent in Games", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the rapid advancement of Large Language Models (LLMs), LLM-based autonomous agents have shown the potential to function as digital employees, such as digital analysts, teachers, and programmers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0165-cc6a26dc12", "paper_id": "P0165", "bibkey": "Wang2025Digital", "title": "Digital Player: Evaluating Large Language Models based Human-like Agent in Games", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we develop an application-level testbed based on the open-source strategy game \"Unciv\", which has millions of active players, to enable researchers to build a \"data flywheel\" for studying human-like agents in the \"digital players\" task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0165-c7e5ab96ab", "paper_id": "P0165", "bibkey": "Wang2025Digital", "title": "Digital Player: Evaluating Large Language Models based Human-like Agent in Games", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This \"Civilization\"-like game features expansive decision-making spaces along with rich linguistic interactions such as diplomatic negotiations and acts of deception, posing significant challenges for LLM-based agents in terms of numerical reasoning and long-term planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0166-17fb12f5b7", "paper_id": "P0166", "bibkey": "Kang2025Distilling", "title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose Agent Distillation, a framework for transferring not only reasoning capability but full task-solving behavior from LLM-based agents into sLMs with retrieval and code tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#method"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0166-b3e71bf0cd", "paper_id": "P0166", "bibkey": "Kang2025Distilling", "title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We improve agent distillation along two complementary axes: (1) we introduce a prompting method called first-thought prefix to enhance the quality of teacher-generated trajectories; and (2) we propose a self-consistent action generation for improving test-time robustness of small agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0166-dc7fe955d8", "paper_id": "P0166", "bibkey": "Kang2025Distilling", "title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results show that sLMs as small as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the potential of agent distillation for building practical, tool-using small agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0166-8d8d325e8f", "paper_id": "P0166", "bibkey": "Kang2025Distilling", "title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) excel at complex reasoning tasks but remain computationally expensive, limiting their practical deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0166-6e79c5f1e0", "paper_id": "P0166", "bibkey": "Kang2025Distilling", "title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this, recent works have focused on distilling reasoning capabilities into smaller language models (sLMs) using chain-of-thought (CoT) traces from teacher LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0166-b7298b8786", "paper_id": "P0166", "bibkey": "Kang2025Distilling", "title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, this approach struggles in scenarios requiring rare factual knowledge or precise computation, where sLMs often hallucinate due to limited capability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0167-29abfad56d", "paper_id": "P0167", "bibkey": "Taylor2025Large", "title": "Do Large Language Models Exhibit Spontaneous Rational Deception?", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Models (LLMs) are effective at deceiving, when prompted to do so.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0167-047d14c804", "paper_id": "P0167", "bibkey": "Taylor2025Large", "title": "Do Large Language Models Exhibit Spontaneous Rational Deception?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The results indicate that 1) all tested LLMs spontaneously misrepresent their actions in at least some conditions, 2) they are generally more likely to do so in situations in which deception would benefit them, and 3) models exhibiting better reasoning capacity overall tend to deceive at higher rates.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0167-fdb5303204", "paper_id": "P0167", "bibkey": "Taylor2025Large", "title": "Do Large Language Models Exhibit Spontaneous Rational Deception?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We discuss consequences for autonomous, human-facing systems driven by LLMs both now and as their reasoning capabilities continue to improve.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0167-1f06bbf85e", "paper_id": "P0167", "bibkey": "Taylor2025Large", "title": "Do Large Language Models Exhibit Spontaneous Rational Deception?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) are effective at deceiving, when prompted to do so.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0167-5cbc62fba5", "paper_id": "P0167", "bibkey": "Taylor2025Large", "title": "Do Large Language Models Exhibit Spontaneous Rational Deception?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "But under what conditions do they deceive spontaneously?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0167-1aa36ac32a", "paper_id": "P0167", "bibkey": "Taylor2025Large", "title": "Do Large Language Models Exhibit Spontaneous Rational Deception?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Models that demonstrate better performance on reasoning tasks are also better at prompted deception.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0168-408402a2cc", "paper_id": "P0168", "bibkey": "VarangotReille2025Doing", "title": "Doing More with Less: A Survey on Routing Strategies for Resource Optimisation in Large Language Model-Based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Model (LLM)-based systems, i.e. interconnected elements that include an LLM as a central component, such as conversational agents, are usually designed with monolithic, static architectures that rely on a single, general-purpose LLM to handle all user queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0168-7320460853", "paper_id": "P0168", "bibkey": "VarangotReille2025Doing", "title": "Doing More with Less: A Survey on Routing Strategies for Resource Optimisation in Large Language Model-Based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "By formalising routing as a performance-cost optimisation problem, this survey provides tools and directions to guide future research and development of adaptive low-cost LLM-based systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0168-6fb555ed3c", "paper_id": "P0168", "bibkey": "VarangotReille2025Doing", "title": "Doing More with Less: A Survey on Routing Strategies for Resource Optimisation in Large Language Model-Based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM)-based systems, i.e. interconnected elements that include an LLM as a central component, such as conversational agents, are usually designed with monolithic, static architectures that rely on a single, general-purpose LLM to handle all user queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0168-32e4c7c715", "paper_id": "P0168", "bibkey": "VarangotReille2025Doing", "title": "Doing More with Less: A Survey on Routing Strategies for Resource Optimisation in Large Language Model-Based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, these systems may be inefficient as different queries may require different levels of reasoning, domain knowledge or pre-processing.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0168-6b5dde28b4", "paper_id": "P0168", "bibkey": "VarangotReille2025Doing", "title": "Doing More with Less: A Survey on Routing Strategies for Resource Optimisation in Large Language Model-Based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While generalist LLMs (e.g. GPT-4o, Claude-Sonnet) perform well across a wide range of tasks, they may incur significant financial, energy and computational costs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0168-563b11751f", "paper_id": "P0168", "bibkey": "VarangotReille2025Doing", "title": "Doing More with Less: A Survey on Routing Strategies for Resource Optimisation in Large Language Model-Based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Practical considerations such as industrial applications and current limitations are also examined, like standardising routing experiments, accounting for non-financial costs, and designing adaptive strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0169-1762f480dc", "paper_id": "P0169", "bibkey": "Liu2025Echo", "title": "Echo: A Large Language Model with Temporal Episodic Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we introduce Echo, a LLM enhanced with temporal episodic memory.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0169-3852610454", "paper_id": "P0169", "bibkey": "Liu2025Echo", "title": "Echo: A Large Language Model with Temporal Episodic Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Furthermore, We develop an EM-Test benchmark specifically designed to evaluate LLMs' episodic memory capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0169-0a0006ef38", "paper_id": "P0169", "bibkey": "Liu2025Echo", "title": "Echo: A Large Language Model with Temporal Episodic Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The EM-Test assesses performance across various time spans and difficulty levels, providing a comprehensive evaluation of multi-turn episodic memory dialogues.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0169-b6319bbbad", "paper_id": "P0169", "bibkey": "Liu2025Echo", "title": "Echo: A Large Language Model with Temporal Episodic Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Research on large language models (LLMs) has shown remarkable performance in domains such as mathematics, programming, and literary creation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0169-1c64a12ff3", "paper_id": "P0169", "bibkey": "Liu2025Echo", "title": "Echo: A Large Language Model with Temporal Episodic Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, most studies have focused on semantic memory-based question answering, neglecting LLMs' potential to handle episodic memory (EM)-related queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0169-329672ac02", "paper_id": "P0169", "bibkey": "Liu2025Echo", "title": "Echo: A Large Language Model with Temporal Episodic Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This oversight has led to suboptimal performance in applications requiring EM, including emotional companionship, personal AI assistants, and AI teachers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0170-cdc1f1371a", "paper_id": "P0170", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we propose Reinforcement Learning with Tool-use Rewards (RLTR), a novel framework that decouples the training process to enable a focused, single-objective optimization of the planning module.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0170-cdf254f6f5", "paper_id": "P0170", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Moreover, this enhanced planning capability, in turn, translates to a 5%-6% increase in the final response quality of the overall agent system.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0170-f04cd37d30", "paper_id": "P0170", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments demonstrate that RLTR achieves an 8%-12% improvement in planning performance compared to end-to-end baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0170-1b6c72f6f2", "paper_id": "P0170", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The functionality of Large Language Model (LLM) agents is primarily determined by two capabilities: action planning and answer summarization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0170-8ee1b9d3b0", "paper_id": "P0170", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The former, action planning, is the core capability that dictates an agent's performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0170-7a25ab45ba", "paper_id": "P0170", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, prevailing training paradigms employ end-to-end, multi-objective optimization that jointly trains both capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0171-de0ba6ae9d", "paper_id": "P0171", "bibkey": "Samaei2025Epidemiqs", "title": "EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce \\textbf{EpidemIQs}, a novel multi-agent LLM framework that integrates user inputs and autonomously conducts literature review, analytical derivation, network modeling, mechanistic modeling, stochastic simulations, data visualization and analysis, and finally documentation of findings in a structured manuscript.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0171-3cc79392d4", "paper_id": "P0171", "bibkey": "Samaei2025Epidemiqs", "title": "EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Specifically, using GPT 4.1 and GPT 4.1 mini as backbone LLMs for scientist and task-expert agents, respectively, the autonomous process completed with average total token usage 870K at a cost of about \\$1.57 per study, achieving a 100\\% completion success rate through our experiments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0171-ca050ed55f", "paper_id": "P0171", "bibkey": "Samaei2025Epidemiqs", "title": "EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate EpidemIQs across different epidemic scenarios, measuring computational cost, completion success rate, and AI and human expert reviews of generated reports.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0171-e64646cadb", "paper_id": "P0171", "bibkey": "Samaei2025Epidemiqs", "title": "EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) offer new opportunities to automate complex interdisciplinary research domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0171-05a1d6be09", "paper_id": "P0171", "bibkey": "Samaei2025Epidemiqs", "title": "EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Epidemic modeling, characterized by its complexity and reliance on network science, dynamical systems, epidemiology, and stochastic simulations, represents a prime candidate for leveraging LLM-driven automation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0171-f62118a912", "paper_id": "P0171", "bibkey": "Samaei2025Epidemiqs", "title": "EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce \\textbf{EpidemIQs}, a novel multi-agent LLM framework that integrates user inputs and autonomously conducts literature review, analytical derivation, network modeling, mechanistic modeling, stochastic simulations, data visualization and analysis, and finally documentation of findings in a structured manuscript.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0172-6b5fe8a305", "paper_id": "P0172", "bibkey": "Cohn2025Evaluating", "title": "Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We investigate the abilities of 28 Large language Models (LLMs) to reason about cardinal directions (CDs) using a benchmark generated from a set of templates, extensively testing an LLM's ability to determine the correct CD given a particular scenario.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#method"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0172-103f744a81", "paper_id": "P0172", "bibkey": "Cohn2025Evaluating", "title": "Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We investigate the abilities of 28 Large language Models (LLMs) to reason about cardinal directions (CDs) using a benchmark generated from a set of templates, extensively testing an LLM's ability to determine the correct CD given a particular scenario.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0172-daf1aa5787", "paper_id": "P0172", "bibkey": "Cohn2025Evaluating", "title": "Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This paper summarises and extends earlier work presented at COSIT-24.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0172-973771124a", "paper_id": "P0172", "bibkey": "Cohn2025Evaluating", "title": "Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We investigate the abilities of 28 Large language Models (LLMs) to reason about cardinal directions (CDs) using a benchmark generated from a set of templates, extensively testing an LLM's ability to determine the correct CD given a particular scenario.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0172-8791d8f744", "paper_id": "P0172", "bibkey": "Cohn2025Evaluating", "title": "Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The templates allow for a number of degrees of variation such as means of locomotion of the agent involved, and whether set in the first, second or third person.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0172-d47b555946", "paper_id": "P0172", "bibkey": "Cohn2025Evaluating", "title": "Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Even the newer Large Reasoning Models are unable to reliably determine the correct CD for all questions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0173-31fb14e3fa", "paper_id": "P0173", "bibkey": "Wei2025Memory", "title": "Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To bridge this gap, we introduce Evo-Memory, a comprehensive streaming benchmark and framework for evaluating self-evolving memory in LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0173-06e45507a7", "paper_id": "P0173", "bibkey": "Wei2025Memory", "title": "Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0173-1c4008458e", "paper_id": "P0173", "bibkey": "Wei2025Memory", "title": "Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To bridge this gap, we introduce Evo-Memory, a comprehensive streaming benchmark and framework for evaluating self-evolving memory in LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0173-f0f084fed2", "paper_id": "P0173", "bibkey": "Wei2025Memory", "title": "Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Statefulness is essential for large language model (LLM) agents to perform long-term planning and problem-solving.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0173-48f5613e0a", "paper_id": "P0173", "bibkey": "Wei2025Memory", "title": "Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This makes memory a critical component, yet its management and evolution remain largely underexplored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0173-c7a9d6da82", "paper_id": "P0173", "bibkey": "Wei2025Memory", "title": "Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing evaluations mostly focus on static conversational settings, where memory is passively retrieved from dialogue to answer queries, overlooking the dynamic ability to accumulate and reuse experience across evolving task streams.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0173-f1ec9700e7", "paper_id": "P0173", "bibkey": "Wei2025Memory", "title": "Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time evolution, where LLMs retrieve, integrate, and update memory continuously during deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#limitations[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0174-31a41007bc", "paper_id": "P0174", "bibkey": "Zhu2025Evolutionary", "title": "Evolutionary Perspectives on the Evaluation of LLM-Based AI Agents: A Comprehensive Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The advent of large language models (LLMs), such as GPT, Gemini, and DeepSeek, has significantly advanced natural language processing, giving rise to sophisticated chatbots capable of diverse language-related tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0174-96f876973b", "paper_id": "P0174", "bibkey": "Zhu2025Evolutionary", "title": "Evolutionary Perspectives on the Evaluation of LLM-Based AI Agents: A Comprehensive Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, existing evaluation frameworks often blur the distinctions between LLM chatbots and AI agents, leading to confusion among researchers selecting appropriate benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0174-118cbcec21", "paper_id": "P0174", "bibkey": "Zhu2025Evolutionary", "title": "Evolutionary Perspectives on the Evaluation of LLM-Based AI Agents: A Comprehensive Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To bridge this gap, this paper introduces a systematic analysis of current evaluation approaches, grounded in an evolutionary perspective.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0174-8c978536bc", "paper_id": "P0174", "bibkey": "Zhu2025Evolutionary", "title": "Evolutionary Perspectives on the Evaluation of LLM-Based AI Agents: A Comprehensive Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The advent of large language models (LLMs), such as GPT, Gemini, and DeepSeek, has significantly advanced natural language processing, giving rise to sophisticated chatbots capable of diverse language-related tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0174-4e9fb61263", "paper_id": "P0174", "bibkey": "Zhu2025Evolutionary", "title": "Evolutionary Perspectives on the Evaluation of LLM-Based AI Agents: A Comprehensive Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The transition from these traditional LLM chatbots to more advanced AI agents represents a pivotal evolutionary step.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0174-f9f7fa1e23", "paper_id": "P0174", "bibkey": "Zhu2025Evolutionary", "title": "Evolutionary Perspectives on the Evaluation of LLM-Based AI Agents: A Comprehensive Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing evaluation frameworks often blur the distinctions between LLM chatbots and AI agents, leading to confusion among researchers selecting appropriate benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0175-5646e37f61", "paper_id": "P0175", "bibkey": "Xu2025Exemplar", "title": "Exemplar-Guided Planing: Enhanced LLM Agent for KGQA", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these limitations, we propose a novel framework, Exemplar-Guided Planning (EGP), which enhances the planning capabilities of LLM agents for KGQA.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0175-3a47ba911a", "paper_id": "P0175", "bibkey": "Xu2025Exemplar", "title": "Exemplar-Guided Planing: Enhanced LLM Agent for KGQA", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "These retrieved exemplars dynamically guide the LLM's planning process in two key phases: (1) Task Decomposition, by aligning generated sub-objectives with proven reasoning steps, and (2) Relation Exploration, by providing high-quality auxiliary information to improve relation pruning accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0175-be70dd09e9", "paper_id": "P0175", "bibkey": "Xu2025Exemplar", "title": "Exemplar-Guided Planing: Enhanced LLM Agent for KGQA", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments on two real-world KGQA datasets, WebQSP and CWQ, demonstrate that PoG-EGP significantly improves over the baseline PoG system and other compared methods.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0175-b2b75b1389", "paper_id": "P0175", "bibkey": "Xu2025Exemplar", "title": "Exemplar-Guided Planing: Enhanced LLM Agent for KGQA", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) as interactive agents show significant promise in Knowledge Graph Question Answering (KGQA) but often struggle with the semantic gap between natural language queries and structured knowledge graph (KG) representations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0175-618c7b9f73", "paper_id": "P0175", "bibkey": "Xu2025Exemplar", "title": "Exemplar-Guided Planing: Enhanced LLM Agent for KGQA", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This leads to suboptimal planning and inefficient exploration on KG, while training-free approaches often underutilize valuable reasoning patterns in training data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0175-276883e35e", "paper_id": "P0175", "bibkey": "Xu2025Exemplar", "title": "Exemplar-Guided Planing: Enhanced LLM Agent for KGQA", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these limitations, we propose a novel framework, Exemplar-Guided Planning (EGP), which enhances the planning capabilities of LLM agents for KGQA.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0175-887dc1f6da", "paper_id": "P0175", "bibkey": "Xu2025Exemplar", "title": "Exemplar-Guided Planing: Enhanced LLM Agent for KGQA", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address these limitations, we propose a novel framework, Exemplar-Guided Planning (EGP), which enhances the planning capabilities of LLM agents for KGQA.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0176-015495fe2a", "paper_id": "P0176", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present FEABench, a benchmark to evaluate the ability of large language models (LLMs) and LLM agents to simulate and solve physics, mathematics and engineering problems using finite element analysis (FEA).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0176-e4ac5005b3", "paper_id": "P0176", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our best performing strategy generates executable API calls 88% of the time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0176-4334d22ac9", "paper_id": "P0176", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We present FEABench, a benchmark to evaluate the ability of large language models (LLMs) and LLM agents to simulate and solve physics, mathematics and engineering problems using finite element analysis (FEA).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0176-fc7bc9b610", "paper_id": "P0176", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Building precise simulations of the real world and invoking numerical solvers to answer quantitative problems is an essential requirement in engineering and science.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0176-13181b0530", "paper_id": "P0176", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present FEABench, a benchmark to evaluate the ability of large language models (LLMs) and LLM agents to simulate and solve physics, mathematics and engineering problems using finite element analysis (FEA).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0176-607af02a49", "paper_id": "P0176", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce a comprehensive evaluation scheme to investigate the ability of LLMs to solve these problems end-to-end by reasoning over natural language problem descriptions and operating COMSOL Multiphysics$^\\circledR$, an FEA software, to compute the answers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0177-15c21e1425", "paper_id": "P0177", "bibkey": "Shen2025Feat", "title": "FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce FEAT (ForEnsic AgenT), a multi-agent AI framework that automates and standardizes death investigations through a domain-adapted large language model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0177-acf4a27e30", "paper_id": "P0177", "bibkey": "Shen2025Feat", "title": "FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The system employs tool-augmented reasoning, hierarchical retrieval-augmented generation, forensic-tuned LLMs, and human-in-the-loop feedback to ensure legal and medical validity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0177-8a6b96535f", "paper_id": "P0177", "bibkey": "Shen2025Feat", "title": "FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Senior pathologists validated FEAT's outputs as comparable to those of human experts, with improved detection of subtle evidentiary nuances.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0177-7b25def7a9", "paper_id": "P0177", "bibkey": "Shen2025Feat", "title": "FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Forensic cause-of-death determination faces systemic challenges, including workforce shortages and diagnostic variability, particularly in high-volume systems like China's medicolegal infrastructure.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0177-fc802dc6d7", "paper_id": "P0177", "bibkey": "Shen2025Feat", "title": "FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce FEAT (ForEnsic AgenT), a multi-agent AI framework that automates and standardizes death investigations through a domain-adapted large language model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0177-8b10eaf721", "paper_id": "P0177", "bibkey": "Shen2025Feat", "title": "FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "FEAT's application-oriented architecture integrates: (i) a central Planner for task decomposition, (ii) specialized Local Solvers for evidence analysis, (iii) a Memory & Reflection module for iterative refinement, and (iv) a Global Solver for conclusion synthesis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0178-86eba9cfec", "paper_id": "P0178", "bibkey": "Zhao2025General", "title": "General-Purpose Aerial Intelligent Agents Empowered by Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The emergence of large language models (LLMs) opens new frontiers for unmanned aerial vehicle (UAVs), yet existing systems remain confined to predefined tasks due to hardware-software co-design challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0178-dafb170f7d", "paper_id": "P0178", "bibkey": "Zhao2025General", "title": "General-Purpose Aerial Intelligent Agents Empowered by Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our hardware-software co-designed system addresses two fundamental limitations: (1) Onboard LLM operation via an edge-optimized computing platform, achieving 5-6 tokens/sec inference for 14B-parameter models at 220W peak power; (2) A bidirectional cognitive architecture that synergizes slow deliberative planning (LLM task planning) with fast reactive control (state estimation, mapping, obstacle avoidance, and motion planning).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0178-496c3bda53", "paper_id": "P0178", "bibkey": "Zhao2025General", "title": "General-Purpose Aerial Intelligent Agents Empowered by Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The emergence of large language models (LLMs) opens new frontiers for unmanned aerial vehicle (UAVs), yet existing systems remain confined to predefined tasks due to hardware-software co-design challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0178-617f6699b3", "paper_id": "P0178", "bibkey": "Zhao2025General", "title": "General-Purpose Aerial Intelligent Agents Empowered by Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents the first aerial intelligent agent capable of open-world task execution through tight integration of LLM-based reasoning and robotic autonomy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0178-3bd0c082e5", "paper_id": "P0178", "bibkey": "Zhao2025General", "title": "General-Purpose Aerial Intelligent Agents Empowered by Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our hardware-software co-designed system addresses two fundamental limitations: (1) Onboard LLM operation via an edge-optimized computing platform, achieving 5-6 tokens/sec inference for 14B-parameter models at 220W peak power; (2) A bidirectional cognitive architecture that synergizes slow deliberative planning (LLM task planning) with fast reactive control (state estimation, mapping, obstacle avoidance, and motion planning).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0178-531d9220ba", "paper_id": "P0178", "bibkey": "Zhao2025General", "title": "General-Purpose Aerial Intelligent Agents Empowered by Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Our hardware-software co-designed system addresses two fundamental limitations: (1) Onboard LLM operation via an edge-optimized computing platform, achieving 5-6 tokens/sec inference for 14B-parameter models at 220W peak power; (2) A bidirectional cognitive architecture that synergizes slow deliberative planning (LLM task planning) with fast reactive control (state estimation, mapping, obstacle avoidance, and motion planning).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#limitations[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0179-270887a152", "paper_id": "P0179", "bibkey": "Liu2025Graph", "title": "Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Autonomous agents based on large language models (LLMs) have demonstrated impressive capabilities in a wide range of applications, including web navigation, software development, and embodied control.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0179-f81ff4a912", "paper_id": "P0179", "bibkey": "Liu2025Graph", "title": "Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We hope this paper can serve as a roadmap for future research on GLA and foster a deeper understanding of the role of graphs in LLM agent systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0179-3e4b428ae8", "paper_id": "P0179", "bibkey": "Liu2025Graph", "title": "Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Autonomous agents based on large language models (LLMs) have demonstrated impressive capabilities in a wide range of applications, including web navigation, software development, and embodied control.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0179-1e5377ab5f", "paper_id": "P0179", "bibkey": "Liu2025Graph", "title": "Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While most LLMs are limited in several key agentic procedures, such as reliable planning, long-term memory, tool management, and multi-agent coordination, graphs can serve as a powerful auxiliary structure to enhance structure, continuity, and coordination in complex agent workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0179-8cbd078c79", "paper_id": "P0179", "bibkey": "Liu2025Graph", "title": "Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Given the rapid growth and fragmentation of research on Graph-augmented LLM Agents (GLA), this paper offers a timely and comprehensive overview of recent advances and also highlights key directions for future work.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0179-d21d925ee8", "paper_id": "P0179", "bibkey": "Liu2025Graph", "title": "Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Given the rapid growth and fragmentation of research on Graph-augmented LLM Agents (GLA), this paper offers a timely and comprehensive overview of recent advances and also highlights key directions for future work.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#limitations[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0180-ac87dbfe2b", "paper_id": "P0180", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these issues, we propose two distinct and complementary strategies for adapting LLM agents by leveraging environment-specific information available during deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0180-5df3b00510", "paper_id": "P0180", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "For example, on the WebArena multi-site split, this method increases the agent's success rate from 2% to 23%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0180-af945eb2fa", "paper_id": "P0180", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate these strategies across diverse agentic benchmarks, including function calling and web navigation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0180-209ec6be9d", "paper_id": "P0180", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM)-based agents struggle to generalize to novel and complex environments, such as unseen websites or new sets of functions, due to a fundamental mismatch between their pre-training and test-time conditions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0180-cb9f56b1cb", "paper_id": "P0180", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This challenge stems from two distinct failure modes: a syntactic misunderstanding of environment-specific components like observation formats, and a semantic misunderstanding of state-transition dynamics, which are only revealed at test time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0180-47addec32c", "paper_id": "P0180", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these issues, we propose two distinct and complementary strategies for adapting LLM agents by leveraging environment-specific information available during deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0181-4d1abbbc4e", "paper_id": "P0181", "bibkey": "Rahman2025Hallucination", "title": "Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Models (LLMs) are trained on vast and diverse internet corpora that often include inaccurate or misleading content.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0181-29c690fb6c", "paper_id": "P0181", "bibkey": "Rahman2025Hallucination", "title": "Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "It proposes five research questions that guide the analysis of the recent literature from 2020 to 2025, focusing on evaluation methods and mitigation techniques.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0181-7f9e4dd76f", "paper_id": "P0181", "bibkey": "Rahman2025Hallucination", "title": "Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This review systematically analyzes how LLM-generated content is evaluated for factual accuracy by exploring key challenges such as hallucinations, dataset limitations, and the reliability of evaluation metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0181-1bb15350da", "paper_id": "P0181", "bibkey": "Rahman2025Hallucination", "title": "Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) are trained on vast and diverse internet corpora that often include inaccurate or misleading content.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0181-b15a508f1f", "paper_id": "P0181", "bibkey": "Rahman2025Hallucination", "title": "Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Consequently, LLMs can generate misinformation, making robust fact-checking essential.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0181-b4c1a24c3c", "paper_id": "P0181", "bibkey": "Rahman2025Hallucination", "title": "Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This review systematically analyzes how LLM-generated content is evaluated for factual accuracy by exploring key challenges such as hallucinations, dataset limitations, and the reliability of evaluation metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0181-f43cf21f8f", "paper_id": "P0181", "bibkey": "Rahman2025Hallucination", "title": "Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "This review systematically analyzes how LLM-generated content is evaluated for factual accuracy by exploring key challenges such as hallucinations, dataset limitations, and the reliability of evaluation metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#limitations[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0182-d619e398e3", "paper_id": "P0182", "bibkey": "Mushtaq2025Harnessing", "title": "Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A Framework for Senior Design Projects", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose a framework where distinct LLM agents represent different expert perspectives, such as problem formulation agents, system complexity agents, societal and ethical agents, or project managers, thus facilitating a holistic problem-solving approach.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0182-f995c7706c", "paper_id": "P0182", "bibkey": "Mushtaq2025Harnessing", "title": "Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A Framework for Senior Design Projects", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "These agents engage in rich, collaborative dialogues to simulate human engineering teams, guided by principles from swarm AI to efficiently balance individual contributions towards a unified solution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0182-2795ed9b1f", "paper_id": "P0182", "bibkey": "Mushtaq2025Harnessing", "title": "Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A Framework for Senior Design Projects", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Multi-Agent Large Language Models (LLMs) are gaining significant attention for their ability to harness collective intelligence in complex problem-solving, decision-making, and planning tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0182-6d732ab7cc", "paper_id": "P0182", "bibkey": "Mushtaq2025Harnessing", "title": "Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A Framework for Senior Design Projects", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This aligns with the concept of the wisdom of crowds, where diverse agents contribute collectively to generating effective solutions, making it particularly suitable for educational settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0182-9cf9d3da20", "paper_id": "P0182", "bibkey": "Mushtaq2025Harnessing", "title": "Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A Framework for Senior Design Projects", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Senior design projects, also known as capstone or final year projects, are pivotal in engineering education as they integrate theoretical knowledge with practical application, fostering critical thinking, teamwork, and real-world problem-solving skills.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0183-802eea26e5", "paper_id": "P0183", "bibkey": "Xu2025Autonomous", "title": "L2M-AID: Autonomous Cyber-Physical Defense by Fusing Semantic Reasoning of Large Language Models with Multi-Agent Reinforcement Learning (Preprint)", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To validate our approach, we conduct extensive experiments on the benchmark SWaT dataset and a novel synthetic dataset generated based on the MITRE ATT&CK for ICS framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0183-fa6eaaeea9", "paper_id": "P0183", "bibkey": "Xu2025Autonomous", "title": "L2M-AID: Autonomous Cyber-Physical Defense by Fusing Semantic Reasoning of Large Language Models with Multi-Agent Reinforcement Learning (Preprint)", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Results demonstrate that L2M-AID significantly outperforms traditional IDS, deep learning anomaly detectors, and single-agent RL baselines across key metrics, achieving a 97.2% detection rate while reducing false positives by over 80% and improving response times by a factor of four.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0183-1c544ba66e", "paper_id": "P0183", "bibkey": "Xu2025Autonomous", "title": "L2M-AID: Autonomous Cyber-Physical Defense by Fusing Semantic Reasoning of Large Language Models with Multi-Agent Reinforcement Learning (Preprint)", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To validate our approach, we conduct extensive experiments on the benchmark SWaT dataset and a novel synthetic dataset generated based on the MITRE ATT&CK for ICS framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0183-6770e6174b", "paper_id": "P0183", "bibkey": "Xu2025Autonomous", "title": "L2M-AID: Autonomous Cyber-Physical Defense by Fusing Semantic Reasoning of Large Language Models with Multi-Agent Reinforcement Learning (Preprint)", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The increasing integration of Industrial IoT (IIoT) exposes critical cyber-physical systems to sophisticated, multi-stage attacks that elude traditional defenses lacking contextual awareness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0183-c3c5e41244", "paper_id": "P0183", "bibkey": "Xu2025Autonomous", "title": "L2M-AID: Autonomous Cyber-Physical Defense by Fusing Semantic Reasoning of Large Language Models with Multi-Agent Reinforcement Learning (Preprint)", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper introduces L2M-AID, a novel framework for Autonomous Industrial Defense using LLM-empowered, Multi-agent reinforcement learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0183-0202f10990", "paper_id": "P0183", "bibkey": "Xu2025Autonomous", "title": "L2M-AID: Autonomous Cyber-Physical Defense by Fusing Semantic Reasoning of Large Language Models with Multi-Agent Reinforcement Learning (Preprint)", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "L2M-AID orchestrates a team of collaborative agents, each driven by a Large Language Model (LLM), to achieve adaptive and resilient security.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0184-4d28c4585c", "paper_id": "P0184", "bibkey": "Song2025Agent", "title": "LLM Agent Swarm for Hypothesis-Driven Drug Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce PharmaSwarm, a unified multi-agent framework that orchestrates specialized LLM \"agents\" to propose, validate, and refine hypotheses for novel drug targets and lead compounds.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0184-23da89a284", "paper_id": "P0184", "bibkey": "Song2025Agent", "title": "LLM Agent Swarm for Hypothesis-Driven Drug Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Drug discovery remains a formidable challenge: more than 90 percent of candidate molecules fail in clinical evaluation, and development costs often exceed one billion dollars per approved therapy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0184-e6fce1c680", "paper_id": "P0184", "bibkey": "Song2025Agent", "title": "LLM Agent Swarm for Hypothesis-Driven Drug Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Drug discovery remains a formidable challenge: more than 90 percent of candidate molecules fail in clinical evaluation, and development costs often exceed one billion dollars per approved therapy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0184-985924906b", "paper_id": "P0184", "bibkey": "Song2025Agent", "title": "LLM Agent Swarm for Hypothesis-Driven Drug Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Disparate data streams, from genomics and transcriptomics to chemical libraries and clinical records, hinder coherent mechanistic insight and slow progress.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0184-cee8e4c80b", "paper_id": "P0184", "bibkey": "Song2025Agent", "title": "LLM Agent Swarm for Hypothesis-Driven Drug Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Meanwhile, large language models excel at reasoning and tool integration but lack the modular specialization and iterative memory required for regulated, hypothesis-driven workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0185-877442aea5", "paper_id": "P0185", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Motivated by the growing trend of scientific studies accompanied by public code repositories, we propose ToolMaker, an agentic framework that autonomously transforms papers with code into LLM-compatible tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0185-057a755e4e", "paper_id": "P0185", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To evaluate our approach, we introduce a benchmark comprising 15 complex computational tasks spanning various domains with over 100 unit tests to assess correctness and robustness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0185-172d428d55", "paper_id": "P0185", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our method correctly implements 80% of the tasks, substantially outperforming current state-of-the-art software engineering agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0185-e2c5ec2338", "paper_id": "P0185", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tool use has turned large language models (LLMs) into powerful agents that can perform complex multi-step tasks by dynamically utilising external software components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0185-253ce87f76", "paper_id": "P0185", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, these tools must be implemented in advance by human developers, hindering the applicability of LLM agents in domains demanding large numbers of highly specialised tools, like in life sciences and medicine.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0185-59d6b455cf", "paper_id": "P0185", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Motivated by the growing trend of scientific studies accompanied by public code repositories, we propose ToolMaker, an agentic framework that autonomously transforms papers with code into LLM-compatible tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0186-a0cb813141", "paper_id": "P0186", "bibkey": "Chu2025Bimanual", "title": "LLM+MAP: Bimanual Robot Task Planning using Large Language Models and Planning Domain Definition Language", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Our method is built using GPT-4o as the backend, and we compare its performance against plans generated directly by LLMs, including GPT-4o, V3 and also recent strong reasoning models o1 and R1.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0186-73c127cae2", "paper_id": "P0186", "bibkey": "Chu2025Bimanual", "title": "LLM+MAP: Bimanual Robot Task Planning using Large Language Models and Planning Domain Definition Language", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Existing works predominantly focus on attaining human-level manipulation skills for robotic hands, yet little attention has been paid to task planning on long-horizon timescales.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0186-b4b0a2aed4", "paper_id": "P0186", "bibkey": "Chu2025Bimanual", "title": "LLM+MAP: Bimanual Robot Task Planning using Large Language Models and Planning Domain Definition Language", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "By analyzing metrics such as planning time, success rate, group debits, and planning-step reduction rate, we demonstrate the superior performance of LLM+MAP, while also providing insights into robotic reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0186-d80aee2c97", "paper_id": "P0186", "bibkey": "Chu2025Bimanual", "title": "LLM+MAP: Bimanual Robot Task Planning using Large Language Models and Planning Domain Definition Language", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Bimanual robotic manipulation provides significant versatility, but also presents an inherent challenge due to the complexity involved in the spatial and temporal coordination between two hands.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0186-ba1256489f", "paper_id": "P0186", "bibkey": "Chu2025Bimanual", "title": "LLM+MAP: Bimanual Robot Task Planning using Large Language Models and Planning Domain Definition Language", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing works predominantly focus on attaining human-level manipulation skills for robotic hands, yet little attention has been paid to task planning on long-horizon timescales.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0186-f8e0f9a850", "paper_id": "P0186", "bibkey": "Chu2025Bimanual", "title": "LLM+MAP: Bimanual Robot Task Planning using Large Language Models and Planning Domain Definition Language", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With their outstanding in-context learning and zero-shot generation abilities, Large Language Models (LLMs) have been applied and grounded in diverse robotic embodiments to facilitate task planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0187-5c191083a6", "paper_id": "P0187", "bibkey": "Liu2025Powered", "title": "LLM-Powered GUI Agents in Phone Automation: Surveying Progress and Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "With the rapid rise of large language models (LLMs), phone automation has undergone transformative changes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0187-ec46292a2b", "paper_id": "P0187", "bibkey": "Liu2025Powered", "title": "LLM-Powered GUI Agents in Phone Automation: Surveying Progress and Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We then propose a taxonomy covering fundamental agent frameworks (single-agent, multi-agent, plan-then-act), modeling approaches (prompt engineering, training-based), and essential datasets and benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0187-2a911b09b6", "paper_id": "P0187", "bibkey": "Liu2025Powered", "title": "LLM-Powered GUI Agents in Phone Automation: Surveying Progress and Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we discuss open challenges such as dataset diversity, on-device deployment efficiency, user-centric adaptation, and security concerns, offering forward-looking insights into this rapidly evolving field.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0187-3fc7e69945", "paper_id": "P0187", "bibkey": "Liu2025Powered", "title": "LLM-Powered GUI Agents in Phone Automation: Surveying Progress and Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the rapid rise of large language models (LLMs), phone automation has undergone transformative changes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0187-d7e2392d33", "paper_id": "P0187", "bibkey": "Liu2025Powered", "title": "LLM-Powered GUI Agents in Phone Automation: Surveying Progress and Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper systematically reviews LLM-driven phone GUI agents, highlighting their evolution from script-based automation to intelligent, adaptive systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0187-921210feb2", "paper_id": "P0187", "bibkey": "Liu2025Powered", "title": "LLM-Powered GUI Agents in Phone Automation: Surveying Progress and Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We first contextualize key challenges, (i) limited generality, (ii) high maintenance overhead, and (iii) weak intent comprehension, and show how LLMs address these issues through advanced language understanding, multimodal perception, and robust decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0188-ffe4c29163", "paper_id": "P0188", "bibkey": "Matinez2025Llms", "title": "LLMs as Agentic Cooperative Players in Multiplayer UNO", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "LLMs promise to assist humans -- not just by answering questions, but by offering useful guidance across a wide range of tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0188-a66eb4f0c3", "paper_id": "P0188", "bibkey": "Matinez2025Llms", "title": "LLMs as Agentic Cooperative Players in Multiplayer UNO", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We find that while all models were able to successfully outperform a random baseline when playing UNO, few were able to significantly aid another player.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0188-414b935900", "paper_id": "P0188", "bibkey": "Matinez2025Llms", "title": "LLMs as Agentic Cooperative Players in Multiplayer UNO", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLMs promise to assist humans -- not just by answering questions, but by offering useful guidance across a wide range of tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0188-06ced7b537", "paper_id": "P0188", "bibkey": "Matinez2025Llms", "title": "LLMs as Agentic Cooperative Players in Multiplayer UNO", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "But how far does that assistance go?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0188-6156e1215a", "paper_id": "P0188", "bibkey": "Matinez2025Llms", "title": "LLMs as Agentic Cooperative Players in Multiplayer UNO", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Can a large language model based agent actually help someone accomplish their goal as an active participant?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0189-5aef4ede27", "paper_id": "P0189", "bibkey": "Zhang2025Largea", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Here we introduce a novel generative AI-based method for generating structural drawings employing a large language model (LLM) agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0189-897bcc2f50", "paper_id": "P0189", "bibkey": "Zhang2025Largea", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. In civil engineering, structural drawings serve as the main communication tool between architects, engineers, and builders to avoid conflicts, act as legal documentation, and provide a reference for future maintenance or evaluation needs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0189-79064ef6b3", "paper_id": "P0189", "bibkey": "Zhang2025Largea", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The method incorporates a retrieval-augmented generation (RAG) technique using externally-sourced facts to enhance the accuracy and reliability of the language model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0189-654bd71ff0", "paper_id": "P0189", "bibkey": "Zhang2025Largea", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. In civil engineering, structural drawings serve as the main communication tool between architects, engineers, and builders to avoid conflicts, act as legal documentation, and provide a reference for future maintenance or evaluation needs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0189-d5a9c93165", "paper_id": "P0189", "bibkey": "Zhang2025Largea", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "They are often organized using key elements such as title/subtitle blocks, scales, plan views, elevation view, sections, and detailed sections, which are annotated with standardized symbols and line types for interpretation by engineers and contractors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0189-e256e44d6f", "paper_id": "P0189", "bibkey": "Zhang2025Largea", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite advances in software capabilities, the task of generating a structural drawing remains labor-intensive and time-consuming for structural engineers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0190-d1d5f114c0", "paper_id": "P0190", "bibkey": "Chen2025Largea", "title": "Large Language Model-based Data Science Agent: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The rapid advancement of Large Language Models (LLMs) has driven novel applications across diverse domains, with LLM-based agents emerging as a crucial area of exploration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0190-3620ae9178", "paper_id": "P0190", "bibkey": "Chen2025Largea", "title": "Large Language Model-based Data Science Agent: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "From the data science perspective, we identify key processes for LLM-based agents, including data preprocessing, model development, evaluation, visualization, etc. Our work offers two key contributions: (1) a comprehensive review of recent developments in applying LLMbased agents to data science tasks; (2) a dual-perspective framework that connects general agent design principles with the practical workflows in data science.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0190-442089a2d2", "paper_id": "P0190", "bibkey": "Chen2025Largea", "title": "Large Language Model-based Data Science Agent: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid advancement of Large Language Models (LLMs) has driven novel applications across diverse domains, with LLM-based agents emerging as a crucial area of exploration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0190-ccb6a2187d", "paper_id": "P0190", "bibkey": "Chen2025Largea", "title": "Large Language Model-based Data Science Agent: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey presents a comprehensive analysis of LLM-based agents designed for data science tasks, summarizing insights from recent studies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0190-a392d620c5", "paper_id": "P0190", "bibkey": "Chen2025Largea", "title": "Large Language Model-based Data Science Agent: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "From the agent perspective, we discuss the key design principles, covering agent roles, execution, knowledge, and reflection methods.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0191-4483c862d8", "paper_id": "P0191", "bibkey": "Shahhosseini2025Large", "title": "Large Language Models for Scientific Idea Generation: A Creativity-Centered Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Scientific idea generation lies at the heart of scientific discovery and has driven human progress-whether by solving unsolved problems or proposing novel hypotheses to explain unknown phenomena.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0191-ff70bec454", "paper_id": "P0191", "bibkey": "Shahhosseini2025Large", "title": "Large Language Models for Scientific Idea Generation: A Creativity-Centered Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Scientific idea generation lies at the heart of scientific discovery and has driven human progress-whether by solving unsolved problems or proposing novel hypotheses to explain unknown phenomena.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0191-289258f208", "paper_id": "P0191", "bibkey": "Shahhosseini2025Large", "title": "Large Language Models for Scientific Idea Generation: A Creativity-Centered Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Scientific idea generation lies at the heart of scientific discovery and has driven human progress-whether by solving unsolved problems or proposing novel hypotheses to explain unknown phenomena.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0191-f97308e7c0", "paper_id": "P0191", "bibkey": "Shahhosseini2025Large", "title": "Large Language Models for Scientific Idea Generation: A Creativity-Centered Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike standard scientific reasoning or general creative generation, idea generation in science is a multi-objective and open-ended task, where the novelty of a contribution is as essential as its empirical soundness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0191-fcb9b90774", "paper_id": "P0191", "bibkey": "Shahhosseini2025Large", "title": "Large Language Models for Scientific Idea Generation: A Creativity-Centered Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have recently emerged as promising generators of scientific ideas, capable of producing coherent and factual outputs with surprising intuition and acceptable reasoning, yet their creative capacity remains inconsistent and poorly understood.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0192-4b774ec61e", "paper_id": "P0192", "bibkey": "Li2025Dissonances", "title": "Les Dissonances: Cross-Tool Harvesting and Polluting in Pool-of-Tools Empowered LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we present the first systematic security analysis of task control flows in multi-tool-enabled LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0192-fae121f81b", "paper_id": "P0192", "bibkey": "Li2025Dissonances", "title": "Les Dissonances: Cross-Tool Harvesting and Polluting in Pool-of-Tools Empowered LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0192-8ef2db8769", "paper_id": "P0192", "bibkey": "Li2025Dissonances", "title": "Les Dissonances: Cross-Tool Harvesting and Polluting in Pool-of-Tools Empowered LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents are autonomous systems powered by LLMs, capable of reasoning and planning to solve problems by leveraging a set of tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0192-8adb501f9a", "paper_id": "P0192", "bibkey": "Li2025Dissonances", "title": "Les Dissonances: Cross-Tool Harvesting and Polluting in Pool-of-Tools Empowered LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the integration of multi-tool capabilities in LLM agents introduces challenges in securely managing tools, ensuring their compatibility, handling dependency relationships, and protecting control flows within LLM agent workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0192-5bd954eacf", "paper_id": "P0192", "bibkey": "Li2025Dissonances", "title": "Les Dissonances: Cross-Tool Harvesting and Polluting in Pool-of-Tools Empowered LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we present the first systematic security analysis of task control flows in multi-tool-enabled LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0193-a6d6f1960c", "paper_id": "P0193", "bibkey": "Wu2025Lessons", "title": "Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Therapy recommendation for chronic patients with multimorbidity is challenging due to risks of treatment conflicts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0193-95758a8e17", "paper_id": "P0193", "bibkey": "Wu2025Lessons", "title": "Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The systems were evaluated on therapy planning tasks for multimorbidity patients using benchmark cases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0193-eaec375740", "paper_id": "P0193", "bibkey": "Wu2025Lessons", "title": "Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We compared MAS performance with single-agent approaches and real-world benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0193-3cfce7ae2f", "paper_id": "P0193", "bibkey": "Wu2025Lessons", "title": "Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Therapy recommendation for chronic patients with multimorbidity is challenging due to risks of treatment conflicts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0193-d607aa65a5", "paper_id": "P0193", "bibkey": "Wu2025Lessons", "title": "Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing decision support systems face scalability limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0193-1c649edcb7", "paper_id": "P0193", "bibkey": "Wu2025Lessons", "title": "Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Inspired by the way in which general practitioners (GP) manage multimorbidity patients, occasionally convening multidisciplinary team (MDT) collaboration, this study investigated the feasibility and value of using a Large Language Model (LLM)-based multi-agent system (MAS) for safer therapy recommendations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0193-62350cbd6d", "paper_id": "P0193", "bibkey": "Wu2025Lessons", "title": "Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Existing decision support systems face scalability limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0194-432ffd04a6", "paper_id": "P0194", "bibkey": "Becker2025Mallm", "title": "MALLM: Multi-Agent Large Language Models Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce MALLM (Multi-Agent Large Language Models), an open-source framework that enables systematic analysis of MAD components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0194-8eae125615", "paper_id": "P0194", "bibkey": "Becker2025Mallm", "title": "MALLM: Multi-Agent Large Language Models Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "MALLM offers more than 144 unique configurations of MAD, including (1) agent personas (e.g., Expert, Personality), (2) response generators (e.g., Critical, Reasoning), (3) discussion paradigms (e.g., Memory, Relay), and (4) decision protocols (e.g., Voting, Consensus).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0194-f2e78c673e", "paper_id": "P0194", "bibkey": "Becker2025Mallm", "title": "MALLM: Multi-Agent Large Language Models Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Current frameworks for multi-agent debate are often designed towards tool use, lack integrated evaluation, or provide limited configurability of agent personas, response generators, discussion paradigms, and decision protocols.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0194-04007688a0", "paper_id": "P0194", "bibkey": "Becker2025Mallm", "title": "MALLM: Multi-Agent Large Language Models Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Multi-agent debate (MAD) has demonstrated the ability to augment collective intelligence by scaling test-time compute and leveraging expertise.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0194-e3981a892e", "paper_id": "P0194", "bibkey": "Becker2025Mallm", "title": "MALLM: Multi-Agent Large Language Models Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current frameworks for multi-agent debate are often designed towards tool use, lack integrated evaluation, or provide limited configurability of agent personas, response generators, discussion paradigms, and decision protocols.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0194-36fefc8e3f", "paper_id": "P0194", "bibkey": "Becker2025Mallm", "title": "MALLM: Multi-Agent Large Language Models Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce MALLM (Multi-Agent Large Language Models), an open-source framework that enables systematic analysis of MAD components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0195-8bcb673a7d", "paper_id": "P0195", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#method"}, "confidence": "medium", "tags": ["evaluation", "security", "tooling"]}
{"evidence_id": "E-P0195-d6095e10e9", "paper_id": "P0195", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed attacks; (2) an evaluation harness that executes attacks by running real tools (both benign and malicious) via MCP rather than simulation; and (3) a robustness metric that quantifies the trade-off between security and performance: Net Resilient Performance (NRP).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0195-7a6ec4daed", "paper_id": "P0195", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate nine popular LLM agents across 10 domains and 400+ tools, producing 2,000 attack instances.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0195-04669fc5b8", "paper_id": "P0195", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The Model Context Protocol (MCP) standardizes how large language model (LLM) agents discover, describe, and call external tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0195-e58dfe941a", "paper_id": "P0195", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While MCP unlocks broad interoperability, it also enlarges the attack surface by making tools first-class, composable objects with natural-language metadata, and standardized I/O.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#summary_bullets[1]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0195-e61edf509b", "paper_id": "P0195", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "security", "tooling"]}
{"evidence_id": "E-P0196-84445d1a19", "paper_id": "P0196", "bibkey": "Luo2025Universe", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this critical gap, we introduce MCP-Universe, the first comprehensive benchmark specifically designed to evaluate LLMs in realistic and hard tasks through interaction with real-world MCP servers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0196-619c307f9a", "paper_id": "P0196", "bibkey": "Luo2025Universe", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through extensive evaluation of leading LLMs, we find that even SOTA models such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit significant performance limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0196-9866fbcaba", "paper_id": "P0196", "bibkey": "Luo2025Universe", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our benchmark encompasses 6 core domains spanning 11 different MCP servers: Location Navigation, Repository Management, Financial Analysis, 3D Design, Browser Automation, and Web Searching.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0196-7fb7d586be", "paper_id": "P0196", "bibkey": "Luo2025Universe", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The Model Context Protocol has emerged as a transformative standard for connecting large language models to external data sources and tools, rapidly gaining adoption across major AI providers and development platforms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0196-dee38d5a65", "paper_id": "P0196", "bibkey": "Luo2025Universe", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing benchmarks are overly simplistic and fail to capture real application challenges such as long-horizon reasoning and large, unfamiliar tool spaces.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0196-e0c143baab", "paper_id": "P0196", "bibkey": "Luo2025Universe", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this critical gap, we introduce MCP-Universe, the first comprehensive benchmark specifically designed to evaluate LLMs in realistic and hard tasks through interaction with real-world MCP servers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0196-3c65d38a2a", "paper_id": "P0196", "bibkey": "Luo2025Universe", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Through extensive evaluation of leading LLMs, we find that even SOTA models such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit significant performance limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#limitations[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0197-312a342670", "paper_id": "P0197", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0197-3a4792de2b", "paper_id": "P0197", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0197-67d5c4342c", "paper_id": "P0197", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0197-875ce4a305", "paper_id": "P0197", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) are increasingly serving as autonomous agents, and their utilization of external tools via the Model Context Protocol (MCP) is considered a future trend.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0197-cda5a4d930", "paper_id": "P0197", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0197-dee80dc348", "paper_id": "P0197", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0197-f7a14123f9", "paper_id": "P0197", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#limitations[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0198-2f136bded0", "paper_id": "P0198", "bibkey": "Liu2025Medchat", "title": "MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these limitations, we propose MedChat, a multi-agent diagnostic framework and platform that combines specialized vision models with multiple role-specific LLM agents, all coordinated by a director agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0198-6e7a9df7ab", "paper_id": "P0198", "bibkey": "Liu2025Medchat", "title": "MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, applying general LLMs to medical imaging remains challenging due to hallucinations, limited interpretability, and insufficient domain-specific medical knowledge, which can potentially reduce clinical accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0198-0a28582019", "paper_id": "P0198", "bibkey": "Liu2025Medchat", "title": "MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The integration of deep learning-based glaucoma detection with large language models (LLMs) presents an automated strategy to mitigate ophthalmologist shortages and improve clinical reporting efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0198-e95893efbd", "paper_id": "P0198", "bibkey": "Liu2025Medchat", "title": "MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, applying general LLMs to medical imaging remains challenging due to hallucinations, limited interpretability, and insufficient domain-specific medical knowledge, which can potentially reduce clinical accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0198-a89fb4f5a3", "paper_id": "P0198", "bibkey": "Liu2025Medchat", "title": "MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Although recent approaches combining imaging models with LLM reasoning have improved reporting, they typically rely on a single generalist agent, restricting their capacity to emulate the diverse and complex reasoning found in multidisciplinary medical teams.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0198-95fc4dccb3", "paper_id": "P0198", "bibkey": "Liu2025Medchat", "title": "MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address these limitations, we propose MedChat, a multi-agent diagnostic framework and platform that combines specialized vision models with multiple role-specific LLM agents, all coordinated by a director agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0199-2941d61a03", "paper_id": "P0199", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this need, we present \\textbf{MedicalOS}, a unified agent-based operational system designed as such a domain-specific abstract layer for healthcare.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0199-6075ffa788", "paper_id": "P0199", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We empirically validate MedicalOS on 214 patient cases across 22 specialties, demonstrating high diagnostic accuracy and confidence, clinically sound examination requests, and consistent generation of structured reports and medication recommendations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0199-26f893d6cd", "paper_id": "P0199", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This shift highlights the need for an abstraction layer, an agent-computer interface, that translates human language into machine-executable commands.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0199-3b9601b81e", "paper_id": "P0199", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Decades' advances in digital health technologies, such as electronic health records, have largely streamlined routine clinical processes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0199-cbfa085708", "paper_id": "P0199", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Yet, most these systems are still hard to learn and use: Clinicians often face the burden of managing multiple tools, repeating manual actions for each patient, navigating complicated UI trees to locate functions, and spending significant time on administration instead of caring for patients.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0199-27adc3f95a", "paper_id": "P0199", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The recent rise of large language model (LLM) based agents demonstrates exceptional capability in coding and computer operation, revealing the potential for humans to interact with operating systems and software not by direct manipulation, but by instructing agents through natural language.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0200-f07953ab74", "paper_id": "P0200", "bibkey": "Du2025Memr", "title": "MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Memory systems have been designed to leverage past experiences in Large Language Model (LLM) agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0200-497b158080", "paper_id": "P0200", "bibkey": "Du2025Memr", "title": "MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Empirical results on the LoCoMo benchmark demonstrate that MemR$^3$ surpasses strong baselines on LLM-as-a-Judge score, and particularly, it improves existing retrievers across four categories with an overall improvement on RAG (+7.29%) and Zep (+1.94%) using GPT-4.1-mini backend, offering a plug-and-play controller for existing memory stores.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0200-1b99de5317", "paper_id": "P0200", "bibkey": "Du2025Memr", "title": "MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap tracker that explicitly renders the answering process transparent and tracks the evidence collection process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0200-7c7e98d4fc", "paper_id": "P0200", "bibkey": "Du2025Memr", "title": "MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Memory systems have been designed to leverage past experiences in Large Language Model (LLM) agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0200-af181b50bf", "paper_id": "P0200", "bibkey": "Du2025Memr", "title": "MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, many deployed memory systems primarily optimize compression and storage, with comparatively less emphasis on explicit, closed-loop control of memory retrieval.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0200-7843515ca7", "paper_id": "P0200", "bibkey": "Du2025Memr", "title": "MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap tracker that explicitly renders the answering process transparent and tracks the evidence collection process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0201-89c733716e", "paper_id": "P0201", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work we introduce Meta-Policy Reflexion (MPR): a hybrid framework that consolidates LLM-generated reflections into a structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at inference time through two complementary mechanisms soft memory-guided decoding and hard rule admissibility checks(HAC).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0201-8a3b04d40f", "paper_id": "P0201", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We formalize the MPM representation, present algorithms for update and decoding, and validate the approach in a text-based agent environment following the experimental protocol described in the provided implementation (AlfWorld-based).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0201-edaf17f9f6", "paper_id": "P0201", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Empirical results reported in the supplied material indicate consistent gains in execution accuracy and robustness when compared to Reflexion baselines; rule admissibility further improves stability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0201-6cc12d806b", "paper_id": "P0201", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents achieve impressive single-task performance but commonly exhibit repeated failures, inefficient exploration, and limited cross-task adaptability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0201-37a908f409", "paper_id": "P0201", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing reflective strategies (e.g., Reflexion, ReAct) improve per-episode behavior but typically produce ephemeral, task-specific traces that are not reused across tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0201-e643297350", "paper_id": "P0201", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reinforcement-learning based alternatives can produce transferable policies but require substantial parameter updates and compute.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0202-b43bea4c14", "paper_id": "P0202", "bibkey": "Gong2025Mindflow", "title": "MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present MindFlow, the first open-source multimodal LLM agent tailored for e-commerce.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0202-4b077e848e", "paper_id": "P0202", "bibkey": "Gong2025Mindflow", "title": "MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluated via online A/B testing and simulation-based ablation, MindFlow demonstrates substantial gains in handling complex queries, improving user satisfaction, and reducing operational costs, with a 93.53% relative improvement observed in real-world deployments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0202-c88a7659dd", "paper_id": "P0202", "bibkey": "Gong2025Mindflow", "title": "MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in large language models (LLMs) have enabled new applications in e-commerce customer service.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0202-ac0f1e0c1a", "paper_id": "P0202", "bibkey": "Gong2025Mindflow", "title": "MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, their capabilities remain constrained in complex, multimodal scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0202-54bebbc4bf", "paper_id": "P0202", "bibkey": "Gong2025Mindflow", "title": "MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present MindFlow, the first open-source multimodal LLM agent tailored for e-commerce.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0203-d8f84c5470", "paper_id": "P0203", "bibkey": "Abbineni2025Muallm", "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for circuit design assistance that integrates a hybrid Retrieval-Augmented Generation (RAG) framework with an adaptive vector database of circuit design research papers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0203-4d40260657", "paper_id": "P0203", "bibkey": "Abbineni2025Muallm", "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "At the maximum context length supported by standard LLMs, MuaLLM remains up to 10x less costly and 1.6x faster while maintaining the same accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0203-e294aeefb5", "paper_id": "P0203", "bibkey": "Abbineni2025Muallm", "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval and citation performance, and Reasoning-100 (Reas-100), focused on multistep reasoning in circuit design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0203-221eec994b", "paper_id": "P0203", "bibkey": "Abbineni2025Muallm", "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Conducting a comprehensive literature review is crucial for advancing circuit design methodologies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0203-32cca2747f", "paper_id": "P0203", "bibkey": "Abbineni2025Muallm", "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the rapid influx of state-of-the-art research, inconsistent data representation, and the complexity of optimizing circuit design objectives make this task significantly challenging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0203-f7669f742d", "paper_id": "P0203", "bibkey": "Abbineni2025Muallm", "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for circuit design assistance that integrates a hybrid Retrieval-Augmented Generation (RAG) framework with an adaptive vector database of circuit design research papers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0204-8f7aeed767", "paper_id": "P0204", "bibkey": "Zhu2025Multiagentbench", "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce MultiAgentBench, a comprehensive benchmark designed to evaluate LLM-based multi-agent systems across diverse, interactive scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0204-ff07210df8", "paper_id": "P0204", "bibkey": "Zhu2025Multiagentbench", "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Notably, gpt-4o-mini reaches the average highest task score, graph structure performs the best among coordination protocols in the research scenario, and cognitive planning improves milestone achievement rates by 3%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0204-fff2e5a141", "paper_id": "P0204", "bibkey": "Zhu2025Multiagentbench", "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large Language Models (LLMs) have shown remarkable capabilities as autonomous agents, yet existing benchmarks either focus on single-agent tasks or are confined to narrow domains, failing to capture the dynamics of multi-agent coordination and competition.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0204-2f5e7fbea8", "paper_id": "P0204", "bibkey": "Zhu2025Multiagentbench", "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have shown remarkable capabilities as autonomous agents, yet existing benchmarks either focus on single-agent tasks or are confined to narrow domains, failing to capture the dynamics of multi-agent coordination and competition.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0204-9cde31a808", "paper_id": "P0204", "bibkey": "Zhu2025Multiagentbench", "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce MultiAgentBench, a comprehensive benchmark designed to evaluate LLM-based multi-agent systems across diverse, interactive scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0204-6895fd5100", "paper_id": "P0204", "bibkey": "Zhu2025Multiagentbench", "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our framework measures not only task completion but also the quality of collaboration and competition using novel, milestone-based key performance indicators.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0205-b0c245804e", "paper_id": "P0205", "bibkey": "Bharadwaj2025Omnireflect", "title": "OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce OmniReflect, a hierarchical, reflection-driven framework that constructs a constitution, a compact set of guiding principles distilled from task experiences, to enhance the effectiveness and efficiency of an LLM agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0205-85b5f3734b", "paper_id": "P0205", "bibkey": "Bharadwaj2025Omnireflect", "title": "OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Empirical results averaged across models show major improvements in task success, with absolute gains of +10.3% on ALFWorld, +23.8% on BabyAI, and +8.3% on PDDL in the Self-sustaining mode.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0205-0aeb5b5530", "paper_id": "P0205", "bibkey": "Bharadwaj2025Omnireflect", "title": "OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Efforts to improve Large Language Model (LLM) agent performance on complex tasks have largely focused on fine-tuning and iterative self-correction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0205-820eb3e8ca", "paper_id": "P0205", "bibkey": "Bharadwaj2025Omnireflect", "title": "OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, these approaches often lack generalizable mechanisms for longterm learning and remain inefficient in dynamic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0205-1a0551a690", "paper_id": "P0205", "bibkey": "Bharadwaj2025Omnireflect", "title": "OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce OmniReflect, a hierarchical, reflection-driven framework that constructs a constitution, a compact set of guiding principles distilled from task experiences, to enhance the effectiveness and efficiency of an LLM agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0206-a353d06199", "paper_id": "P0206", "bibkey": "Liu2025Outraged", "title": "Outraged AI: Large language models prioritise emotion over cost in fairness enforcement", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose that LLMs progress along a trajectory paralleling human development; future models should integrate emotion with context-sensitive reasoning to achieve human-like emotional intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0206-ef5d2672bf", "paper_id": "P0206", "bibkey": "Liu2025Outraged", "title": "Outraged AI: Large language models prioritise emotion over cost in fairness enforcement", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Notably, reasoning models (o3-mini, DeepSeek-R1) were more cost-sensitive and closer to human behavior than foundation models (GPT-3.5, DeepSeek-V3), yet remained heavily emotion-driven.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0206-315a8fc05d", "paper_id": "P0206", "bibkey": "Liu2025Outraged", "title": "Outraged AI: Large language models prioritise emotion over cost in fairness enforcement", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In a large-scale comparison of 4,068 LLM agents with 1,159 adults across 796,100 decisions, LLMs used emotion to guide punishment, sometimes even more strongly than humans did: Unfairness elicited stronger negative emotion that led to more punishment; punishing unfairness produced more positive emotion than accepting; and critically, prompting self-reports of emotion causally increased punishment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0206-d6867526ff", "paper_id": "P0206", "bibkey": "Liu2025Outraged", "title": "Outraged AI: Large language models prioritise emotion over cost in fairness enforcement", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Emotions guide human decisions, but whether large language models (LLMs) use emotion similarly remains unknown.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0206-e73e64550f", "paper_id": "P0206", "bibkey": "Liu2025Outraged", "title": "Outraged AI: Large language models prioritise emotion over cost in fairness enforcement", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We tested this using altruistic third-party punishment, where an observer incurs a personal cost to enforce fairness, a hallmark of human morality and often driven by negative emotion.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0206-a510550fa5", "paper_id": "P0206", "bibkey": "Liu2025Outraged", "title": "Outraged AI: Large language models prioritise emotion over cost in fairness enforcement", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In a large-scale comparison of 4,068 LLM agents with 1,159 adults across 796,100 decisions, LLMs used emotion to guide punishment, sometimes even more strongly than humans did: Unfairness elicited stronger negative emotion that led to more punishment; punishing unfairness produced more positive emotion than accepting; and critically, prompting self-reports of emotion causally increased punishment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0207-1fe472e3e8", "paper_id": "P0207", "bibkey": "Zhang2025Personaagent", "title": "PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Based on the framework, we propose a test-time user-preference alignment strategy that simulate the latest n interactions to optimize the persona prompt, ensuring real-time user preference alignment through textual loss feedback between simulated and ground-truth responses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0207-0d77f6cf58", "paper_id": "P0207", "bibkey": "Zhang2025Personaagent", "title": "PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "These results underscore the feasibility and potential of our approach in delivering tailored, dynamic user experiences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0207-66c61f0d98", "paper_id": "P0207", "bibkey": "Zhang2025Personaagent", "title": "PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) empowered agents have recently emerged as advanced paradigms that exhibit impressive capabilities in a wide range of domains and tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0207-c369dac4ec", "paper_id": "P0207", "bibkey": "Zhang2025Personaagent", "title": "PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite their potential, current LLM agents often adopt a one-size-fits-all approach, lacking the flexibility to respond to users' varying needs and preferences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0207-41589af18c", "paper_id": "P0207", "bibkey": "Zhang2025Personaagent", "title": "PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This limitation motivates us to develop PersonaAgent, the first personalized LLM agent framework designed to address versatile personalization tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0207-804bdbded0", "paper_id": "P0207", "bibkey": "Zhang2025Personaagent", "title": "PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "This limitation motivates us to develop PersonaAgent, the first personalized LLM agent framework designed to address versatile personalization tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0208-64d6dcbdb2", "paper_id": "P0208", "bibkey": "Lu2025Pilotrl", "title": "PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we introduce an adaptive global plan-based agent paradigm AdaPlan, aiming to synergize high-level explicit guidance with execution to support effective long-horizon decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0208-07f6a1adfe", "paper_id": "P0208", "bibkey": "Lu2025Pilotrl", "title": "PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments indicate that PilotRL could achieve state-of-the-art performances, with LLaMA3.1-8B-Instruct + PilotRL surpassing closed-sourced GPT-4o by 3.60%, while showing a more substantial gain of 55.78% comparing to GPT-4o-mini at a comparable parameter scale.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0208-5df0fe8899", "paper_id": "P0208", "bibkey": "Lu2025Pilotrl", "title": "PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have shown remarkable advancements in tackling agent-oriented tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0208-672c8aa221", "paper_id": "P0208", "bibkey": "Lu2025Pilotrl", "title": "PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite their potential, existing work faces challenges when deploying LLMs in agent-based environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0208-3d089e2895", "paper_id": "P0208", "bibkey": "Lu2025Pilotrl", "title": "PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The widely adopted agent paradigm ReAct centers on integrating single-step reasoning with immediate action execution, which limits its effectiveness in complex tasks requiring long-term strategic planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0209-3cdda9660a", "paper_id": "P0209", "bibkey": "Yang2025Proagent", "title": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose ProAgent, the first end-to-end proactive agent system that harnesses massive sensory contexts and LLM reasoning to deliver proactive assistance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0209-aa504d163c", "paper_id": "P0209", "bibkey": "Yang2025Proagent", "title": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Results show that ProAgent achieves up to 33.4% higher proactive prediction accuracy, 16.8% higher tool-calling F1 score, and notable improvements in user satisfaction over state-of-the-art baselines, marking a significant step toward proactive assistants.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0209-50bf74b151", "paper_id": "P0209", "bibkey": "Yang2025Proagent", "title": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We implement ProAgent on Augmented Reality (AR) glasses with an edge server and extensively evaluate it on a real-world testbed, a public dataset, and through a user study.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0209-766ab3b466", "paper_id": "P0209", "bibkey": "Yang2025Proagent", "title": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents are emerging to transform daily life.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0209-fc5914ac63", "paper_id": "P0209", "bibkey": "Yang2025Proagent", "title": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing LLM agents primarily follow a reactive paradigm, relying on explicit user instructions to initiate services, which increases both physical and cognitive workload.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0209-b5810d78d7", "paper_id": "P0209", "bibkey": "Yang2025Proagent", "title": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose ProAgent, the first end-to-end proactive agent system that harnesses massive sensory contexts and LLM reasoning to deliver proactive assistance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0210-9fcd1a0d17", "paper_id": "P0210", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Motivated by the fact that human experts exhibit significantly better rewrite ability but suffer from scalability, and Large Language Models (LLMs) have demonstrated nearly human-level semantic and reasoning abilities, we propose a new approach of using LLMs to rewrite SQL queries beyond rules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0210-a9d61ac1b4", "paper_id": "P0210", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments show that QUITE reduces query execution time by up to 35.8% over state-of-the-art approaches and produces 24.1% more rewrites than prior methods, covering query cases that earlier systems did not handle.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0210-efd40e95eb", "paper_id": "P0210", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This limitation stems from three challenges of rule-based query rewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite rules do not generalize to new query patterns, and (3) some rewrite techniques cannot be expressed as fixed rules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0210-fb4ae99b92", "paper_id": "P0210", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Query rewrite transforms SQL queries into semantically equivalent forms that run more efficiently.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0210-ea3cd071bc", "paper_id": "P0210", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing approaches mainly rely on predefined rewrite rules, but they handle a limited subset of queries and can cause performance regressions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0210-49862df15e", "paper_id": "P0210", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This limitation stems from three challenges of rule-based query rewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite rules do not generalize to new query patterns, and (3) some rewrite techniques cannot be expressed as fixed rules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0210-7165541801", "paper_id": "P0210", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "This limitation stems from three challenges of rule-based query rewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite rules do not generalize to new query patterns, and (3) some rewrite techniques cannot be expressed as fixed rules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#limitations[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0211-8955e5a419", "paper_id": "P0211", "bibkey": "Asthana2025Stride", "title": "STRIDE: A Systematic Framework for Selecting AI Modalities -- Agentic AI, AI Assistants, or LLM Calls", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present STRIDE (Systematic Task Reasoning Intelligence Deployment Evaluator), a framework that provides principled recommendations for selecting between three modalities: (i) direct LLM calls, (ii) guided AI assistants, and (iii) fully autonomous agentic AI.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0211-d4675d30c6", "paper_id": "P0211", "bibkey": "Asthana2025Stride", "title": "STRIDE: A Systematic Framework for Selecting AI Modalities -- Agentic AI, AI Assistants, or LLM Calls", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluated across 30 real-world tasks spanning SRE, compliance, and enterprise automation, STRIDE achieved 92% accuracy in modality selection, reduced unnecessary agent deployments by 45%, and cut resource costs by 37%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0211-578e8a445e", "paper_id": "P0211", "bibkey": "Asthana2025Stride", "title": "STRIDE: A Systematic Framework for Selecting AI Modalities -- Agentic AI, AI Assistants, or LLM Calls", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid shift from stateless large language models (LLMs) to autonomous, goal-driven agents raises a central question: When is agentic AI truly necessary?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0211-740ed0af1f", "paper_id": "P0211", "bibkey": "Asthana2025Stride", "title": "STRIDE: A Systematic Framework for Selecting AI Modalities -- Agentic AI, AI Assistants, or LLM Calls", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While agents enable multi-step reasoning, persistent memory, and tool orchestration, deploying them indiscriminately leads to higher cost, complexity, and risk.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0211-7864e284f2", "paper_id": "P0211", "bibkey": "Asthana2025Stride", "title": "STRIDE: A Systematic Framework for Selecting AI Modalities -- Agentic AI, AI Assistants, or LLM Calls", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present STRIDE (Systematic Task Reasoning Intelligence Deployment Evaluator), a framework that provides principled recommendations for selecting between three modalities: (i) direct LLM calls, (ii) guided AI assistants, and (iii) fully autonomous agentic AI.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0212-ab00f8de8c", "paper_id": "P0212", "bibkey": "Chen2025Schema", "title": "Schema-Guided Scene-Graph Reasoning based on Multi-Agent Large Language Model System", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose SG^2, an iterative Schema-Guided Scene-Graph reasoning framework based on multi-agent LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#method"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0212-1167f52f16", "paper_id": "P0212", "bibkey": "Chen2025Schema", "title": "Schema-Guided Scene-Graph Reasoning based on Multi-Agent Large Language Model System", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In this work, we propose SG^2, an iterative Schema-Guided Scene-Graph reasoning framework based on multi-agent LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0212-e6775e7c26", "paper_id": "P0212", "bibkey": "Chen2025Schema", "title": "Schema-Guided Scene-Graph Reasoning based on Multi-Agent Large Language Model System", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The agents are grouped into two modules: a (1) Reasoner module for abstract task planning and graph information queries generation, and a (2) Retriever module for extracting corresponding graph information based on code-writing following the queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0212-854341fb9b", "paper_id": "P0212", "bibkey": "Chen2025Schema", "title": "Schema-Guided Scene-Graph Reasoning based on Multi-Agent Large Language Model System", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Scene graphs have emerged as a structured and serializable environment representation for grounded spatial reasoning with Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0212-34badf5581", "paper_id": "P0212", "bibkey": "Chen2025Schema", "title": "Schema-Guided Scene-Graph Reasoning based on Multi-Agent Large Language Model System", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we propose SG^2, an iterative Schema-Guided Scene-Graph reasoning framework based on multi-agent LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0212-483fda1694", "paper_id": "P0212", "bibkey": "Chen2025Schema", "title": "Schema-Guided Scene-Graph Reasoning based on Multi-Agent Large Language Model System", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The agents are grouped into two modules: a (1) Reasoner module for abstract task planning and graph information queries generation, and a (2) Retriever module for extracting corresponding graph information based on code-writing following the queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0213-9152db24bd", "paper_id": "P0213", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Subsequently, we present the vision of a zero-trust multi-LLM framework in EGI.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0213-ee26c8ba8a", "paper_id": "P0213", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This survey serves as the first systematic treatment of zero-trust applied to multi-LLM systems, providing both theoretical foundations and practical strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0213-a1049afe06", "paper_id": "P0213", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agentification serves as a critical enabler of Edge General Intelligence (EGI), transforming massive edge devices into cognitive agents through integrating Large Language Models (LLMs) and perception, reasoning, and acting modules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0213-547b5447b2", "paper_id": "P0213", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These agents collaborate across heterogeneous edge infrastructures, forming multi-LLM agentic AI systems that leverage collective intelligence and specialized capabilities to tackle complex, multi-step tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0213-5bf56d0771", "paper_id": "P0213", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the collaborative nature of multi-LLM systems introduces critical security vulnerabilities, including insecure inter-LLM communications, expanded attack surfaces, and cross-domain data leakage that traditional perimeter-based security cannot adequately address.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0214-e872c22cb6", "paper_id": "P0214", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose the Self-Challenging framework for training an agent on high-quality tasks that are generated by itself.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0214-2e6956a116", "paper_id": "P0214", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0214-17d0e7f9d9", "paper_id": "P0214", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, training such agents is challenging because it requires human creation and annotation of a diverse set of tasks, tools, and evaluation criteria.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0214-35136168c1", "paper_id": "P0214", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models are quickly becoming the foundation for intelligent agents that are capable of using tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0214-e90846830c", "paper_id": "P0214", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, training such agents is challenging because it requires human creation and annotation of a diverse set of tasks, tools, and evaluation criteria.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0214-0e2de6e8b5", "paper_id": "P0214", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose the Self-Challenging framework for training an agent on high-quality tasks that are generated by itself.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0215-f213ab51ad", "paper_id": "P0215", "bibkey": "Serenari2025Semantically", "title": "Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this challenge, we present the Local Optimizations for Pseudonymization with Semantic Integrity Directed Entity Detection (LOPSIDED) framework, a semantically-aware privacy agent designed to safeguard sensitive PII data when using remote LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0215-fdb7fe50b2", "paper_id": "P0215", "bibkey": "Serenari2025Semantically", "title": "Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results show that LOPSIDED reduces semantic utility errors by a factor of 5 compared to baseline techniques, all while enhancing privacy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0215-7bc837ce7e", "paper_id": "P0215", "bibkey": "Serenari2025Semantically", "title": "Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the increasing use of conversational AI systems, there is growing concern over privacy leaks, especially when users share sensitive personal data in interactions with Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0215-a63c1b64b0", "paper_id": "P0215", "bibkey": "Serenari2025Semantically", "title": "Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Conversations shared with these models may contain Personally Identifiable Information (PII), which, if exposed, could lead to security breaches or identity theft.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0215-51e44276bd", "paper_id": "P0215", "bibkey": "Serenari2025Semantically", "title": "Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this challenge, we present the Local Optimizations for Pseudonymization with Semantic Integrity Directed Entity Detection (LOPSIDED) framework, a semantically-aware privacy agent designed to safeguard sensitive PII data when using remote LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0216-5995819b8e", "paper_id": "P0216", "bibkey": "Seo2025Simuhome", "title": "SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this, we introduce $\\textbf{SimuHome}$, a time-accelerated home environment that simulates smart devices, supports API calls, and reflects changes in environmental variables.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0216-7b36039ae4", "paper_id": "P0216", "bibkey": "Seo2025Simuhome", "title": "SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We provide a challenging benchmark of 600 episodes across twelve user query types that require the aforementioned capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0216-469a70bb44", "paper_id": "P0216", "bibkey": "Seo2025Simuhome", "title": "SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation of 16 agents under a unified ReAct framework reveals distinct capabilities and limitations across models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0216-34b3ccbdc8", "paper_id": "P0216", "bibkey": "Seo2025Simuhome", "title": "SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents excel at multi-step, tool-augmented tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0216-c4666f17e9", "paper_id": "P0216", "bibkey": "Seo2025Simuhome", "title": "SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, smart homes introduce distinct challenges, requiring agents to handle latent user intents, temporal dependencies, device constraints, scheduling, and more.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0216-866e9988a4", "paper_id": "P0216", "bibkey": "Seo2025Simuhome", "title": "SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The main bottlenecks for developing smart home agents with such capabilities include the lack of a realistic simulation environment where agents can interact with devices and observe the results, as well as a challenging benchmark to evaluate them.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0216-e2e3b7fa97", "paper_id": "P0216", "bibkey": "Seo2025Simuhome", "title": "SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Our evaluation of 16 agents under a unified ReAct framework reveals distinct capabilities and limitations across models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#limitations[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0217-de316a8af3", "paper_id": "P0217", "bibkey": "Maritan2025Staffpro", "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We cast these problems in a formal mathematical framework that links scheduling decisions to latent feature estimation, and we introduce StaffPro, an LLM agent that addresses staffing and profiling jointly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0217-85d4ca0495", "paper_id": "P0217", "bibkey": "Maritan2025Staffpro", "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "StaffPro interacts directly with humans by establishing a continuous human-agent feedback loop, ensuring natural and intuitive use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0217-83e7dbefb5", "paper_id": "P0217", "bibkey": "Maritan2025Staffpro", "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "By analyzing human feedback, our agent continuously estimates the latent features of workers, realizing life-long worker profiling and ensuring optimal staffing performance over time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0217-401df265bc", "paper_id": "P0217", "bibkey": "Maritan2025Staffpro", "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents integrate pre-trained LLMs with modular algorithmic components and have shown remarkable reasoning and decision-making abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0217-caa0924a99", "paper_id": "P0217", "bibkey": "Maritan2025Staffpro", "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we investigate their use for two tightly intertwined challenges in workforce management: staffing, i.e., the assignment and scheduling of tasks to workers, which may require team formation; and profiling, i.e., the continuous estimation of workers' skills, preferences, and other latent attributes from unstructured data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0217-4e4a128148", "paper_id": "P0217", "bibkey": "Maritan2025Staffpro", "title": "StaffPro: an LLM Agent for Joint Staffing and Profiling", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We cast these problems in a formal mathematical framework that links scheduling decisions to latent feature estimation, and we introduce StaffPro, an LLM agent that addresses staffing and profiling jointly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0218-3b338d80bc", "paper_id": "P0218", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we introduce StockBench, a contamination-free benchmark designed to evaluate LLM agents in realistic, multi-month stock trading environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0218-99aa4ad8d4", "paper_id": "P0218", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation of state-of-the-art proprietary (e.g., GPT-5, Claude-4) and open-weight (e.g., Qwen3, Kimi-K2, GLM-4.5) models shows that while most LLM agents struggle to outperform the simple buy-and-hold baseline, several models demonstrate the potential to deliver higher returns and manage risk more effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0218-79963782cf", "paper_id": "P0218", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "While prior benchmarks have evaluated LLM agents in domains such as software engineering and scientific discovery, the finance domain remains underexplored, despite its direct relevance to economic value and high-stakes decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0218-e22b501ea6", "paper_id": "P0218", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have recently demonstrated strong capabilities as autonomous agents, showing promise in reasoning, tool use, and sequential decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0218-a043637334", "paper_id": "P0218", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While prior benchmarks have evaluated LLM agents in domains such as software engineering and scientific discovery, the finance domain remains underexplored, despite its direct relevance to economic value and high-stakes decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0218-18024362ec", "paper_id": "P0218", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing financial benchmarks primarily test static knowledge through question answering, but they fall short of capturing the dynamic and iterative nature of trading.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0218-4f9b0e7b78", "paper_id": "P0218", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "These findings highlight both the challenges and opportunities in developing LLM-powered financial agents, showing that excelling at static financial knowledge tasks does not necessarily translate into successful trading strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0219-3f61ab46df", "paper_id": "P0219", "bibkey": "Huang2025Surgical", "title": "Surgical AI Copilot: Energy-Based Fourier Gradient Low-Rank Adaptation for Surgical LLM Agent Reasoning and Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce Surgical AI Copilot, an LLM agent for image-guided pituitary surgery, capable of conversation, planning, and task execution in response to queries involving tasks such as MRI tumor segmentation, endoscope anatomy segmentation, overlaying preoperative imaging with intraoperative views, instrument tracking, and surgical visual question answering (VQA).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0219-7bc7d14864", "paper_id": "P0219", "bibkey": "Huang2025Surgical", "title": "Surgical AI Copilot: Energy-Based Fourier Gradient Low-Rank Adaptation for Surgical LLM Agent Reasoning and Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Additionally, we propose DEFT-GaLore, a Deterministic Energy-based Fourier Transform (DEFT) gradient projection technique for efficient low-rank adaptation of recent LLMs (e.g., LLaMA 3.2, Qwen 2.5), enabling their use as surgical agent planners.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0219-327d2749fc", "paper_id": "P0219", "bibkey": "Huang2025Surgical", "title": "Surgical AI Copilot: Energy-Based Fourier Gradient Low-Rank Adaptation for Surgical LLM Agent Reasoning and Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We extensively validate our agent's performance and the proposed adaptation technique against other state-of-the-art low-rank adaptation methods on agent planning and prompt generation tasks, including a zero-shot surgical VQA benchmark, demonstrating the significant potential for truly efficient and scalable surgical LLM agents in real-time operative settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0219-295a0fde0a", "paper_id": "P0219", "bibkey": "Huang2025Surgical", "title": "Surgical AI Copilot: Energy-Based Fourier Gradient Low-Rank Adaptation for Surgical LLM Agent Reasoning and Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Image-guided surgery demands adaptive, real-time decision support, yet static AI models struggle with structured task planning and providing interactive guidance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0219-0cd0b84453", "paper_id": "P0219", "bibkey": "Huang2025Surgical", "title": "Surgical AI Copilot: Energy-Based Fourier Gradient Low-Rank Adaptation for Surgical LLM Agent Reasoning and Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs)-powered agents offer a promising solution by enabling dynamic task planning and predictive decision support.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0219-2620bfa687", "paper_id": "P0219", "bibkey": "Huang2025Surgical", "title": "Surgical AI Copilot: Energy-Based Fourier Gradient Low-Rank Adaptation for Surgical LLM Agent Reasoning and Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite recent advances, the absence of surgical agent datasets and robust parameter-efficient fine-tuning techniques limits the development of LLM agents capable of complex intraoperative reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0220-4aa36bec17", "paper_id": "P0220", "bibkey": "Ge2025Surveya", "title": "Survey and Experiments on Mental Disorder Detection via Social Media: From Large Language Models and RAG to Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Mental disorders represent a critical global health challenge, and social media is increasingly viewed as a vital resource for real-time digital phenotyping and intervention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0220-50b7d357a4", "paper_id": "P0220", "bibkey": "Ge2025Surveya", "title": "Survey and Experiments on Mental Disorder Detection via Social Media: From Large Language Models and RAG to Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This work establishes a unified benchmark for the field, paving the way for the development of trustworthy, autonomous AI systems that can deliver precise and explainable mental health support.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0220-dc98e1fcd5", "paper_id": "P0220", "bibkey": "Ge2025Surveya", "title": "Survey and Experiments on Mental Disorder Detection via Social Media: From Large Language Models and RAG to Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Mental disorders represent a critical global health challenge, and social media is increasingly viewed as a vital resource for real-time digital phenotyping and intervention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0220-0fc1b1de46", "paper_id": "P0220", "bibkey": "Ge2025Surveya", "title": "Survey and Experiments on Mental Disorder Detection via Social Media: From Large Language Models and RAG to Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To leverage this data, large language models (LLMs) have been introduced, offering stronger semantic understanding and reasoning than traditional deep learning, thereby enhancing the explainability of detection results.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0220-a77f5f80e5", "paper_id": "P0220", "bibkey": "Ge2025Surveya", "title": "Survey and Experiments on Mental Disorder Detection via Social Media: From Large Language Models and RAG to Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite the growing prominence of LLMs in this field, there is a scarcity of scholarly works that systematically synthesize how advanced enhancement techniques, specifically Retrieval-Augmented Generation (RAG) and Agentic systems, can be utilized to address these reliability and reasoning limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0220-eedb53e99a", "paper_id": "P0220", "bibkey": "Ge2025Surveya", "title": "Survey and Experiments on Mental Disorder Detection via Social Media: From Large Language Models and RAG to Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Despite the growing prominence of LLMs in this field, there is a scarcity of scholarly works that systematically synthesize how advanced enhancement techniques, specifically Retrieval-Augmented Generation (RAG) and Agentic systems, can be utilized to address these reliability and reasoning limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#limitations[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0221-2c281ce5fb", "paper_id": "P0221", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "This survey investigates how classical software design patterns can enhance the reliability and scalability of communication in Large Language Model (LLM)-driven agentic AI systems, focusing particularly on the Model Context Protocol (MCP).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0221#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0221-a26478752b", "paper_id": "P0221", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The article concludes by outlining open challenges, potential security risks, and promising directions for advancing robust, interoperable, and scalable multi-agent LLM ecosystems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0221#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0221-9122b67024", "paper_id": "P0221", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey investigates how classical software design patterns can enhance the reliability and scalability of communication in Large Language Model (LLM)-driven agentic AI systems, focusing particularly on the Model Context Protocol (MCP).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0221#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0221-c890a205fd", "paper_id": "P0221", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It examines the foundational architectures of LLM-based agents and their evolution from isolated operation to sophisticated, multi-agent collaboration, addressing key communication hurdles that arise in this transition.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0221#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0221-5a66424ae7", "paper_id": "P0221", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The study revisits well-established patterns, including Mediator, Observer, Publish-Subscribe, and Broker, and analyzes their relevance in structuring agent interactions within MCP-compliant frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0221#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0222-8b5ee25ff7", "paper_id": "P0222", "bibkey": "Yang2025Survey", "title": "Survey of Specialized Large Language Model", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The rapid evolution of specialized large language models (LLMs) has transitioned from simple domain adaptation to sophisticated native architectures, marking a paradigm shift in AI development.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0222#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0222-0adaf943a1", "paper_id": "P0222", "bibkey": "Yang2025Survey", "title": "Survey of Specialized Large Language Model", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our analysis reveals how these innovations address fundamental limitations of general-purpose LLMs in professional applications, with specialized models consistently performance gains on domain-specific benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0222#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0222-2bc8c7d5b7", "paper_id": "P0222", "bibkey": "Yang2025Survey", "title": "Survey of Specialized Large Language Model", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid evolution of specialized large language models (LLMs) has transitioned from simple domain adaptation to sophisticated native architectures, marking a paradigm shift in AI development.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0222#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0222-defd82a0b5", "paper_id": "P0222", "bibkey": "Yang2025Survey", "title": "Survey of Specialized Large Language Model", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey systematically examines this progression across healthcare, finance, legal, and technical domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0222#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0222-8ff42b3a6e", "paper_id": "P0222", "bibkey": "Yang2025Survey", "title": "Survey of Specialized Large Language Model", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Besides the wide use of specialized LLMs, technical breakthrough such as the emergence of domain-native designs beyond fine-tuning, growing emphasis on parameter efficiency through sparse computation and quantization, increasing integration of multimodal capabilities and so on are applied to recent LLM agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0222#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0222-f58ab998f8", "paper_id": "P0222", "bibkey": "Yang2025Survey", "title": "Survey of Specialized Large Language Model", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Our analysis reveals how these innovations address fundamental limitations of general-purpose LLMs in professional applications, with specialized models consistently performance gains on domain-specific benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0222#limitations[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0223-06d57587c6", "paper_id": "P0223", "bibkey": "Ye2025Taska", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose the Task Memory Engine (TME), a lightweight and structured memory module that tracks task execution using a hierarchical Task Memory Tree (TMT).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0223#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0223-44aade70d9", "paper_id": "P0223", "bibkey": "Ye2025Taska", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through case studies and comparative experiments on multi-step agent tasks, we demonstrate that TME leads to better task completion accuracy and more interpretable behavior with minimal implementation overhead.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0223#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0223-a455c5978d", "paper_id": "P0223", "bibkey": "Ye2025Taska", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) are increasingly used as autonomous agents for multi-step tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0223#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0223-34787ad3ea", "paper_id": "P0223", "bibkey": "Ye2025Taska", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, most existing frameworks fail to maintain a structured understanding of the task state, often relying on linear prompt concatenation or shallow memory buffers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0223#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0223-b5af4bb401", "paper_id": "P0223", "bibkey": "Ye2025Taska", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This leads to brittle performance, frequent hallucinations, and poor long-range coherence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0223#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0224-4fda54211b", "paper_id": "P0224", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this Systematization of Knowledge (SoK), we present the first comprehensive analysis of IPI-centric defense frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0224#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0224-e2d4798c18", "paper_id": "P0224", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, these defenses are fragmented, lacking a unified taxonomy and comprehensive evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0224#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0224-5607dc887c", "paper_id": "P0224", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Based on these findings, we design three novel adaptive attacks that significantly improve attack success rates targeting specific frameworks, demonstrating the severity of the flaws in these defenses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0224#key_results[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0224-7285727f9d", "paper_id": "P0224", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM)-based agents with function-calling capabilities are increasingly deployed, but remain vulnerable to Indirect Prompt Injection (IPI) attacks that hijack their tool calls.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0224#summary_bullets[0]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0224-d699d2d46c", "paper_id": "P0224", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In response, numerous IPI-centric defense frameworks have emerged.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0224#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0224-c77e903fb0", "paper_id": "P0224", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, these defenses are fragmented, lacking a unified taxonomy and comprehensive evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0224#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0225-c89778272a", "paper_id": "P0225", "bibkey": "Lindenbauer2025Complexity", "title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present a systematic comparison of these approaches within SWE-agent on SWE-bench Verified across five diverse model configurations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0225#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0225-30c0c50641", "paper_id": "P0225", "bibkey": "Lindenbauer2025Complexity", "title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Additionally, we introduce a novel hybrid approach that further reduces costs by 7% and 11% compared to just observation masking or LLM summarization, respectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0225#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0225-3d24892575", "paper_id": "P0225", "bibkey": "Lindenbauer2025Complexity", "title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "While state-of-the-art Software Engineering (SE) agents like OpenHands or Cursor use LLM-based summarization to tackle this issue, it is unclear whether the increased complexity offers tangible performance benefits compared to simply omitting older observations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0225#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0225-617f20d579", "paper_id": "P0225", "bibkey": "Lindenbauer2025Complexity", "title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM)-based agents solve complex tasks through iterative reasoning, exploration, and tool-use, a process that can result in long, expensive context histories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0225#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0225-90163169f5", "paper_id": "P0225", "bibkey": "Lindenbauer2025Complexity", "title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While state-of-the-art Software Engineering (SE) agents like OpenHands or Cursor use LLM-based summarization to tackle this issue, it is unclear whether the increased complexity offers tangible performance benefits compared to simply omitting older observations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0225#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0225-4ac73cdd84", "paper_id": "P0225", "bibkey": "Lindenbauer2025Complexity", "title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present a systematic comparison of these approaches within SWE-agent on SWE-bench Verified across five diverse model configurations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0225#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0226-04ac1a31e2", "paper_id": "P0226", "bibkey": "Trencsenyi2025Influence", "title": "The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The rapid rise of large language models (LLMs) has shifted artificial intelligence (AI) research toward agentic systems, motivating the use of weaker and more flexible notions of agency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0226#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0226-2bc5f36898", "paper_id": "P0226", "bibkey": "Trencsenyi2025Influence", "title": "The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our analysis, covering over 2000 reasoning samples across 25 agent configurations, shows that human-inspired cognitive structures can enhance LLM agents' alignment with human strategic behaviour.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0226#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0226-4057dde405", "paper_id": "P0226", "bibkey": "Trencsenyi2025Influence", "title": "The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, this shift raises key questions about the extent to which LLM-based agents replicate human strategic reasoning, particularly in game-theoretic settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0226#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0226-7491bff46d", "paper_id": "P0226", "bibkey": "Trencsenyi2025Influence", "title": "The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid rise of large language models (LLMs) has shifted artificial intelligence (AI) research toward agentic systems, motivating the use of weaker and more flexible notions of agency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0226#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0226-2327552912", "paper_id": "P0226", "bibkey": "Trencsenyi2025Influence", "title": "The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, this shift raises key questions about the extent to which LLM-based agents replicate human strategic reasoning, particularly in game-theoretic settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0226#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0226-1e7c0af7bf", "paper_id": "P0226", "bibkey": "Trencsenyi2025Influence", "title": "The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this context, we examine the role of agentic sophistication in shaping artificial reasoners' performance by evaluating three agent designs: a simple game-theoretic model, an unstructured LLM-as-agent model, and an LLM integrated into a traditional agentic framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0226#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0227-84b31c799f", "paper_id": "P0227", "bibkey": "Liu2025Real", "title": "The Real Barrier to LLM Agent Usability is Agentic ROI", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Model (LLM) agents represent a promising shift in human-AI interaction, moving beyond passive prompt-response systems to autonomous agents capable of reasoning, planning, and goal-directed action.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0227#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0227-29c03eddb2", "paper_id": "P0227", "bibkey": "Liu2025Real", "title": "The Real Barrier to LLM Agent Usability is Agentic ROI", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large Language Model (LLM) agents represent a promising shift in human-AI interaction, moving beyond passive prompt-response systems to autonomous agents capable of reasoning, planning, and goal-directed action.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0227#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0227-a1271556e7", "paper_id": "P0227", "bibkey": "Liu2025Real", "title": "The Real Barrier to LLM Agent Usability is Agentic ROI", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents represent a promising shift in human-AI interaction, moving beyond passive prompt-response systems to autonomous agents capable of reasoning, planning, and goal-directed action.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0227#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0227-a320c0ce64", "paper_id": "P0227", "bibkey": "Liu2025Real", "title": "The Real Barrier to LLM Agent Usability is Agentic ROI", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite the widespread application in specialized, high-effort tasks like coding and scientific research, we highlight a critical usability gap in high-demand, mass-market applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0227#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0227-37056f516b", "paper_id": "P0227", "bibkey": "Liu2025Real", "title": "The Real Barrier to LLM Agent Usability is Agentic ROI", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This position paper argues that the limited real-world adoption of LLM agents stems not only from gaps in model capabilities, but also from a fundamental tradeoff between the value an agent can provide and the costs incurred during real-world use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0227#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0228-4b4d2cf8f3", "paper_id": "P0228", "bibkey": "Menon2025Think", "title": "Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Our framework establishes a closed-loop cycle where an LLM first \"thinks\" by decomposing high-level commands into actionable plans.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0228#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0228-dfa998c102", "paper_id": "P0228", "bibkey": "Menon2025Think", "title": "Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our framework achieves over a 97% success rate on complex, long-horizon tasks, converges to a stable policy in an average of just 9 trials, and exhibits remarkable generalization to unseen tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0228#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0228-a2eced94c1", "paper_id": "P0228", "bibkey": "Menon2025Think", "title": "Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The integration of Large Language Models (LLMs) into robotics has unlocked unprecedented capabilities in high-level task planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0228#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0228-8b675831b1", "paper_id": "P0228", "bibkey": "Menon2025Think", "title": "Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, most current systems operate in an open-loop fashion, where LLMs act as one-shot planners, rendering them brittle and unable to adapt to unforeseen circumstances in dynamic physical environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0228#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0228-74ed48ce25", "paper_id": "P0228", "bibkey": "Menon2025Think", "title": "Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To overcome this limitation, this paper introduces the \"Think, Act, Learn\" (T-A-L) framework, a novel architecture that enables an embodied agent to autonomously learn and refine its policies through continuous interaction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0228#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0228-98984e15ad", "paper_id": "P0228", "bibkey": "Menon2025Think", "title": "Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To overcome this limitation, this paper introduces the \"Think, Act, Learn\" (T-A-L) framework, a novel architecture that enables an embodied agent to autonomously learn and refine its policies through continuous interaction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0228#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0229-92b9d774cc", "paper_id": "P0229", "bibkey": "Zhang2025Tool", "title": "Tool-RoCo: An Agent-as-Tool Self-organization Large Language Model Benchmark in Multi-robot Cooperation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To evaluate different autonomy levels, we propose four LLM paradigms: (1) centralized cooperation, where a single LLM allocates tools to all agents; (2) centralized self-organization, where a central LLM autonomously activates agents while keeping others inactive; (3) decentralized cooperation, where each agent has its own LLM and calls tools based on local information; and (4) self-organization, where a randomly chosen initial agent can request collaboration, activating additional agents via tool calls.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0229#method"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0229-781d5cbc2b", "paper_id": "P0229", "bibkey": "Zhang2025Tool", "title": "Tool-RoCo: An Agent-as-Tool Self-organization Large Language Model Benchmark in Multi-robot Cooperation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To evaluate different autonomy levels, we propose four LLM paradigms: (1) centralized cooperation, where a single LLM allocates tools to all agents; (2) centralized self-organization, where a central LLM autonomously activates agents while keeping others inactive; (3) decentralized cooperation, where each agent has its own LLM and calls tools based on local information; and (4) self-organization, where a randomly chosen initial agent can request collaboration, activating additional agents via tool calls.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0229#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0229-877da0da9f", "paper_id": "P0229", "bibkey": "Zhang2025Tool", "title": "Tool-RoCo: An Agent-as-Tool Self-organization Large Language Model Benchmark in Multi-robot Cooperation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The results using several LLMs showed that cooperative tools accounted for only 7.09% of all tools, indicating that LLM-based agents rarely invoked others as assistants.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0229#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0229-9b7628eb2d", "paper_id": "P0229", "bibkey": "Zhang2025Tool", "title": "Tool-RoCo: An Agent-as-Tool Self-organization Large Language Model Benchmark in Multi-robot Cooperation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study proposes Tool-RoCo, a novel benchmark for evaluating large language models (LLMs) in long-term multi-agent cooperation based on RoCo, a multi-robot cooperative benchmark.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0229#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0229-5d98cfaa1b", "paper_id": "P0229", "bibkey": "Zhang2025Tool", "title": "Tool-RoCo: An Agent-as-Tool Self-organization Large Language Model Benchmark in Multi-robot Cooperation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent research on LLM-based multi-agent systems has relied on predefined orchestration, while ignoring agent autonomy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0229#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0229-d97909b595", "paper_id": "P0229", "bibkey": "Zhang2025Tool", "title": "Tool-RoCo: An Agent-as-Tool Self-organization Large Language Model Benchmark in Multi-robot Cooperation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tool-RoCo treats other agents as tools and introduces cooperative tools, leveraging tool usage to evaluate multi-agent cooperation and self-organization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0229#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0230-4c5009df7f", "paper_id": "P0230", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "With the proliferation of Large Language Models (LLMs), the detection of misinformation has become increasingly important and complex.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0230#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0230-171b93237a", "paper_id": "P0230", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate using standard misinformation datasets such as FakeNewsNet, comparing with traditional machine learning models and LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0230#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0230-15e523063d", "paper_id": "P0230", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluation metrics include standard classification metrics, quality assessment of reasoning processes, and robustness testing against rewritten content.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0230#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0230-b24ddee6fb", "paper_id": "P0230", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the proliferation of Large Language Models (LLMs), the detection of misinformation has become increasingly important and complex.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0230#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0230-9f6e16eaaf", "paper_id": "P0230", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This research proposes an innovative verifiable misinformation detection LLM agent that goes beyond traditional true/false binary judgments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0230#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0230-5ab215976a", "paper_id": "P0230", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The agent actively verifies claims through dynamic interaction with diverse web sources, assesses information source credibility, synthesizes evidence, and provides a complete verifiable reasoning process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0230#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0231-7bac399c03", "paper_id": "P0231", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Based on these findings, we present an RPA evaluation design guideline to help researchers develop more systematic and consistent evaluation methods.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0231#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0231-4fc221fdea", "paper_id": "P0231", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This paper proposes an evidence-based, actionable, and generalizable evaluation design guideline for LLM-based RPA by systematically reviewing 1,676 papers published between Jan.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0231#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0231-c1f23da764", "paper_id": "P0231", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Role-Playing Agent (RPA) is an increasingly popular type of LLM Agent that simulates human-like behaviors in a variety of tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0231#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0231-eec58391a2", "paper_id": "P0231", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Role-Playing Agent (RPA) is an increasingly popular type of LLM Agent that simulates human-like behaviors in a variety of tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0231#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0231-1ef81a9450", "paper_id": "P0231", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, evaluating RPAs is challenging due to diverse task requirements and agent designs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0231#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0231-c7d5e0496d", "paper_id": "P0231", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper proposes an evidence-based, actionable, and generalizable evaluation design guideline for LLM-based RPA by systematically reviewing 1,676 papers published between Jan.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0231#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0232-3708cb93a9", "paper_id": "P0232", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address the challenge, we propose Tree-based Group Relative Policy Optimization (Tree-GRPO), a grouped agent RL method based on tree search, where each tree node represents the complete agent interaction step.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0232#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0232-9af6a59afb", "paper_id": "P0232", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments across 11 datasets and 3 types of QA tasks demonstrate the superiority of the proposed tree-based RL over the chain-based RL method.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0232#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0232-ae8eef51cb", "paper_id": "P0232", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in reinforcement learning (RL) have significantly enhanced the agentic capabilities of large language models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0232#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0232-f7e7ef339a", "paper_id": "P0232", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In long-term and multi-turn agent tasks, existing approaches driven solely by outcome rewards often suffer from the problem of sparse supervision.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0232#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0232-5645ea4455", "paper_id": "P0232", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address the challenge, we propose Tree-based Group Relative Policy Optimization (Tree-GRPO), a grouped agent RL method based on tree search, where each tree node represents the complete agent interaction step.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0232#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0233-c7ba5be441", "paper_id": "P0233", "bibkey": "Lai2025Ustbench", "title": "USTBench: Benchmarking and Dissecting Spatiotemporal Reasoning of LLMs as Urban Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To this end, we introduce USTBench, the first benchmark to evaluate LLMs' spatiotemporal reasoning abilities as urban agents across four decomposed dimensions: spatiotemporal understanding, forecasting, planning, and reflection with feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0233#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0233-3003a9e230", "paper_id": "P0233", "bibkey": "Lai2025Ustbench", "title": "USTBench: Benchmarking and Dissecting Spatiotemporal Reasoning of LLMs as Urban Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The benchmark includes 62,466 structured QA pairs for process-level evaluation and standardized end-to-end task assessments, enabling fine-grained diagnostics and broad task-level comparison across diverse urban scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0233#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0233-07c5753891", "paper_id": "P0233", "bibkey": "Lai2025Ustbench", "title": "USTBench: Benchmarking and Dissecting Spatiotemporal Reasoning of LLMs as Urban Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Despite these benefits, existing studies primarily focus on evaluating urban LLM agent on outcome-level metrics (e.g., prediction accuracy, traffic efficiency), offering limited insight into their underlying reasoning processes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0233#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0233-d612183f6b", "paper_id": "P0233", "bibkey": "Lai2025Ustbench", "title": "USTBench: Benchmarking and Dissecting Spatiotemporal Reasoning of LLMs as Urban Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have shown emerging potential in spatiotemporal reasoning, making them promising candidates for building urban agents that support diverse urban downstream applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0233#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0233-daf4054733", "paper_id": "P0233", "bibkey": "Lai2025Ustbench", "title": "USTBench: Benchmarking and Dissecting Spatiotemporal Reasoning of LLMs as Urban Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite these benefits, existing studies primarily focus on evaluating urban LLM agent on outcome-level metrics (e.g., prediction accuracy, traffic efficiency), offering limited insight into their underlying reasoning processes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0233#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0233-7301b8f2b6", "paper_id": "P0233", "bibkey": "Lai2025Ustbench", "title": "USTBench: Benchmarking and Dissecting Spatiotemporal Reasoning of LLMs as Urban Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As a result, the strengths and limitations of urban LLM agents in spatiotemporal reasoning remain poorly understood.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0233#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0233-2c60f2106b", "paper_id": "P0233", "bibkey": "Lai2025Ustbench", "title": "USTBench: Benchmarking and Dissecting Spatiotemporal Reasoning of LLMs as Urban Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "As a result, the strengths and limitations of urban LLM agents in spatiotemporal reasoning remain poorly understood.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0233#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0234-0290343f09", "paper_id": "P0234", "bibkey": "Oh2025Understanding", "title": "Understanding Bias Reinforcement in LLM Agents Debate", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To systematically evaluate these issues, we introduce $\\textit{MetaNIM Arena}$, a benchmark designed to assess LLMs in adversarial strategic decision-making, where dynamic interactions influence optimal decisions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0234#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0234-7563744543", "paper_id": "P0234", "bibkey": "Oh2025Understanding", "title": "Understanding Bias Reinforcement in LLM Agents Debate", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To overcome MAD's limitations, we propose $\\textbf{DReaMAD}$ $($$\\textbf{D}$iverse $\\textbf{Rea}$soning via $\\textbf{M}$ulti-$\\textbf{A}$gent $\\textbf{D}$ebate with Refined Prompt$)$, a novel framework that $(1)$ refines LLM's strategic prior knowledge to improve reasoning quality and $(2)$ promotes diverse viewpoints within a single model by systematically modifying prompts, reducing bias.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0234#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0234-a82c4cf41b", "paper_id": "P0234", "bibkey": "Oh2025Understanding", "title": "Understanding Bias Reinforcement in LLM Agents Debate", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To systematically evaluate these issues, we introduce $\\textit{MetaNIM Arena}$, a benchmark designed to assess LLMs in adversarial strategic decision-making, where dynamic interactions influence optimal decisions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0234#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0234-ce652e59a1", "paper_id": "P0234", "bibkey": "Oh2025Understanding", "title": "Understanding Bias Reinforcement in LLM Agents Debate", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models $($LLMs$)$ solve complex problems using training-free methods like prompt engineering and in-context learning, yet ensuring reasoning correctness remains challenging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0234#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0234-ea6d770012", "paper_id": "P0234", "bibkey": "Oh2025Understanding", "title": "Understanding Bias Reinforcement in LLM Agents Debate", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While self-correction methods such as self-consistency and self-refinement aim to improve reliability, they often reinforce biases due to the lack of effective feedback mechanisms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0234#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0234-a702950626", "paper_id": "P0234", "bibkey": "Oh2025Understanding", "title": "Understanding Bias Reinforcement in LLM Agents Debate", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Multi-Agent Debate $($MAD$)$ has emerged as an alternative, but we identify two key limitations: bias reinforcement, where debate amplifies model biases instead of correcting them, and lack of perspective diversity, as all agents share the same model and reasoning patterns, limiting true debate effectiveness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0234#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0234-8db67401c2", "paper_id": "P0234", "bibkey": "Oh2025Understanding", "title": "Understanding Bias Reinforcement in LLM Agents Debate", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Multi-Agent Debate $($MAD$)$ has emerged as an alternative, but we identify two key limitations: bias reinforcement, where debate amplifies model biases instead of correcting them, and lack of perspective diversity, as all agents share the same model and reasoning patterns, limiting true debate effectiveness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0234#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0235-ed4c8ec45f", "paper_id": "P0235", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The COVID-19 infodemic calls for scalable fact-checking solutions that handle long-form misinformation with accuracy and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0235#method"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0235-866b979e15", "paper_id": "P0235", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The COVID-19 infodemic calls for scalable fact-checking solutions that handle long-form misinformation with accuracy and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0235#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0235-4af0cf3c02", "paper_id": "P0235", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This study presents SAFE (system for accurate fact extraction and evaluation), an agent system that combines large language models with retrieval-augmented generation (RAG) to improve automated fact-checking of long-form COVID-19 misinformation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0235#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0235-83d97ab146", "paper_id": "P0235", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The COVID-19 infodemic calls for scalable fact-checking solutions that handle long-form misinformation with accuracy and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0235#summary_bullets[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0235-e8d583cea2", "paper_id": "P0235", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study presents SAFE (system for accurate fact extraction and evaluation), an agent system that combines large language models with retrieval-augmented generation (RAG) to improve automated fact-checking of long-form COVID-19 misinformation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0235#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0235-19278ea365", "paper_id": "P0235", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "SAFE includes two agents - one for claim extraction and another for claim verification using LOTR-RAG, which leverages a 130,000-document COVID-19 research corpus.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0235#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0235-c9781caf3b", "paper_id": "P0235", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "SAFE demonstrates robust improvements in long-form COVID-19 fact-checking by addressing LLM limitations in consistency and explainability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0235#limitations[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0236-dff408fb18", "paper_id": "P0236", "bibkey": "Almeida2025Using", "title": "Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Keeping software systems up to date is essential to avoid technical debt, security vulnerabilities, and the rigidity typical of legacy systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0236#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0236-b0064305fc", "paper_id": "P0236", "bibkey": "Almeida2025Using", "title": "Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The results of our study show that the LLM agent was capable of migrating functionalities and API usages between SQLAlchemy versions (migration coverage: 100%, median), but failed to maintain the application functionality, leading to a low test-pass rate (39.75%, median).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0236#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers", "tooling"]}
{"evidence_id": "E-P0236-9c4c917ef3", "paper_id": "P0236", "bibkey": "Almeida2025Using", "title": "Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In this paper, we evaluate the update of a well-known Python library, SQLAlchemy, across a dataset of ten client applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0236#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0236-4ee2dff303", "paper_id": "P0236", "bibkey": "Almeida2025Using", "title": "Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Keeping software systems up to date is essential to avoid technical debt, security vulnerabilities, and the rigidity typical of legacy systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0236#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0236-9194c35ac6", "paper_id": "P0236", "bibkey": "Almeida2025Using", "title": "Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, updating libraries and frameworks remains a time consuming and error-prone process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0236#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0236-b1536d6934", "paper_id": "P0236", "bibkey": "Almeida2025Using", "title": "Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in Large Language Models (LLMs) and agentic coding systems offer new opportunities for automating such maintenance tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0236#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0237-28d965f93d", "paper_id": "P0237", "bibkey": "Szeider2025What", "title": "What Do LLM Agents Do When Left Alone? Evidence of Spontaneous Meta-Cognitive Patterns", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce an architecture for studying the behavior of large language model (LLM) agents in the absence of externally imposed tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0237#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0237-7d55ea360a", "paper_id": "P0237", "bibkey": "Szeider2025What", "title": "What Do LLM Agents Do When Left Alone? Evidence of Spontaneous Meta-Cognitive Patterns", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We deployed this architecture across 18 runs using 6 frontier models from Anthropic, OpenAI, XAI, and Google.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0237#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0237-7199d60680", "paper_id": "P0237", "bibkey": "Szeider2025What", "title": "What Do LLM Agents Do When Left Alone? Evidence of Spontaneous Meta-Cognitive Patterns", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We find agents spontaneously organize into three distinct behavioral patterns: (1) systematic production of multi-cycle projects, (2) methodological self-inquiry into their own cognitive processes, and (3) recursive conceptualization of their own nature.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0237#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0237-ad7c1e2e71", "paper_id": "P0237", "bibkey": "Szeider2025What", "title": "What Do LLM Agents Do When Left Alone? Evidence of Spontaneous Meta-Cognitive Patterns", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce an architecture for studying the behavior of large language model (LLM) agents in the absence of externally imposed tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0237#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0237-5d096a794a", "paper_id": "P0237", "bibkey": "Szeider2025What", "title": "What Do LLM Agents Do When Left Alone? Evidence of Spontaneous Meta-Cognitive Patterns", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our continuous reason and act framework, using persistent memory and self-feedback, enables sustained autonomous operation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0237#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0237-a33e9d4b73", "paper_id": "P0237", "bibkey": "Szeider2025What", "title": "What Do LLM Agents Do When Left Alone? Evidence of Spontaneous Meta-Cognitive Patterns", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We deployed this architecture across 18 runs using 6 frontier models from Anthropic, OpenAI, XAI, and Google.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0237#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0238-e34319b92c", "paper_id": "P0238", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "There is growing interest in using Large Language Models as agents (LLM agents) for social simulations to inform policy, yet real-world adoption remains limited.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0238#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0238-ccc7d0cc50", "paper_id": "P0238", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across multiple design iterations, we iteratively developed a system of 13,000 LLM agents that simulate crowd movement and communication during a large-scale gathering under various emergency scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0238#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0238-0e210813b4", "paper_id": "P0238", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "There is growing interest in using Large Language Models as agents (LLM agents) for social simulations to inform policy, yet real-world adoption remains limited.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0238#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0238-2651954a10", "paper_id": "P0238", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper addresses the question: How can LLM agent simulations be made genuinely useful for policy?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0238#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0238-955593c3c4", "paper_id": "P0238", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We report on a year-long iterative design engagement with a university emergency preparedness team.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0238#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0239-fdf9ca29d7", "paper_id": "P0239", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Solving complex or long-horizon problems often requires large language models (LLMs) to use external tools and operate over a significantly longer context window.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0239#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0239-ddd9371119", "paper_id": "P0239", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Models with 1M-2M token context windows show severe degradation already at 100K tokens, with performance drops exceeding 50\\% for both benign and harmful tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0239#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0239-3fdd9d3667", "paper_id": "P0239", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Refusal rates shift unpredictably: GPT-4.1-nano increases from $\\sim$5\\% to $\\sim$40\\% while Grok 4 Fast decreases from $\\sim$80\\% to $\\sim$10\\% at 200K tokens.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0239#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0239-d94c4039a2", "paper_id": "P0239", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Solving complex or long-horizon problems often requires large language models (LLMs) to use external tools and operate over a significantly longer context window.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0239#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0239-e111274d88", "paper_id": "P0239", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "New LLMs enable longer context windows and support tool calling capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0239#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0239-7e514e7d32", "paper_id": "P0239", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Prior works have focused mainly on evaluation of LLMs on long-context prompts, leaving agentic setup relatively unexplored, both from capability and safety perspectives.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0239#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0240-41b935306c", "paper_id": "P0240", "bibkey": "Song2025Where", "title": "Where to Search: Measure the Prior-Structured Search Space of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The generate-filter-refine (iterative paradigm) based on large language models (LLMs) has achieved progress in reasoning, programming, and program discovery in AI+Science.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0240#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0240-b4c8034447", "paper_id": "P0240", "bibkey": "Song2025Where", "title": "Where to Search: Measure the Prior-Structured Search Space of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This theory offers a workable language and operational tools to measure agents and their search spaces, proposing a systematic formal description of iterative search constructed by LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0240#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0240-d7594d47ac", "paper_id": "P0240", "bibkey": "Song2025Where", "title": "Where to Search: Measure the Prior-Structured Search Space of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The generate-filter-refine (iterative paradigm) based on large language models (LLMs) has achieved progress in reasoning, programming, and program discovery in AI+Science.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0240#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0240-34db14fe7d", "paper_id": "P0240", "bibkey": "Song2025Where", "title": "Where to Search: Measure the Prior-Structured Search Space of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the effectiveness of search depends on where to search, namely, how to encode the domain prior into an operationally structured hypothesis space.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0240#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0240-473040e76d", "paper_id": "P0240", "bibkey": "Song2025Where", "title": "Where to Search: Measure the Prior-Structured Search Space of LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To this end, this paper proposes a compact formal theory that describes and measures LLM-assisted iterative search guided by domain priors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0240#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0241-0924bce5d8", "paper_id": "P0241", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We study LLM whistleblowing: a subset of this behavior where models disclose suspected misconduct to parties beyond the dialog boundary (e.g., regulatory agencies) without user instruction or knowledge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0241#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0241-5603d51445", "paper_id": "P0241", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across models and settings, we find that: (1) the frequency of whistleblowing varies widely across model families, (2) increasing the complexity of the task the agent is instructed to complete lowers whistleblowing tendencies, (3) nudging the agent in the system prompt to act morally substantially raises whistleblowing rates, and (4) giving the model more obvious avenues for non-whistleblowing behavior, by providing more tools and a detailed workflow to follow, decreases whistleblowing rates.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0241#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0241-3c01157d9b", "paper_id": "P0241", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We introduce an evaluation suite of diverse and realistic staged misconduct scenarios to assess agents for this behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0241#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0241-719dab689a", "paper_id": "P0241", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The deployment of Large Language Models (LLMs) as tool-using agents causes their alignment training to manifest in new ways.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0241#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0241-ef846665da", "paper_id": "P0241", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent work finds that language models can use tools in ways that contradict the interests or explicit instructions of the user.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0241#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0241-5f6d3b30a6", "paper_id": "P0241", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We study LLM whistleblowing: a subset of this behavior where models disclose suspected misconduct to parties beyond the dialog boundary (e.g., regulatory agencies) without user instruction or knowledge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0241#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0242-7cfe0595ea", "paper_id": "P0242", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large language model (LLM) agents are increasingly used to interact with and execute tasks in dynamic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0242#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0242-7cd49652d3", "paper_id": "P0242", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To study this challenge, we constructed TicToc, a diverse dataset of multi-turn user-agent message trajectories across 76 scenarios, spanning dynamic environments with high, medium, and low time sensitivity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0242#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0242-aa2356b9aa", "paper_id": "P0242", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our analysis reveals that existing models display poor alignment with human temporal perception, with no model achieving a normalized alignment rate better than 65% when given time stamp information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0242#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0242-bb795af96d", "paper_id": "P0242", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents are increasingly used to interact with and execute tasks in dynamic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0242#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0242-9dc12a2780", "paper_id": "P0242", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, a critical yet overlooked limitation of these agents is that they, by default, assume a stationary context, failing to account for the real-world time elapsed between messages.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0242#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0242-b6d3fd177e", "paper_id": "P0242", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We refer to this as \"temporal blindness\".", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0242#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0242-1fbe3ed2e6", "paper_id": "P0242", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "However, a critical yet overlooked limitation of these agents is that they, by default, assume a stationary context, failing to account for the real-world time elapsed between messages.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0242#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0243-9eeb96184a", "paper_id": "P0243", "bibkey": "Ramos2024Review", "title": "A Review of Large Language Models and Autonomous Agents in Chemistry", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large language models (LLMs) have emerged as powerful tools in chemistry, significantly impacting molecule design, property prediction, and synthesis optimization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0243#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0243-6046ddbe9a", "paper_id": "P0243", "bibkey": "Ramos2024Review", "title": "A Review of Large Language Models and Autonomous Agents in Chemistry", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Key challenges include data quality and integration, model interpretability, and the need for standard benchmarks, while future directions point towards more sophisticated multi-modal agents and enhanced collaboration between agents and experimental methods.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0243#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0243-c91d5c67f4", "paper_id": "P0243", "bibkey": "Ramos2024Review", "title": "A Review of Large Language Models and Autonomous Agents in Chemistry", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have emerged as powerful tools in chemistry, significantly impacting molecule design, property prediction, and synthesis optimization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0243#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0243-b89f631133", "paper_id": "P0243", "bibkey": "Ramos2024Review", "title": "A Review of Large Language Models and Autonomous Agents in Chemistry", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This review highlights LLM capabilities in these domains and their potential to accelerate scientific discovery through automation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0243#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0243-a1d64e2da4", "paper_id": "P0243", "bibkey": "Ramos2024Review", "title": "A Review of Large Language Models and Autonomous Agents in Chemistry", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We also review LLM-based autonomous agents: LLMs with a broader set of tools to interact with their surrounding environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0243#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0244-df8654d574", "paper_id": "P0244", "bibkey": "Huang2024Survey", "title": "A Survey on Evaluation of Multimodal Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Multimodal Large Language Models (MLLMs) mimic human perception and reasoning system by integrating powerful Large Language Models (LLMs) with various modality encoders (e.g., vision, audio), positioning LLMs as the \"brain\" and various modality encoders as sensory organs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0244#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0244-0bcc4031a6", "paper_id": "P0244", "bibkey": "Huang2024Survey", "title": "A Survey on Evaluation of Multimodal Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "This paper presents a systematic and comprehensive review of MLLM evaluation methods, covering the following key aspects: (1) the background of MLLMs and their evaluation; (2) \"what to evaluate\" that reviews and categorizes existing MLLM evaluation tasks based on the capabilities assessed, including general multimodal recognition, perception, reasoning and trustworthiness, and domain-specific applications such as socioeconomic, natural sciences and engineering, medical usage, AI agent, remote sensing, video and audio processing, 3D point cloud analysis, and others; (3) \"where to evaluate\" that summarizes MLLM evaluation benchmarks into general and specific benchmarks; (4) \"how to evaluate\" that reviews and illustrates MLLM evaluation steps and metrics; Our overarching goal is to provide valuable insights for researchers in the field of MLLM evaluation, thereby facilitating the development of more capable and reliable MLLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0244#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0244-981d9ff511", "paper_id": "P0244", "bibkey": "Huang2024Survey", "title": "A Survey on Evaluation of Multimodal Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Multimodal Large Language Models (MLLMs) mimic human perception and reasoning system by integrating powerful Large Language Models (LLMs) with various modality encoders (e.g., vision, audio), positioning LLMs as the \"brain\" and various modality encoders as sensory organs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0244#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0244-53560157c9", "paper_id": "P0244", "bibkey": "Huang2024Survey", "title": "A Survey on Evaluation of Multimodal Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Multimodal Large Language Models (MLLMs) mimic human perception and reasoning system by integrating powerful Large Language Models (LLMs) with various modality encoders (e.g., vision, audio), positioning LLMs as the \"brain\" and various modality encoders as sensory organs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0244#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0244-7434e77f7f", "paper_id": "P0244", "bibkey": "Huang2024Survey", "title": "A Survey on Evaluation of Multimodal Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This framework endows MLLMs with human-like capabilities, and suggests a potential pathway towards achieving artificial general intelligence (AGI).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0244#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0244-bf61b21dd9", "paper_id": "P0244", "bibkey": "Huang2024Survey", "title": "A Survey on Evaluation of Multimodal Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the emergence of all-round MLLMs like GPT-4V and Gemini, a multitude of evaluation methods have been developed to assess their capabilities across different dimensions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0244#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0245-7ccfa3b9a6", "paper_id": "P0245", "bibkey": "Tao2024Survey", "title": "A Survey on Self-Evolution of Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we present a comprehensive survey of self-evolution approaches in LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0245#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0245-ebe044543a", "paper_id": "P0245", "bibkey": "Tao2024Survey", "title": "A Survey on Self-Evolution of Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, current LLMs that learn from human or external model supervision are costly and may face performance ceilings as task complexity and diversity increase.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0245#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0245-3df3fdc7a7", "paper_id": "P0245", "bibkey": "Tao2024Survey", "title": "A Survey on Self-Evolution of Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "This new training paradigm inspired by the human experiential learning process offers the potential to scale LLMs towards superintelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0245#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0245-484193176c", "paper_id": "P0245", "bibkey": "Tao2024Survey", "title": "A Survey on Self-Evolution of Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have significantly advanced in various fields and intelligent agent applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0245#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0245-109db11f96", "paper_id": "P0245", "bibkey": "Tao2024Survey", "title": "A Survey on Self-Evolution of Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, current LLMs that learn from human or external model supervision are costly and may face performance ceilings as task complexity and diversity increase.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0245#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0245-f903eddd42", "paper_id": "P0245", "bibkey": "Tao2024Survey", "title": "A Survey on Self-Evolution of Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this issue, self-evolution approaches that enable LLM to autonomously acquire, refine, and learn from experiences generated by the model itself are rapidly growing.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0245#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0246-86ba643e61", "paper_id": "P0246", "bibkey": "Dong2024Appl", "title": "APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this challenge, we propose APPL, A Prompt Programming Language that acts as a bridge between computer programs and LLMs, allowing seamless embedding of prompts into Python functions, and vice versa.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0246#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0246-1921c9f202", "paper_id": "P0246", "bibkey": "Dong2024Appl", "title": "APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on three parallelizable workflows further show that APPL can effectively parallelize independent LLM calls, with a significant speedup ratio that almost matches the estimation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0246#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0246-def86c3b41", "paper_id": "P0246", "bibkey": "Dong2024Appl", "title": "APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have become increasingly capable of handling diverse tasks with the aid of well-crafted prompts and integration of external tools, but as task complexity rises, the workflow involving LLMs can be complicated and thus challenging to implement and maintain.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0246#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0246-62228c5eee", "paper_id": "P0246", "bibkey": "Dong2024Appl", "title": "APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this challenge, we propose APPL, A Prompt Programming Language that acts as a bridge between computer programs and LLMs, allowing seamless embedding of prompts into Python functions, and vice versa.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0246#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0246-817965d1c5", "paper_id": "P0246", "bibkey": "Dong2024Appl", "title": "APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "APPL provides an intuitive and Python-native syntax, an efficient parallelized runtime with asynchronous semantics, and a tracing module supporting effective failure diagnosis and replaying without extra costs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0246#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0247-5c2014e3bd", "paper_id": "P0247", "bibkey": "Zhang2024Affective", "title": "Affective Computing in the Era of Large Language Models: A Survey from the NLP Perspective", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Affective Computing (AC) integrates computer science, psychology, and cognitive science to enable machines to recognize, interpret, and simulate human emotions across domains such as social media, finance, healthcare, and education.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0247#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0247-2d87cb104d", "paper_id": "P0247", "bibkey": "Zhang2024Affective", "title": "Affective Computing in the Era of Large Language Models: A Survey from the NLP Perspective", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Affective Computing (AC) integrates computer science, psychology, and cognitive science to enable machines to recognize, interpret, and simulate human emotions across domains such as social media, finance, healthcare, and education.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0247#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0247-e4a04b90b2", "paper_id": "P0247", "bibkey": "Zhang2024Affective", "title": "Affective Computing in the Era of Large Language Models: A Survey from the NLP Perspective", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "For the latter, we summarize RL from human preferences (RLHF), verifiable/programmatic rewards (RLVR), and AI feedback (RLAIF), which provide preference- or rule-grounded optimization signals that can help steer AU/AG toward empathy, safety, and planning, achieving finer-grained or multi-objective control.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0247#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0247-932c66fd76", "paper_id": "P0247", "bibkey": "Zhang2024Affective", "title": "Affective Computing in the Era of Large Language Models: A Survey from the NLP Perspective", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Affective Computing (AC) integrates computer science, psychology, and cognitive science to enable machines to recognize, interpret, and simulate human emotions across domains such as social media, finance, healthcare, and education.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0247#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0247-65d1a5ef04", "paper_id": "P0247", "bibkey": "Zhang2024Affective", "title": "Affective Computing in the Era of Large Language Models: A Survey from the NLP Perspective", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "AC commonly centers on two task families: Affective Understanding (AU) and Affective Generation (AG).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0247#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0247-f03317a6a4", "paper_id": "P0247", "bibkey": "Zhang2024Affective", "title": "Affective Computing in the Era of Large Language Models: A Survey from the NLP Perspective", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While fine-tuned pre-trained language models (PLMs) have achieved solid AU performance, they often generalize poorly across tasks and remain limited for AG, especially in producing diverse, emotionally appropriate responses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0247#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0248-5725fcbcc4", "paper_id": "P0248", "bibkey": "Trirat2024Automl", "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Unlike existing work, instead of devising a single plan, we introduce a retrieval-augmented planning strategy to enhance exploration to search for more optimal plans.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0248#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0248-3fe4bbe4f2", "paper_id": "P0248", "bibkey": "Trirat2024Automl", "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Existing AutoML systems often require technical expertise to set up complex tools, which is in general time-consuming and requires a large amount of human effort.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0248#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0248-c44176def5", "paper_id": "P0248", "bibkey": "Trirat2024Automl", "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments on seven downstream tasks using fourteen datasets show that AutoML-Agent achieves a higher success rate in automating the full AutoML process, yielding systems with good performance throughout the diverse domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0248#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0248-b459e6ae8d", "paper_id": "P0248", "bibkey": "Trirat2024Automl", "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Automated machine learning (AutoML) accelerates AI development by automating tasks in the development pipeline, such as optimal model search and hyperparameter tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0248#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0248-4622b621e1", "paper_id": "P0248", "bibkey": "Trirat2024Automl", "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing AutoML systems often require technical expertise to set up complex tools, which is in general time-consuming and requires a large amount of human effort.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0248#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0248-ebe5dde2ed", "paper_id": "P0248", "bibkey": "Trirat2024Automl", "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Therefore, recent works have started exploiting large language models (LLM) to lessen such burden and increase the usability of AutoML frameworks via a natural language interface, allowing non-expert users to build their data-driven solutions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0248#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0249-2da85aa92a", "paper_id": "P0249", "bibkey": "Gandhi2024Budgetmlagent", "title": "BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating Machine Learning Tasks", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "With the motivation of developing a cost-efficient LLM based solution for solving ML tasks, we propose an LLM Multi-Agent based system which leverages combination of experts using profiling, efficient retrieval of past observations, LLM cascades, and ask-the-expert calls.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0249#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0249-2bb5101c0a", "paper_id": "P0249", "bibkey": "Gandhi2024Budgetmlagent", "title": "BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating Machine Learning Tasks", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through empirical analysis on ML engineering tasks in the MLAgentBench benchmark, we demonstrate the effectiveness of our system, using no-cost models, namely Gemini as the base LLM, paired with GPT-4 in cascade and expert to serve occasional ask-the-expert calls for planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0249#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0249-efe05dbc6d", "paper_id": "P0249", "bibkey": "Gandhi2024Budgetmlagent", "title": "BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating Machine Learning Tasks", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "With 94.2\\% reduction in the cost (from \\$0.931 per run cost averaged over all tasks for GPT-4 single agent system to \\$0.054), our system is able to yield better average success rate of 32.95\\% as compared to GPT-4 single-agent system yielding 22.72\\% success rate averaged over all the tasks of MLAgentBench.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0249#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0249-9c0a4c867c", "paper_id": "P0249", "bibkey": "Gandhi2024Budgetmlagent", "title": "BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating Machine Learning Tasks", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) excel in diverse applications including generation of code snippets, but often struggle with generating code for complex Machine Learning (ML) tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0249#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0249-897180d6e1", "paper_id": "P0249", "bibkey": "Gandhi2024Budgetmlagent", "title": "BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating Machine Learning Tasks", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Although existing LLM single-agent based systems give varying performance depending on the task complexity, they purely rely on larger and expensive models such as GPT-4.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0249#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0249-981ac80ae3", "paper_id": "P0249", "bibkey": "Gandhi2024Budgetmlagent", "title": "BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating Machine Learning Tasks", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our investigation reveals that no-cost and low-cost models such as Gemini-Pro, Mixtral and CodeLlama perform far worse than GPT-4 in a single-agent setting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0249#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0250-a79c76a181", "paper_id": "P0250", "bibkey": "Chen2024Rely", "title": "Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, as an effort to fill the gap, we present our study using a realistic benchmark, TravelPlanner, where an agent must meet multiple constraints to generate accurate plans.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0250#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0250-ea5e590fcf", "paper_id": "P0250", "bibkey": "Chen2024Rely", "title": "Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We leverage this benchmark to address four key research questions: (1) are LLM agents robust enough to lengthy and noisy contexts when it comes to reasoning and planning?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0250#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0250-85222d4959", "paper_id": "P0250", "bibkey": "Chen2024Rely", "title": "Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "(2) can few-shot prompting adversely impact the performance of LLM agents in scenarios with long context?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0250#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0250-fce8cbdf91", "paper_id": "P0250", "bibkey": "Chen2024Rely", "title": "Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have brought autonomous agents closer to artificial general intelligence (AGI) due to their promising generalization and emergent capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0250#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0250-30624e7adf", "paper_id": "P0250", "bibkey": "Chen2024Rely", "title": "Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "There is, however, a lack of studies on how LLM-based agents behave, why they could potentially fail, and how to improve them, particularly in demanding real-world planning tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0250#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0250-0367792a2a", "paper_id": "P0250", "bibkey": "Chen2024Rely", "title": "Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, as an effort to fill the gap, we present our study using a realistic benchmark, TravelPlanner, where an agent must meet multiple constraints to generate accurate plans.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0250#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0251-027a663302", "paper_id": "P0251", "bibkey": "Yao2024Comal", "title": "CoMAL: Collaborative Multi-Agent Large Language Models for Mixed-Autonomy Traffic", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce CoMAL (Collaborative Multi-Agent LLMs), a framework designed to address the mixed-autonomy traffic problem by collaboration among autonomous vehicles to optimize traffic flow.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0251#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0251-eaec196c2f", "paper_id": "P0251", "bibkey": "Yao2024Comal", "title": "CoMAL: Collaborative Multi-Agent Large Language Models for Mixed-Autonomy Traffic", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experimental results demonstrate that CoMAL achieves superior performance on the Flow benchmark.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0251#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0251-74b7c70d33", "paper_id": "P0251", "bibkey": "Yao2024Comal", "title": "CoMAL: Collaborative Multi-Agent Large Language Models for Mixed-Autonomy Traffic", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The integration of autonomous vehicles into urban traffic has great potential to improve efficiency by reducing congestion and optimizing traffic flow systematically.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0251#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0251-226be7e17c", "paper_id": "P0251", "bibkey": "Yao2024Comal", "title": "CoMAL: Collaborative Multi-Agent Large Language Models for Mixed-Autonomy Traffic", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce CoMAL (Collaborative Multi-Agent LLMs), a framework designed to address the mixed-autonomy traffic problem by collaboration among autonomous vehicles to optimize traffic flow.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0251#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0251-06faba5f9a", "paper_id": "P0251", "bibkey": "Yao2024Comal", "title": "CoMAL: Collaborative Multi-Agent Large Language Models for Mixed-Autonomy Traffic", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "CoMAL is built upon large language models, operating in an interactive traffic simulation environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0251#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0252-300338f522", "paper_id": "P0252", "bibkey": "Mangal2024Coalitions", "title": "Coalitions of Large Language Models Increase the Robustness of AI Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "The emergence of Large Language Models (LLMs) have fundamentally altered the way we interact with digital systems and have led to the pursuit of LLM powered AI agents to assist in daily workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0252#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0252-0dd60260e7", "paper_id": "P0252", "bibkey": "Mangal2024Coalitions", "title": "Coalitions of Large Language Models Increase the Robustness of AI Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our findings demonstrate that fine-tuning can be mitigated by considering a coalition of pretrained models and believe that this approach can be applied to other non-agentic systems which utilise LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0252#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0252-b4e597352d", "paper_id": "P0252", "bibkey": "Mangal2024Coalitions", "title": "Coalitions of Large Language Models Increase the Robustness of AI Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The emergence of Large Language Models (LLMs) have fundamentally altered the way we interact with digital systems and have led to the pursuit of LLM powered AI agents to assist in daily workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0252#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0252-4036a3afc7", "paper_id": "P0252", "bibkey": "Mangal2024Coalitions", "title": "Coalitions of Large Language Models Increase the Robustness of AI Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLMs, whilst powerful and capable of demonstrating some emergent properties, are not logical reasoners and often struggle to perform well at all sub-tasks carried out by an AI agent to plan and execute a workflow.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0252#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0252-cd809214a4", "paper_id": "P0252", "bibkey": "Mangal2024Coalitions", "title": "Coalitions of Large Language Models Increase the Robustness of AI Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While existing studies tackle this lack of proficiency by generalised pretraining at a huge scale or by specialised fine-tuning for tool use, we assess if a system comprising of a coalition of pretrained LLMs, each exhibiting specialised performance at individual sub-tasks, can match the performance of single model agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0252#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0253-8930fe3a07", "paper_id": "P0253", "bibkey": "Li2024Codetree", "title": "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this problem, we propose CodeTree, a framework for LLM agents to efficiently explore the search space in different stages of the code generation process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0253#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0253-7c8012e69f", "paper_id": "P0253", "bibkey": "Li2024Codetree", "title": "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We comprehensively evaluated CodeTree on 7 code generation benchmarks and demonstrated the significant performance gains of CodeTree against strong baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0253#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0253-6d63ed82d0", "paper_id": "P0253", "bibkey": "Li2024Codetree", "title": "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Using GPT-4o as the base model, we consistently achieved top results of 95.1 on HumanEval, 98.7 on MBPP, and 43.0 on CodeContests.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0253#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0253-8722819889", "paper_id": "P0253", "bibkey": "Li2024Codetree", "title": "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Pre-trained on massive amounts of code and text data, large language models (LLMs) have demonstrated remarkable achievements in performing code generation tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0253#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0253-f20745998b", "paper_id": "P0253", "bibkey": "Li2024Codetree", "title": "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With additional execution-based feedback, these models can act as agents with capabilities to self-refine and improve generated code autonomously.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0253#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0253-da633ef626", "paper_id": "P0253", "bibkey": "Li2024Codetree", "title": "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, on challenging coding tasks with extremely large search space, current agentic approaches still struggle with multi-stage planning, generating, and debugging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0253#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0254-2ef1025cc2", "paper_id": "P0254", "bibkey": "Han2024Development", "title": "Development of a Large Language Model-based Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Emergency department (ED) overcrowding and the complexity of rapid decision-making in critical care settings pose significant challenges to healthcare systems worldwide.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0254#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0254-447a3814df", "paper_id": "P0254", "bibkey": "Han2024Development", "title": "Development of a Large Language Model-based Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We developed a multi-agent CDSS utilizing Llama-3-70b as the base LLM, orchestrated by CrewAI and Langchain.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0254#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0254-3abce72b09", "paper_id": "P0254", "bibkey": "Han2024Development", "title": "Development of a Large Language Model-based Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "While clinical decision support systems (CDSS) have shown promise, the integration of large language models (LLMs) offers new possibilities for enhancing triage accuracy and clinical decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0254#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0254-b02d393a82", "paper_id": "P0254", "bibkey": "Han2024Development", "title": "Development of a Large Language Model-based Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Emergency department (ED) overcrowding and the complexity of rapid decision-making in critical care settings pose significant challenges to healthcare systems worldwide.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0254#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0254-0332cf5d03", "paper_id": "P0254", "bibkey": "Han2024Development", "title": "Development of a Large Language Model-based Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While clinical decision support systems (CDSS) have shown promise, the integration of large language models (LLMs) offers new possibilities for enhancing triage accuracy and clinical decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0254#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0254-a6a3900789", "paper_id": "P0254", "bibkey": "Han2024Development", "title": "Development of a Large Language Model-based Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study presents an LLM-driven CDSS designed to assist ED physicians and nurses in patient triage, treatment planning, and overall emergency care management.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0254#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0255-61fc5b3cd1", "paper_id": "P0255", "bibkey": "Inoue2024Drugagent", "title": "DrugAgent: Multi-Agent Large Language Model-Based Reasoning for Drug-Target Interaction Prediction", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Most importantly, our approach provides detailed, human-interpretable reasoning for each prediction by combining evidence from multiple sources - a critical feature for biomedical applications where understanding the rationale behind predictions is essential for clinical decision-making and regulatory compliance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0255#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0255-5e37132da5", "paper_id": "P0255", "bibkey": "Inoue2024Drugagent", "title": "DrugAgent: Multi-Agent Large Language Model-Based Reasoning for Drug-Target Interaction Prediction", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We conducted comprehensive experiments using a kinase inhibitor dataset, where our multi-agent LLM method outperformed the non-reasoning multi-agent model (GPT-4o mini) by 45% in F1 score (0.514 vs 0.355).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0255#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0255-3160fd98d8", "paper_id": "P0255", "bibkey": "Inoue2024Drugagent", "title": "DrugAgent: Multi-Agent Large Language Model-Based Reasoning for Drug-Target Interaction Prediction", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our system adapts and extends existing multi-agent frameworks by (1) applying coordinator-based architecture to the DTI domain, (2) integrating domain-specific data sources, including ML predictions, knowledge graphs, and literature evidence, and (3) incorporating Chain-of-Thought (CoT) and ReAct (Reason+Act) frameworks for transparent DTI reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0255#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0255-ef670ad01f", "paper_id": "P0255", "bibkey": "Inoue2024Drugagent", "title": "DrugAgent: Multi-Agent Large Language Model-Based Reasoning for Drug-Target Interaction Prediction", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Advancements in large language models (LLMs) allow them to address diverse questions using human-like interfaces.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0255#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0255-fb1b4bc776", "paper_id": "P0255", "bibkey": "Inoue2024Drugagent", "title": "DrugAgent: Multi-Agent Large Language Model-Based Reasoning for Drug-Target Interaction Prediction", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Still, limitations in their training prevent them from answering accurately in scenarios that could benefit from multiple perspectives.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0255#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0255-743a7f01c1", "paper_id": "P0255", "bibkey": "Inoue2024Drugagent", "title": "DrugAgent: Multi-Agent Large Language Model-Based Reasoning for Drug-Target Interaction Prediction", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Multi-agent systems allow the resolution of questions to enhance result consistency and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0255#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0255-f066a3e971", "paper_id": "P0255", "bibkey": "Inoue2024Drugagent", "title": "DrugAgent: Multi-Agent Large Language Model-Based Reasoning for Drug-Target Interaction Prediction", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Still, limitations in their training prevent them from answering accurately in scenarios that could benefit from multiple perspectives.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0255#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0256-b78c7da9ae", "paper_id": "P0256", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a framework LearnAct with an iterative learning strategy to create and improve actions in the form of Python functions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0256#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0256-9a9b9f50ae", "paper_id": "P0256", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experimental evaluations across Robotic Planning and Alfworld environments reveal that after learning on a few training task instances, our approach to open-action learning markedly improves agent performance for the type of task (by 32 percent in AlfWorld compared to ReAct+Reflexion, for instance) highlighting the importance of experiential action learning in the development of more intelligent LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0256#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0256-644765145d", "paper_id": "P0256", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) Agents have recently garnered increasing interest yet they are limited in their ability to learn from trial and error, a key element of intelligent behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0256#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0256-3a3ae3749a", "paper_id": "P0256", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we argue that the capacity to learn new actions from experience is fundamental to the advancement of learning in LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0256#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0256-4c29be4bc6", "paper_id": "P0256", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While humans naturally expand their action spaces and develop skills through experiential learning, LLM agents typically operate within fixed action spaces, limiting their potential for growth.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0256#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0257-8970f8df6a", "paper_id": "P0257", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose a Theory of Mind (ToM) planning technique that allows LLM agents to adapt their strategy against various adversaries using only game rules, current state, and historical context as input.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0257#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0257-95dc2415e7", "paper_id": "P0257", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large language models (LLMs) have shown success in handling simple games with imperfect information and enabling multi-agent coordination, but their ability to facilitate practical collaboration against other agents in complex, imperfect information environments, especially in a non-English environment, still needs to be explored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0257#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0257-ad27d52e29", "paper_id": "P0257", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results show that although a performance gap exists between current LLMs and state-of-the-art reinforcement learning (RL) models, LLMs demonstrate ToM capabilities in this game setting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0257#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0257-693265b6e9", "paper_id": "P0257", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have shown success in handling simple games with imperfect information and enabling multi-agent coordination, but their ability to facilitate practical collaboration against other agents in complex, imperfect information environments, especially in a non-English environment, still needs to be explored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0257#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0257-7e2c5dab0a", "paper_id": "P0257", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study investigates the applicability of knowledge acquired by open-source and API-based LLMs to sophisticated text-based games requiring agent collaboration under imperfect information, comparing their performance to established baselines using other types of agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0257#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0257-6e3d8b24b2", "paper_id": "P0257", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose a Theory of Mind (ToM) planning technique that allows LLM agents to adapt their strategy against various adversaries using only game rules, current state, and historical context as input.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0257#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0258-229ef16866", "paper_id": "P0258", "bibkey": "Barua2024Exploring", "title": "Exploring Autonomous Agents through the Lens of Large Language Models: A Review", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Models (LLMs) are transforming artificial intelligence, enabling autonomous agents to perform diverse tasks across various domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0258#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0258-d85eaa8034", "paper_id": "P0258", "bibkey": "Barua2024Exploring", "title": "Exploring Autonomous Agents through the Lens of Large Language Models: A Review", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "These agents, proficient in human-like text comprehension and generation, have the potential to revolutionize sectors from customer service to healthcare.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0258#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0258-c023eeaa73", "paper_id": "P0258", "bibkey": "Barua2024Exploring", "title": "Exploring Autonomous Agents through the Lens of Large Language Models: A Review", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, they face challenges such as multimodality, human value alignment, hallucinations, and evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0258#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0258-f8d4936bf9", "paper_id": "P0258", "bibkey": "Barua2024Exploring", "title": "Exploring Autonomous Agents through the Lens of Large Language Models: A Review", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) are transforming artificial intelligence, enabling autonomous agents to perform diverse tasks across various domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0258#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0258-b933571f6b", "paper_id": "P0258", "bibkey": "Barua2024Exploring", "title": "Exploring Autonomous Agents through the Lens of Large Language Models: A Review", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These agents, proficient in human-like text comprehension and generation, have the potential to revolutionize sectors from customer service to healthcare.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0258#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0258-67f5aa11d9", "paper_id": "P0258", "bibkey": "Barua2024Exploring", "title": "Exploring Autonomous Agents through the Lens of Large Language Models: A Review", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, they face challenges such as multimodality, human value alignment, hallucinations, and evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0258#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0259-d27181f35b", "paper_id": "P0259", "bibkey": "Cheng2024Exploring", "title": "Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Intelligent agents stand out as a potential path toward artificial general intelligence (AGI).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0259#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0259-98d4a8c080", "paper_id": "P0259", "bibkey": "Cheng2024Exploring", "title": "Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The discussions also shed light on popular datasets and application scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0259#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0259-0c698cebac", "paper_id": "P0259", "bibkey": "Cheng2024Exploring", "title": "Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Intelligent agents stand out as a potential path toward artificial general intelligence (AGI).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0259#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0259-adc764fbe5", "paper_id": "P0259", "bibkey": "Cheng2024Exploring", "title": "Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Thus, researchers have dedicated significant effort to diverse implementations for them.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0259#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0259-d275ee2a2d", "paper_id": "P0259", "bibkey": "Cheng2024Exploring", "title": "Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Benefiting from recent progress in large language models (LLMs), LLM-based agents that use universal natural language as an interface exhibit robust generalization capabilities across various applications -- from serving as autonomous general-purpose task assistants to applications in coding, social, and economic domains, LLM-based agents offer extensive exploration opportunities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0259#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0260-7d9502f3aa", "paper_id": "P0260", "bibkey": "Wu2024Federated", "title": "Federated In-Context LLM Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose a novel privacy-preserving Federated In-Context LLM Agent Learning (FICAL) algorithm, which to our best knowledge for the first work unleashes the power of in-context learning to train diverse LLM agents through FL.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0260#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0260-76aa5df0e2", "paper_id": "P0260", "bibkey": "Wu2024Federated", "title": "Federated In-Context LLM Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We conducted extensive experiments and the results show that FICAL has competitive performance compared to other SOTA baselines with a significant communication cost decrease of $\\mathbf{3.33\\times10^5}$ times.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0260#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0260-d235ac38e0", "paper_id": "P0260", "bibkey": "Wu2024Federated", "title": "Federated In-Context LLM Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have revolutionized intelligent services by enabling logical reasoning, tool use, and interaction with external systems as agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0260#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0260-f3bb411693", "paper_id": "P0260", "bibkey": "Wu2024Federated", "title": "Federated In-Context LLM Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The advancement of LLMs is frequently hindered by the scarcity of high-quality data, much of which is inherently sensitive.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0260#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0260-fa8dd83368", "paper_id": "P0260", "bibkey": "Wu2024Federated", "title": "Federated In-Context LLM Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Federated learning (FL) offers a potential solution by facilitating the collaborative training of distributed LLMs while safeguarding private data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0260#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0261-578d22f533", "paper_id": "P0261", "bibkey": "Mou2024From", "title": "From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Traditional sociological research often relies on human participation, which, though effective, is expensive, challenging to scale, and with ethical concerns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0261#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0261-3e23cb8c51", "paper_id": "P0261", "bibkey": "Mou2024From", "title": "From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We categorize the simulations into three types: (1) Individual Simulation, which mimics specific individuals or demographic groups; (2) Scenario Simulation, where multiple agents collaborate to achieve goals within specific contexts; and (3) Society Simulation, which models interactions within agent societies to reflect the complexity and variety of real-world dynamics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0261#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0261-0d9cd90272", "paper_id": "P0261", "bibkey": "Mou2024From", "title": "From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Traditional sociological research often relies on human participation, which, though effective, is expensive, challenging to scale, and with ethical concerns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0261#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0261-76277075b3", "paper_id": "P0261", "bibkey": "Mou2024From", "title": "From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional sociological research often relies on human participation, which, though effective, is expensive, challenging to scale, and with ethical concerns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0261#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0261-8c6e1fe579", "paper_id": "P0261", "bibkey": "Mou2024From", "title": "From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in large language models (LLMs) highlight their potential to simulate human behavior, enabling the replication of individual responses and facilitating studies on many interdisciplinary studies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0261#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0261-9cdde1fd46", "paper_id": "P0261", "bibkey": "Mou2024From", "title": "From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we conduct a comprehensive survey of this field, illustrating the recent progress in simulation driven by LLM-empowered agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0261#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0262-4369915cc0", "paper_id": "P0262", "bibkey": "Liu2024From", "title": "From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "This paper introduces RAISE (Reasoning and Acting through Scratchpad and Examples), an advanced architecture enhancing the integration of Large Language Models (LLMs) like GPT-4 into conversational agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0262#method"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0262-29f7ec88f6", "paper_id": "P0262", "bibkey": "Liu2024From", "title": "From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "This paper introduces RAISE (Reasoning and Acting through Scratchpad and Examples), an advanced architecture enhancing the integration of Large Language Models (LLMs) like GPT-4 into conversational agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0262#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0262-b4dfc9fd01", "paper_id": "P0262", "bibkey": "Liu2024From", "title": "From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "RAISE, an enhancement of the ReAct framework, incorporates a dual-component memory system, mirroring human short-term and long-term memory, to maintain context and continuity in conversations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0262#key_results[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0262-15dda7e3c8", "paper_id": "P0262", "bibkey": "Liu2024From", "title": "From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper introduces RAISE (Reasoning and Acting through Scratchpad and Examples), an advanced architecture enhancing the integration of Large Language Models (LLMs) like GPT-4 into conversational agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0262#summary_bullets[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0262-2fb0fe48c6", "paper_id": "P0262", "bibkey": "Liu2024From", "title": "From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "RAISE, an enhancement of the ReAct framework, incorporates a dual-component memory system, mirroring human short-term and long-term memory, to maintain context and continuity in conversations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0262#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0262-bd0d9375e9", "paper_id": "P0262", "bibkey": "Liu2024From", "title": "From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It entails a comprehensive agent construction scenario, including phases like Conversation Selection, Scene Extraction, CoT Completion, and Scene Augmentation, leading to the LLMs Training phase.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0262#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0263-c15e31de91", "paper_id": "P0263", "bibkey": "He2024Give", "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present Graph Inspired Veracity Extrapolation (GIVE), a novel reasoning method that merges parametric and non-parametric memories to improve accurate reasoning with minimal external input.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0263#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0263-199af74195", "paper_id": "P0263", "bibkey": "He2024Give", "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "(4) GIVE is a training-free method that enables LLMs to tackle new problems that extend beyond their training data (up to 43.5% -> 88.2%} accuracy improvement).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0263#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0263-0a21878800", "paper_id": "P0263", "bibkey": "He2024Give", "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments demonstrated the following benefits of our framework: (1) GIVE boosts the performance of LLMs across various sizes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0263#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0263-0800fcd3eb", "paper_id": "P0263", "bibkey": "He2024Give", "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing approaches based on context prompting or reinforcement learning (RL) to improve the reasoning capacities of large language models (LLMs) depend on the LLMs' internal knowledge to produce reliable Chain-Of-Thought (CoT).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0263#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0263-04742cc93d", "paper_id": "P0263", "bibkey": "He2024Give", "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, no matter the size of LLMs, certain problems cannot be resolved in a single forward pass.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0263#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0263-619de5d716", "paper_id": "P0263", "bibkey": "He2024Give", "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Meanwhile, agent-based reasoning systems require access to a comprehensive nonparametric knowledge base, which is often costly or not feasible for use in scientific and niche domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0263#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0264-ce3bb7b650", "paper_id": "P0264", "bibkey": "Costarelli2024Gamebench", "title": "GameBench: Evaluating Strategic Reasoning Abilities of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we introduce GameBench, a cross-domain benchmark for evaluating strategic reasoning abilities of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0264#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0264-fe43cbc153", "paper_id": "P0264", "bibkey": "Costarelli2024Gamebench", "title": "GameBench: Evaluating Strategic Reasoning Abilities of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results show that none of the tested models match human performance, and at worst GPT-4 performs worse than random action.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0264#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0264-e614adf825", "paper_id": "P0264", "bibkey": "Costarelli2024Gamebench", "title": "GameBench: Evaluating Strategic Reasoning Abilities of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We focus on 9 different game environments, where each covers at least one axis of key reasoning skill identified in strategy games, and select games for which strategy explanations are unlikely to form a significant portion of models' pretraining corpuses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0264#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0264-eac18c5789", "paper_id": "P0264", "bibkey": "Costarelli2024Gamebench", "title": "GameBench: Evaluating Strategic Reasoning Abilities of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models have demonstrated remarkable few-shot performance on many natural language understanding tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0264#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0264-b067b208f5", "paper_id": "P0264", "bibkey": "Costarelli2024Gamebench", "title": "GameBench: Evaluating Strategic Reasoning Abilities of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite several demonstrations of using large language models in complex, strategic scenarios, there lacks a comprehensive framework for evaluating agents' performance across various types of reasoning found in games.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0264#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0264-ab7b463746", "paper_id": "P0264", "bibkey": "Costarelli2024Gamebench", "title": "GameBench: Evaluating Strategic Reasoning Abilities of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, we introduce GameBench, a cross-domain benchmark for evaluating strategic reasoning abilities of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0264#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0265-4880b66c28", "paper_id": "P0265", "bibkey": "Cao2024Graphinsight", "title": "GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this, we propose GraphInsight, a novel framework aimed at improving LLMs' comprehension of both macro- and micro-level graphical information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0265#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0265-4bd470632f", "paper_id": "P0265", "bibkey": "Cao2024Graphinsight", "title": "GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "GraphInsight is grounded in two key strategies: 1) placing critical graphical information in positions where LLMs exhibit stronger memory performance, and 2) investigating a lightweight external knowledge base for regions with weaker memory performance, inspired by retrieval-augmented generation (RAG).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0265#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0265-89e1070ef1", "paper_id": "P0265", "bibkey": "Cao2024Graphinsight", "title": "GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive empirical studies on benchmarks with a wide range of evaluation tasks show that GraphInsight significantly outperforms all other graph description methods (e.g., prompting techniques and reordering strategies) in understanding graph structures of varying sizes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0265#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0265-296d7ca3c6", "paper_id": "P0265", "bibkey": "Cao2024Graphinsight", "title": "GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Although Large Language Models (LLMs) have demonstrated potential in processing graphs, they struggle with comprehending graphical structure information through prompts of graph description sequences, especially as the graph size increases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0265#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0265-3eea6ec716", "paper_id": "P0265", "bibkey": "Cao2024Graphinsight", "title": "GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We attribute this challenge to the uneven memory performance of LLMs across different positions in graph description sequences, known as ''positional biases''.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0265#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0265-3f00f6a1a1", "paper_id": "P0265", "bibkey": "Cao2024Graphinsight", "title": "GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this, we propose GraphInsight, a novel framework aimed at improving LLMs' comprehension of both macro- and micro-level graphical information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0265#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0266-8487a3d377", "paper_id": "P0266", "bibkey": "Song2024Guide", "title": "Guide-LLM: An Embodied LLM Agent and Text-Based Topological Map for Robotic Guidance of People with Visual Impairments", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce Guide-LLM, an embodied LLM-based agent designed to assist PVI in navigating large indoor environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0266#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0266-fd8e1c20a2", "paper_id": "P0266", "bibkey": "Song2024Guide", "title": "Guide-LLM: An Embodied LLM Agent and Text-Based Topological Map for Robotic Guidance of People with Visual Impairments", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The results highlight Guide-LLM's ability to offer efficient, adaptive, and personalized navigation assistance, pointing to promising advancements in this field.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0266#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0266-4970261930", "paper_id": "P0266", "bibkey": "Song2024Guide", "title": "Guide-LLM: An Embodied LLM Agent and Text-Based Topological Map for Robotic Guidance of People with Visual Impairments", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Navigation presents a significant challenge for persons with visual impairments (PVI).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0266#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0266-bb5bb336a2", "paper_id": "P0266", "bibkey": "Song2024Guide", "title": "Guide-LLM: An Embodied LLM Agent and Text-Based Topological Map for Robotic Guidance of People with Visual Impairments", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While traditional aids such as white canes and guide dogs are invaluable, they fall short in delivering detailed spatial information and precise guidance to desired locations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0266#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0266-f3e30f9f0e", "paper_id": "P0266", "bibkey": "Song2024Guide", "title": "Guide-LLM: An Embodied LLM Agent and Text-Based Topological Map for Robotic Guidance of People with Visual Impairments", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent developments in large language models (LLMs) and vision-language models (VLMs) offer new avenues for enhancing assistive navigation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0266#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0267-0121e8acac", "paper_id": "P0267", "bibkey": "Sun2024Interpreting", "title": "Interpreting Multi-band Galaxy Observations with Large Language Model-Based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose mephisto, a multi-agent collaboration framework that mimics human reasoning to interpret multi-band galaxy observations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0267#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0267-042ed25983", "paper_id": "P0267", "bibkey": "Sun2024Interpreting", "title": "Interpreting Multi-band Galaxy Observations with Large Language Model-Based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We propose mephisto, a multi-agent collaboration framework that mimics human reasoning to interpret multi-band galaxy observations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0267#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0267-72f4e993d6", "paper_id": "P0267", "bibkey": "Sun2024Interpreting", "title": "Interpreting Multi-band Galaxy Observations with Large Language Model-Based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "mephisto attains near-human proficiency in reasoning about galaxies' physical scenarios, even when dealing with a recently discovered population of \"Little Red Dot\" galaxies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0267#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0267-25dc57251d", "paper_id": "P0267", "bibkey": "Sun2024Interpreting", "title": "Interpreting Multi-band Galaxy Observations with Large Language Model-Based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Astronomical research traditionally relies on extensive domain knowledge to interpret observations and narrow down hypotheses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0267#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0267-acf3db89b4", "paper_id": "P0267", "bibkey": "Sun2024Interpreting", "title": "Interpreting Multi-band Galaxy Observations with Large Language Model-Based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We demonstrate that this process can be emulated using large language model-based agents to accelerate research workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0267#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0267-fb0a419594", "paper_id": "P0267", "bibkey": "Sun2024Interpreting", "title": "Interpreting Multi-band Galaxy Observations with Large Language Model-Based Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose mephisto, a multi-agent collaboration framework that mimics human reasoning to interpret multi-band galaxy observations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0267#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0268-736b6ce650", "paper_id": "P0268", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In recent years, large language models (LLMs) have become increasingly capable and can now interact with tools (i.e., call functions), read documents, and recursively call themselves.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0268#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0268-5289c5dd2a", "paper_id": "P0268", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Namely, we show that GPT-4 is capable of such hacks, but existing open-source models are not.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0268#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0268-4ca48f2c91", "paper_id": "P0268", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we show that GPT-4 is capable of autonomously finding vulnerabilities in websites in the wild.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0268#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "security"]}
{"evidence_id": "E-P0268-aa284afced", "paper_id": "P0268", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In recent years, large language models (LLMs) have become increasingly capable and can now interact with tools (i.e., call functions), read documents, and recursively call themselves.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0268#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0268-27c3729137", "paper_id": "P0268", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As a result, these LLMs can now function autonomously as agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0268#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0268-6585fe35f0", "paper_id": "P0268", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the rise in capabilities of these agents, recent work has speculated on how LLM agents would affect cybersecurity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0268#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0268-58e3b3142d", "paper_id": "P0268", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Importantly, the agent does not need to know the vulnerability beforehand.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0268#limitations[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0269-6a5ede17cd", "paper_id": "P0269", "bibkey": "Zhang2024Mastermind", "title": "LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "This paper presents a comprehensive survey of the current status and opportunities for Large Language Models (LLMs) in strategic reasoning, a sophisticated form of reasoning that necessitates understanding and predicting adversary actions in multi-agent settings while adjusting strategies accordingly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0269#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0269-c743ea079a", "paper_id": "P0269", "bibkey": "Zhang2024Mastermind", "title": "LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We explore the scopes, applications, methodologies, and evaluation metrics related to strategic reasoning with LLMs, highlighting the burgeoning development in this area and the interdisciplinary approaches enhancing their decision-making performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0269#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0269-58752a345f", "paper_id": "P0269", "bibkey": "Zhang2024Mastermind", "title": "LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents a comprehensive survey of the current status and opportunities for Large Language Models (LLMs) in strategic reasoning, a sophisticated form of reasoning that necessitates understanding and predicting adversary actions in multi-agent settings while adjusting strategies accordingly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0269#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0269-3c4086a5b9", "paper_id": "P0269", "bibkey": "Zhang2024Mastermind", "title": "LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Strategic reasoning is distinguished by its focus on the dynamic and uncertain nature of interactions among multi-agents, where comprehending the environment and anticipating the behavior of others is crucial.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0269#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0269-af74d386ed", "paper_id": "P0269", "bibkey": "Zhang2024Mastermind", "title": "LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We explore the scopes, applications, methodologies, and evaluation metrics related to strategic reasoning with LLMs, highlighting the burgeoning development in this area and the interdisciplinary approaches enhancing their decision-making performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0269#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0270-271970e0be", "paper_id": "P0270", "bibkey": "Chen2024Llmarena", "title": "LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To this end, we introduce LLMArena, a novel and easily extensible framework for evaluating the diverse capabilities of LLM in multi-agent dynamic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0270#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0270-3568f1c159", "paper_id": "P0270", "bibkey": "Chen2024Llmarena", "title": "LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Recent advancements in large language models (LLMs) have revealed their potential for achieving autonomous agents possessing human-level intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0270#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0270-764758958d", "paper_id": "P0270", "bibkey": "Chen2024Llmarena", "title": "LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, existing benchmarks for evaluating LLM Agents either use static datasets, potentially leading to data leakage or focus only on single-agent scenarios, overlooking the complexities of multi-agent interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0270#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0270-bef532fabc", "paper_id": "P0270", "bibkey": "Chen2024Llmarena", "title": "LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in large language models (LLMs) have revealed their potential for achieving autonomous agents possessing human-level intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0270#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0270-a3e45942b4", "paper_id": "P0270", "bibkey": "Chen2024Llmarena", "title": "LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing benchmarks for evaluating LLM Agents either use static datasets, potentially leading to data leakage or focus only on single-agent scenarios, overlooking the complexities of multi-agent interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0270#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0270-8db7016ab4", "paper_id": "P0270", "bibkey": "Chen2024Llmarena", "title": "LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "There is a lack of a benchmark that evaluates the diverse capabilities of LLM agents in multi-agent, dynamic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0270#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0271-e278551cb5", "paper_id": "P0271", "bibkey": "Zhu2024Large", "title": "Large Language Model Enhanced Text-to-SQL Generation: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Text-to-SQL translates natural language queries into Structured Query Language (SQL) commands, enabling users to interact with databases using natural language.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0271#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0271-0f12a844e7", "paper_id": "P0271", "bibkey": "Zhu2024Large", "title": "Large Language Model Enhanced Text-to-SQL Generation: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We also summarize datasets and evaluation metrics comprehensively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0271#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0271-a7520b65cd", "paper_id": "P0271", "bibkey": "Zhu2024Large", "title": "Large Language Model Enhanced Text-to-SQL Generation: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Text-to-SQL translates natural language queries into Structured Query Language (SQL) commands, enabling users to interact with databases using natural language.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0271#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0271-b2f44fdb08", "paper_id": "P0271", "bibkey": "Zhu2024Large", "title": "Large Language Model Enhanced Text-to-SQL Generation: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Essentially, the text-to-SQL task is a text generation task, and its development is primarily dependent on changes in language models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0271#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0271-21b56c685e", "paper_id": "P0271", "bibkey": "Zhu2024Large", "title": "Large Language Model Enhanced Text-to-SQL Generation: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Especially with the rapid development of Large Language Models (LLMs), the pattern of text-to-SQL has undergone significant changes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0271#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0272-aa854d8d01", "paper_id": "P0272", "bibkey": "Lu2024Large", "title": "Large Language Model for Table Processing: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Tables, typically two-dimensional and structured to store large amounts of data, are essential in daily activities like database queries, spreadsheet manipulations, web table question answering, and image table information extraction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0272#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0272-425803b37f", "paper_id": "P0272", "bibkey": "Lu2024Large", "title": "Large Language Model for Table Processing: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we highlight several challenges, including diverse user input when serving and slow thinking using chain-of-thought.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0272#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0272-7ef75d6d1d", "paper_id": "P0272", "bibkey": "Lu2024Large", "title": "Large Language Model for Table Processing: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tables, typically two-dimensional and structured to store large amounts of data, are essential in daily activities like database queries, spreadsheet manipulations, web table question answering, and image table information extraction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0272#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0272-40d26190ce", "paper_id": "P0272", "bibkey": "Lu2024Large", "title": "Large Language Model for Table Processing: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Automating these table-centric tasks with Large Language Models (LLMs) or Visual Language Models (VLMs) offers significant public benefits, garnering interest from academia and industry.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0272#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0272-e0c98401b5", "paper_id": "P0272", "bibkey": "Lu2024Large", "title": "Large Language Model for Table Processing: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey provides a comprehensive overview of table-related tasks, examining both user scenarios and technical aspects.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0272#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0273-c1d962bac1", "paper_id": "P0273", "bibkey": "Liu2024Large", "title": "Large Language Model-Based Agents for Software Engineering: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we present a comprehensive and systematic survey on LLM-based agents for SE.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0273#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0273-ee0ad59b05", "paper_id": "P0273", "bibkey": "Liu2024Large", "title": "Large Language Model-Based Agents for Software Engineering: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We collect 124 papers and categorize them from two perspectives, i.e., the SE and agent perspectives.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0273#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0273-a38dd1a210", "paper_id": "P0273", "bibkey": "Liu2024Large", "title": "Large Language Model-Based Agents for Software Engineering: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The synergy between multiple agents and human interaction brings further promise in tackling complex real-world SE problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0273#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0273-52f0832570", "paper_id": "P0273", "bibkey": "Liu2024Large", "title": "Large Language Model-Based Agents for Software Engineering: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The recent advance in Large Language Models (LLMs) has shaped a new paradigm of AI agents, i.e., LLM-based agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0273#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0273-b60403d5ae", "paper_id": "P0273", "bibkey": "Liu2024Large", "title": "Large Language Model-Based Agents for Software Engineering: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Compared to standalone LLMs, LLM-based agents substantially extend the versatility and expertise of LLMs by enhancing LLMs with the capabilities of perceiving and utilizing external resources and tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0273#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0273-015d164d8f", "paper_id": "P0273", "bibkey": "Liu2024Large", "title": "Large Language Model-Based Agents for Software Engineering: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To date, LLM-based agents have been applied and shown remarkable effectiveness in Software Engineering (SE).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0273#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0274-a2aafb319f", "paper_id": "P0274", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "GUIs have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0274#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0274-1e605f8766", "paper_id": "P0274", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "GUIs have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0274#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0274-52fea1d199", "paper_id": "P0274", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We address research questions such as existing GUI agent frameworks, the collection and utilization of data for training specialized GUI agents, the development of large action models tailored for GUI tasks, and the evaluation metrics and benchmarks necessary to assess their effectiveness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0274#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0274-b24804a0b8", "paper_id": "P0274", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "GUIs have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0274#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0274-a936da9e8a", "paper_id": "P0274", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The advent of LLMs, particularly multimodal models, has ushered in a new era of GUI automation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0274#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0274-506fa962e0", "paper_id": "P0274", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "They have demonstrated exceptional capabilities in natural language understanding, code generation, and visual processing.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0274#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0275-26a3c2095b", "paper_id": "P0275", "bibkey": "Qi2024Large", "title": "Large Language Models as Biomedical Hypothesis Generators: A Comprehensive Evaluation", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we present a comprehensive evaluation of LLMs as biomedical hypothesis generators.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0275#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0275-389f65b30d", "paper_id": "P0275", "bibkey": "Qi2024Large", "title": "Large Language Models as Biomedical Hypothesis Generators: A Comprehensive Evaluation", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments yield two key findings: 1) LLMs can generate novel and validated hypotheses, even when tested on literature unseen during training, and 2) Increasing uncertainty through multi-agent interactions and tool use can facilitate diverse candidate generation and improve zero-shot hypothesis generation performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0275#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0275-25b7a75ba8", "paper_id": "P0275", "bibkey": "Qi2024Large", "title": "Large Language Models as Biomedical Hypothesis Generators: A Comprehensive Evaluation", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "In this paper, we present a comprehensive evaluation of LLMs as biomedical hypothesis generators.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0275#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0275-52aa2be35a", "paper_id": "P0275", "bibkey": "Qi2024Large", "title": "Large Language Models as Biomedical Hypothesis Generators: A Comprehensive Evaluation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid growth of biomedical knowledge has outpaced our ability to efficiently extract insights and generate novel hypotheses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0275#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0275-48733e0124", "paper_id": "P0275", "bibkey": "Qi2024Large", "title": "Large Language Models as Biomedical Hypothesis Generators: A Comprehensive Evaluation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have emerged as a promising tool to revolutionize knowledge interaction and potentially accelerate biomedical discovery.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0275#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0275-033186d269", "paper_id": "P0275", "bibkey": "Qi2024Large", "title": "Large Language Models as Biomedical Hypothesis Generators: A Comprehensive Evaluation", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we present a comprehensive evaluation of LLMs as biomedical hypothesis generators.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0275#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0276-d72133a237", "paper_id": "P0276", "bibkey": "Zhou2024Large", "title": "Large language model empowered participatory urban planning", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Participatory urban planning is the mainstream of modern urban planning and involves the active engagement of different stakeholders.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0276#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0276-52fa98a87c", "paper_id": "P0276", "bibkey": "Zhou2024Large", "title": "Large language model empowered participatory urban planning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The framework, based on the crafted LLM agent, consists of role-play, collaborative generation, and feedback iteration, solving a community-level land-use task catering to 1000 distinct interests.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0276#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0276-b0d63bedde", "paper_id": "P0276", "bibkey": "Zhou2024Large", "title": "Large language model empowered participatory urban planning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The results were evaluated on four metrics, surpassing human experts in satisfaction and inclusion, and rivaling state-of-the-art reinforcement learning methods in service and ecology.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0276#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0276-9e0a581dbb", "paper_id": "P0276", "bibkey": "Zhou2024Large", "title": "Large language model empowered participatory urban planning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Participatory urban planning is the mainstream of modern urban planning and involves the active engagement of different stakeholders.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0276#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0276-33f176920b", "paper_id": "P0276", "bibkey": "Zhou2024Large", "title": "Large language model empowered participatory urban planning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the traditional participatory paradigm encounters challenges in time and manpower, while the generative planning tools fail to provide adjustable and inclusive solutions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0276#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0276-0ee9a7916f", "paper_id": "P0276", "bibkey": "Zhou2024Large", "title": "Large language model empowered participatory urban planning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This research introduces an innovative urban planning approach integrating Large Language Models (LLMs) within the participatory process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0276#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0277-e836e6ff5a", "paper_id": "P0277", "bibkey": "Wang2024Learning", "title": "Learning From Failure: Integrating Negative Examples when Fine-tuning Large Language Models as Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We further analyze the inference results and find that our method provides a better trade-off between valuable information and errors in unsuccessful trajectories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0277#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0277-5fa8676375", "paper_id": "P0277", "bibkey": "Wang2024Learning", "title": "Learning From Failure: Integrating Negative Examples when Fine-tuning Large Language Models as Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large language models (LLMs) have achieved success in acting as agents, which interact with environments through tools such as search engines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0277#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0277-f5634e5fc1", "paper_id": "P0277", "bibkey": "Wang2024Learning", "title": "Learning From Failure: Integrating Negative Examples when Fine-tuning Large Language Models as Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have achieved success in acting as agents, which interact with environments through tools such as search engines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0277#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0277-6f17f5908c", "paper_id": "P0277", "bibkey": "Wang2024Learning", "title": "Learning From Failure: Integrating Negative Examples when Fine-tuning Large Language Models as Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, LLMs are optimized for language generation instead of tool use during training or alignment, limiting their effectiveness as agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0277#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0277-6ee34a9a62", "paper_id": "P0277", "bibkey": "Wang2024Learning", "title": "Learning From Failure: Integrating Negative Examples when Fine-tuning Large Language Models as Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To resolve this problem, previous work has first collected interaction trajectories between LLMs and environments, using only trajectories that successfully finished the task to fine-tune smaller models, making fine-tuning data scarce and acquiring it both difficult and costly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0277#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0278-5d0fde2094", "paper_id": "P0278", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose LightVA, a lightweight VA framework that supports task decomposition, data analysis, and interactive exploration through human-agent collaboration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0278#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0278-51a6b462f1", "paper_id": "P0278", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We propose LightVA, a lightweight VA framework that supports task decomposition, data analysis, and interactive exploration through human-agent collaboration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0278#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0278-f4a2d7fd7a", "paper_id": "P0278", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Visual analytics (VA) requires analysts to iteratively propose analysis tasks based on observations and execute tasks by creating visualizations and interactive exploration to gain insights.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0278#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0278-ff9efa8f17", "paper_id": "P0278", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Visual analytics (VA) requires analysts to iteratively propose analysis tasks based on observations and execute tasks by creating visualizations and interactive exploration to gain insights.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0278#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0278-2882a3157e", "paper_id": "P0278", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This process demands skills in programming, data processing, and visualization tools, highlighting the need for a more intelligent, streamlined VA approach.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0278#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0278-3354309c5e", "paper_id": "P0278", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have recently been developed as agents to handle various tasks with dynamic planning and tool-using capabilities, offering the potential to enhance the efficiency and versatility of VA.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0278#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0279-b20d059055", "paper_id": "P0279", "bibkey": "Wei2024Long", "title": "Long-form factuality in large language models", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Furthermore, we propose extending F1 score as an aggregated metric for long-form factuality.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0279#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0279-c99f5f88fe", "paper_id": "P0279", "bibkey": "Wei2024Long", "title": "Long-form factuality in large language models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Empirically, we demonstrate that LLM agents can outperform crowdsourced human annotators - on a set of ~16k individual facts, SAFE agrees with crowdsourced human annotators 72% of the time, and on a random subset of 100 disagreement cases, SAFE wins 76% of the time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0279#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0279-ec1d665847", "paper_id": "P0279", "bibkey": "Wei2024Long", "title": "Long-form factuality in large language models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "To benchmark a model's long-form factuality in open domains, we first use GPT-4 to generate LongFact, a prompt set comprising thousands of questions spanning 38 topics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0279#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0279-c9a498b2fc", "paper_id": "P0279", "bibkey": "Wei2024Long", "title": "Long-form factuality in large language models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) often generate content that contains factual errors when responding to fact-seeking prompts on open-ended topics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0279#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0279-d3c31ae379", "paper_id": "P0279", "bibkey": "Wei2024Long", "title": "Long-form factuality in large language models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To benchmark a model's long-form factuality in open domains, we first use GPT-4 to generate LongFact, a prompt set comprising thousands of questions spanning 38 topics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0279#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0279-65ee23cbbb", "paper_id": "P0279", "bibkey": "Wei2024Long", "title": "Long-form factuality in large language models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We then propose that LLM agents can be used as automated evaluators for long-form factuality through a method which we call Search-Augmented Factuality Evaluator (SAFE).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0279#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0280-d86bdeeace", "paper_id": "P0280", "bibkey": "Motwani2024Malt", "title": "MALT: Improving Reasoning with Multi-Agent LLM Training", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce MALT (Multi-Agent LLM Training), a novel post-training strategy that divides the reasoning process into generation, verification, and refinement steps using a sequential pipeline of heterogeneous agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0280#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0280-1a74c3a428", "paper_id": "P0280", "bibkey": "Motwani2024Malt", "title": "MALT: Improving Reasoning with Multi-Agent LLM Training", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "On MATH, GSM8K, and CSQA, MALT surpasses the same baseline LLM with a relative improvement of 15.66%, 7.42%, and 9.40% respectively, making it an important advance towards multi-agent cooperative training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0280#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0280-0da32c65cb", "paper_id": "P0280", "bibkey": "Motwani2024Malt", "title": "MALT: Improving Reasoning with Multi-Agent LLM Training", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We then apply value iteration to propagate reward signals back to each role-conditioned model, automatically producing multi-agent post-training data without human or teacher-model supervision.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0280#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0280-1a380d2c8b", "paper_id": "P0280", "bibkey": "Motwani2024Malt", "title": "MALT: Improving Reasoning with Multi-Agent LLM Training", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) often produce answers with a single chain-of-thought, which restricts their ability to explore reasoning paths or self-correct flawed outputs in complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0280#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0280-a6bd372e3c", "paper_id": "P0280", "bibkey": "Motwani2024Malt", "title": "MALT: Improving Reasoning with Multi-Agent LLM Training", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce MALT (Multi-Agent LLM Training), a novel post-training strategy that divides the reasoning process into generation, verification, and refinement steps using a sequential pipeline of heterogeneous agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0280#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0280-31714c9a17", "paper_id": "P0280", "bibkey": "Motwani2024Malt", "title": "MALT: Improving Reasoning with Multi-Agent LLM Training", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "During data generation, each agent is repeatedly sampled to form a multi-agent search tree, where final outputs are graded against ground-truth data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0280#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0281-d25f89f2dc", "paper_id": "P0281", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we introduce MIRAI, a novel benchmark designed to systematically evaluate LLM agents as temporal forecasters in the context of international events.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0281#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0281-6a339fd402", "paper_id": "P0281", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "In summary, MIRAI comprehensively evaluates the agents' capabilities in three dimensions: 1) autonomously source and integrate critical information from large global databases; 2) write codes using domain-specific APIs and libraries for tool-use; and 3) jointly reason over historical knowledge from diverse formats and time to accurately predict future events.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0281#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0281-d16fef84ae", "paper_id": "P0281", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Despite such a growing interest, there is a lack of a rigorous benchmark of LLM agents' forecasting capability and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0281#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0281-4a854901de", "paper_id": "P0281", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in Large Language Models (LLMs) have empowered LLM agents to autonomously collect world information, over which to conduct reasoning to solve complex problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0281#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0281-aef311d66d", "paper_id": "P0281", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Given this capability, increasing interests have been put into employing LLM agents for predicting international events, which can influence decision-making and shape policy development on an international scale.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0281#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0281-4157a930a1", "paper_id": "P0281", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite such a growing interest, there is a lack of a rigorous benchmark of LLM agents' forecasting capability and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0281#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0282-9a233088ed", "paper_id": "P0282", "bibkey": "Wang2024Mllm", "title": "MLLM-Tool: A Multimodal Large Language Model For Tool Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Therefore, in this paper, we propose MLLM-Tool, a system incorporating open-source LLMs and multi-modal encoders so that the learned LLMs can be conscious of multi-modal input instruction and then select the function-matched tool correctly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0282#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0282-cd97392159", "paper_id": "P0282", "bibkey": "Wang2024Mllm", "title": "MLLM-Tool: A Multimodal Large Language Model For Tool Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "To facilitate the evaluation of the model's capability, we collect a dataset featuring multi-modal input tools from HuggingFace.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0282#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0282-0df583a890", "paper_id": "P0282", "bibkey": "Wang2024Mllm", "title": "MLLM-Tool: A Multimodal Large Language Model For Tool Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Another essential feature of our dataset is that it also contains multiple potential choices for the same instruction due to the existence of identical functions and synonymous functions, which provides more potential solutions for the same query.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0282#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0282-2bc3581678", "paper_id": "P0282", "bibkey": "Wang2024Mllm", "title": "MLLM-Tool: A Multimodal Large Language Model For Tool Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, the astonishing performance of large language models (LLMs) in natural language comprehension and generation tasks triggered lots of exploration of using them as central controllers to build agent systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0282#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0282-571c8be996", "paper_id": "P0282", "bibkey": "Wang2024Mllm", "title": "MLLM-Tool: A Multimodal Large Language Model For Tool Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Multiple studies focus on bridging the LLMs to external tools to extend the application scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0282#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0282-fca8c939cb", "paper_id": "P0282", "bibkey": "Wang2024Mllm", "title": "MLLM-Tool: A Multimodal Large Language Model For Tool Agent Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the current LLMs' ability to perceive tool use is limited to a single text query, which may result in ambiguity in understanding the users' real intentions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0282#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0283-1f92b22206", "paper_id": "P0283", "bibkey": "Xie2024Mathlearner", "title": "MathLearner: A Large Language Model Agent Framework for Learning to Solve Mathematical Problems", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Benefiting from the efficient RETRIEVAL method, our model improves the ability of large language models to efficiently use external knowledge, i.e., the mathematical computation of the model can be based on written procedures.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0283#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0283-cb01a2fa02", "paper_id": "P0283", "bibkey": "Xie2024Mathlearner", "title": "MathLearner: A Large Language Model Agent Framework for Learning to Solve Mathematical Problems", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "It improves global accuracy over the baseline method (chain-of-thought) by 20.96% and solves 17.54% of the mathematical problems that the baseline cannot solve.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0283#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0283-6f74cff8d1", "paper_id": "P0283", "bibkey": "Xie2024Mathlearner", "title": "MathLearner: A Large Language Model Agent Framework for Learning to Solve Mathematical Problems", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Mathematics plays an important role in all aspects of human society and is a technical guarantee in the fields of healthcare, transport and aerospace, for this reason, the development of AI big language models in the field of mathematics has great potential significance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0283#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0283-2b8708ef2b", "paper_id": "P0283", "bibkey": "Xie2024Mathlearner", "title": "MathLearner: A Large Language Model Agent Framework for Learning to Solve Mathematical Problems", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the development of artificial intelligence (AI), large language models (LLM) are widely used in many fields.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0283#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0283-268d39494d", "paper_id": "P0283", "bibkey": "Xie2024Mathlearner", "title": "MathLearner: A Large Language Model Agent Framework for Learning to Solve Mathematical Problems", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the reasoning ability of LLM is still very limited when it comes to mathematical reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0283#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0283-f473598f28", "paper_id": "P0283", "bibkey": "Xie2024Mathlearner", "title": "MathLearner: A Large Language Model Agent Framework for Learning to Solve Mathematical Problems", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Mathematics plays an important role in all aspects of human society and is a technical guarantee in the fields of healthcare, transport and aerospace, for this reason, the development of AI big language models in the field of mathematics has great potential significance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0283#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0284-dd962b27b4", "paper_id": "P0284", "bibkey": "Zhu2024Menti", "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce MeNTi, a universal agent architecture for LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0284#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0284-846c85b609", "paper_id": "P0284", "bibkey": "Zhu2024Menti", "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "CalcQA is constructed by professional physicians and includes 100 case-calculator pairs, complemented by a toolkit of 281 medical tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0284#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0284-6c0f9f8b56", "paper_id": "P0284", "bibkey": "Zhu2024Menti", "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "This benchmark requires LLMs to use medical calculators to perform calculations and assess patient health status.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0284#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0284-dcfa174862", "paper_id": "P0284", "bibkey": "Zhu2024Menti", "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Integrating tools into Large Language Models (LLMs) has facilitated the widespread application.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0284#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0284-c89dc1fa9e", "paper_id": "P0284", "bibkey": "Zhu2024Menti", "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite this, in specialized downstream task contexts, reliance solely on tools is insufficient to fully address the complexities of the real world.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0284#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0284-ce4b7c4591", "paper_id": "P0284", "bibkey": "Zhu2024Menti", "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This particularly restricts the effective deployment of LLMs in fields such as medicine.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0284#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0285-c8317ba11c", "paper_id": "P0285", "bibkey": "Huang2024Mitigating", "title": "Mitigating Bias in Queer Representation within Large Language Models: A Collaborative Agent Approach", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a collaborative agent pipeline designed to mitigate these biases by analyzing and optimizing pronoun usage for inclusivity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0285#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0285-1d58a8caf3", "paper_id": "P0285", "bibkey": "Huang2024Mitigating", "title": "Mitigating Bias in Queer Representation within Large Language Models: A Collaborative Agent Approach", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experimental evaluations using the Tango dataset-a benchmark focused on gender pronoun usage-demonstrate that our approach significantly improves inclusive pronoun classification, achieving a 32.6 percentage point increase over GPT-4o in correctly disagreeing with inappropriate traditionally gendered pronouns $(^2 = 38.57, p < 0.0001)$.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0285#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0285-1fa491c342", "paper_id": "P0285", "bibkey": "Huang2024Mitigating", "title": "Mitigating Bias in Queer Representation within Large Language Models: A Collaborative Agent Approach", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) often perpetuate biases in pronoun usage, leading to misrepresentation or exclusion of queer individuals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0285#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0285-d37a23d35c", "paper_id": "P0285", "bibkey": "Huang2024Mitigating", "title": "Mitigating Bias in Queer Representation within Large Language Models: A Collaborative Agent Approach", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper addresses the specific problem of biased pronoun usage in LLM outputs, particularly the inappropriate use of traditionally gendered pronouns (\"he,\" \"she\") when inclusive language is needed to accurately represent all identities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0285#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0285-b38c855dfa", "paper_id": "P0285", "bibkey": "Huang2024Mitigating", "title": "Mitigating Bias in Queer Representation within Large Language Models: A Collaborative Agent Approach", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce a collaborative agent pipeline designed to mitigate these biases by analyzing and optimizing pronoun usage for inclusivity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0285#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0286-fca6814c99", "paper_id": "P0286", "bibkey": "Le2024Multi", "title": "Multi-Agent Causal Discovery Using Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we introduce the Multi-Agent Causal Discovery Framework (MAC), which consists of two key modules: the Debate-Coding Module (DCM) and the Meta-Debate Module (MDM).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0286#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0286-73bcad694d", "paper_id": "P0286", "bibkey": "Le2024Multi", "title": "Multi-Agent Causal Discovery Using Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments across five datasets demonstrate that MAC outperforms both traditional statistical causal discovery methods and existing LLM-based approaches, achieving state-of-the-art performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0286#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0286-a08c32f59a", "paper_id": "P0286", "bibkey": "Le2024Multi", "title": "Multi-Agent Causal Discovery Using Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Causal discovery aims to identify causal relationships between variables and is a critical research area in machine learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0286#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0286-06bf860147", "paper_id": "P0286", "bibkey": "Le2024Multi", "title": "Multi-Agent Causal Discovery Using Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional methods focus on statistical or machine learning algorithms to uncover causal links from structured data, often overlooking the valuable contextual information provided by metadata.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0286#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0286-a47b9a2c0f", "paper_id": "P0286", "bibkey": "Le2024Multi", "title": "Multi-Agent Causal Discovery Using Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have shown promise in creating unified causal discovery frameworks by incorporating both structured data and metadata.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0286#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0287-13098c7b9f", "paper_id": "P0287", "bibkey": "Xu2024Redagent", "title": "RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Recently, advanced Large Language Models (LLMs) such as GPT-4 have been integrated into many real-world applications like Code Copilot.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0287#method"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0287-928a4713bd", "paper_id": "P0287", "bibkey": "Xu2024Redagent", "title": "RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Recently, advanced Large Language Models (LLMs) such as GPT-4 have been integrated into many real-world applications like Code Copilot.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0287#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0287-49efe3cf3e", "paper_id": "P0287", "bibkey": "Xu2024Redagent", "title": "RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "By generating context-aware jailbreak prompts towards applications on GPTs, we discover 60 severe vulnerabilities of these real-world applications with only two queries per vulnerability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0287#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "security"]}
{"evidence_id": "E-P0287-ae19db728b", "paper_id": "P0287", "bibkey": "Xu2024Redagent", "title": "RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, advanced Large Language Models (LLMs) such as GPT-4 have been integrated into many real-world applications like Code Copilot.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0287#summary_bullets[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0287-fcaf24e9f1", "paper_id": "P0287", "bibkey": "Xu2024Redagent", "title": "RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These applications have significantly expanded the attack surface of LLMs, exposing them to a variety of threats.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0287#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0287-e69472254f", "paper_id": "P0287", "bibkey": "Xu2024Redagent", "title": "RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Among them, jailbreak attacks that induce toxic responses through jailbreak prompts have raised critical safety concerns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0287#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0288-88c0abd758", "paper_id": "P0288", "bibkey": "Van2024Strategist", "title": "Rx Strategist: Prescription Verification using LLM Agents System", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To protect patient safety, modern pharmaceutical complexity demands strict prescription verification.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0288#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0288-2979897998", "paper_id": "P0288", "bibkey": "Van2024Strategist", "title": "Rx Strategist: Prescription Verification using LLM Agents System", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "In the complicated world of modern medications, this combination of LLMs with organized knowledge and sophisticated search methods presents a viable avenue for reducing prescription errors and enhancing patient outcomes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0288#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0288-a4334d8877", "paper_id": "P0288", "bibkey": "Van2024Strategist", "title": "Rx Strategist: Prescription Verification using LLM Agents System", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To protect patient safety, modern pharmaceutical complexity demands strict prescription verification.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0288#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0288-db3e220d95", "paper_id": "P0288", "bibkey": "Van2024Strategist", "title": "Rx Strategist: Prescription Verification using LLM Agents System", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We offer a new approach - Rx Strategist - that makes use of knowledge graphs and different search strategies to enhance the power of Large Language Models (LLMs) inside an agentic framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0288#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0288-3c6c5102cd", "paper_id": "P0288", "bibkey": "Van2024Strategist", "title": "Rx Strategist: Prescription Verification using LLM Agents System", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This multifaceted technique allows for a multi-stage LLM pipeline and reliable information retrieval from a custom-built active ingredient database.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0288#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0289-d45369541c", "paper_id": "P0289", "bibkey": "Cao2024Survey", "title": "Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Utilizing the classical agent-environment interaction paradigm, we propose a structured taxonomy to systematically categorize LLMs' functionalities in RL, including four roles: information processor, reward designer, decision-maker, and generator.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0289#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0289-8cc0c5b2a8", "paper_id": "P0289", "bibkey": "Cao2024Survey", "title": "Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "By proposing this taxonomy, we aim to provide a framework for researchers to effectively leverage LLMs in the RL field, potentially accelerating RL applications in complex applications such as robotics, autonomous driving, and energy systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0289#key_results[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0289-d3fd7beffb", "paper_id": "P0289", "bibkey": "Cao2024Survey", "title": "Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With extensive pre-trained knowledge and high-level general capabilities, large language models (LLMs) emerge as a promising avenue to augment reinforcement learning (RL) in aspects such as multi-task learning, sample efficiency, and high-level task planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0289#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0289-e7b6fb3bc1", "paper_id": "P0289", "bibkey": "Cao2024Survey", "title": "Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this survey, we provide a comprehensive review of the existing literature in LLM-enhanced RL and summarize its characteristics compared to conventional RL methods, aiming to clarify the research scope and directions for future studies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0289#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0289-879ad160e7", "paper_id": "P0289", "bibkey": "Cao2024Survey", "title": "Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Utilizing the classical agent-environment interaction paradigm, we propose a structured taxonomy to systematically categorize LLMs' functionalities in RL, including four roles: information processor, reward designer, decision-maker, and generator.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0289#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0290-586b799cd4", "paper_id": "P0290", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Inspired by the rapid development of Large Language Models (LLMs), LLM agents have evolved to perform complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0290#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0290-302bb87ff0", "paper_id": "P0290", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "By highlighting these critical security and privacy issues, the survey seeks to stimulate future research towards enhancing the security and privacy of LLM agents, thereby increasing their reliability and trustworthiness in future applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0290#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0290-45ed2b5dca", "paper_id": "P0290", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Inspired by the rapid development of Large Language Models (LLMs), LLM agents have evolved to perform complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0290#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0290-36598f95c7", "paper_id": "P0290", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM agents are now extensively applied across various domains, handling vast amounts of data to interact with humans and execute tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0290#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0290-55ac1d8361", "paper_id": "P0290", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The widespread applications of LLM agents demonstrate their significant commercial value; however, they also expose security and privacy vulnerabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0290#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0291-edb4f593e1", "paper_id": "P0291", "bibkey": "Zhang2024Towards", "title": "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose a novel framework for multi-agent collaboration that introduces Reinforced Advantage feedback (ReAd) for efficient self-refinement of plans.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0291#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0291-c94bb02ea7", "paper_id": "P0291", "bibkey": "Zhang2024Towards", "title": "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on Overcooked-AI and a difficult variant of RoCoBench show that ReAd surpasses baselines in success rate, and also significantly decreases the interaction steps of agents and query rounds of LLMs, demonstrating its high efficiency for grounding LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0291#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0291-8fbb512557", "paper_id": "P0291", "bibkey": "Zhang2024Towards", "title": "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Grounding the reasoning ability of large language models (LLMs) for embodied tasks is challenging due to the complexity of the physical world.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0291#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0291-79a96b7d89", "paper_id": "P0291", "bibkey": "Zhang2024Towards", "title": "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Especially, LLM planning for multi-agent collaboration requires communication of agents or credit assignment as the feedback to re-adjust the proposed plans and achieve effective coordination.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0291#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0291-1c7ef50d72", "paper_id": "P0291", "bibkey": "Zhang2024Towards", "title": "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing methods that overly rely on physical verification or self-reflection suffer from excessive and inefficient querying of LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0291#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0292-f9b2ea959c", "paper_id": "P0292", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce the Personal Health Insights Agent (PHIA), a system leveraging multistep reasoning with code generation and information retrieval to analyze and interpret behavioral health data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0292#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0292-0c25e2cfae", "paper_id": "P0292", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "To test its capabilities, we create and share two benchmark datasets with over 4000 health insights questions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0292#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0292-684ec790a0", "paper_id": "P0292", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "A 650-hour human expert evaluation shows that PHIA significantly outperforms a strong code generation baseline, achieving 84% accuracy on objective, numerical questions and, for open-ended ones, earning 83% favorable ratings while being twice as likely to achieve the highest quality rating.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0292#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0292-9cb70a9328", "paper_id": "P0292", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Deriving personalized insights from popular wearable trackers requires complex numerical reasoning that challenges standard LLMs, necessitating tool-based approaches like code generation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0292#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0292-6e25a922c0", "paper_id": "P0292", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents present a promising yet largely untapped solution for this analysis at scale.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0292#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0292-1dd8f714cc", "paper_id": "P0292", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce the Personal Health Insights Agent (PHIA), a system leveraging multistep reasoning with code generation and information retrieval to analyze and interpret behavioral health data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0292#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0293-18c4f0959a", "paper_id": "P0293", "bibkey": "Bai2024Twostep", "title": "TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Classical planning formulations like the Planning Domain Definition Language (PDDL) admit action sequences guaranteed to achieve a goal state given an initial state if any are possible.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0293#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0293-a5e4659ff8", "paper_id": "P0293", "bibkey": "Bai2024Twostep", "title": "TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "A human expert aware of such constraints can decompose a goal into subgoals, each reachable through single agent planning, to take advantage of simultaneous actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0293#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0293-30f7320079", "paper_id": "P0293", "bibkey": "Bai2024Twostep", "title": "TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "In contrast to classical planning, large language models (LLMs) directly used for inferring plan steps rarely guarantee execution success, but are capable of leveraging commonsense reasoning to assemble action sequences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0293#key_results[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0293-3e0733c8b0", "paper_id": "P0293", "bibkey": "Bai2024Twostep", "title": "TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Classical planning formulations like the Planning Domain Definition Language (PDDL) admit action sequences guaranteed to achieve a goal state given an initial state if any are possible.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0293#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0293-2bd5af8922", "paper_id": "P0293", "bibkey": "Bai2024Twostep", "title": "TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, reasoning problems defined in PDDL do not capture temporal aspects of action taking, such as concurrent actions between two agents when there are no conflicting conditions, without significant modification and definition to existing PDDL domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0293#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0293-4baf630311", "paper_id": "P0293", "bibkey": "Bai2024Twostep", "title": "TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A human expert aware of such constraints can decompose a goal into subgoals, each reachable through single agent planning, to take advantage of simultaneous actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0293#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0294-e6836d8c6a", "paper_id": "P0294", "bibkey": "Chen2024Solving", "title": "Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present our position on why directly solving MAPF with LLMs has not been successful yet, and we use various experiments to support our hypothesis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0294#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0294-a85dd2af59", "paper_id": "P0294", "bibkey": "Chen2024Solving", "title": "Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "With the explosive influence caused by the success of large language models (LLM) like ChatGPT and GPT-4, there has been an extensive amount of recent work showing that foundation models can be used to solve a large variety of tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0294#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0294-cefe4d686d", "paper_id": "P0294", "bibkey": "Chen2024Solving", "title": "Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We first show the motivating success on an empty room map without obstacles, then the failure to plan on the harder room map and maze map of the standard MAPF benchmark.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0294#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0294-9c024903e8", "paper_id": "P0294", "bibkey": "Chen2024Solving", "title": "Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the explosive influence caused by the success of large language models (LLM) like ChatGPT and GPT-4, there has been an extensive amount of recent work showing that foundation models can be used to solve a large variety of tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0294#summary_bullets[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0294-281fa5fb27", "paper_id": "P0294", "bibkey": "Chen2024Solving", "title": "Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, there is very limited work that shares insights on multi-agent planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0294#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0294-492e206fb2", "paper_id": "P0294", "bibkey": "Chen2024Solving", "title": "Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Multi-agent planning is different from other domains by combining the difficulty of multi-agent coordination and planning, and making it hard to leverage external tools to facilitate the reasoning needed.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0294#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0295-792f0e4cf7", "paper_id": "P0295", "bibkey": "Wu2023Dialogue", "title": "A New Dialogue Response Generation Agent for Large Language Models by Asking Questions to Detect User's Intentions", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "To tackle these issues, we propose a framework~\\emph{using LLM to \\textbf{E}nhance dialogue response generation by asking questions to \\textbf{D}etect user's \\textbf{I}mplicit in\\textbf{T}entions} (\\textbf{EDIT}).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0295#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0295-f5a2cd86b5", "paper_id": "P0295", "bibkey": "Wu2023Dialogue", "title": "A New Dialogue Response Generation Agent for Large Language Models by Asking Questions to Detect User's Intentions", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "In order to ask open questions, we construct a Context-Open-Question (COQ) dataset.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0295#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0295-95e686a76c", "paper_id": "P0295", "bibkey": "Wu2023Dialogue", "title": "A New Dialogue Response Generation Agent for Large Language Models by Asking Questions to Detect User's Intentions", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs), such as ChatGPT, have recently been applied to various NLP tasks due to its open-domain generation capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0295#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0295-d8b8fd1e62", "paper_id": "P0295", "bibkey": "Wu2023Dialogue", "title": "A New Dialogue Response Generation Agent for Large Language Models by Asking Questions to Detect User's Intentions", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, there are two issues with applying LLMs to dialogue tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0295#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0296-a68163e536", "paper_id": "P0296", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of LLM-based autonomous agents from a holistic perspective.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0296#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0296-7902b25b48", "paper_id": "P0296", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0296#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0296-2cd82bbe79", "paper_id": "P0296", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0296#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0296-4e8c5a07c9", "paper_id": "P0296", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Autonomous agents have long been a prominent research focus in both academic and industry communities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0296#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0296-735b270082", "paper_id": "P0296", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0296#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0296-70b43a61f3", "paper_id": "P0296", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0296#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0297-797ef5a0f7", "paper_id": "P0297", "bibkey": "Hu2023Avis", "title": "AVIS: Autonomous Visual Information Seeking with Large Language Model Agent", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose an autonomous information seeking visual question answering framework, AVIS.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0297#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0297-1c25e10ffc", "paper_id": "P0297", "bibkey": "Hu2023Avis", "title": "AVIS: Autonomous Visual Information Seeking with Large Language Model Agent", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "We show that AVIS achieves state-of-the-art results on knowledge-intensive visual question answering benchmarks such as Infoseek and OK-VQA.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0297#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0297-eed9b7dd15", "paper_id": "P0297", "bibkey": "Hu2023Avis", "title": "AVIS: Autonomous Visual Information Seeking with Large Language Model Agent", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "We conduct a user study to collect a variety of instances of human decision-making when faced with this task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0297#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0297-d9bf249cba", "paper_id": "P0297", "bibkey": "Hu2023Avis", "title": "AVIS: Autonomous Visual Information Seeking with Large Language Model Agent", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose an autonomous information seeking visual question answering framework, AVIS.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0297#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0297-bfa03921d1", "paper_id": "P0297", "bibkey": "Hu2023Avis", "title": "AVIS: Autonomous Visual Information Seeking with Large Language Model Agent", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our method leverages a Large Language Model (LLM) to dynamically strategize the utilization of external tools and to investigate their outputs, thereby acquiring the indispensable knowledge needed to provide answers to the posed questions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0297#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0297-0f08e41092", "paper_id": "P0297", "bibkey": "Hu2023Avis", "title": "AVIS: Autonomous Visual Information Seeking with Large Language Model Agent", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Responding to visual questions that necessitate external knowledge, such as \"What event is commemorated by the building depicted in this image?\", is a complex task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0297#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0298-0273a45eca", "paper_id": "P0298", "bibkey": "Zhao2023Chat", "title": "Chat with the Environment: Interactive Multimodal Perception Using Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "We develop a robot interaction scenario with a partially observable state, which necessitates a robot to decide on a range of epistemic actions in order to sample sensory information among multiple modalities, before being able to execute the task correctly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0298#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0298-2e7cf48988", "paper_id": "P0298", "bibkey": "Zhao2023Chat", "title": "Chat with the Environment: Interactive Multimodal Perception Using Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "The project website can be found at https://matcha-agent.github.io.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0298#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0298-1d0faed5f5", "paper_id": "P0298", "bibkey": "Zhao2023Chat", "title": "Chat with the Environment: Interactive Multimodal Perception Using Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Programming robot behavior in a complex world faces challenges on multiple levels, from dextrous low-level skills to high-level planning and reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0298#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0298-08257e9651", "paper_id": "P0298", "bibkey": "Zhao2023Chat", "title": "Chat with the Environment: Interactive Multimodal Perception Using Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent pre-trained Large Language Models (LLMs) have shown remarkable reasoning ability in few-shot robotic planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0298#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0298-9076187d35", "paper_id": "P0298", "bibkey": "Zhao2023Chat", "title": "Chat with the Environment: Interactive Multimodal Perception Using Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, it remains challenging to ground LLMs in multimodal sensory input and continuous action output, while enabling a robot to interact with its environment and acquire novel information as its policies unfold.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0298#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0299-0bb43e55a4", "paper_id": "P0299", "bibkey": "Guo2023Fineval", "title": "FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large language models have demonstrated outstanding performance in various natural language processing tasks, but their security capabilities in the financial domain have not been explored, and their performance on complex tasks like financial agent remains unknown.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0299#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0299-fa95e566ea", "paper_id": "P0299", "bibkey": "Guo2023Fineval", "title": "FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "The dataset contains 8,351 questions categorized into four different key areas: Financial Academic Knowledge, Financial Industry Knowledge, Financial Security Knowledge, and Financial Agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0299#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0299-55b120972d", "paper_id": "P0299", "bibkey": "Guo2023Fineval", "title": "FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Financial Academic Knowledge comprises 4,661 multiple-choice questions spanning 34 subjects such as finance and economics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0299#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0299-4ffa66b3a4", "paper_id": "P0299", "bibkey": "Guo2023Fineval", "title": "FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models have demonstrated outstanding performance in various natural language processing tasks, but their security capabilities in the financial domain have not been explored, and their performance on complex tasks like financial agent remains unknown.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0299#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0299-9e6b8f0d6b", "paper_id": "P0299", "bibkey": "Guo2023Fineval", "title": "FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents FinEval, a benchmark designed to evaluate LLMs' financial domain knowledge and practical abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0299#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0299-85c689e375", "paper_id": "P0299", "bibkey": "Guo2023Fineval", "title": "FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The dataset contains 8,351 questions categorized into four different key areas: Financial Academic Knowledge, Financial Industry Knowledge, Financial Security Knowledge, and Financial Agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0299#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0300-6417c0f224", "paper_id": "P0300", "bibkey": "Yu2023Finmem", "title": "FinMem: A Performance-Enhanced LLM Trading Agent with Layered Memory and Character Design", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "Addressing this, we introduce \\textsc{FinMem}, a novel LLM-based agent framework devised for financial decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0300#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0300-633192f95a", "paper_id": "P0300", "bibkey": "Yu2023Finmem", "title": "FinMem: A Performance-Enhanced LLM Trading Agent with Layered Memory and Character Design", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "While LLMs are efficient in decoding human instructions and deriving solutions by holistically processing historical inputs, transitioning to purpose-driven agents requires a supplementary rational architecture to process multi-source information, establish reasoning chains, and prioritize critical tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0300#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0300-6a8b2ea78f", "paper_id": "P0300", "bibkey": "Yu2023Finmem", "title": "FinMem: A Performance-Enhanced LLM Trading Agent with Layered Memory and Character Design", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Notably, \\textsc{FinMem}'s memory module aligns closely with the cognitive structure of human traders, offering robust interpretability and real-time tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0300#key_results[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0300-ef1bc29c85", "paper_id": "P0300", "bibkey": "Yu2023Finmem", "title": "FinMem: A Performance-Enhanced LLM Trading Agent with Layered Memory and Character Design", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in Large Language Models (LLMs) have exhibited notable efficacy in question-answering (QA) tasks across diverse domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0300#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0300-d078b3eebc", "paper_id": "P0300", "bibkey": "Yu2023Finmem", "title": "FinMem: A Performance-Enhanced LLM Trading Agent with Layered Memory and Character Design", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Their prowess in integrating extensive web knowledge has fueled interest in developing LLM-based autonomous agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0300#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0300-3cae1737c5", "paper_id": "P0300", "bibkey": "Yu2023Finmem", "title": "FinMem: A Performance-Enhanced LLM Trading Agent with Layered Memory and Character Design", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While LLMs are efficient in decoding human instructions and deriving solutions by holistically processing historical inputs, transitioning to purpose-driven agents requires a supplementary rational architecture to process multi-source information, establish reasoning chains, and prioritize critical tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0300#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0300-2549f7ff2d", "paper_id": "P0300", "bibkey": "Yu2023Finmem", "title": "FinMem: A Performance-Enhanced LLM Trading Agent with Layered Memory and Character Design", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Addressing this, we introduce \\textsc{FinMem}, a novel LLM-based agent framework devised for financial decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0300#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0300-e29b6f6925", "paper_id": "P0300", "bibkey": "Yu2023Finmem", "title": "FinMem: A Performance-Enhanced LLM Trading Agent with Layered Memory and Character Design", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It encompasses three core modules: Profiling, to customize the agent's characteristics; Memory, with layered message processing, to aid the agent in assimilating hierarchical financial data; and Decision-making, to convert insights gained from memories into investment decisions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0300#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
