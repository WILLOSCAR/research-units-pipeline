# Evidence draft: 6.2 Safety, security, and governance

## Evidence snippets (with provenance)
- (E-P0195-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed attacks; (2) an evaluation harness that executes attacks by running real tools (both benign and malicious) via MCP rather than simulation; and (3) a robustness metric that quantifies the trade-off between security and performance: Net Resilient Performance (NRP). Zhang2025Security (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0195#key_results[0])
- (E-P0196-3c65d38a2a) Through extensive evaluation of leading LLMs, we find that even SOTA models such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit significant performance limitations. Luo2025Universe (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0196#limitations[1])
- (E-P0086-68db58914f) Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed. Shi2025Progent (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0086#key_results[0])
- (E-P0142-03ed8e82d6) We evaluate AgentVigil on two public benchmarks, AgentDojo and VWA-adv, where it achieves 71% and 70% success rates against agents based on o3-mini and GPT-4o, respectively, nearly doubling the performance of baseline attacks. Wang2025Agentvigil (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0142#key_results[0])
- (E-P0155-e4be1f69f1) Evaluations on two novel benchmarks demonstrate that BridgeScope enables LLM agents to operate databases more effectively, reduces token usage by up to 80% through improved security awareness, and uniquely supports data-intensive workflows beyond existing toolkits, establishing BridgeScope as a robust foundation for next-generation intelligent data automation. Weng2025Bridgescope (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0155#key_results[0])
- (E-P0158-7edb91824f) Leveraging the ToolEmu framework, we conduct a systematic evaluation of quitting behavior across 12 state-of-the-art LLMs. Bonagiri2025Check (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0158#key_results[0])
- (E-P0058-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
- (E-P0146-a0b404d928) Extensive experiments across ten realistic, simulated tool-use scenarios and a range of popular LLM agents demonstrate consistently high attack success rates (81\%-95\%) and significant privacy leakage, with negligible impact on primary task execution. Mo2025Attractive (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0146#key_results[0])
- (E-P0081-419e1464da) MCP-RADAR features a challenging dataset of 507 tasks spanning six domains: mathematical reasoning, web search, email, calendar, file management, and terminal operations. Gao2025Radar (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0081#key_results[0])
- (E-P0126-8b56718f74) Our major contributions include: (1) systematically analyzing the technical transition from standard legal LLMs to legal agents; (2) presenting a structured taxonomy of current agent applications across distinct legal practice areas; (3) discussing evaluation methodologies specifically for agentic performance in law; and (4) identifying open challenges and outlining future directions for developing robust and autonomous legal assistants. Liu2026Agents (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0126#key_results[0])
- (E-P0216-469a70bb44) Our evaluation of 16 agents under a unified ReAct framework reveals distinct capabilities and limitations across models. Seo2025Simuhome (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0216#key_results[1])
- (E-P0274-52fea1d199) We address research questions such as existing GUI agent frameworks, the collection and utilization of data for training specialized GUI agents, the development of large action models tailored for GUI tasks, and the evaluation metrics and benchmarks necessary to assess their effectiveness. Zhang2024Large (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0274#key_results[1])
- (E-P0008-a1fb101bda) Further, agentic LLMs provide a solution for the problem of LLMs running out of training data: inference-time behavior generates new training states, such that LLMs can keep learning without needing ever larger datasets. Plaat2025Agentic (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0008#key_results[1])
- (E-P0075-fedc33d121) Finally, we discuss trustworthiness and evaluation issues that are critical for real-world deployment, and identify several open problems for future research. Han2025Large (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0075#key_results[0])
- (E-P0060-f10376c14d) A case study on an auxiliary feedwater system demonstrated the framework's effectiveness, with over 90% accuracy in key elements and consistent tool and argument extraction, supporting its use in safety-critical diagnostics. Marandi2025Complex (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0060#key_results[0])
- (E-P0241-5603d51445) Across models and settings, we find that: (1) the frequency of whistleblowing varies widely across model families, (2) increasing the complexity of the task the agent is instructed to complete lowers whistleblowing tendencies, (3) nudging the agent in the system prompt to act morally substantially raises whistleblowing rates, and (4) giving the model more obvious avenues for non-whistleblowing behavior, by providing more tools and a detailed workflow to follow, decreases whistleblowing rates. Agrawal2025Language (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0241#key_results[0])
- (E-P0030-e38b4bdff3) To quantify these shifts, we develop the Reasoning Style Vector (RSV), a metric tracking Verification depth, Self-confidence, and Attention focus. Zhou2025Reasoning (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0030#key_results[1])
- (E-P0048-108346ac22) Large language models (LLMs) are increasingly deployed as agents in dynamic, real-world environments, where success requires both reasoning and effective tool use. Kang2025Acon (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0048#key_results[1])

## Definitions / setup

- Setup: Which design choices in Safety, security, and governance drive the major trade-offs, and how are those trade-offs measured? Scope: in-scope: Core topics directly relevant to 'Safety, security, and governance'.. Axes: evaluation protocol (datasets, metrics, human evaluation); compute and latency constraints; tool interface contract (schemas / protocols); tool selection / routing policy; sandboxing / permissions / observability. Liu2026Agents Plaat2025Agentic Zhou2025Reasoning

## Claim candidates

- MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed attacks; (2) an evaluation harness that executes attacks by running real tools (both benign and malicious) via MCP Zhang2025Security
- Through extensive evaluation of leading LLMs, we find that even SOTA models such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit significant performance limitations. Luo2025Universe
- Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed. Shi2025Progent
- We evaluate AgentVigil on two public benchmarks, AgentDojo and VWA-adv, where it achieves 71% and 70% success rates against agents based on o3-mini and GPT-4o, respectively, nearly doubling the performance of baseline attacks. Wang2025Agentvigil
- Evaluations on two novel benchmarks demonstrate that BridgeScope enables LLM agents to operate databases more effectively, reduces token usage by up to 80% through improved security awareness, and uniquely supports data-intensive workflows beyond existing toolkits, establishing BridgeScope as a robust foundation for next-generation intelligent data automation. Weng2025Bridgescope

## Concrete comparisons

- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Agent frameworks / architectures: `P0126`, `P0008`, `P0030`; B: Safety / security / guardrails: `P0058`, `P0129`, `P0142`. Gasmi2025Bridging Plaat2025Agentic Zhang2025Security
  - A highlight: (E-P0058-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - A highlight: (E-P0008-a1fb101bda) Further, agentic LLMs provide a solution for the problem of LLMs running out of training data: inference-time behavior generates new training states, such that LLMs can keep learning without needing ever larger datasets. Plaat2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0008#key_results[1])
  - B highlight: (E-P0195-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0195#key_results[0])
  - B highlight: (E-P0058-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Agent frameworks / architectures: `P0126`, `P0008`, `P0030`; B: Tool-use and function calling: `P0081`, `P0146`, `P0155`. Gasmi2025Bridging Plaat2025Agentic Zhang2025Security Weng2025Bridgescope
  - A highlight: (E-P0058-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - A highlight: (E-P0008-a1fb101bda) Further, agentic LLMs provide a solution for the problem of LLMs running out of training data: inference-time behavior generates new training states, such that LLMs can keep learning without needing ever larger datasets. Plaat2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0008#key_results[1])
  - B highlight: (E-P0195-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0195#key_results[0])
  - B highlight: (E-P0155-e4be1f69f1) Evaluations on two novel benchmarks demonstrate that BridgeScope enables LLM agents to operate databases more effectively, reduces token usage by up to 80% through improved security awareness, and uniquely supports data-intensive workflows beyond existing toolkits, establishing Weng2025Bridgescope (pointer: papers/paper_notes.jsonl:paper_id=P0155#key_results[0])
- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Safety / security / guardrails: `P0058`, `P0129`, `P0142`; B: Tool-use and function calling: `P0081`, `P0146`, `P0155`. Zhang2025Security Gasmi2025Bridging Weng2025Bridgescope
  - A highlight: (E-P0195-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0195#key_results[0])
  - A highlight: (E-P0058-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - B highlight: (E-P0195-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0195#key_results[0])
  - B highlight: (E-P0155-e4be1f69f1) Evaluations on two novel benchmarks demonstrate that BridgeScope enables LLM agents to operate databases more effectively, reduces token usage by up to 80% through improved security awareness, and uniquely supports data-intensive workflows beyond existing toolkits, establishing Weng2025Bridgescope (pointer: papers/paper_notes.jsonl:paper_id=P0155#key_results[0])
- Axis: compute and latency constraints; A: Agent frameworks / architectures: `P0126`, `P0008`, `P0030`; B: Safety / security / guardrails: `P0058`, `P0129`, `P0142`. Plaat2025Agentic Shi2025Progent Zhang2025Security Wang2025Agentvigil
  - A highlight: (E-P0008-a1fb101bda) Further, agentic LLMs provide a solution for the problem of LLMs running out of training data: inference-time behavior generates new training states, such that LLMs can keep learning without needing ever larger datasets. Plaat2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0008#key_results[1])
  - A highlight: (E-P0086-68db58914f) Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed. Shi2025Progent (pointer: papers/paper_notes.jsonl:paper_id=P0086#key_results[0])
  - B highlight: (E-P0195-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0195#key_results[0])
  - B highlight: (E-P0142-03ed8e82d6) We evaluate AgentVigil on two public benchmarks, AgentDojo and VWA-adv, where it achieves 71% and 70% success rates against agents based on o3-mini and GPT-4o, respectively, nearly doubling the performance of baseline attacks. Wang2025Agentvigil (pointer: papers/paper_notes.jsonl:paper_id=P0142#key_results[0])
- Axis: compute and latency constraints; A: Agent frameworks / architectures: `P0126`, `P0008`, `P0030`; B: Tool-use and function calling: `P0081`, `P0146`, `P0155`. Plaat2025Agentic Shi2025Progent Zhang2025Security Weng2025Bridgescope
  - A highlight: (E-P0008-a1fb101bda) Further, agentic LLMs provide a solution for the problem of LLMs running out of training data: inference-time behavior generates new training states, such that LLMs can keep learning without needing ever larger datasets. Plaat2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0008#key_results[1])
  - A highlight: (E-P0086-68db58914f) Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed. Shi2025Progent (pointer: papers/paper_notes.jsonl:paper_id=P0086#key_results[0])
  - B highlight: (E-P0195-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0195#key_results[0])
  - B highlight: (E-P0155-e4be1f69f1) Evaluations on two novel benchmarks demonstrate that BridgeScope enables LLM agents to operate databases more effectively, reduces token usage by up to 80% through improved security awareness, and uniquely supports data-intensive workflows beyond existing toolkits, establishing Weng2025Bridgescope (pointer: papers/paper_notes.jsonl:paper_id=P0155#key_results[0])
- Axis: compute and latency constraints; A: Safety / security / guardrails: `P0058`, `P0129`, `P0142`; B: Tool-use and function calling: `P0081`, `P0146`, `P0155`. Zhang2025Security Wang2025Agentvigil Weng2025Bridgescope
  - A highlight: (E-P0195-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0195#key_results[0])
  - A highlight: (E-P0142-03ed8e82d6) We evaluate AgentVigil on two public benchmarks, AgentDojo and VWA-adv, where it achieves 71% and 70% success rates against agents based on o3-mini and GPT-4o, respectively, nearly doubling the performance of baseline attacks. Wang2025Agentvigil (pointer: papers/paper_notes.jsonl:paper_id=P0142#key_results[0])
  - B highlight: (E-P0195-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0195#key_results[0])
  - B highlight: (E-P0155-e4be1f69f1) Evaluations on two novel benchmarks demonstrate that BridgeScope enables LLM agents to operate databases more effectively, reduces token usage by up to 80% through improved security awareness, and uniquely supports data-intensive workflows beyond existing toolkits, establishing Weng2025Bridgescope (pointer: papers/paper_notes.jsonl:paper_id=P0155#key_results[0])
- Axis: tool interface contract (schemas / protocols); A: Agent frameworks / architectures: `P0126`, `P0008`, `P0030`; B: Safety / security / guardrails: `P0058`, `P0129`, `P0142`. Gasmi2025Bridging Kang2025Acon Zhang2025Security
  - A highlight: (E-P0058-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - A highlight: (E-P0048-108346ac22) Large language models (LLMs) are increasingly deployed as agents in dynamic, real-world environments, where success requires both reasoning and effective tool use. Kang2025Acon (pointer: papers/paper_notes.jsonl:paper_id=P0048#key_results[1])
  - B highlight: (E-P0195-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0195#key_results[0])
  - B highlight: (E-P0058-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
- Axis: tool interface contract (schemas / protocols); A: Agent frameworks / architectures: `P0126`, `P0008`, `P0030`; B: Tool-use and function calling: `P0081`, `P0146`, `P0155`. Gasmi2025Bridging Kang2025Acon Zhang2025Security Weng2025Bridgescope
  - A highlight: (E-P0058-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - A highlight: (E-P0048-108346ac22) Large language models (LLMs) are increasingly deployed as agents in dynamic, real-world environments, where success requires both reasoning and effective tool use. Kang2025Acon (pointer: papers/paper_notes.jsonl:paper_id=P0048#key_results[1])
  - B highlight: (E-P0195-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0195#key_results[0])
  - B highlight: (E-P0155-e4be1f69f1) Evaluations on two novel benchmarks demonstrate that BridgeScope enables LLM agents to operate databases more effectively, reduces token usage by up to 80% through improved security awareness, and uniquely supports data-intensive workflows beyond existing toolkits, establishing Weng2025Bridgescope (pointer: papers/paper_notes.jsonl:paper_id=P0155#key_results[0])
- Axis: tool interface contract (schemas / protocols); A: Safety / security / guardrails: `P0058`, `P0129`, `P0142`; B: Tool-use and function calling: `P0081`, `P0146`, `P0155`. Zhang2025Security Gasmi2025Bridging Weng2025Bridgescope
  - A highlight: (E-P0195-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0195#key_results[0])
  - A highlight: (E-P0058-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - B highlight: (E-P0195-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0195#key_results[0])
  - B highlight: (E-P0155-e4be1f69f1) Evaluations on two novel benchmarks demonstrate that BridgeScope enables LLM agents to operate databases more effectively, reduces token usage by up to 80% through improved security awareness, and uniquely supports data-intensive workflows beyond existing toolkits, establishing Weng2025Bridgescope (pointer: papers/paper_notes.jsonl:paper_id=P0155#key_results[0])
- Axis: tool selection / routing policy; A: Agent frameworks / architectures: `P0126`, `P0008`, `P0030`; B: Safety / security / guardrails: `P0058`, `P0129`, `P0142`. Gasmi2025Bridging Kang2025Acon Zhang2025Security
  - A highlight: (E-P0058-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - A highlight: (E-P0048-108346ac22) Large language models (LLMs) are increasingly deployed as agents in dynamic, real-world environments, where success requires both reasoning and effective tool use. Kang2025Acon (pointer: papers/paper_notes.jsonl:paper_id=P0048#key_results[1])
  - B highlight: (E-P0195-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0195#key_results[0])
  - B highlight: (E-P0058-8e34a29629) Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Gasmi2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])

## Evaluation protocol

- Evaluation mentions include: LLMs, RSP, GSI, RSV, FEVER, RSP-M, HotpotQA, ReAct, ACON, LMs. Liu2026Agents Plaat2025Agentic Zhou2025Reasoning Kang2025Acon
- When comparing results, anchor the paragraph with: task type + metric + constraint (budget, tool access, horizon, or threat model) when stated. Liu2026Agents Plaat2025Agentic
- Prefer head-to-head comparisons only when benchmark/metric are shared; otherwise frame differences as protocol-driven rather than method superiority. Liu2026Agents Plaat2025Agentic
- Avoid underspecified model/baseline naming; if abstracts omit details, state that the baseline is reported but underspecified instead of guessing. Liu2026Agents Plaat2025Agentic
- If a claim relies on a single reported number, pair it with a limitation/caveat from the same evidence so the draft remains conservative. Liu2026Agents Plaat2025Agentic
- If budgets or environments differ across papers, treat cross-paper numeric comparison as fragile and prefer qualitative contrasts aligned to the subsection axes. Liu2026Agents Plaat2025Agentic

## Failures / limitations

- Large language models (LLMs) have precipitated a dramatic improvement in the legal domain, yet the deployment of standalone models faces significant limitations regarding hallucination, outdated information, and verifiability. Liu2026Agents
- We note that there is risk associated with LLM assistants taking action in the real world-safety, liability and security are open problems-while agentic LLMs are also likely to benefit society. Plaat2025Agentic
- While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. Zhou2025Reasoning
- We introduce Generative Style Injection (GSI), an attack method that rewrites retrieved documents into pathological tones--specifically "analysis paralysis" or "cognitive haste"--without altering underlying facts or using explicit triggers. Zhou2025Reasoning
- A central challenge for agentic tasks is the growing context length, as agents must accumulate long histories of actions and observations. Kang2025Acon
- ACON leverages compression guideline optimization in natural language space: given paired trajectories where full context succeeds but compressed context fails, capable LLMs analyze the causes of failure, and the compression guideline is updated accordingly. Kang2025Acon
- Large Language Model (LLM) agents face security vulnerabilities spanning AI-specific and traditional software domains, yet current research addresses these separately. Gasmi2025Bridging
- This study bridges this gap through comparative evaluation of Function Calling architecture and Model Context Protocol (MCP) deployment paradigms using a unified threat classification framework. Gasmi2025Bridging

## Verify fields (non-blocking)

- named benchmarks/datasets used
- metrics/human-eval protocol
- compute/training/inference cost
- training data and supervision signal
- baseline choices and ablation evidence
