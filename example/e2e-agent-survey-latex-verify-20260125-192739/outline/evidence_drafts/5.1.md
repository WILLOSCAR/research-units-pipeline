# Evidence draft: 5.1 Self-improvement and adaptation

## Evidence snippets (with provenance)
- (E-P0144-7d85a7241d) Across agent and domain-specific benchmarks, ACE optimizes contexts both offline (e.g., system prompts) and online (e.g., agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while significantly reducing adaptation latency and rollout cost. Zhang2025Agentic (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0144#key_results[0])
- (E-P0195-8bcb673a7d) We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling. Zhang2025Security (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0195#method)
- (E-P0079-01f439b837) We address this limitation by introducing a framework that enables LLM agents to learn and evolve both before and during test time, equipping them with environment-relevant knowledge for better planning and enhanced communication for improved cooperation. Li2025Learn (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0079#limitations[1])
- (E-P0214-2e6956a116) Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data. Zhou2025Self (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0214#key_results[0])
- (E-P0190-3620ae9178) From the data science perspective, we identify key processes for LLM-based agents, including data preprocessing, model development, evaluation, visualization, etc. Our work offers two key contributions: (1) a comprehensive review of recent developments in applying LLMbased agents to data science tasks; (2) a dual-perspective framework that connects general agent design principles with the practical workflows in data science. Chen2025Largea (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0190#key_results[0])
- (E-P0087-6273763a98) Evaluating on two representative interactive agent tasks, SAND achieves an average 20% improvement over initial supervised finetuning and also outperforms state-of-the-art agent tuning approaches. Xia2025Sand (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0087#key_results[0])
- (E-P0167-047d14c804) The results indicate that 1) all tested LLMs spontaneously misrepresent their actions in at least some conditions, 2) they are generally more likely to do so in situations in which deception would benefit them, and 3) models exhibiting better reasoning capacity overall tend to deceive at higher rates. Taylor2025Large (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0167#key_results[0])
- (E-P0099-33c7e5174b) We review and differentiate the work of LLMs and LLM-based agents from these six topics, examining their differences and similarities in tasks, benchmarks, and evaluation metrics. Jin2024From (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0099#key_results[1])
- (E-P0171-ca050ed55f) We evaluate EpidemIQs across different epidemic scenarios, measuring computational cost, completion success rate, and AI and human expert reviews of generated reports. Samaei2025Epidemiqs (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0171#key_results[1])
- (E-P0187-ec46292a2b) We then propose a taxonomy covering fundamental agent frameworks (single-agent, multi-agent, plan-then-act), modeling approaches (prompt engineering, training-based), and essential datasets and benchmarks. Liu2025Powered (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0187#key_results[0])
- (E-P0042-44dce85d3e) We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. Wei2026Agentic (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0042#key_results[0])
- (E-P0050-f38be5e04b) It outlines the general workflow of the task and establishes a taxonomy across three dimensions: benchmarks, techniques, and empirical studies. Jiang2025Agentic (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0050#key_results[1])
- (E-P0133-a68f39bc04) This survey provides a comprehensive overview of foundation models, agentic systems, datasets, and computational tools supporting this growing field. Van2025Survey (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0133#key_results[0])
- (E-P0180-af945eb2fa) We evaluate these strategies across diverse agentic benchmarks, including function calling and web navigation. Chen2025Grounded (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0180#key_results[1])
- (E-P0051-eae2720c71) Settlers of Catan provides a challenging benchmark: success depends on balancing short- and long-term goals amid randomness, trading, expansion, and blocking. Belle2025Agents (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0051#key_results[1])
- (E-P0260-76aa5df0e2) We conducted extensive experiments and the results show that FICAL has competitive performance compared to other SOTA baselines with a significant communication cost decrease of $\mathbf{3.33\times10^5}$ times. Wu2024Federated (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0260#key_results[0])
- (E-P0205-85b5f3734b) Empirical results averaged across models show major improvements in task success, with absolute gains of +10.3% on ALFWorld, +23.8% on BabyAI, and +8.3% on PDDL in the Self-sustaining mode. Bharadwaj2025Omnireflect (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0205#key_results[0])
- (E-P0261-3e23cb8c51) We categorize the simulations into three types: (1) Individual Simulation, which mimics specific individuals or demographic groups; (2) Scenario Simulation, where multiple agents collaborate to achieve goals within specific contexts; and (3) Society Simulation, which models interactions within agent societies to reflect the complexity and variety of real-world dynamics. Mou2024From (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0261#key_results[0])

## Definitions / setup

- Setup: Which design choices in Self-improvement and adaptation drive the major trade-offs, and how are those trade-offs measured? Scope: in-scope: Core topics directly relevant to 'Self-improvement and adaptation'.. Axes: evaluation protocol (datasets, metrics, human evaluation); compute and latency constraints; communication protocol / roles; aggregation (vote / debate / referee); stability / robustness. Wei2026Agentic Jiang2025Agentic Belle2025Agents

## Claim candidates

- Across agent and domain-specific benchmarks, ACE optimizes contexts both offline (e.g., system prompts) and online (e.g., agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while significantly reducing adaptation latency and rollout cost. Zhang2025Agentic
- We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling. Zhang2025Security
- We address this limitation by introducing a framework that enables LLM agents to learn and evolve both before and during test time, equipping them with environment-relevant knowledge for better planning and enhanced communication for improved cooperation. Li2025Learn
- Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data. Zhou2025Self
- From the data science perspective, we identify key processes for LLM-based agents, including data preprocessing, model development, evaluation, visualization, etc. Chen2025Largea

## Concrete comparisons

- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Agent frameworks / architectures: `P0042`, `P0050`, `P0051`; B: Planning / reasoning loops: `P0042`, `P0051`, `P0136`. Van2025Survey Zhang2025Agentic Wei2026Agentic Belle2025Agents
  - A highlight: (E-P0133-a68f39bc04) This survey provides a comprehensive overview of foundation models, agentic systems, datasets, and computational tools supporting this growing field. Van2025Survey (pointer: papers/paper_notes.jsonl:paper_id=P0133#key_results[0])
  - A highlight: (E-P0144-7d85a7241d) Across agent and domain-specific benchmarks, ACE optimizes contexts both offline (e.g., system prompts) and online (e.g., agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while significantly reducing adaptation latency and Zhang2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0144#key_results[0])
  - B highlight: (E-P0042-44dce85d3e) We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. Wei2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0042#key_results[0])
  - B highlight: (E-P0051-eae2720c71) Settlers of Catan provides a challenging benchmark: success depends on balancing short- and long-term goals amid randomness, trading, expansion, and blocking. Belle2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0051#key_results[1])
- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Agent frameworks / architectures: `P0042`, `P0050`, `P0051`; B: Code agents / software tasks: `P0050`, `P0221`, `P0099`. Van2025Survey Zhang2025Agentic Jin2024From Jiang2025Agentic
  - A highlight: (E-P0133-a68f39bc04) This survey provides a comprehensive overview of foundation models, agentic systems, datasets, and computational tools supporting this growing field. Van2025Survey (pointer: papers/paper_notes.jsonl:paper_id=P0133#key_results[0])
  - A highlight: (E-P0144-7d85a7241d) Across agent and domain-specific benchmarks, ACE optimizes contexts both offline (e.g., system prompts) and online (e.g., agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while significantly reducing adaptation latency and Zhang2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0144#key_results[0])
  - B highlight: (E-P0099-33c7e5174b) We review and differentiate the work of LLMs and LLM-based agents from these six topics, examining their differences and similarities in tasks, benchmarks, and evaluation metrics. Jin2024From (pointer: papers/paper_notes.jsonl:paper_id=P0099#key_results[1])
  - B highlight: (E-P0050-f38be5e04b) It outlines the general workflow of the task and establishes a taxonomy across three dimensions: benchmarks, techniques, and empirical studies. Jiang2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0050#key_results[1])
- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Planning / reasoning loops: `P0042`, `P0051`, `P0136`; B: Code agents / software tasks: `P0050`, `P0221`, `P0099`. Wei2026Agentic Belle2025Agents Jin2024From Jiang2025Agentic
  - A highlight: (E-P0042-44dce85d3e) We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. Wei2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0042#key_results[0])
  - A highlight: (E-P0051-eae2720c71) Settlers of Catan provides a challenging benchmark: success depends on balancing short- and long-term goals amid randomness, trading, expansion, and blocking. Belle2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0051#key_results[1])
  - B highlight: (E-P0099-33c7e5174b) We review and differentiate the work of LLMs and LLM-based agents from these six topics, examining their differences and similarities in tasks, benchmarks, and evaluation metrics. Jin2024From (pointer: papers/paper_notes.jsonl:paper_id=P0099#key_results[1])
  - B highlight: (E-P0050-f38be5e04b) It outlines the general workflow of the task and establishes a taxonomy across three dimensions: benchmarks, techniques, and empirical studies. Jiang2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0050#key_results[1])
- Axis: compute and latency constraints; A: Agent frameworks / architectures: `P0042`, `P0050`, `P0051`; B: Planning / reasoning loops: `P0042`, `P0051`, `P0136`. Zhang2025Agentic Li2025Learn Wei2026Agentic Belle2025Agents
  - A highlight: (E-P0144-7d85a7241d) Across agent and domain-specific benchmarks, ACE optimizes contexts both offline (e.g., system prompts) and online (e.g., agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while significantly reducing adaptation latency and Zhang2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0144#key_results[0])
  - A highlight: (E-P0079-01f439b837) We address this limitation by introducing a framework that enables LLM agents to learn and evolve both before and during test time, equipping them with environment-relevant knowledge for better planning and enhanced communication for improved cooperation. Li2025Learn (pointer: papers/paper_notes.jsonl:paper_id=P0079#limitations[1])
  - B highlight: (E-P0042-44dce85d3e) We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. Wei2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0042#key_results[0])
  - B highlight: (E-P0051-eae2720c71) Settlers of Catan provides a challenging benchmark: success depends on balancing short- and long-term goals amid randomness, trading, expansion, and blocking. Belle2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0051#key_results[1])
- Axis: compute and latency constraints; A: Agent frameworks / architectures: `P0042`, `P0050`, `P0051`; B: Code agents / software tasks: `P0050`, `P0221`, `P0099`. Zhang2025Agentic Li2025Learn Jin2024From Jiang2025Agentic
  - A highlight: (E-P0144-7d85a7241d) Across agent and domain-specific benchmarks, ACE optimizes contexts both offline (e.g., system prompts) and online (e.g., agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while significantly reducing adaptation latency and Zhang2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0144#key_results[0])
  - A highlight: (E-P0079-01f439b837) We address this limitation by introducing a framework that enables LLM agents to learn and evolve both before and during test time, equipping them with environment-relevant knowledge for better planning and enhanced communication for improved cooperation. Li2025Learn (pointer: papers/paper_notes.jsonl:paper_id=P0079#limitations[1])
  - B highlight: (E-P0099-33c7e5174b) We review and differentiate the work of LLMs and LLM-based agents from these six topics, examining their differences and similarities in tasks, benchmarks, and evaluation metrics. Jin2024From (pointer: papers/paper_notes.jsonl:paper_id=P0099#key_results[1])
  - B highlight: (E-P0050-f38be5e04b) It outlines the general workflow of the task and establishes a taxonomy across three dimensions: benchmarks, techniques, and empirical studies. Jiang2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0050#key_results[1])
- Axis: compute and latency constraints; A: Planning / reasoning loops: `P0042`, `P0051`, `P0136`; B: Code agents / software tasks: `P0050`, `P0221`, `P0099`. Wei2026Agentic Belle2025Agents Jin2024From Jiang2025Agentic
  - A highlight: (E-P0042-44dce85d3e) We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. Wei2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0042#key_results[0])
  - A highlight: (E-P0051-eae2720c71) Settlers of Catan provides a challenging benchmark: success depends on balancing short- and long-term goals amid randomness, trading, expansion, and blocking. Belle2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0051#key_results[1])
  - B highlight: (E-P0099-33c7e5174b) We review and differentiate the work of LLMs and LLM-based agents from these six topics, examining their differences and similarities in tasks, benchmarks, and evaluation metrics. Jin2024From (pointer: papers/paper_notes.jsonl:paper_id=P0099#key_results[1])
  - B highlight: (E-P0050-f38be5e04b) It outlines the general workflow of the task and establishes a taxonomy across three dimensions: benchmarks, techniques, and empirical studies. Jiang2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0050#key_results[1])
- Axis: communication protocol / roles; A: Agent frameworks / architectures: `P0042`, `P0050`, `P0051`; B: Planning / reasoning loops: `P0042`, `P0051`, `P0136`. Van2025Survey Zhang2025Agentic Wei2026Agentic Belle2025Agents
  - A highlight: (E-P0133-a68f39bc04) This survey provides a comprehensive overview of foundation models, agentic systems, datasets, and computational tools supporting this growing field. Van2025Survey (pointer: papers/paper_notes.jsonl:paper_id=P0133#key_results[0])
  - A highlight: (E-P0144-7d85a7241d) Across agent and domain-specific benchmarks, ACE optimizes contexts both offline (e.g., system prompts) and online (e.g., agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while significantly reducing adaptation latency and Zhang2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0144#key_results[0])
  - B highlight: (E-P0042-44dce85d3e) We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. Wei2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0042#key_results[0])
  - B highlight: (E-P0051-eae2720c71) Settlers of Catan provides a challenging benchmark: success depends on balancing short- and long-term goals amid randomness, trading, expansion, and blocking. Belle2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0051#key_results[1])
- Axis: communication protocol / roles; A: Agent frameworks / architectures: `P0042`, `P0050`, `P0051`; B: Code agents / software tasks: `P0050`, `P0221`, `P0099`. Van2025Survey Zhang2025Agentic Jin2024From Jiang2025Agentic
  - A highlight: (E-P0133-a68f39bc04) This survey provides a comprehensive overview of foundation models, agentic systems, datasets, and computational tools supporting this growing field. Van2025Survey (pointer: papers/paper_notes.jsonl:paper_id=P0133#key_results[0])
  - A highlight: (E-P0144-7d85a7241d) Across agent and domain-specific benchmarks, ACE optimizes contexts both offline (e.g., system prompts) and online (e.g., agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while significantly reducing adaptation latency and Zhang2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0144#key_results[0])
  - B highlight: (E-P0099-33c7e5174b) We review and differentiate the work of LLMs and LLM-based agents from these six topics, examining their differences and similarities in tasks, benchmarks, and evaluation metrics. Jin2024From (pointer: papers/paper_notes.jsonl:paper_id=P0099#key_results[1])
  - B highlight: (E-P0050-f38be5e04b) It outlines the general workflow of the task and establishes a taxonomy across three dimensions: benchmarks, techniques, and empirical studies. Jiang2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0050#key_results[1])
- Axis: communication protocol / roles; A: Planning / reasoning loops: `P0042`, `P0051`, `P0136`; B: Code agents / software tasks: `P0050`, `P0221`, `P0099`. Wei2026Agentic Belle2025Agents Jin2024From Jiang2025Agentic
  - A highlight: (E-P0042-44dce85d3e) We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. Wei2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0042#key_results[0])
  - A highlight: (E-P0051-eae2720c71) Settlers of Catan provides a challenging benchmark: success depends on balancing short- and long-term goals amid randomness, trading, expansion, and blocking. Belle2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0051#key_results[1])
  - B highlight: (E-P0099-33c7e5174b) We review and differentiate the work of LLMs and LLM-based agents from these six topics, examining their differences and similarities in tasks, benchmarks, and evaluation metrics. Jin2024From (pointer: papers/paper_notes.jsonl:paper_id=P0099#key_results[1])
  - B highlight: (E-P0050-f38be5e04b) It outlines the general workflow of the task and establishes a taxonomy across three dimensions: benchmarks, techniques, and empirical studies. Jiang2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0050#key_results[1])
- Axis: aggregation (vote / debate / referee); A: Agent frameworks / architectures: `P0042`, `P0050`, `P0051`; B: Planning / reasoning loops: `P0042`, `P0051`, `P0136`. Zhang2025Agentic Li2025Learn Wei2026Agentic Belle2025Agents
  - A highlight: (E-P0144-7d85a7241d) Across agent and domain-specific benchmarks, ACE optimizes contexts both offline (e.g., system prompts) and online (e.g., agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while significantly reducing adaptation latency and Zhang2025Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0144#key_results[0])
  - A highlight: (E-P0079-01f439b837) We address this limitation by introducing a framework that enables LLM agents to learn and evolve both before and during test time, equipping them with environment-relevant knowledge for better planning and enhanced communication for improved cooperation. Li2025Learn (pointer: papers/paper_notes.jsonl:paper_id=P0079#limitations[1])
  - B highlight: (E-P0042-44dce85d3e) We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. Wei2026Agentic (pointer: papers/paper_notes.jsonl:paper_id=P0042#key_results[0])
  - B highlight: (E-P0051-eae2720c71) Settlers of Catan provides a challenging benchmark: success depends on balancing short- and long-term goals amid randomness, trading, expansion, and blocking. Belle2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0051#key_results[1])

## Evaluation protocol

- Evaluation mentions include: LLMs, LLM-based, ReAct, HexMachina, AlphaBeta, LIET, LLaMA, GPT-4o, ThreeD-World, MARL. Wei2026Agentic Jiang2025Agentic Belle2025Agents Li2025Learn
- When comparing results, anchor the paragraph with: task type + metric + constraint (budget, tool access, horizon, or threat model) when stated. Wei2026Agentic Jiang2025Agentic
- Prefer head-to-head comparisons only when benchmark/metric are shared; otherwise frame differences as protocol-driven rather than method superiority. Wei2026Agentic Jiang2025Agentic
- Avoid underspecified model/baseline naming; if abstracts omit details, state that the baseline is reported but underspecified instead of guessing. Wei2026Agentic Jiang2025Agentic
- If a claim relies on a single reported number, pair it with a limitation/caveat from the same evidence so the draft remains conservative. Wei2026Agentic Jiang2025Agentic
- If budgets or environments differ across papers, treat cross-paper numeric comparison as fragile and prefer qualitative contrasts aligned to the subsection axes. Wei2026Agentic Jiang2025Agentic

## Failures / limitations

- We address this limitation by introducing a framework that enables LLM agents to learn and evolve both before and during test time, equipping them with environment-relevant knowledge for better planning and enhanced communication for improved cooperation. Li2025Learn
- The survey begins by analyzing current LLM limitations, such as hallucinations and the lack of internal self-assessment mechanisms. Bilal2025Meta
- It then talks about newer methods, including RL from human feedback (RLHF), self-distillation, and chain-of-thought prompting, and each of their limitations. Bilal2025Meta
- We assess the early successes of foundation models and identify persistent limitations, including challenges in generalizability, interpretability, data imbalance, safety concerns, and limited multimodal fusion. Van2025Survey
- On the AppWorld leaderboard, ACE matches the top-ranked production-level agent on the overall average and surpasses it on the harder test-challenge split, despite using a smaller open-source model. Zhang2025Agentic
- The article concludes by outlining open challenges, potential security risks, and promising directions for advancing robust, interoperable, and scalable multi-agent LLM ecosystems. Sarkar2025Survey
- However, they also exhibit numerous limitations and shortcomings. Jin2024From
- LLM-based agents, a novel tech nology with the potential for Artificial General Intelligence (AGI), combine LLMs as the core for decision-making and action-taking, addressing some of the inherent limitations of LLMs such as lack of autonomy and self-improvement. Jin2024From

## Verify fields (non-blocking)

- named benchmarks/datasets used
- metrics/human-eval protocol
- compute/training/inference cost
- training data and supervision signal
- baseline choices and ablation evidence
