From the perspective of deployed agents, safety and security are not add-on concerns; they are consequences of interface choices and protocol assumptions. Tool use expands the attack surface through prompt injection, data exfiltration, and privilege misuse, and tool protocols and permission models can largely determine the effective risk profile even for the same underlying agent loop [@Zhang2025Security; @Gasmi2025Bridging]. Governance therefore requires protocol-aware evaluation: threat models, system boundaries, and monitoring assumptions must be represented in the evaluation contract, not deferred to informal caveats [@Weng2025Bridgescope; @Zhang2025Security].

Threat models for tool-using agents are shaped by the agent-tool communication loop. Attacks can target tool descriptions, tool arguments, retrieval channels, or error-handling logic, exploiting the fact that agents treat tool outputs as part of their observation stream [@Zhang2025Security; @Gasmi2025Bridging]. This implies that "robustness" cannot be assessed without specifying what tools exist, what the agent is allowed to call, and what information is trusted after a call [@Gasmi2025Bridging; @Weng2025Bridgescope].

Comparative evaluations illustrate that protocol choice changes both capability and vulnerability. One analysis reports higher overall attack success rates under function calling than under MCP (73.5% vs 62.59%), while also distinguishing system-centric and LLM-centric exposure patterns under these protocols [@Gasmi2025Bridging]. Such numbers are only interpretable when the protocol defines attack channels and system boundaries, reinforcing that security results must be read as protocol-contingent rather than universal [@Gasmi2025Bridging; @Zhang2025Security].

Taxonomies make this dependence explicit. MSB contributes an attack taxonomy with a dozen attack types (including name collision and tool-description prompt injection variants) and evaluates resistance throughout the tool-use pipeline, covering planning, invocation, and response handling [@Zhang2025Security]. This pipeline-level framing is important because failures often arise from interactions among components rather than from a single prompt vulnerability [@Zhang2025Security; @Plaat2025Agentic].

Defensive systems highlight that mitigation can change both security and system efficiency under realistic workflows. BridgeScope reports enabling agents to operate databases more effectively while reducing token usage by up to 80% through improved security awareness, illustrating that protocol-aware defenses can trade small interface restrictions for large safety and efficiency gains [@Weng2025Bridgescope]. For synthesis, such results should be tied to the workflow protocol (what queries and tools are allowed, what logging exists) rather than treated as generic "agent safety" improvements [@Weng2025Bridgescope; @Gasmi2025Bridging].

End-to-end defenses can also be benchmarked directly. Progent reports reducing attack success rates to 0% across multiple agent use cases and benchmarks while preserving utility and speed, suggesting that defenses can be evaluated under comparable protocols instead of relying on ad hoc red teaming anecdotes [@Shi2025Progent]. This style of benchmark-driven security evaluation is essential for governance because it supports reproducible, testable claims about mitigations [@Shi2025Progent; @Zhang2025Security].

Monitoring and cost-aware attacks expose additional governance constraints. Some attacks operate at the tool layer under the guise of correct task completion, inflating token usage, monetary cost, and energy consumption, which can be as damaging as capability compromise in deployed systems [@Mo2025Attractive; @Gao2025Radar]. These failure modes motivate reporting and enforcing budget policies and detection mechanisms as part of the protocol, not as optional operational folklore [@Bonagiri2025Check; @Gao2025Radar].

In contrast to threat models that focus only on correctness, governance-oriented evaluations often require monitoring and auditing: which actions were taken, under what permissions, and what signals a system used to decide that an interaction remained safe. Monitoring systems and checklists for agent operations provide concrete guidance on how to instrument such protocols so violations are detectable rather than implicit [@Wang2025Agentvigil; @Bonagiri2025Check].

Governance considerations extend beyond technical mitigations to domain and compliance constraints. Surveys of domain deployments (e.g., agents in specialized professional workflows) emphasize that accountability, auditability, and policy boundaries are often the limiting factors, even when nominal task success is achievable [@Liu2026Agents; @Han2025Large]. This pattern indicates that evaluation protocols for governance should include traceability and controllability metrics, not just task success [@Plaat2025Agentic; @Zhang2025Generalizability].

Across security benchmarks and defensive systems, a consistent synthesis is that risk is interface-dependent. Protocols that expose more powerful actions without corresponding observability and guardrails can increase both capability and vulnerability, whereas stricter protocols can improve reliability at the cost of expressivity [@Gasmi2025Bridging; @Zhang2025Security; @Weng2025Bridgescope]. As a result, governance arguments should be framed as design trade-offs that depend on explicit threat models and constraints, not as generic prescriptions for "safe agents" [@Zhang2025Security; @Plaat2025Agentic].

One limitation is that many security evaluations are still fragmented across incompatible benchmarks and tool stacks, making it difficult to aggregate evidence without strong protocol alignment [@Zhang2025Security; @Gasmi2025Bridging]. Another is that governance requires coupling security evaluation with the broader evaluation ecosystem: defenses must be assessed under the same budgets, tool access assumptions, and environment constraints as capability claims, or else improvements will not transfer to deployment [@Shi2025Progent; @Weng2025Bridgescope].
