{"kind": "h3", "id": "3.1", "title": "Agent loop and action spaces", "section_id": "3", "section_title": "Foundations & Interfaces", "section_role": "mechanism + evaluation_lens", "depends_on": ["Global scope + definitions (agent, tool use, protocol context)", "Chapter lens: Foundations & Interfaces"], "adds": ["Subsection lens: Agent loop and action spaces", "A reusable contrast/protocol constraint for downstream synthesis"], "paragraphs": [{"i": 1, "moves": ["claim", "contrast", "justification"], "output": "A central tension in agent loops is that richer action spaces promise broader capability but they also make"}, {"i": 2, "moves": ["definition_setup", "contrast", "justification"], "output": "An agent loop can be modeled as a repeated state-decide-act-observe cycle but the semantics of act vary widely"}, {"i": 3, "moves": ["justification"], "output": "Action spaces are inseparable from the observation model If observations are lossy or delayed agents may rely on"}, {"i": 4, "moves": ["justification"], "output": "The benchmark landscape itself reveals why protocol context matters A broad survey of agent evaluation spans 190 benchmark"}, {"i": 5, "moves": ["justification"], "output": "Recent benchmark-driven agent frameworks illustrate the consequence of wide heterogeneous evaluation AgentSwift evaluates across seven benchmarks spanning embodied"}, {"i": 6, "moves": ["contrast", "boundary_failure", "justification"], "output": "Targeted dataset design provides a complementary angle in contrast to broad benchmark suites some work introduces bespoke datasets"}, {"i": 7, "moves": ["contrast", "boundary_failure", "justification"], "output": "Security and robustness further complicate the notion of an action space Memory and tool interactions can act as"}, {"i": 8, "moves": ["justification", "local_conclusion"], "output": "Compute latency and monetary cost impose another unavoidable constraint The agent system trilemma formalizes the tension among state-of-the-art"}, {"i": 9, "moves": ["justification", "local_conclusion"], "output": "Across these threads a consistent pattern is that evaluation and action design co-determine each other Loop abstractions that"}, {"i": 10, "moves": ["contrast", "boundary_failure", "justification", "local_conclusion"], "output": "One limitation is that many papers still underspecify protocol details budgets tool access visibility which forces any survey-level"}]}
{"kind": "h3", "id": "3.2", "title": "Tool interfaces and orchestration", "section_id": "3", "section_title": "Foundations & Interfaces", "section_role": "interface_contract + protocol_lens", "depends_on": ["Global scope + definitions (agent, tool use, protocol context)", "Chapter lens: Foundations & Interfaces"], "adds": ["Subsection lens: Tool interfaces and orchestration", "A reusable contrast/protocol constraint for downstream synthesis"], "paragraphs": [{"i": 1, "moves": ["claim", "contrast", "justification"], "output": "For system builders the crux of tool interface design is choosing how much expressivity to expose while keeping"}, {"i": 2, "moves": ["justification"], "output": "Tool interfaces range from free-form natural-language tool descriptions to structured function signatures and protocolized multi-tool stacks As interfaces"}, {"i": 3, "moves": ["justification"], "output": "Concrete protocolized systems illustrate how evaluation must name the interface details MemTool evaluates multiple tool modes across 13"}, {"i": 4, "moves": ["contrast", "justification", "local_conclusion"], "output": "Complementing system-driven evaluations benchmark and dataset audits provide a map of what is actually being measured An analysis"}, {"i": 5, "moves": ["contrast", "justification"], "output": "A useful contrast is between protocol-first tool stacks and ad hoc tool calling Protocolized interfaces can make tool"}, {"i": 6, "moves": ["contrast", "justification"], "output": "Retrieval-augmented orchestration provides another contrast class In contrast to ad hoc tool calling systems such as AvaTaR exploit"}, {"i": 7, "moves": ["justification"], "output": "Classic reasoning-action interleaving remains a useful baseline for tool interface discussions because it exposes how interface constraints change"}, {"i": 8, "moves": ["boundary_failure", "justification"], "output": "Security and cost failures can originate directly from the agent-tool communication loop The interface is a critical attack"}, {"i": 9, "moves": ["boundary_failure", "justification", "local_conclusion"], "output": "Across these studies the most stable synthesis is to compare orchestration choices within shared protocol envelopes and to"}, {"i": 10, "moves": ["boundary_failure", "justification", "local_conclusion"], "output": "One limitation is that interface descriptions often omit operational constraints permissioning sandbox boundaries failure recovery which makes post"}]}
{"kind": "h3", "id": "4.1", "title": "Planning and reasoning loops", "section_id": "4", "section_title": "Core Components (Planning + Memory)", "section_role": "planning_mechanisms + tradeoffs", "depends_on": ["Global scope + definitions (agent, tool use, protocol context)", "Chapter lens: Core Components (Planning + Memory)"], "adds": ["Subsection lens: Planning and reasoning loops", "A reusable contrast/protocol constraint for downstream synthesis"], "paragraphs": [{"i": 1, "moves": ["claim", "contrast", "justification"], "output": "Results in planning-heavy agent loops are only comparable when the evaluation protocol is explicit task family metric interaction"}, {"i": 2, "moves": ["justification"], "output": "Planning and reasoning loops cover a spectrum of mechanisms that decide what to do next and how to"}, {"i": 3, "moves": ["contrast", "justification"], "output": "A useful contrast is between training-based planners and steering-based planners Training can bake in long-horizon behaviors and reduce"}, {"i": 4, "moves": ["justification"], "output": "Concrete evidence of protocol sensitivity appears in planning benchmarks A 1 5B-parameter model trained with single-turn GRPO reports"}, {"i": 5, "moves": ["contrast", "justification"], "output": "Benchmark construction further shapes what planning means USTBench evaluates spatiotemporal reasoning as an urban-agent capability across multiple dimensions"}, {"i": 6, "moves": ["justification"], "output": "Planning often interacts with tool use and code in ways that undermine naive comparisons Some tasks that appear"}, {"i": 7, "moves": ["justification", "local_conclusion"], "output": "Memory and retrieval can make planning look better or worse depending on how evidence is supplied to the"}, {"i": 8, "moves": ["contrast", "boundary_failure", "justification"], "output": "Failure modes in reasoning loops can also be adversarial rather than purely capability-driven Process-oriented attacks that target reasoning"}, {"i": 9, "moves": ["justification"], "output": "Finally planning loops are often evaluated in settings that implicitly assume structured knowledge and controllable environments these assumptions"}, {"i": 10, "moves": ["contrast", "boundary_failure", "justification", "local_conclusion"], "output": "One limitation is that planning comparisons are frequently confounded by unreported protocol details budgets tool access verification which"}]}
{"kind": "h3", "id": "4.2", "title": "Memory and retrieval (RAG)", "section_id": "4", "section_title": "Core Components (Planning + Memory)", "section_role": "memory_retrieval + failure_modes", "depends_on": ["Global scope + definitions (agent, tool use, protocol context)", "Chapter lens: Core Components (Planning + Memory)"], "adds": ["Subsection lens: Memory and retrieval (RAG)", "A reusable contrast/protocol constraint for downstream synthesis"], "paragraphs": [{"i": 1, "moves": ["claim", "contrast", "justification"], "output": "Seen through the lens of long-horizon agency memory is not an optional enhancement but a constraint that reshapes"}, {"i": 2, "moves": ["contrast", "justification"], "output": "Memory mechanisms range from retrieval-augmented prompting to persistent stores that act as long-lived state Retrieval can be treated"}, {"i": 3, "moves": ["justification"], "output": "Concrete systems illustrate how memory control can be operationalized MemR 3 treats memory retrieval as an autonomous component"}, {"i": 4, "moves": ["justification"], "output": "Interactive benchmarks show why memory cannot be evaluated in isolation In ReAct-style loops decisions are conditioned on a"}, {"i": 5, "moves": ["contrast", "justification"], "output": "A useful contrast is between memory systems that prioritize breadth of context and those that prioritize structured verified"}, {"i": 6, "moves": ["contrast", "justification"], "output": "Error-taxonomy and failure-trajectory datasets make these issues more concrete AgentErrorTaxonomy and AgentErrorBench classify failures across memory reflection planning"}, {"i": 7, "moves": ["boundary_failure", "justification"], "output": "Security concerns are especially salient for memory If memory is treated as a writable store that future decisions"}, {"i": 8, "moves": ["contrast", "boundary_failure", "justification"], "output": "Defenses therefore need to be evaluated as loop components A-MemGuard reports large reductions in attack success rates over"}, {"i": 9, "moves": ["contrast", "boundary_failure", "justification"], "output": "Across recent surveys and component taxonomies memory and retrieval are increasingly treated as core axes for agents but"}, {"i": 10, "moves": ["boundary_failure", "justification", "local_conclusion"], "output": "One limitation is that many papers report memory mechanisms without exposing enough provenance or trust signals to support"}]}
{"kind": "h3", "id": "5.1", "title": "Self-improvement and adaptation", "section_id": "5", "section_title": "Learning, Adaptation & Coordination", "section_role": "adaptation_loops + stability_risks", "depends_on": ["Global scope + definitions (agent, tool use, protocol context)", "Chapter lens: Learning, Adaptation & Coordination"], "adds": ["Subsection lens: Self-improvement and adaptation", "A reusable contrast/protocol constraint for downstream synthesis"], "paragraphs": [{"i": 1, "moves": ["claim", "boundary_failure", "justification"], "output": "For system builders the key decision in self-improvement is how much the agent is allowed to change under"}, {"i": 2, "moves": ["justification"], "output": "Self-improvement and adaptation mechanisms include prompt and context optimization reflection and revision loops and learning procedures that update"}, {"i": 3, "moves": ["contrast", "justification"], "output": "Context optimization provides a concrete protocol-aware form of adaptation ACE reports optimizing contexts both offline e g system"}, {"i": 4, "moves": ["contrast", "boundary_failure", "justification"], "output": "Self-challenging and self-generated training data highlight a different trade-off In contrast to one-shot prompt tuning a self-challenging framework"}, {"i": 5, "moves": ["justification"], "output": "More general learning frameworks attempt to expand beyond prompt-level tuning by enabling agents to learn and evolve before"}, {"i": 6, "moves": ["contrast", "justification"], "output": "A useful contrast is between adaptation that primarily changes the agent s context and adaptation that changes the"}, {"i": 7, "moves": ["boundary_failure", "justification", "local_conclusion"], "output": "Evaluation protocols for adaptation must also address what is being optimized Surveys of foundation-model limitations emphasize issues such"}, {"i": 8, "moves": ["boundary_failure", "justification"], "output": "Security is an especially important axis for self-improvement Adaptation mechanisms can amplify vulnerabilities by internalizing adversarial signals or"}, {"i": 9, "moves": ["justification", "local_conclusion"], "output": "Across the literature adaptation also interacts with multi-agent settings and system architecture Agent evolution can change communication policies"}, {"i": 10, "moves": ["boundary_failure", "justification", "local_conclusion"], "output": "One limitation is that many adaptation papers report gains without sufficiently specifying update budgets and feedback channels which"}]}
{"kind": "h3", "id": "5.2", "title": "Multi-agent coordination", "section_id": "5", "section_title": "Learning, Adaptation & Coordination", "section_role": "coordination_protocols + aggregation_failures", "depends_on": ["Global scope + definitions (agent, tool use, protocol context)", "Chapter lens: Learning, Adaptation & Coordination"], "adds": ["Subsection lens: Multi-agent coordination", "A reusable contrast/protocol constraint for downstream synthesis"], "paragraphs": [{"i": 1, "moves": ["claim", "contrast", "justification"], "output": "A sharp contrast in agent design is between single-agent loops that internalize all decisions whereas multi-agent systems distribute"}, {"i": 2, "moves": ["justification"], "output": "Multi-agent coordination mechanisms include role specialization planner verifier executor communication protocols messages shared memory structured schemas and aggregation"}, {"i": 3, "moves": ["justification"], "output": "Rubric-based evaluation provides one way to make coordination protocols explicit ARCANE is evaluated on tasks requiring multi-step reasoning"}, {"i": 4, "moves": ["contrast", "justification"], "output": "Coordination is also tested in collaborative settings where agents must share observations negotiate roles and recover from each"}, {"i": 5, "moves": ["justification"], "output": "Domain-specific multi-agent systems further illustrate how protocol assumptions become part of the method In a drug-discovery setting a"}, {"i": 6, "moves": ["contrast", "justification"], "output": "Evaluation settings can also involve multi-agent scoring and assessment AutoSCORE is evaluated on multiple datasets from the ASAP"}, {"i": 7, "moves": ["contrast", "justification"], "output": "Security verification offers a complementary coordination pattern centralized supervision with delegated execution MARVEL uses a supervisor agent that"}, {"i": 8, "moves": ["contrast", "justification"], "output": "A useful architectural contrast is centralized supervision versus more decentralized coordination Centralized designs can simplify protocol design and"}, {"i": 9, "moves": ["justification", "local_conclusion"], "output": "Across these studies multi-agent systems tend to trade raw capability for controllability and verification Systems that embed critics"}, {"i": 10, "moves": ["boundary_failure", "justification", "local_conclusion"], "output": "One limitation is that coordination methods often face scalability and real-time response constraints which means that improvements observed"}]}
{"kind": "h3", "id": "6.1", "title": "Benchmarks and evaluation protocols", "section_id": "6", "section_title": "Evaluation & Risks", "section_role": "benchmark_protocols + comparability", "depends_on": ["Global scope + definitions (agent, tool use, protocol context)", "Chapter lens: Evaluation & Risks"], "adds": ["Subsection lens: Benchmarks and evaluation protocols", "A reusable contrast/protocol constraint for downstream synthesis"], "paragraphs": [{"i": 1, "moves": ["claim", "contrast", "justification"], "output": "A practical decision for evaluating agents is what to treat as success and what constraints to enforce while"}, {"i": 2, "moves": ["justification", "local_conclusion"], "output": "Benchmark suites increasingly span heterogeneous domains web interaction embodied control tool use code and multi-agent coordination This breadth"}, {"i": 3, "moves": ["contrast", "justification"], "output": "Concrete examples illustrate the sensitivity to model access and infrastructure DataSciBench reports that API-based models outperform open-source models"}, {"i": 4, "moves": ["justification"], "output": "Cost and latency constraints are themselves evaluation axes EvoRoute reports that when integrated into off-the-shelf agentic systems it"}, {"i": 5, "moves": ["boundary_failure", "justification"], "output": "Security and robustness benchmarks make protocol design even more explicit by including adversarial interactions Progent reports reducing attack"}, {"i": 6, "moves": ["contrast", "justification"], "output": "Efficiency and long-context constraints are also becoming first-class evaluation targets ACBench spans multiple tasks capabilities and model variants"}, {"i": 7, "moves": ["contrast", "justification"], "output": "Simulated environments and agent behavior suites provide another evaluation route Simulators can stress multi-step interaction patterns and reveal"}, {"i": 8, "moves": ["contrast", "boundary_failure", "justification", "local_conclusion"], "output": "Several surveys of evaluation practice emphasize recurring pitfalls benchmark leakage implicit tool access assumptions and metrics that do"}, {"i": 9, "moves": ["contrast", "justification"], "output": "Across benchmark suites protocol papers and surveys a consistent theme is that comparability requires explicit protocol anchors When"}, {"i": 10, "moves": ["boundary_failure", "justification", "local_conclusion"], "output": "One limitation is that protocol reporting is still inconsistent especially for tool access costs and environment versions which"}]}
{"kind": "h3", "id": "6.2", "title": "Safety, security, and governance", "section_id": "6", "section_title": "Evaluation & Risks", "section_role": "safety_security_governance + threat_models", "depends_on": ["Global scope + definitions (agent, tool use, protocol context)", "Chapter lens: Evaluation & Risks"], "adds": ["Subsection lens: Safety, security, and governance", "A reusable contrast/protocol constraint for downstream synthesis"], "paragraphs": [{"i": 1, "moves": ["claim", "boundary_failure", "justification"], "output": "From the perspective of deployed agents safety and security are not add-on concerns they are consequences of interface"}, {"i": 2, "moves": ["boundary_failure", "justification"], "output": "Threat models for tool-using agents are shaped by the agent-tool communication loop Attacks can target tool descriptions tool"}, {"i": 3, "moves": ["contrast", "boundary_failure", "justification", "local_conclusion"], "output": "Comparative evaluations illustrate that protocol choice changes both capability and vulnerability One analysis reports higher overall attack success"}, {"i": 4, "moves": ["contrast", "boundary_failure", "justification"], "output": "Taxonomies make this dependence explicit MSB contributes an attack taxonomy with a dozen attack types including name collision"}, {"i": 5, "moves": ["contrast", "justification", "local_conclusion"], "output": "Defensive systems highlight that mitigation can change both security and system efficiency under realistic workflows BridgeScope reports enabling"}, {"i": 6, "moves": ["boundary_failure", "justification"], "output": "End-to-end defenses can also be benchmarked directly Progent reports reducing attack success rates to 0 across multiple agent"}, {"i": 7, "moves": ["boundary_failure", "justification"], "output": "Monitoring and cost-aware attacks expose additional governance constraints Some attacks operate at the tool layer under the guise"}, {"i": 8, "moves": ["contrast", "boundary_failure", "justification"], "output": "In contrast to threat models that focus only on correctness governance-oriented evaluations often require monitoring and auditing which"}, {"i": 9, "moves": ["justification"], "output": "Governance considerations extend beyond technical mitigations to domain and compliance constraints Surveys of domain deployments e g agents"}, {"i": 10, "moves": ["contrast", "boundary_failure", "justification"], "output": "Across security benchmarks and defensive systems a consistent synthesis is that risk is interface-dependent Protocols that expose more"}, {"i": 11, "moves": ["boundary_failure", "justification", "local_conclusion"], "output": "One limitation is that many security evaluations are still fragmented across incompatible benchmarks and tool stacks making it"}]}
