{"sub_id": "3.1", "title": "Agent loop and action spaces", "section_id": "3", "section_title": "Foundations & Interfaces", "rq": "Which design choices in Agent loop and action spaces drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Agent loop and action spaces highlights a tension around mechanism / architecture and data / training setup, motivating a protocol-aware synthesis rather than per-paper summaries.", "axes": ["mechanism / architecture", "data / training setup", "evaluation protocol (datasets / metrics / human)", "efficiency / compute", "failure modes / limitations"], "bridge_terms": ["benchmarks/metrics", "compute"], "contrast_hook": "evaluation", "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "compute / cost (train/infer)", "training signal / supervision", "failure modes / limitations"], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Agent loop and action spaces drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "To ground this thesis, Agent frameworks / architectures approaches provide a natural starting point because they make the agent-loop decision explicit.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: mechanism / architecture, data / training setup, evaluation protocol (datasets / metrics / human), efficiency / compute, failure modes / limitations"], "connector_to_prev": "elaboration", "connector_phrase": "More concretely, these designs imply concrete interface/data assumptions that shape behavior.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "To evaluate these trade-offs, protocols and metrics clarify where Agent frameworks / architectures works, and where it fails or becomes costly.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Planning / reasoning loops", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Unlike this route, Planning / reasoning loops approaches shift the emphasis and optimize for a different point in the trade-off space.", "use_clusters": ["Planning / reasoning loops"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Planning / reasoning loops", "data / training setup", "interface contract", "axes: mechanism / architecture, data / training setup, evaluation protocol (datasets / metrics / human), efficiency / compute, failure modes / limitations"], "connector_to_prev": "elaboration", "connector_phrase": "More concretely, the B-route relies on different interface/training assumptions, which changes failure modes and costs.", "use_clusters": ["Planning / reasoning loops"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Planning / reasoning loops", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "To evaluate these trade-offs, when comparable settings exist, evaluation evidence for B can be contrasted against A to surface the trade-offs.", "use_clusters": ["Planning / reasoning loops"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Planning / reasoning loops", "multiple citations in one paragraph", "axes: mechanism / architecture, data / training setup, evaluation protocol (datasets / metrics / human), efficiency / compute, failure modes / limitations"], "connector_to_prev": "synthesis", "connector_phrase": "Stepping back, the key distinction between Agent frameworks / architectures and Planning / reasoning loops is how they trade off mechanism / architecture, data / training setup, evaluation protocol (datasets / metrics / human), efficiency / compute, failure modes / limitations under evaluation constraints.", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Tool-use and function calling"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "As a result, a decision checklist can map evaluation signals and constraints to route selection.", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Tool-use and function calling"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "A key limitation is that key claims hinge on assumptions that merit stress-testing, which motivates concrete verification targets.", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Tool-use and function calling"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "chapter_throughline": ["Pin scope to goal: LLM agents survey (tool-use, planning, memory, multi-agent).", "Compare approaches along: mechanism / architecture.", "Compare approaches along: data / training setup.", "Compare approaches along: evaluation protocol (datasets / metrics / human).", "Compare approaches along: efficiency / compute.", "Compare approaches along: failure modes / limitations."], "chapter_key_contrasts": ["evaluation", "tool interfaces"], "chapter_synthesis_mode": "tradeoff_matrix", "allowed_bibkeys_selected": ["Kim2025Bridging", "Zhao2025Achieving", "Liu2025Mcpagentbench", "Qiu2025Locobench", "Fumero2025Cybersleuth", "Li2025Agentswift", "Feng2025Group", "Xi2026Toolgym", "Yao2022React", "Zhang2026Evoroute"], "allowed_bibkeys_mapped": ["Li2025From", "Zhao2025Achieving", "Kim2025Bridging", "Li2025Agentswift", "Ghose2025Orfs", "Song2026Envscaler", "Feng2025Group", "Wu2025Meta", "Fumero2025Cybersleuth", "You2025Datawiseagent", "Xu2025Exemplar", "Qiu2025Locobench", "Zhang2026Evoroute", "Xi2026Toolgym", "Luo2025Large", "Gasmi2025Bridging", "Liu2025Mcpagentbench", "Yao2022React"], "allowed_bibkeys_chapter": ["Cheng2025Your", "Dong2025Bench", "Du2024Anytool", "Feng2025Group", "Fumero2025Cybersleuth", "Gasmi2025Bridging", "Ghose2025Orfs", "Jia2025Autotool", "Kim2025Bridging", "Li2024Personal", "Li2024Stride", "Li2025Agentswift", "Li2025Dissonances", "Li2025From", "Liu2025Mcpagentbench", "Liu2025Toolscope", "Lumer2025Memtool", "Luo2025Large", "Mohammadi2025Evaluation", "Qiu2025Locobench", "Shen2024Small", "Song2026Envscaler", "Van2025Survey", "Wu2025Meta", "Xi2026Toolgym", "Xian2025Measuring", "Xu2025Exemplar", "Xuan2026Confidence", "Yao2022React", "You2025Datawiseagent", "Zhang2026Evoroute", "Zhao2025Achieving", "Zhou2025Self"], "evidence_ids": ["E-P0011-9d9d60644a", "E-P0138-1063eee7ce", "E-P0090-f7a14123f9", "E-P0182-7aa3167337", "E-P0156-c8c4670812", "E-P0182-fa8206acb2", "E-P0019-904ba35500", "E-P0024-4b027dfb27", "E-P0059-895b04aa5c", "E-P0059-8c9597d805", "E-P0001-ca4a00b5cf", "E-P0055-60cc0d458f"], "anchor_facts": [{"hook_type": "quant", "text": "Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\\% over both existing automated agent search methods and manually designed agents.", "citations": ["@Li2025Agentswift"], "paper_id": "P0019", "evidence_id": "E-P0019-904ba35500", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#key_results[0]"}, {"hook_type": "quant", "text": "Finally, we collect 1,170 trajectories from our environment to fine-tune LLMs, achieving superior performance to baselines using 119k samples, indicating the environment's value as both a realistic benchmark and a data engine for tool-using agents.", "citations": ["@Xi2026Toolgym"], "paper_id": "P0059", "evidence_id": "E-P0059-8c9597d805", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#key_results[1]"}, {"hook_type": "quant", "text": "Comprehensive evaluation of state-of-the-art LLMs reveals the misalignment between tool planning and execution abilities, the constraint following weakness of existing LLMs, and DeepSeek-v3.2's strongest robustness.", "citations": ["@Xi2026Toolgym"], "paper_id": "P0059", "evidence_id": "E-P0059-895b04aa5c", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#key_results[0]"}, {"hook_type": "quant", "text": "We evaluate GiGPO on challenging agent benchmarks, including ALFWorld and WebShop, as well as tool-integrated reasoning on search-augmented QA tasks, using Qwen2.5-1.5B/3B/7B-Instruct.", "citations": ["@Feng2025Group"], "paper_id": "P0024", "evidence_id": "E-P0024-4b027dfb27", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#key_results[0]"}, {"hook_type": "quant", "text": "However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation.", "citations": ["@Zhao2025Achieving"], "paper_id": "P0138", "evidence_id": "E-P0138-1063eee7ce", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#key_results[0]"}, {"hook_type": "eval", "text": "To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents.", "citations": ["@Liu2025Mcpagentbench"], "paper_id": "P0090", "evidence_id": "E-P0090-f7a14123f9", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#limitations[1]"}, {"hook_type": "quant", "text": "Our framework extends LoCoBench's 8,000 scenarios into interactive agent environments, enabling systematic evaluation of multi-turn conversations, tool usage efficiency, error recovery, and architectural consistency across extended development sessions.", "citations": ["@Qiu2025Locobench"], "paper_id": "P0182", "evidence_id": "E-P0182-7aa3167337", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#key_results[1]"}, {"hook_type": "quant", "text": "We benchmark four agent architectures and six LLM backends on 20 incident scenarios of increasing complexity, identifying CyberSleuth as the best-performing design.", "citations": ["@Fumero2025Cybersleuth"], "paper_id": "P0156", "evidence_id": "E-P0156-c8c4670812", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#key_results[0]"}], "comparison_cards": [{"axis": "mechanism / architecture", "A_label": "Agent frameworks / architectures", "B_label": "Planning / reasoning loops", "citations": ["@Li2025Agentswift", "@Xi2026Toolgym", "@Kim2025Bridging"], "A_highlights": [{"paper_id": "P0019", "evidence_id": "E-P0019-904ba35500", "excerpt": "Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\\% over both existing automated agent search methods and manually designed agents.", "citations": ["@Li2025Agentswift"], "pointer": "papers/paper_notes.jsonl:paper_id=P0019#key_results[0]"}, {"paper_id": "P0059", "evidence_id": "E-P0059-8c9597d805", "excerpt": "Finally, we collect 1,170 trajectories from our environment to fine-tune LLMs, achieving superior performance to baselines using 119k samples, indicating the environment's value as both a realistic benchmark and a data engine for tool-using agents.", "citations": ["@Xi2026Toolgym"], "pointer": "papers/paper_notes.jsonl:paper_id=P0059#key_results[1]"}], "B_highlights": [{"paper_id": "P0019", "evidence_id": "E-P0019-904ba35500", "excerpt": "Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\\% over both existing automated agent search methods and manually designed agents.", "citations": ["@Li2025Agentswift"], "pointer": "papers/paper_notes.jsonl:paper_id=P0019#key_results[0]"}, {"paper_id": "P0011", "evidence_id": "E-P0011-9d9d60644a", "excerpt": "We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM).", "citations": ["@Kim2025Bridging"], "pointer": "papers/paper_notes.jsonl:paper_id=P0011#method"}], "write_prompt": "Contrast Agent frameworks / architectures vs Planning / reasoning loops along 'mechanism / architecture'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "data / training setup", "A_label": "Agent frameworks / architectures", "B_label": "Planning / reasoning loops", "citations": ["@Xi2026Toolgym", "@Feng2025Group", "@Li2025Agentswift", "@Kim2025Bridging"], "A_highlights": [{"paper_id": "P0059", "evidence_id": "E-P0059-895b04aa5c", "excerpt": "Comprehensive evaluation of state-of-the-art LLMs reveals the misalignment between tool planning and execution abilities, the constraint following weakness of existing LLMs, and DeepSeek-v3.2's strongest robustness.", "citations": ["@Xi2026Toolgym"], "pointer": "papers/paper_notes.jsonl:paper_id=P0059#key_results[0]"}, {"paper_id": "P0024", "evidence_id": "E-P0024-4b027dfb27", "excerpt": "We evaluate GiGPO on challenging agent benchmarks, including ALFWorld and WebShop, as well as tool-integrated reasoning on search-augmented QA tasks, using Qwen2.5-1.5B/3B/7B-Instruct.", "citations": ["@Feng2025Group"], "pointer": "papers/paper_notes.jsonl:paper_id=P0024#key_results[0]"}], "B_highlights": [{"paper_id": "P0019", "evidence_id": "E-P0019-904ba35500", "excerpt": "Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\\% over both existing automated agent search methods and manually designed agents.", "citations": ["@Li2025Agentswift"], "pointer": "papers/paper_notes.jsonl:paper_id=P0019#key_results[0]"}, {"paper_id": "P0011", "evidence_id": "E-P0011-9d9d60644a", "excerpt": "We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM).", "citations": ["@Kim2025Bridging"], "pointer": "papers/paper_notes.jsonl:paper_id=P0011#method"}], "write_prompt": "Contrast Agent frameworks / architectures vs Planning / reasoning loops along 'data / training setup'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "evaluation protocol (datasets / metrics / human)", "A_label": "Agent frameworks / architectures", "B_label": "Planning / reasoning loops", "citations": ["@Li2025Agentswift", "@Xi2026Toolgym", "@Kim2025Bridging"], "A_highlights": [{"paper_id": "P0019", "evidence_id": "E-P0019-904ba35500", "excerpt": "Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\\% over both existing automated agent search methods and manually designed agents.", "citations": ["@Li2025Agentswift"], "pointer": "papers/paper_notes.jsonl:paper_id=P0019#key_results[0]"}, {"paper_id": "P0059", "evidence_id": "E-P0059-8c9597d805", "excerpt": "Finally, we collect 1,170 trajectories from our environment to fine-tune LLMs, achieving superior performance to baselines using 119k samples, indicating the environment's value as both a realistic benchmark and a data engine for tool-using agents.", "citations": ["@Xi2026Toolgym"], "pointer": "papers/paper_notes.jsonl:paper_id=P0059#key_results[1]"}], "B_highlights": [{"paper_id": "P0019", "evidence_id": "E-P0019-904ba35500", "excerpt": "Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\\% over both existing automated agent search methods and manually designed agents.", "citations": ["@Li2025Agentswift"], "pointer": "papers/paper_notes.jsonl:paper_id=P0019#key_results[0]"}, {"paper_id": "P0011", "evidence_id": "E-P0011-9d9d60644a", "excerpt": "We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM).", "citations": ["@Kim2025Bridging"], "pointer": "papers/paper_notes.jsonl:paper_id=P0011#method"}], "write_prompt": "Contrast Agent frameworks / architectures vs Planning / reasoning loops along 'evaluation protocol (datasets / metrics / human)'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "efficiency / compute", "A_label": "Agent frameworks / architectures", "B_label": "Planning / reasoning loops", "citations": ["@Li2025Agentswift", "@Xi2026Toolgym", "@Kim2025Bridging"], "A_highlights": [{"paper_id": "P0019", "evidence_id": "E-P0019-904ba35500", "excerpt": "Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\\% over both existing automated agent search methods and manually designed agents.", "citations": ["@Li2025Agentswift"], "pointer": "papers/paper_notes.jsonl:paper_id=P0019#key_results[0]"}, {"paper_id": "P0059", "evidence_id": "E-P0059-8c9597d805", "excerpt": "Finally, we collect 1,170 trajectories from our environment to fine-tune LLMs, achieving superior performance to baselines using 119k samples, indicating the environment's value as both a realistic benchmark and a data engine for tool-using agents.", "citations": ["@Xi2026Toolgym"], "pointer": "papers/paper_notes.jsonl:paper_id=P0059#key_results[1]"}], "B_highlights": [{"paper_id": "P0019", "evidence_id": "E-P0019-904ba35500", "excerpt": "Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\\% over both existing automated agent search methods and manually designed agents.", "citations": ["@Li2025Agentswift"], "pointer": "papers/paper_notes.jsonl:paper_id=P0019#key_results[0]"}, {"paper_id": "P0011", "evidence_id": "E-P0011-9d9d60644a", "excerpt": "We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM).", "citations": ["@Kim2025Bridging"], "pointer": "papers/paper_notes.jsonl:paper_id=P0011#method"}], "write_prompt": "Contrast Agent frameworks / architectures vs Planning / reasoning loops along 'efficiency / compute'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}], "evaluation_protocol": [{"bullet": "Evaluation tokens mentioned in mapped evidence: LLMs; GAIA; EvoRoute; BrowseComp; DeepSeek-v3; LLM-simulated; SFT; RUC-NLPIR; EnvScaler; SkelBuilder.", "citations": ["@Zhang2026Evoroute", "@Xi2026Toolgym", "@Song2026Envscaler", "@Kim2025Bridging"]}], "limitation_hooks": [{"excerpt": "We formalize this challenge as the \\textbf{Agent System Trilemma}: the inherent tension among achieving state-of-the-art performance, minimizing monetary cost, and ensuring rapid task completion.", "citations": ["@Zhang2026Evoroute"], "pointer": ""}, {"excerpt": "Large language model (LLM) agents have demonstrated strong capabilities across diverse domains, yet automated agent design remains a significant challenge.", "citations": ["@Li2025Agentswift"], "pointer": ""}, {"excerpt": "MPR (i) externalizes reusable corrective knowledge without model weight updates, (ii) enforces domain constraints to reduce unsafe or invalid actions, and (iii) retains the adaptability of language-based reflection.", "citations": ["@Wu2025Meta"], "pointer": ""}, {"excerpt": "We analyze mechanisms that explain these gains, discuss scalability and failure modes, and outline future directions for multimodal and multi-agent extensions.", "citations": ["@Wu2025Meta"], "pointer": ""}], "must_use": {"min_anchor_facts": 1, "min_comparison_cards": 1, "min_limitation_hooks": 1, "require_cited_numeric_if_available": true, "require_multi_cite_synthesis_paragraph": true, "thesis_required": true}, "do_not_repeat_phrases": ["This subsection surveys", "This subsection argues", "In this subsection", "Next, we move from", "We now turn to", "claims remain provisional under abstract-only evidence", "abstract-only evidence", "Key takeaway:", "Main takeaway:"], "pack_warnings": [], "pack_stats": {"anchors": {"raw": 9, "considered": 8, "kept": 8, "dropped_no_cites": 0}, "comparisons": {"raw": 5, "considered": 4, "kept": 4, "dropped_no_highlights": 0, "highlights_dropped_no_cites": 0}, "evaluation_protocol": {"raw": 1, "considered": 1, "kept": 1, "dropped_no_cites": 0}, "limitation_hooks": {"raw": 4, "considered": 4, "kept": 4, "dropped_no_cites": 0}, "trim_policy": {"default": 400, "anchor_fact": 420, "highlight_excerpt": 280, "comparison_write_prompt": 420, "eval_bullet": 320, "limitation_excerpt": 320}}, "generated_at": "2026-01-18T01:21:06"}
{"sub_id": "3.2", "title": "Tool interfaces and orchestration", "section_id": "3", "section_title": "Foundations & Interfaces", "rq": "Which design choices in Tool interfaces and orchestration drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Tool interfaces and orchestration highlights a tension around tool interface (function calling, schemas, protocols) and tool selection / routing policy, motivating a protocol-aware synthesis rather than per-paper summaries.", "axes": ["tool interface (function calling, schemas, protocols)", "tool selection / routing policy", "sandboxing / permissions / observability", "mechanism / architecture", "data / training setup"], "bridge_terms": ["function calling", "tool schema", "routing", "sandbox", "observability"], "contrast_hook": "tool interfaces", "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision", "threat model", "defense surface"], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Tool interfaces and orchestration drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "To make this concrete, Agent frameworks / architectures approaches provide a natural starting point because they make the agent-loop decision explicit.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Following this design, these designs imply concrete interface/data assumptions that shape behavior.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "In evaluations, protocols and metrics clarify where Agent frameworks / architectures works, and where it fails or becomes costly.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Tool-use and function calling", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "However, Tool-use and function calling approaches shift the emphasis and optimize for a different point in the trade-off space.", "use_clusters": ["Tool-use and function calling"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Tool-use and function calling", "data / training setup", "interface contract", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Following this design, the B-route relies on different interface/training assumptions, which changes failure modes and costs.", "use_clusters": ["Tool-use and function calling"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Tool-use and function calling", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "In evaluations, when comparable settings exist, evaluation evidence for B can be contrasted against A to surface the trade-offs.", "use_clusters": ["Tool-use and function calling"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Tool-use and function calling", "multiple citations in one paragraph", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Overall, the key distinction between Agent frameworks / architectures and Tool-use and function calling is how they trade off tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, mechanism / architecture, data / training setup under evaluation constraints.", "use_clusters": ["Agent frameworks / architectures", "Tool-use and function calling", "Evaluation / benchmark-focused works"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "This suggests that a decision checklist can map evaluation signals and constraints to route selection.", "use_clusters": ["Agent frameworks / architectures", "Tool-use and function calling", "Evaluation / benchmark-focused works"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Despite these advances, key claims hinge on assumptions that merit stress-testing, which motivates concrete verification targets.", "use_clusters": ["Agent frameworks / architectures", "Tool-use and function calling", "Evaluation / benchmark-focused works"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "chapter_throughline": ["Pin scope to goal: LLM agents survey (tool-use, planning, memory, multi-agent).", "Compare approaches along: mechanism / architecture.", "Compare approaches along: data / training setup.", "Compare approaches along: evaluation protocol (datasets / metrics / human).", "Compare approaches along: efficiency / compute.", "Compare approaches along: failure modes / limitations."], "chapter_key_contrasts": ["evaluation", "tool interfaces"], "chapter_synthesis_mode": "tradeoff_matrix", "allowed_bibkeys_selected": ["Liu2025Toolscope", "Zhou2025Self", "Dong2025Bench", "Li2025Dissonances", "Lumer2025Memtool", "Du2024Anytool", "Mohammadi2025Evaluation", "Jia2025Autotool"], "allowed_bibkeys_mapped": ["Dong2025Bench", "Jia2025Autotool", "Lumer2025Memtool", "Cheng2025Your", "Shen2024Small", "Du2024Anytool", "Li2025Dissonances", "Ghose2025Orfs", "Xuan2026Confidence", "Zhou2025Self", "Mohammadi2025Evaluation", "Liu2025Toolscope", "Li2024Personal", "Li2024Stride", "Liu2025Mcpagentbench", "Van2025Survey", "Xian2025Measuring", "Yao2022React"], "allowed_bibkeys_chapter": ["Cheng2025Your", "Dong2025Bench", "Du2024Anytool", "Feng2025Group", "Fumero2025Cybersleuth", "Gasmi2025Bridging", "Ghose2025Orfs", "Jia2025Autotool", "Kim2025Bridging", "Li2024Personal", "Li2024Stride", "Li2025Agentswift", "Li2025Dissonances", "Li2025From", "Liu2025Mcpagentbench", "Liu2025Toolscope", "Lumer2025Memtool", "Luo2025Large", "Mohammadi2025Evaluation", "Qiu2025Locobench", "Shen2024Small", "Song2026Envscaler", "Van2025Survey", "Wu2025Meta", "Xi2026Toolgym", "Xian2025Measuring", "Xu2025Exemplar", "Xuan2026Confidence", "Yao2022React", "You2025Datawiseagent", "Zhang2026Evoroute", "Zhao2025Achieving", "Zhou2025Self"], "evidence_ids": ["E-P0220-32b9aafe57", "E-P0035-2e6956a116", "E-P0028-f8def223dc", "E-P0088-fae121f81b", "E-P0220-468a77ff1d", "E-P0220-cb30da23cb", "E-P0029-35271418ac", "E-P0029-38dc800de9", "E-P0108-d5c234444e", "E-P0164-37f9ea924c", "E-P0070-d3344c79dc", "E-P0108-e046416ff1"], "anchor_facts": [{"hook_type": "quant", "text": "Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy.", "citations": ["@Lumer2025Memtool"], "paper_id": "P0029", "evidence_id": "E-P0029-35271418ac", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[0]"}, {"hook_type": "quant", "text": "Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat.", "citations": ["@Li2025Dissonances"], "paper_id": "P0088", "evidence_id": "E-P0088-fae121f81b", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#key_results[0]"}, {"hook_type": "quant", "text": "MemTool offers three agentic architectures: 1) Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow Mode, providing deterministic control without autonomy, and 3) Hybrid Mode, combining autonomous and deterministic control.", "citations": ["@Lumer2025Memtool"], "paper_id": "P0029", "evidence_id": "E-P0029-38dc800de9", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[1]"}, {"hook_type": "quant", "text": "Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data.", "citations": ["@Zhou2025Self"], "paper_id": "P0035", "evidence_id": "E-P0035-2e6956a116", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#key_results[0]"}, {"hook_type": "quant", "text": "To address these challenges, we propose ToolScope, which includes: (1) ToolScopeMerger with Auto-Correction to automatically audit and fix tool merges, reducing redundancy, and (2) ToolScopeRetriever to rank and select only the most relevant tools for each query, compressing tool", "citations": ["@Liu2025Toolscope"], "paper_id": "P0220", "evidence_id": "E-P0220-32b9aafe57", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#method"}, {"hook_type": "quant", "text": "Evaluations on three state-of-the-art LLMs and three open-source tool-use benchmarks show gains of 8.38% to 38.6% in tool selection accuracy, demonstrating ToolScope's effectiveness in enhancing LLM tool use.", "citations": ["@Liu2025Toolscope"], "paper_id": "P0220", "evidence_id": "E-P0220-468a77ff1d", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#key_results[0]"}, {"hook_type": "quant", "text": "Experiments across various datasets demonstrate the superiority of our AnyTool over strong baselines such as ToolLLM and a GPT-4 variant tailored for tool utilization.", "citations": ["@Du2024Anytool"], "paper_id": "P0108", "evidence_id": "E-P0108-d5c234444e", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#key_results[0]"}, {"hook_type": "quant", "text": "This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and (", "citations": ["@Mohammadi2025Evaluation"], "paper_id": "P0164", "evidence_id": "E-P0164-37f9ea924c", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#key_results[0]"}], "comparison_cards": [{"axis": "tool interface (function calling, schemas, protocols)", "A_label": "Agent frameworks / architectures", "B_label": "Tool-use and function calling", "citations": ["@Lumer2025Memtool", "@Li2025Dissonances"], "A_highlights": [{"paper_id": "P0029", "evidence_id": "E-P0029-35271418ac", "excerpt": "Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy.", "citations": ["@Lumer2025Memtool"], "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[0]"}, {"paper_id": "P0088", "evidence_id": "E-P0088-fae121f81b", "excerpt": "Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat.", "citations": ["@Li2025Dissonances"], "pointer": "papers/paper_notes.jsonl:paper_id=P0088#key_results[0]"}], "B_highlights": [{"paper_id": "P0029", "evidence_id": "E-P0029-35271418ac", "excerpt": "Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy.", "citations": ["@Lumer2025Memtool"], "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[0]"}, {"paper_id": "P0088", "evidence_id": "E-P0088-fae121f81b", "excerpt": "Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat.", "citations": ["@Li2025Dissonances"], "pointer": "papers/paper_notes.jsonl:paper_id=P0088#key_results[0]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Tool-use and function calling along 'tool interface (function calling, schemas, protocols)'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "tool selection / routing policy", "A_label": "Agent frameworks / architectures", "B_label": "Tool-use and function calling", "citations": ["@Lumer2025Memtool", "@Li2025Dissonances"], "A_highlights": [{"paper_id": "P0029", "evidence_id": "E-P0029-35271418ac", "excerpt": "Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy.", "citations": ["@Lumer2025Memtool"], "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[0]"}, {"paper_id": "P0088", "evidence_id": "E-P0088-fae121f81b", "excerpt": "Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat.", "citations": ["@Li2025Dissonances"], "pointer": "papers/paper_notes.jsonl:paper_id=P0088#key_results[0]"}], "B_highlights": [{"paper_id": "P0029", "evidence_id": "E-P0029-35271418ac", "excerpt": "Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy.", "citations": ["@Lumer2025Memtool"], "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[0]"}, {"paper_id": "P0088", "evidence_id": "E-P0088-fae121f81b", "excerpt": "Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat.", "citations": ["@Li2025Dissonances"], "pointer": "papers/paper_notes.jsonl:paper_id=P0088#key_results[0]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Tool-use and function calling along 'tool selection / routing policy'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "sandboxing / permissions / observability", "A_label": "Agent frameworks / architectures", "B_label": "Tool-use and function calling", "citations": ["@Li2025Dissonances", "@Lumer2025Memtool"], "A_highlights": [{"paper_id": "P0088", "evidence_id": "E-P0088-fae121f81b", "excerpt": "Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat.", "citations": ["@Li2025Dissonances"], "pointer": "papers/paper_notes.jsonl:paper_id=P0088#key_results[0]"}, {"paper_id": "P0029", "evidence_id": "E-P0029-38dc800de9", "excerpt": "MemTool offers three agentic architectures: 1) Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow Mode, providing deterministic control without autonomy, and 3) Hybrid Mode, combining autonomous and deterministic control.", "citations": ["@Lumer2025Memtool"], "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[1]"}], "B_highlights": [{"paper_id": "P0088", "evidence_id": "E-P0088-fae121f81b", "excerpt": "Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat.", "citations": ["@Li2025Dissonances"], "pointer": "papers/paper_notes.jsonl:paper_id=P0088#key_results[0]"}, {"paper_id": "P0029", "evidence_id": "E-P0029-38dc800de9", "excerpt": "MemTool offers three agentic architectures: 1) Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow Mode, providing deterministic control without autonomy, and 3) Hybrid Mode, combining autonomous and deterministic control.", "citations": ["@Lumer2025Memtool"], "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[1]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Tool-use and function calling along 'sandboxing / permissions / observability'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "mechanism / architecture", "A_label": "Agent frameworks / architectures", "B_label": "Tool-use and function calling", "citations": ["@Li2025Dissonances", "@Lumer2025Memtool"], "A_highlights": [{"paper_id": "P0088", "evidence_id": "E-P0088-fae121f81b", "excerpt": "Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat.", "citations": ["@Li2025Dissonances"], "pointer": "papers/paper_notes.jsonl:paper_id=P0088#key_results[0]"}, {"paper_id": "P0029", "evidence_id": "E-P0029-38dc800de9", "excerpt": "MemTool offers three agentic architectures: 1) Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow Mode, providing deterministic control without autonomy, and 3) Hybrid Mode, combining autonomous and deterministic control.", "citations": ["@Lumer2025Memtool"], "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[1]"}], "B_highlights": [{"paper_id": "P0088", "evidence_id": "E-P0088-fae121f81b", "excerpt": "Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat.", "citations": ["@Li2025Dissonances"], "pointer": "papers/paper_notes.jsonl:paper_id=P0088#key_results[0]"}, {"paper_id": "P0029", "evidence_id": "E-P0029-38dc800de9", "excerpt": "MemTool offers three agentic architectures: 1) Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow Mode, providing deterministic control without autonomy, and 3) Hybrid Mode, combining autonomous and deterministic control.", "citations": ["@Lumer2025Memtool"], "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[1]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Tool-use and function calling along 'mechanism / architecture'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}], "evaluation_protocol": [{"bullet": "Evaluation tokens mentioned in mapped evidence: LLMs; MCP; MemTool; ScaleMCP; TauBench; TicToc; FMs; MatSci; ReAct; AutoTool.", "citations": ["@Xuan2026Confidence", "@Lumer2025Memtool", "@Zhou2025Self", "@Cheng2025Your"]}], "limitation_hooks": [{"excerpt": "Autonomous agents based on large language models (LLMs) are rapidly evolving to handle multi-turn tasks, but ensuring their trustworthiness remains a critical challenge.", "citations": ["@Xuan2026Confidence"], "pointer": ""}, {"excerpt": "The tasks take the form of a novel general class of problems termed Code-as-Task, which are defined by an instruction, a verification function and solution and failure cases which serve as tests, allowing to filter only for high-quality tasks.", "citations": ["@Zhou2025Self"], "pointer": ""}, {"excerpt": "However, a critical yet overlooked limitation of these agents is that they, by default, assume a stationary context, failing to account for the real-world time elapsed between messages.", "citations": ["@Cheng2025Your"], "pointer": ""}, {"excerpt": "This limitation hinders decisions about when to invoke tools, leading agents to either over-rely on stale context and skip needed tool calls, or under-rely on it and redundantly repeat tool calls.", "citations": ["@Cheng2025Your"], "pointer": ""}], "must_use": {"min_anchor_facts": 1, "min_comparison_cards": 1, "min_limitation_hooks": 1, "require_cited_numeric_if_available": true, "require_multi_cite_synthesis_paragraph": true, "thesis_required": true}, "do_not_repeat_phrases": ["This subsection surveys", "This subsection argues", "In this subsection", "Next, we move from", "We now turn to", "claims remain provisional under abstract-only evidence", "abstract-only evidence", "Key takeaway:", "Main takeaway:"], "pack_warnings": [], "pack_stats": {"anchors": {"raw": 8, "considered": 8, "kept": 8, "dropped_no_cites": 0}, "comparisons": {"raw": 5, "considered": 4, "kept": 4, "dropped_no_highlights": 0, "highlights_dropped_no_cites": 0}, "evaluation_protocol": {"raw": 1, "considered": 1, "kept": 1, "dropped_no_cites": 0}, "limitation_hooks": {"raw": 4, "considered": 4, "kept": 4, "dropped_no_cites": 0}, "trim_policy": {"default": 400, "anchor_fact": 420, "highlight_excerpt": 280, "comparison_write_prompt": 420, "eval_bullet": 320, "limitation_excerpt": 320}}, "generated_at": "2026-01-18T01:21:06"}
{"sub_id": "4.1", "title": "Planning and reasoning loops", "section_id": "4", "section_title": "Core Components (Planning + Memory)", "rq": "Which design choices in Planning and reasoning loops drive the major trade-offs, and how are those trade-offs measured?", "thesis": "In Planning and reasoning loops, differences in control loop design (planner / executor, search) and deliberation method (CoT / ToT / MCTS) frequently imply different evaluation setups, so the key is to compare under consistent protocols where possible.", "axes": ["control loop design (planner / executor, search)", "deliberation method (CoT / ToT / MCTS)", "action grounding (tool calls vs environment actions)", "mechanism / architecture", "data / training setup"], "bridge_terms": ["planner/executor", "search", "deliberation", "action grounding"], "contrast_hook": "planning/control loop", "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision"], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Planning and reasoning loops drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "To ground this thesis, Agent frameworks / architectures approaches provide a natural starting point because they make the agent-loop decision explicit.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: control loop design (planner / executor, search), deliberation method (CoT / ToT / MCTS), action grounding (tool calls vs environment actions), mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "More concretely, these designs imply concrete interface/data assumptions that shape behavior.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Under standard benchmarks, protocols and metrics clarify where Agent frameworks / architectures works, and where it fails or becomes costly.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Planning / reasoning loops", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "By contrast, Planning / reasoning loops approaches shift the emphasis and optimize for a different point in the trade-off space.", "use_clusters": ["Planning / reasoning loops"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Planning / reasoning loops", "data / training setup", "interface contract", "axes: control loop design (planner / executor, search), deliberation method (CoT / ToT / MCTS), action grounding (tool calls vs environment actions), mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "More concretely, the B-route relies on different interface/training assumptions, which changes failure modes and costs.", "use_clusters": ["Planning / reasoning loops"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Planning / reasoning loops", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Under standard benchmarks, when comparable settings exist, evaluation evidence for B can be contrasted against A to surface the trade-offs.", "use_clusters": ["Planning / reasoning loops"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Planning / reasoning loops", "multiple citations in one paragraph", "axes: control loop design (planner / executor, search), deliberation method (CoT / ToT / MCTS), action grounding (tool calls vs environment actions), mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Overall, the key distinction between Agent frameworks / architectures and Planning / reasoning loops is how they trade off control loop design (planner / executor, search), deliberation method (CoT / ToT / MCTS), action grounding (tool calls vs environment actions), mechanism / architecture, data / training setup under evaluation constraints.", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Memory / retrieval augmentation"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "This suggests that a decision checklist can map evaluation signals and constraints to route selection.", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Memory / retrieval augmentation"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "A key limitation is that key claims hinge on assumptions that merit stress-testing, which motivates concrete verification targets.", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Memory / retrieval augmentation"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "chapter_throughline": ["Pin scope to goal: LLM agents survey (tool-use, planning, memory, multi-agent).", "Compare approaches along: control loop design (planner / executor, search).", "Compare approaches along: deliberation method (CoT / ToT / MCTS).", "Compare approaches along: action grounding (tool calls vs environment actions).", "Compare approaches along: mechanism / architecture.", "Compare approaches along: data / training setup."], "chapter_key_contrasts": ["planning/control loop", "memory/retrieval"], "chapter_synthesis_mode": "clusters", "allowed_bibkeys_selected": ["Hu2025Training", "Nakano2025Guided", "Seo2025Simuhome", "Hong2025Planning", "Kim2025Bridging", "Du2025Memr", "Zhou2025Reasoning", "Liu2025Costbench", "Yao2022React", "Kiruluta2025Novel"], "allowed_bibkeys_mapped": ["Hong2025Planning", "Hu2025Training", "Silva2025Agents", "Kim2025Bridging", "Hatalis2025Review", "Zhou2025Reasoning", "Lu2025Pilotrl", "Huang2025Surgical", "Hu2025Evaluating", "Yang2025Coarse", "Du2025Memr", "Dagan2024Plancraft", "Kiruluta2025Novel", "Liu2025Costbench", "Nakano2025Guided", "Li2025Draft", "Seo2025Simuhome", "Yao2022React"], "allowed_bibkeys_chapter": ["Abbineni2025Muallm", "Anokhin2024Arigraph", "Dagan2024Plancraft", "Du2025Memr", "Hatalis2025Review", "Hong2025Planning", "Hu2025Evaluating", "Hu2025Training", "Huang2025Surgical", "Kim2025Bridging", "Kiruluta2025Novel", "Li2025Draft", "Li2025Graphcodeagent", "Liu2023Reason", "Liu2025Costbench", "Lu2025Pilotrl", "Nakano2025Guided", "Seo2025Simuhome", "Silva2025Agents", "Tao2026Membox", "Tawosi2025Meta", "Wei2025Memory", "Wu2025Meta", "Xia2025From", "Xu2025Agentic", "Yang2025Coarse", "Yao2022React", "Ye2025Task", "Ye2025Taska", "Yu2026Agentic", "Zhang2024Large", "Zhang2025Large", "Zhou2025Reasoning"], "evidence_ids": ["E-P0039-f4d80ca542", "E-P0084-99359acdd7", "E-P0212-e2e3b7fa97", "E-P0013-1ad09376fe", "E-P0011-04c60086db", "E-P0184-1b99de5317", "E-P0034-c17bcfb7d4", "E-P0039-771620f84f", "E-P0077-32d61c8fae", "E-P0001-ca4a00b5cf", "E-P0060-a666552417", "E-P0060-c7423180cf"], "anchor_facts": [{"hook_type": "quant", "text": "Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and", "citations": ["@Liu2025Costbench"], "paper_id": "P0077", "evidence_id": "E-P0077-32d61c8fae", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#key_results[0]"}, {"hook_type": "quant", "text": "Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning", "citations": ["@Hu2025Training"], "paper_id": "P0039", "evidence_id": "E-P0039-771620f84f", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#key_results[0]"}, {"hook_type": "quant", "text": "Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design", "citations": ["@Kim2025Bridging"], "paper_id": "P0011", "evidence_id": "E-P0011-04c60086db", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#key_results[0]"}, {"hook_type": "quant", "text": "Comparatively, the state-of-the-art LLM penetration testing tool using self-guided reasoning completed only 13.5\\%, 16.5\\%, and 75.7\\% of subtasks and required 86.2\\%, 118.7\\%, and 205.9\\% more model queries.", "citations": ["@Nakano2025Guided"], "paper_id": "P0084", "evidence_id": "E-P0084-99359acdd7", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#key_results[0]"}, {"hook_type": "quant", "text": "Our evaluation of 16 agents under a unified ReAct framework reveals distinct capabilities and limitations across models.", "citations": ["@Seo2025Simuhome"], "paper_id": "P0212", "evidence_id": "E-P0212-e2e3b7fa97", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#limitations[1]"}, {"hook_type": "quant", "text": "Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design p", "citations": ["@Kim2025Bridging"], "paper_id": "P0011", "evidence_id": "E-P0011-04c60086db", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#key_results[0]"}, {"hook_type": "quant", "text": "From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap track", "citations": ["@Du2025Memr"], "paper_id": "P0184", "evidence_id": "E-P0184-1b99de5317", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#key_results[1]"}, {"hook_type": "quant", "text": "It increases reasoning steps by up to 4.4 times or induces premature errors, successfully bypassing state-of-the-art content filters.", "citations": ["@Zhou2025Reasoning"], "paper_id": "P0034", "evidence_id": "E-P0034-c17bcfb7d4", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#key_results[0]"}], "comparison_cards": [{"axis": "control loop design (planner / executor, search)", "A_label": "Agent frameworks / architectures", "B_label": "Planning / reasoning loops", "citations": ["@Liu2025Costbench", "@Hu2025Training"], "A_highlights": [{"paper_id": "P0077", "evidence_id": "E-P0077-32d61c8fae", "excerpt": "Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and", "citations": ["@Liu2025Costbench"], "pointer": "papers/paper_notes.jsonl:paper_id=P0077#key_results[0]"}, {"paper_id": "P0039", "evidence_id": "E-P0039-771620f84f", "excerpt": "Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning", "citations": ["@Hu2025Training"], "pointer": "papers/paper_notes.jsonl:paper_id=P0039#key_results[0]"}], "B_highlights": [{"paper_id": "P0077", "evidence_id": "E-P0077-32d61c8fae", "excerpt": "Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and", "citations": ["@Liu2025Costbench"], "pointer": "papers/paper_notes.jsonl:paper_id=P0077#key_results[0]"}, {"paper_id": "P0039", "evidence_id": "E-P0039-771620f84f", "excerpt": "Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning", "citations": ["@Hu2025Training"], "pointer": "papers/paper_notes.jsonl:paper_id=P0039#key_results[0]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Planning / reasoning loops along 'control loop design (planner / executor, search)'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "deliberation method (CoT / ToT / MCTS)", "A_label": "Agent frameworks / architectures", "B_label": "Planning / reasoning loops", "citations": ["@Liu2025Costbench", "@Hu2025Training"], "A_highlights": [{"paper_id": "P0077", "evidence_id": "E-P0077-32d61c8fae", "excerpt": "Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and", "citations": ["@Liu2025Costbench"], "pointer": "papers/paper_notes.jsonl:paper_id=P0077#key_results[0]"}, {"paper_id": "P0039", "evidence_id": "E-P0039-771620f84f", "excerpt": "Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning", "citations": ["@Hu2025Training"], "pointer": "papers/paper_notes.jsonl:paper_id=P0039#key_results[0]"}], "B_highlights": [{"paper_id": "P0077", "evidence_id": "E-P0077-32d61c8fae", "excerpt": "Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and", "citations": ["@Liu2025Costbench"], "pointer": "papers/paper_notes.jsonl:paper_id=P0077#key_results[0]"}, {"paper_id": "P0039", "evidence_id": "E-P0039-771620f84f", "excerpt": "Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning", "citations": ["@Hu2025Training"], "pointer": "papers/paper_notes.jsonl:paper_id=P0039#key_results[0]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Planning / reasoning loops along 'deliberation method (CoT / ToT / MCTS)'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "action grounding (tool calls vs environment actions)", "A_label": "Agent frameworks / architectures", "B_label": "Planning / reasoning loops", "citations": ["@Kim2025Bridging", "@Liu2025Costbench"], "A_highlights": [{"paper_id": "P0011", "evidence_id": "E-P0011-04c60086db", "excerpt": "Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design", "citations": ["@Kim2025Bridging"], "pointer": "papers/paper_notes.jsonl:paper_id=P0011#key_results[0]"}, {"paper_id": "P0077", "evidence_id": "E-P0077-32d61c8fae", "excerpt": "Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and", "citations": ["@Liu2025Costbench"], "pointer": "papers/paper_notes.jsonl:paper_id=P0077#key_results[0]"}], "B_highlights": [{"paper_id": "P0011", "evidence_id": "E-P0011-04c60086db", "excerpt": "Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design", "citations": ["@Kim2025Bridging"], "pointer": "papers/paper_notes.jsonl:paper_id=P0011#key_results[0]"}, {"paper_id": "P0077", "evidence_id": "E-P0077-32d61c8fae", "excerpt": "Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and", "citations": ["@Liu2025Costbench"], "pointer": "papers/paper_notes.jsonl:paper_id=P0077#key_results[0]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Planning / reasoning loops along 'action grounding (tool calls vs environment actions)'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "mechanism / architecture", "A_label": "Agent frameworks / architectures", "B_label": "Planning / reasoning loops", "citations": ["@Kim2025Bridging", "@Liu2025Costbench"], "A_highlights": [{"paper_id": "P0011", "evidence_id": "E-P0011-04c60086db", "excerpt": "Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design", "citations": ["@Kim2025Bridging"], "pointer": "papers/paper_notes.jsonl:paper_id=P0011#key_results[0]"}, {"paper_id": "P0077", "evidence_id": "E-P0077-32d61c8fae", "excerpt": "Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and", "citations": ["@Liu2025Costbench"], "pointer": "papers/paper_notes.jsonl:paper_id=P0077#key_results[0]"}], "B_highlights": [{"paper_id": "P0011", "evidence_id": "E-P0011-04c60086db", "excerpt": "Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design", "citations": ["@Kim2025Bridging"], "pointer": "papers/paper_notes.jsonl:paper_id=P0011#key_results[0]"}, {"paper_id": "P0077", "evidence_id": "E-P0077-32d61c8fae", "excerpt": "Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and", "citations": ["@Liu2025Costbench"], "pointer": "papers/paper_notes.jsonl:paper_id=P0077#key_results[0]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Planning / reasoning loops along 'mechanism / architecture'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}], "evaluation_protocol": [{"bullet": "Evaluation tokens mentioned in mapped evidence: LLMs; CBR; CBR-enhanced; SCL; CCAM; GPT-4o-powered; ReAct; AutoGPT; RSP; GSI.", "citations": ["@Hatalis2025Review", "@Kim2025Bridging", "@Silva2025Agents", "@Zhou2025Reasoning"]}], "limitation_hooks": [{"excerpt": "Still, they face limitations in tasks requiring specific, structured knowledge, flexibility, or accountable decision-making.", "citations": ["@Hatalis2025Review"], "pointer": ""}, {"excerpt": "This study offers new insights into the strengths and failure modes of LLMs in physically grounded multi-agent collaboration tasks, contributing to future benchmarks and architectural improvements.", "citations": ["@Silva2025Agents"], "pointer": ""}, {"excerpt": "While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style.", "citations": ["@Zhou2025Reasoning"], "pointer": ""}, {"excerpt": "We introduce Generative Style Injection (GSI), an attack method that rewrites retrieved documents into pathological tones--specifically \"analysis paralysis\" or \"cognitive haste\"--without altering underlying facts or using explicit triggers.", "citations": ["@Zhou2025Reasoning"], "pointer": ""}], "must_use": {"min_anchor_facts": 1, "min_comparison_cards": 1, "min_limitation_hooks": 1, "require_cited_numeric_if_available": true, "require_multi_cite_synthesis_paragraph": true, "thesis_required": true}, "do_not_repeat_phrases": ["This subsection surveys", "This subsection argues", "In this subsection", "Next, we move from", "We now turn to", "claims remain provisional under abstract-only evidence", "abstract-only evidence", "Key takeaway:", "Main takeaway:"], "pack_warnings": [], "pack_stats": {"anchors": {"raw": 11, "considered": 8, "kept": 8, "dropped_no_cites": 0}, "comparisons": {"raw": 5, "considered": 4, "kept": 4, "dropped_no_highlights": 0, "highlights_dropped_no_cites": 0}, "evaluation_protocol": {"raw": 1, "considered": 1, "kept": 1, "dropped_no_cites": 0}, "limitation_hooks": {"raw": 4, "considered": 4, "kept": 4, "dropped_no_cites": 0}, "trim_policy": {"default": 400, "anchor_fact": 420, "highlight_excerpt": 280, "comparison_write_prompt": 420, "eval_bullet": 320, "limitation_excerpt": 320}}, "generated_at": "2026-01-18T01:21:06"}
{"sub_id": "4.2", "title": "Memory and retrieval (RAG)", "section_id": "4", "section_title": "Core Components (Planning + Memory)", "rq": "Which design choices in Memory and retrieval (RAG) drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Memory and retrieval (RAG) highlights a tension around memory type (episodic / semantic / scratchpad) and retrieval source + index (docs / web / logs), motivating a protocol-aware synthesis rather than per-paper summaries.", "axes": ["memory type (episodic / semantic / scratchpad)", "retrieval source + index (docs / web / logs)", "write / update / forgetting policy", "mechanism / architecture", "data / training setup"], "bridge_terms": ["retrieval", "index", "write policy", "long-term memory"], "contrast_hook": "memory/retrieval", "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision"], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Memory and retrieval (RAG) drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "To ground this thesis, Agent frameworks / architectures approaches provide a natural starting point because they make the agent-loop decision explicit.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: memory type (episodic / semantic / scratchpad), retrieval source + index (docs / web / logs), write / update / forgetting policy, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "At the implementation level, these designs imply concrete interface/data assumptions that shape behavior.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "In evaluations, protocols and metrics clarify where Agent frameworks / architectures works, and where it fails or becomes costly.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Memory / retrieval augmentation", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Unlike this route, Memory / retrieval augmentation approaches shift the emphasis and optimize for a different point in the trade-off space.", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Memory / retrieval augmentation", "data / training setup", "interface contract", "axes: memory type (episodic / semantic / scratchpad), retrieval source + index (docs / web / logs), write / update / forgetting policy, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "At the implementation level, the B-route relies on different interface/training assumptions, which changes failure modes and costs.", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Memory / retrieval augmentation", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "In evaluations, when comparable settings exist, evaluation evidence for B can be contrasted against A to surface the trade-offs.", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Memory / retrieval augmentation", "multiple citations in one paragraph", "axes: memory type (episodic / semantic / scratchpad), retrieval source + index (docs / web / logs), write / update / forgetting policy, mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Taken together, the key distinction between Agent frameworks / architectures and Memory / retrieval augmentation is how they trade off memory type (episodic / semantic / scratchpad), retrieval source + index (docs / web / logs), write / update / forgetting policy, mechanism / architecture, data / training setup under evaluation constraints.", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Planning / reasoning loops"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "As a result, a decision checklist can map evaluation signals and constraints to route selection.", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Planning / reasoning loops"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "However, these routes remain limited in practice, since key claims hinge on assumptions that merit stress-testing, which motivates concrete verification targets.", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Planning / reasoning loops"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "chapter_throughline": ["Pin scope to goal: LLM agents survey (tool-use, planning, memory, multi-agent).", "Compare approaches along: control loop design (planner / executor, search).", "Compare approaches along: deliberation method (CoT / ToT / MCTS).", "Compare approaches along: action grounding (tool calls vs environment actions).", "Compare approaches along: mechanism / architecture.", "Compare approaches along: data / training setup."], "chapter_key_contrasts": ["planning/control loop", "memory/retrieval"], "chapter_synthesis_mode": "clusters", "allowed_bibkeys_selected": ["Anokhin2024Arigraph", "Du2025Memr", "Wei2025Memory", "Tawosi2025Meta", "Abbineni2025Muallm", "Yao2022React", "Ye2025Task", "Tao2026Membox"], "allowed_bibkeys_mapped": ["Hu2025Evaluating", "Du2025Memr", "Yu2026Agentic", "Xia2025From", "Zhang2025Large", "Wu2025Meta", "Tao2026Membox", "Ye2025Task", "Tawosi2025Meta", "Ye2025Taska", "Wei2025Memory", "Xu2025Agentic", "Li2025Graphcodeagent", "Abbineni2025Muallm", "Anokhin2024Arigraph", "Zhang2024Large", "Liu2023Reason", "Yao2022React"], "allowed_bibkeys_chapter": ["Abbineni2025Muallm", "Anokhin2024Arigraph", "Dagan2024Plancraft", "Du2025Memr", "Hatalis2025Review", "Hong2025Planning", "Hu2025Evaluating", "Hu2025Training", "Huang2025Surgical", "Kim2025Bridging", "Kiruluta2025Novel", "Li2025Draft", "Li2025Graphcodeagent", "Liu2023Reason", "Liu2025Costbench", "Lu2025Pilotrl", "Nakano2025Guided", "Seo2025Simuhome", "Silva2025Agents", "Tao2026Membox", "Tawosi2025Meta", "Wei2025Memory", "Wu2025Meta", "Xia2025From", "Xu2025Agentic", "Yang2025Coarse", "Yao2022React", "Ye2025Task", "Ye2025Taska", "Yu2026Agentic", "Zhang2024Large", "Zhang2025Large", "Zhou2025Reasoning"], "evidence_ids": ["E-P0045-43287d5458", "E-P0184-1b99de5317", "E-P0080-f1ec9700e7", "E-P0031-f36b515991", "E-P0184-497b158080", "E-P0187-e294aeefb5", "E-P0080-06e45507a7", "E-P0001-ca4a00b5cf", "E-P0014-3bf4dab38c", "E-P0031-e3ebb83eb2", "E-P0128-d8feedefd0", "E-P0187-4d40260657"], "anchor_facts": [{"hook_type": "quant", "text": "We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets.", "citations": ["@Wei2025Memory"], "paper_id": "P0080", "evidence_id": "E-P0080-06e45507a7", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#key_results[0]"}, {"hook_type": "quant", "text": "Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\\%, into a compact, structured, natural language representation.", "citations": ["@Tawosi2025Meta"], "paper_id": "P0031", "evidence_id": "E-P0031-f36b515991", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#key_results[1]"}, {"hook_type": "quant", "text": "Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns,", "citations": ["@Ye2025Task"], "paper_id": "P0014", "evidence_id": "E-P0014-3bf4dab38c", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#key_results[0]"}, {"hook_type": "quant", "text": "From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap track", "citations": ["@Du2025Memr"], "paper_id": "P0184", "evidence_id": "E-P0184-1b99de5317", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#key_results[1]"}, {"hook_type": "limitation", "text": "In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time evolution,", "citations": ["@Wei2025Memory"], "paper_id": "P0080", "evidence_id": "E-P0080-f1ec9700e7", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#limitations[1]"}, {"hook_type": "quant", "text": "Empirical results on the LoCoMo benchmark demonstrate that MemR$^3$ surpasses strong baselines on LLM-as-a-Judge score, and particularly, it improves existing retrievers across four categories with an overall improvement on RAG (+7.29%) and Zep (+1.94%) using GPT-4.1-mini backend", "citations": ["@Du2025Memr"], "paper_id": "P0184", "evidence_id": "E-P0184-497b158080", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#key_results[0]"}, {"hook_type": "quant", "text": "To evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval and citation performance, and Reasoning-100 (Reas-100), focused on multistep reasoning in circuit design.", "citations": ["@Abbineni2025Muallm"], "paper_id": "P0187", "evidence_id": "E-P0187-e294aeefb5", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#key_results[1]"}, {"hook_type": "quant", "text": "On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples.", "citations": ["@Yao2022React"], "paper_id": "P0001", "evidence_id": "E-P0001-ca4a00b5cf", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#key_results[0]"}], "comparison_cards": [{"axis": "memory type (episodic / semantic / scratchpad)", "A_label": "Agent frameworks / architectures", "B_label": "Memory / retrieval augmentation", "citations": ["@Wei2025Memory", "@Tawosi2025Meta"], "A_highlights": [{"paper_id": "P0080", "evidence_id": "E-P0080-06e45507a7", "excerpt": "We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets.", "citations": ["@Wei2025Memory"], "pointer": "papers/paper_notes.jsonl:paper_id=P0080#key_results[0]"}, {"paper_id": "P0080", "evidence_id": "E-P0080-f1ec9700e7", "excerpt": "In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time", "citations": ["@Wei2025Memory"], "pointer": "papers/paper_notes.jsonl:paper_id=P0080#limitations[1]"}], "B_highlights": [{"paper_id": "P0031", "evidence_id": "E-P0031-f36b515991", "excerpt": "Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\\%, into a compact, structured, natural language representation.", "citations": ["@Tawosi2025Meta"], "pointer": "papers/paper_notes.jsonl:paper_id=P0031#key_results[1]"}, {"paper_id": "P0080", "evidence_id": "E-P0080-06e45507a7", "excerpt": "We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets.", "citations": ["@Wei2025Memory"], "pointer": "papers/paper_notes.jsonl:paper_id=P0080#key_results[0]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Memory / retrieval augmentation along 'memory type (episodic / semantic / scratchpad)'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "retrieval source + index (docs / web / logs)", "A_label": "Agent frameworks / architectures", "B_label": "Memory / retrieval augmentation", "citations": ["@Wei2025Memory", "@Tawosi2025Meta"], "A_highlights": [{"paper_id": "P0080", "evidence_id": "E-P0080-06e45507a7", "excerpt": "We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets.", "citations": ["@Wei2025Memory"], "pointer": "papers/paper_notes.jsonl:paper_id=P0080#key_results[0]"}, {"paper_id": "P0080", "evidence_id": "E-P0080-f1ec9700e7", "excerpt": "In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time", "citations": ["@Wei2025Memory"], "pointer": "papers/paper_notes.jsonl:paper_id=P0080#limitations[1]"}], "B_highlights": [{"paper_id": "P0031", "evidence_id": "E-P0031-f36b515991", "excerpt": "Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\\%, into a compact, structured, natural language representation.", "citations": ["@Tawosi2025Meta"], "pointer": "papers/paper_notes.jsonl:paper_id=P0031#key_results[1]"}, {"paper_id": "P0080", "evidence_id": "E-P0080-06e45507a7", "excerpt": "We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets.", "citations": ["@Wei2025Memory"], "pointer": "papers/paper_notes.jsonl:paper_id=P0080#key_results[0]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Memory / retrieval augmentation along 'retrieval source + index (docs / web / logs)'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "write / update / forgetting policy", "A_label": "Agent frameworks / architectures", "B_label": "Memory / retrieval augmentation", "citations": ["@Ye2025Task", "@Wei2025Memory", "@Tawosi2025Meta"], "A_highlights": [{"paper_id": "P0014", "evidence_id": "E-P0014-3bf4dab38c", "excerpt": "Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns,", "citations": ["@Ye2025Task"], "pointer": "papers/paper_notes.jsonl:paper_id=P0014#key_results[0]"}, {"paper_id": "P0080", "evidence_id": "E-P0080-06e45507a7", "excerpt": "We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets.", "citations": ["@Wei2025Memory"], "pointer": "papers/paper_notes.jsonl:paper_id=P0080#key_results[0]"}], "B_highlights": [{"paper_id": "P0014", "evidence_id": "E-P0014-3bf4dab38c", "excerpt": "Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns,", "citations": ["@Ye2025Task"], "pointer": "papers/paper_notes.jsonl:paper_id=P0014#key_results[0]"}, {"paper_id": "P0031", "evidence_id": "E-P0031-f36b515991", "excerpt": "Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\\%, into a compact, structured, natural language representation.", "citations": ["@Tawosi2025Meta"], "pointer": "papers/paper_notes.jsonl:paper_id=P0031#key_results[1]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Memory / retrieval augmentation along 'write / update / forgetting policy'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "mechanism / architecture", "A_label": "Agent frameworks / architectures", "B_label": "Memory / retrieval augmentation", "citations": ["@Ye2025Task", "@Wei2025Memory", "@Tawosi2025Meta"], "A_highlights": [{"paper_id": "P0014", "evidence_id": "E-P0014-3bf4dab38c", "excerpt": "Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns,", "citations": ["@Ye2025Task"], "pointer": "papers/paper_notes.jsonl:paper_id=P0014#key_results[0]"}, {"paper_id": "P0080", "evidence_id": "E-P0080-06e45507a7", "excerpt": "We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets.", "citations": ["@Wei2025Memory"], "pointer": "papers/paper_notes.jsonl:paper_id=P0080#key_results[0]"}], "B_highlights": [{"paper_id": "P0014", "evidence_id": "E-P0014-3bf4dab38c", "excerpt": "Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns,", "citations": ["@Ye2025Task"], "pointer": "papers/paper_notes.jsonl:paper_id=P0014#key_results[0]"}, {"paper_id": "P0031", "evidence_id": "E-P0031-f36b515991", "excerpt": "Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\\%, into a compact, structured, natural language representation.", "citations": ["@Tawosi2025Meta"], "pointer": "papers/paper_notes.jsonl:paper_id=P0031#key_results[1]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Memory / retrieval augmentation along 'mechanism / architecture'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}], "evaluation_protocol": [{"bullet": "Evaluation tokens mentioned in mapped evidence: LTM; STM; GRPO; AgeMem; MEM; LoCoMo; LLMs; TME; DAG; TRIM.", "citations": ["@Yu2026Agentic", "@Tao2026Membox", "@Ye2025Task", "@Wu2025Meta"]}], "limitation_hooks": [{"excerpt": "Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical.", "citations": ["@Yu2026Agentic"], "pointer": ""}, {"excerpt": "MPR (i) externalizes reusable corrective knowledge without model weight updates, (ii) enforces domain constraints to reduce unsafe or invalid actions, and (iii) retains the adaptability of language-based reflection.", "citations": ["@Wu2025Meta"], "pointer": ""}, {"excerpt": "We analyze mechanisms that explain these gains, discuss scalability and failure modes, and outline future directions for multimodal and multi-agent extensions.", "citations": ["@Wu2025Meta"], "pointer": ""}, {"excerpt": "In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time evolution, where LLMs retrieve, integrate, and", "citations": ["@Wei2025Memory"], "pointer": ""}], "must_use": {"min_anchor_facts": 1, "min_comparison_cards": 1, "min_limitation_hooks": 1, "require_cited_numeric_if_available": true, "require_multi_cite_synthesis_paragraph": true, "thesis_required": true}, "do_not_repeat_phrases": ["This subsection surveys", "This subsection argues", "In this subsection", "Next, we move from", "We now turn to", "claims remain provisional under abstract-only evidence", "abstract-only evidence", "Key takeaway:", "Main takeaway:"], "pack_warnings": [], "pack_stats": {"anchors": {"raw": 10, "considered": 8, "kept": 8, "dropped_no_cites": 0}, "comparisons": {"raw": 5, "considered": 4, "kept": 4, "dropped_no_highlights": 0, "highlights_dropped_no_cites": 0}, "evaluation_protocol": {"raw": 1, "considered": 1, "kept": 1, "dropped_no_cites": 0}, "limitation_hooks": {"raw": 4, "considered": 4, "kept": 4, "dropped_no_cites": 0}, "trim_policy": {"default": 400, "anchor_fact": 420, "highlight_excerpt": 280, "comparison_write_prompt": 420, "eval_bullet": 320, "limitation_excerpt": 320}}, "generated_at": "2026-01-18T01:21:06"}
{"sub_id": "5.1", "title": "Self-improvement and adaptation", "section_id": "5", "section_title": "Learning, Adaptation & Coordination", "rq": "Which design choices in Self-improvement and adaptation drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Self-improvement and adaptation methods emphasize training signal (SFT / preference / RL) and data synthesis + evaluator / reward trade-offs, but synthesis is clearest when claims are tied to explicit evaluation settings and reporting conventions.", "axes": ["training signal (SFT / preference / RL)", "data synthesis + evaluator / reward", "generalization + regression control", "mechanism / architecture", "data / training setup"], "bridge_terms": ["preference", "reward", "feedback", "self-improvement"], "contrast_hook": "learning/feedback", "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision"], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Self-improvement and adaptation drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "To make this concrete, Agent frameworks / architectures approaches provide a natural starting point because they make the agent-loop decision explicit.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: training signal (SFT / preference / RL), data synthesis + evaluator / reward, generalization + regression control, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Following this design, these designs imply concrete interface/data assumptions that shape behavior.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "In evaluations, protocols and metrics clarify where Agent frameworks / architectures works, and where it fails or becomes costly.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Memory / retrieval augmentation", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Unlike this route, Memory / retrieval augmentation approaches shift the emphasis and optimize for a different point in the trade-off space.", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Memory / retrieval augmentation", "data / training setup", "interface contract", "axes: training signal (SFT / preference / RL), data synthesis + evaluator / reward, generalization + regression control, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Following this design, the B-route relies on different interface/training assumptions, which changes failure modes and costs.", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Memory / retrieval augmentation", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "In evaluations, when comparable settings exist, evaluation evidence for B can be contrasted against A to surface the trade-offs.", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Memory / retrieval augmentation", "multiple citations in one paragraph", "axes: training signal (SFT / preference / RL), data synthesis + evaluator / reward, generalization + regression control, mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Taken together, the key distinction between Agent frameworks / architectures and Memory / retrieval augmentation is how they trade off training signal (SFT / preference / RL), data synthesis + evaluator / reward, generalization + regression control, mechanism / architecture, data / training setup under evaluation constraints.", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Planning / reasoning loops"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "Therefore, a decision checklist can map evaluation signals and constraints to route selection.", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Planning / reasoning loops"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Despite these advances, key claims hinge on assumptions that merit stress-testing, which motivates concrete verification targets.", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Planning / reasoning loops"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "chapter_throughline": ["Pin scope to goal: LLM agents survey (tool-use, planning, memory, multi-agent).", "Compare approaches along: training signal (SFT / preference / RL).", "Compare approaches along: data synthesis + evaluator / reward.", "Compare approaches along: generalization + regression control.", "Compare approaches along: mechanism / architecture.", "Compare approaches along: data / training setup."], "chapter_key_contrasts": ["learning/feedback", "coordination"], "chapter_synthesis_mode": "clusters", "allowed_bibkeys_selected": ["Zhou2025Self", "Zhao2025Achieving", "Van2025Survey", "Wu2025Evolver", "Yao2022React", "Belle2025Agents", "Zhou2024Archer", "Zhang2026Evoroute", "Wei2025Memory", "Nitin2025Faultline"], "allowed_bibkeys_mapped": ["Xia2025Sand", "Sarukkai2025Context", "Zhou2025Self", "Chen2025Grounded", "Belle2025Agents", "Wu2025Evolver", "Zhou2024Archer", "Du2024Anytool", "He2025Enabling", "Schneider2025Learning", "Wang2025Ragen", "Zhao2025Achieving", "Nitin2025Faultline", "Wang2025Swarms", "Zhang2026Evoroute", "Van2025Survey", "Wei2025Memory", "Yao2022React"], "allowed_bibkeys_chapter": ["Belle2025Agents", "Cao2025Skyrl", "Chang2025Alas", "Chen2025Grounded", "Chuang2025Debate", "Du2024Anytool", "Hao2025Multi", "Hassouna2024Agent", "He2025Enabling", "Li2025Draft", "Liu2025Aligning", "Lumer2025Memtool", "Nitin2025Faultline", "Papadakis2025Atlas", "Sarkar2025Survey", "Sarukkai2025Context", "Schneider2025Learning", "Shen2024Small", "Silva2025Agents", "Van2025Survey", "Wang2023Voyager", "Wang2025Ragen", "Wang2025Swarms", "Wei2025Memory", "Wu2025Agents", "Wu2025Evolver", "Xia2025Sand", "Yao2022React", "Yim2024Evaluating", "Zahedifar2025Agent", "Zhang2025Cognitive", "Zhang2026Evoroute", "Zhao2025Achieving", "Zhou2024Archer", "Zhou2025Self"], "evidence_ids": ["E-P0035-e872c22cb6", "E-P0138-1063eee7ce", "E-P0061-7acf4de689", "E-P0035-2e6956a116", "E-P0138-5f246d0ca8", "E-P0081-0c10233369", "E-P0001-ca4a00b5cf", "E-P0020-7929ef7a56", "E-P0044-faa3d4c9ee", "E-P0055-60cc0d458f", "E-P0080-06e45507a7", "E-P0082-74188ef933"], "anchor_facts": [{"hook_type": "quant", "text": "Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data.", "citations": ["@Zhou2025Self"], "paper_id": "P0035", "evidence_id": "E-P0035-2e6956a116", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#key_results[0]"}, {"hook_type": "quant", "text": "Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\\%$ and latency by over $70\\%$.", "citations": ["@Zhang2026Evoroute"], "paper_id": "P0055", "evidence_id": "E-P0055-60cc0d458f", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#key_results[0]"}, {"hook_type": "quant", "text": "This lifecycle comprises two key stages: (1) Offline Self-Distillation, where the agent's interaction trajectories are synthesized into a structured repository of abstract, reusable strategic principles; (2) Online Interaction, where the agent interacts with tasks and actively", "citations": ["@Wu2025Evolver"], "paper_id": "P0081", "evidence_id": "E-P0081-0c10233369", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#key_results[0]"}, {"hook_type": "quant", "text": "However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation.", "citations": ["@Zhao2025Achieving"], "paper_id": "P0138", "evidence_id": "E-P0138-1063eee7ce", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#key_results[0]"}, {"hook_type": "limitation", "text": "We assess the early successes of foundation models and identify persistent limitations, including challenges in generalizability, interpretability, data imbalance, safety concerns, and limited multimodal fusion.", "citations": ["@Van2025Survey"], "paper_id": "P0061", "evidence_id": "E-P0061-7acf4de689", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#limitations[1]"}, {"hook_type": "quant", "text": "Built on InternThinker-32B, InternGeometry solves 44 of 50 IMO geometry problems (2000-2024), exceeding the average gold medalist score (40.9), using only 13K training examples, just 0.004% of the data used by AlphaGeometry 2, demonstrating the potential of LLM agents on expert-l", "citations": ["@Zhao2025Achieving"], "paper_id": "P0138", "evidence_id": "E-P0138-5f246d0ca8", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#key_results[1]"}, {"hook_type": "quant", "text": "This lifecycle comprises two key stages: (1) Offline Self-Distillation, where the agent's interaction trajectories are synthesized into a structured repository of abstract, reusable strategic principles; (2) Online Interaction, where the agent interacts with tasks and actively re", "citations": ["@Wu2025Evolver"], "paper_id": "P0081", "evidence_id": "E-P0081-0c10233369", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#key_results[0]"}, {"hook_type": "quant", "text": "On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples.", "citations": ["@Yao2022React"], "paper_id": "P0001", "evidence_id": "E-P0001-ca4a00b5cf", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#key_results[0]"}], "comparison_cards": [{"axis": "training signal (SFT / preference / RL)", "A_label": "Agent frameworks / architectures", "B_label": "Memory / retrieval augmentation", "citations": ["@Zhou2025Self"], "A_highlights": [{"paper_id": "P0035", "evidence_id": "E-P0035-2e6956a116", "excerpt": "Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data.", "citations": ["@Zhou2025Self"], "pointer": "papers/paper_notes.jsonl:paper_id=P0035#key_results[0]"}, {"paper_id": "P0035", "evidence_id": "E-P0035-e872c22cb6", "excerpt": "In this paper, we propose the Self-Challenging framework for training an agent on high-quality tasks that are generated by itself.", "citations": ["@Zhou2025Self"], "pointer": "papers/paper_notes.jsonl:paper_id=P0035#method"}], "B_highlights": [], "write_prompt": "Contrast Agent frameworks / architectures vs Memory / retrieval augmentation along 'training signal (SFT / preference / RL)'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "data synthesis + evaluator / reward", "A_label": "Agent frameworks / architectures", "B_label": "Memory / retrieval augmentation", "citations": ["@Zhou2025Self", "@Zhang2026Evoroute"], "A_highlights": [{"paper_id": "P0035", "evidence_id": "E-P0035-2e6956a116", "excerpt": "Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data.", "citations": ["@Zhou2025Self"], "pointer": "papers/paper_notes.jsonl:paper_id=P0035#key_results[0]"}, {"paper_id": "P0055", "evidence_id": "E-P0055-60cc0d458f", "excerpt": "Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\\%$ and latency by over $70\\%$.", "citations": ["@Zhang2026Evoroute"], "pointer": "papers/paper_notes.jsonl:paper_id=P0055#key_results[0]"}], "B_highlights": [], "write_prompt": "Contrast Agent frameworks / architectures vs Memory / retrieval augmentation along 'data synthesis + evaluator / reward'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "generalization + regression control", "A_label": "Agent frameworks / architectures", "B_label": "Memory / retrieval augmentation", "citations": ["@Wu2025Evolver", "@Zhang2026Evoroute"], "A_highlights": [{"paper_id": "P0081", "evidence_id": "E-P0081-0c10233369", "excerpt": "This lifecycle comprises two key stages: (1) Offline Self-Distillation, where the agent's interaction trajectories are synthesized into a structured repository of abstract, reusable strategic principles; (2) Online Interaction, where the agent interacts with tasks and actively", "citations": ["@Wu2025Evolver"], "pointer": "papers/paper_notes.jsonl:paper_id=P0081#key_results[0]"}, {"paper_id": "P0055", "evidence_id": "E-P0055-60cc0d458f", "excerpt": "Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\\%$ and latency by over $70\\%$.", "citations": ["@Zhang2026Evoroute"], "pointer": "papers/paper_notes.jsonl:paper_id=P0055#key_results[0]"}], "B_highlights": [], "write_prompt": "Contrast Agent frameworks / architectures vs Memory / retrieval augmentation along 'generalization + regression control'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "mechanism / architecture", "A_label": "Agent frameworks / architectures", "B_label": "Memory / retrieval augmentation", "citations": ["@Wu2025Evolver", "@Zhang2026Evoroute"], "A_highlights": [{"paper_id": "P0081", "evidence_id": "E-P0081-0c10233369", "excerpt": "This lifecycle comprises two key stages: (1) Offline Self-Distillation, where the agent's interaction trajectories are synthesized into a structured repository of abstract, reusable strategic principles; (2) Online Interaction, where the agent interacts with tasks and actively", "citations": ["@Wu2025Evolver"], "pointer": "papers/paper_notes.jsonl:paper_id=P0081#key_results[0]"}, {"paper_id": "P0055", "evidence_id": "E-P0055-60cc0d458f", "excerpt": "Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\\%$ and latency by over $70\\%$.", "citations": ["@Zhang2026Evoroute"], "pointer": "papers/paper_notes.jsonl:paper_id=P0055#key_results[0]"}], "B_highlights": [], "write_prompt": "Contrast Agent frameworks / architectures vs Memory / retrieval augmentation along 'mechanism / architecture'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}], "evaluation_protocol": [{"bullet": "Evaluation tokens mentioned in mapped evidence: LLMs; GAIA; EvoRoute; BrowseComp; ReAct; HexMachina; AlphaBeta; TauBench; FMs; MatSci.", "citations": ["@Zhang2026Evoroute", "@Belle2025Agents", "@Zhou2025Self", "@Van2025Survey"]}], "limitation_hooks": [{"excerpt": "We formalize this challenge as the \\textbf{Agent System Trilemma}: the inherent tension among achieving state-of-the-art performance, minimizing monetary cost, and ensuring rapid task completion.", "citations": ["@Zhang2026Evoroute"], "pointer": ""}, {"excerpt": "The tasks take the form of a novel general class of problems termed Code-as-Task, which are defined by an instruction, a verification function and solution and failure cases which serve as tests, allowing to filter only for high-quality tasks.", "citations": ["@Zhou2025Self"], "pointer": ""}, {"excerpt": "We assess the early successes of foundation models and identify persistent limitations, including challenges in generalizability, interpretability, data imbalance, safety concerns, and limited multimodal fusion.", "citations": ["@Van2025Survey"], "pointer": ""}, {"excerpt": "In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time evolution, where LLMs retrieve, integrate, and", "citations": ["@Wei2025Memory"], "pointer": ""}], "must_use": {"min_anchor_facts": 1, "min_comparison_cards": 1, "min_limitation_hooks": 1, "require_cited_numeric_if_available": true, "require_multi_cite_synthesis_paragraph": true, "thesis_required": true}, "do_not_repeat_phrases": ["This subsection surveys", "This subsection argues", "In this subsection", "Next, we move from", "We now turn to", "claims remain provisional under abstract-only evidence", "abstract-only evidence", "Key takeaway:", "Main takeaway:"], "pack_warnings": [], "pack_stats": {"anchors": {"raw": 10, "considered": 8, "kept": 8, "dropped_no_cites": 0}, "comparisons": {"raw": 5, "considered": 4, "kept": 4, "dropped_no_highlights": 0, "highlights_dropped_no_cites": 0}, "evaluation_protocol": {"raw": 1, "considered": 1, "kept": 1, "dropped_no_cites": 0}, "limitation_hooks": {"raw": 4, "considered": 4, "kept": 4, "dropped_no_cites": 0}, "trim_policy": {"default": 400, "anchor_fact": 420, "highlight_excerpt": 280, "comparison_write_prompt": 420, "eval_bullet": 320, "limitation_excerpt": 320}}, "generated_at": "2026-01-18T01:21:06"}
{"sub_id": "5.2", "title": "Multi-agent coordination", "section_id": "5", "section_title": "Learning, Adaptation & Coordination", "rq": "Which design choices in Multi-agent coordination drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Multi-agent coordination highlights a tension around communication protocol + role assignment and aggregation (vote / debate / referee), motivating a protocol-aware synthesis rather than per-paper summaries.", "axes": ["communication protocol + role assignment", "aggregation (vote / debate / referee)", "stability (collusion, mode collapse, incentives)", "mechanism / architecture", "data / training setup"], "bridge_terms": ["roles", "communication", "debate", "aggregation", "stability"], "contrast_hook": "coordination", "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision"], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Multi-agent coordination drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "To make this concrete, Agent frameworks / architectures approaches provide a natural starting point because they make the agent-loop decision explicit.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: communication protocol + role assignment, aggregation (vote / debate / referee), stability (collusion, mode collapse, incentives), mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "At the implementation level, these designs imply concrete interface/data assumptions that shape behavior.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "In evaluations, protocols and metrics clarify where Agent frameworks / architectures works, and where it fails or becomes costly.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Multi-agent coordination", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Unlike this route, Multi-agent coordination approaches shift the emphasis and optimize for a different point in the trade-off space.", "use_clusters": ["Multi-agent coordination"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Multi-agent coordination", "data / training setup", "interface contract", "axes: communication protocol + role assignment, aggregation (vote / debate / referee), stability (collusion, mode collapse, incentives), mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "At the implementation level, the B-route relies on different interface/training assumptions, which changes failure modes and costs.", "use_clusters": ["Multi-agent coordination"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Multi-agent coordination", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "In evaluations, when comparable settings exist, evaluation evidence for B can be contrasted against A to surface the trade-offs.", "use_clusters": ["Multi-agent coordination"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Multi-agent coordination", "multiple citations in one paragraph", "axes: communication protocol + role assignment, aggregation (vote / debate / referee), stability (collusion, mode collapse, incentives), mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Stepping back, the key distinction between Agent frameworks / architectures and Multi-agent coordination is how they trade off communication protocol + role assignment, aggregation (vote / debate / referee), stability (collusion, mode collapse, incentives), mechanism / architecture, data / training setup under evaluation constraints.", "use_clusters": ["Agent frameworks / architectures", "Multi-agent coordination", "Planning / reasoning loops"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "Therefore, a decision checklist can map evaluation signals and constraints to route selection.", "use_clusters": ["Agent frameworks / architectures", "Multi-agent coordination", "Planning / reasoning loops"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Despite these advances, key claims hinge on assumptions that merit stress-testing, which motivates concrete verification targets.", "use_clusters": ["Agent frameworks / architectures", "Multi-agent coordination", "Planning / reasoning loops"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "chapter_throughline": ["Pin scope to goal: LLM agents survey (tool-use, planning, memory, multi-agent).", "Compare approaches along: training signal (SFT / preference / RL).", "Compare approaches along: data synthesis + evaluator / reward.", "Compare approaches along: generalization + regression control.", "Compare approaches along: mechanism / architecture.", "Compare approaches along: data / training setup."], "chapter_key_contrasts": ["learning/feedback", "coordination"], "chapter_synthesis_mode": "clusters", "allowed_bibkeys_selected": ["Sarkar2025Survey", "Wang2023Voyager", "Shen2024Small", "Lumer2025Memtool", "Cao2025Skyrl", "Chuang2025Debate", "Zhou2024Archer", "Zahedifar2025Agent", "Yim2024Evaluating"], "allowed_bibkeys_mapped": ["Papadakis2025Atlas", "Wu2025Agents", "Chuang2025Debate", "Zahedifar2025Agent", "Chang2025Alas", "Zhang2025Cognitive", "Hassouna2024Agent", "Li2025Draft", "Cao2025Skyrl", "Shen2024Small", "Hao2025Multi", "Yim2024Evaluating", "Silva2025Agents", "Lumer2025Memtool", "Sarkar2025Survey", "Zhou2024Archer", "Liu2025Aligning", "Wang2023Voyager"], "allowed_bibkeys_chapter": ["Belle2025Agents", "Cao2025Skyrl", "Chang2025Alas", "Chen2025Grounded", "Chuang2025Debate", "Du2024Anytool", "Hao2025Multi", "Hassouna2024Agent", "He2025Enabling", "Li2025Draft", "Liu2025Aligning", "Lumer2025Memtool", "Nitin2025Faultline", "Papadakis2025Atlas", "Sarkar2025Survey", "Sarukkai2025Context", "Schneider2025Learning", "Shen2024Small", "Silva2025Agents", "Van2025Survey", "Wang2023Voyager", "Wang2025Ragen", "Wang2025Swarms", "Wei2025Memory", "Wu2025Agents", "Wu2025Evolver", "Xia2025Sand", "Yao2022React", "Yim2024Evaluating", "Zahedifar2025Agent", "Zhang2025Cognitive", "Zhang2026Evoroute", "Zhao2025Achieving", "Zhou2024Archer", "Zhou2025Self"], "evidence_ids": ["E-P0037-2c281ce5fb", "E-P0005-506120a6cd", "E-P0050-c92ed293ba", "E-P0029-35271418ac", "E-P0029-38dc800de9", "E-P0036-5ed988eb67", "E-P0157-3acffd03b4", "E-P0005-b2eceb5b30", "E-P0036-3af1ce8090", "E-P0044-faa3d4c9ee", "E-P0087-ebcb5ebf6c", "E-P0046-95dc2415e7"], "anchor_facts": [{"hook_type": "quant", "text": "Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy.", "citations": ["@Lumer2025Memtool"], "paper_id": "P0029", "evidence_id": "E-P0029-35271418ac", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[0]"}, {"hook_type": "quant", "text": "We introduce two key components: an optimized asynchronous pipeline dispatcher that achieves a 1.55x speedup over naive asynchronous batching, and a tool-enhanced training recipe leveraging an AST-based search tool to facilitate code navigation, boost rollout Pass@K, and", "citations": ["@Cao2025Skyrl"], "paper_id": "P0036", "evidence_id": "E-P0036-5ed988eb67", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#key_results[1]"}, {"hook_type": "quant", "text": "DEBATE contains 29,417 messages from multi-round debate conversations among over 2,792 U.S.-based participants discussing 107 controversial topics, capturing both publicly-expressed messages and privately-reported opinions.", "citations": ["@Chuang2025Debate"], "paper_id": "P0157", "evidence_id": "E-P0157-3acffd03b4", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#key_results[0]"}, {"hook_type": "quant", "text": "MemTool offers three agentic architectures: 1) Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow Mode, providing deterministic control without autonomy, and 3) Hybrid Mode, combining autonomous and deterministic control.", "citations": ["@Lumer2025Memtool"], "paper_id": "P0029", "evidence_id": "E-P0029-38dc800de9", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[1]"}, {"hook_type": "quant", "text": "Using SkyRL-Agent, we train SA-SWE-32B, a software engineering agent trained from Qwen3-32B (24.4% Pass@1) purely with reinforcement learning.", "citations": ["@Cao2025Skyrl"], "paper_id": "P0036", "evidence_id": "E-P0036-3af1ce8090", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#key_results[0]"}, {"hook_type": "eval", "text": "This survey investigates how classical software design patterns can enhance the reliability and scalability of communication in Large Language Model (LLM)-driven agentic AI systems, focusing particularly on the Model Context Protocol (MCP).", "citations": ["@Sarkar2025Survey"], "paper_id": "P0037", "evidence_id": "E-P0037-2c281ce5fb", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#method"}, {"hook_type": "quant", "text": "Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, ex", "citations": ["@Wang2023Voyager"], "paper_id": "P0005", "evidence_id": "E-P0005-506120a6cd", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#key_results[1]"}, {"hook_type": "quant", "text": "We introduce two key components: an optimized asynchronous pipeline dispatcher that achieves a 1.55x speedup over naive asynchronous batching, and a tool-enhanced training recipe leveraging an AST-based search tool to facilitate code navigation, boost rollout Pass@K, and improve", "citations": ["@Cao2025Skyrl"], "paper_id": "P0036", "evidence_id": "E-P0036-5ed988eb67", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#key_results[1]"}], "comparison_cards": [{"axis": "communication protocol + role assignment", "A_label": "Agent frameworks / architectures", "B_label": "Multi-agent coordination", "citations": ["@Lumer2025Memtool", "@Cao2025Skyrl", "@Chuang2025Debate"], "A_highlights": [{"paper_id": "P0029", "evidence_id": "E-P0029-35271418ac", "excerpt": "Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy.", "citations": ["@Lumer2025Memtool"], "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[0]"}, {"paper_id": "P0036", "evidence_id": "E-P0036-5ed988eb67", "excerpt": "We introduce two key components: an optimized asynchronous pipeline dispatcher that achieves a 1.55x speedup over naive asynchronous batching, and a tool-enhanced training recipe leveraging an AST-based search tool to facilitate code navigation, boost rollout Pass@K, and", "citations": ["@Cao2025Skyrl"], "pointer": "papers/paper_notes.jsonl:paper_id=P0036#key_results[1]"}], "B_highlights": [{"paper_id": "P0157", "evidence_id": "E-P0157-3acffd03b4", "excerpt": "DEBATE contains 29,417 messages from multi-round debate conversations among over 2,792 U.S.-based participants discussing 107 controversial topics, capturing both publicly-expressed messages and privately-reported opinions.", "citations": ["@Chuang2025Debate"], "pointer": "papers/paper_notes.jsonl:paper_id=P0157#key_results[0]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Multi-agent coordination along 'communication protocol + role assignment'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "aggregation (vote / debate / referee)", "A_label": "Agent frameworks / architectures", "B_label": "Multi-agent coordination", "citations": ["@Cao2025Skyrl", "@Lumer2025Memtool", "@Chuang2025Debate"], "A_highlights": [{"paper_id": "P0036", "evidence_id": "E-P0036-5ed988eb67", "excerpt": "We introduce two key components: an optimized asynchronous pipeline dispatcher that achieves a 1.55x speedup over naive asynchronous batching, and a tool-enhanced training recipe leveraging an AST-based search tool to facilitate code navigation, boost rollout Pass@K, and", "citations": ["@Cao2025Skyrl"], "pointer": "papers/paper_notes.jsonl:paper_id=P0036#key_results[1]"}, {"paper_id": "P0029", "evidence_id": "E-P0029-38dc800de9", "excerpt": "MemTool offers three agentic architectures: 1) Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow Mode, providing deterministic control without autonomy, and 3) Hybrid Mode, combining autonomous and deterministic control.", "citations": ["@Lumer2025Memtool"], "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[1]"}], "B_highlights": [{"paper_id": "P0157", "evidence_id": "E-P0157-3acffd03b4", "excerpt": "DEBATE contains 29,417 messages from multi-round debate conversations among over 2,792 U.S.-based participants discussing 107 controversial topics, capturing both publicly-expressed messages and privately-reported opinions.", "citations": ["@Chuang2025Debate"], "pointer": "papers/paper_notes.jsonl:paper_id=P0157#key_results[0]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Multi-agent coordination along 'aggregation (vote / debate / referee)'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "stability (collusion, mode collapse, incentives)", "A_label": "Agent frameworks / architectures", "B_label": "Multi-agent coordination", "citations": ["@Cao2025Skyrl", "@Lumer2025Memtool", "@Chuang2025Debate"], "A_highlights": [{"paper_id": "P0036", "evidence_id": "E-P0036-5ed988eb67", "excerpt": "We introduce two key components: an optimized asynchronous pipeline dispatcher that achieves a 1.55x speedup over naive asynchronous batching, and a tool-enhanced training recipe leveraging an AST-based search tool to facilitate code navigation, boost rollout Pass@K, and", "citations": ["@Cao2025Skyrl"], "pointer": "papers/paper_notes.jsonl:paper_id=P0036#key_results[1]"}, {"paper_id": "P0029", "evidence_id": "E-P0029-38dc800de9", "excerpt": "MemTool offers three agentic architectures: 1) Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow Mode, providing deterministic control without autonomy, and 3) Hybrid Mode, combining autonomous and deterministic control.", "citations": ["@Lumer2025Memtool"], "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[1]"}], "B_highlights": [{"paper_id": "P0157", "evidence_id": "E-P0157-3acffd03b4", "excerpt": "DEBATE contains 29,417 messages from multi-round debate conversations among over 2,792 U.S.-based participants discussing 107 controversial topics, capturing both publicly-expressed messages and privately-reported opinions.", "citations": ["@Chuang2025Debate"], "pointer": "papers/paper_notes.jsonl:paper_id=P0157#key_results[0]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Multi-agent coordination along 'stability (collusion, mode collapse, incentives)'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "mechanism / architecture", "A_label": "Agent frameworks / architectures", "B_label": "Multi-agent coordination", "citations": ["@Cao2025Skyrl", "@Lumer2025Memtool", "@Chuang2025Debate"], "A_highlights": [{"paper_id": "P0036", "evidence_id": "E-P0036-5ed988eb67", "excerpt": "We introduce two key components: an optimized asynchronous pipeline dispatcher that achieves a 1.55x speedup over naive asynchronous batching, and a tool-enhanced training recipe leveraging an AST-based search tool to facilitate code navigation, boost rollout Pass@K, and", "citations": ["@Cao2025Skyrl"], "pointer": "papers/paper_notes.jsonl:paper_id=P0036#key_results[1]"}, {"paper_id": "P0029", "evidence_id": "E-P0029-38dc800de9", "excerpt": "MemTool offers three agentic architectures: 1) Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow Mode, providing deterministic control without autonomy, and 3) Hybrid Mode, combining autonomous and deterministic control.", "citations": ["@Lumer2025Memtool"], "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[1]"}], "B_highlights": [{"paper_id": "P0157", "evidence_id": "E-P0157-3acffd03b4", "excerpt": "DEBATE contains 29,417 messages from multi-round debate conversations among over 2,792 U.S.-based participants discussing 107 controversial topics, capturing both publicly-expressed messages and privately-reported opinions.", "citations": ["@Chuang2025Debate"], "pointer": "papers/paper_notes.jsonl:paper_id=P0157#key_results[0]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Multi-agent coordination along 'mechanism / architecture'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}], "evaluation_protocol": [{"bullet": "Evaluation tokens mentioned in mapped evidence: LLMs; MCP; MemTool; ScaleMCP; SA-SWE-32B; AST-based; SWE-Bench; SWE; SkyRL-Agent; SkyRL-train.", "citations": ["@Silva2025Agents", "@Lumer2025Memtool", "@Cao2025Skyrl", "@Sarkar2025Survey"]}], "limitation_hooks": [{"excerpt": "This study offers new insights into the strengths and failure modes of LLMs in physically grounded multi-agent collaboration tasks, contributing to future benchmarks and architectural improvements.", "citations": ["@Silva2025Agents"], "pointer": ""}, {"excerpt": "The article concludes by outlining open challenges, potential security risks, and promising directions for advancing robust, interoperable, and scalable multi-agent LLM ecosystems.", "citations": ["@Sarkar2025Survey"], "pointer": ""}, {"excerpt": "Across regime-specific equity studies and multiple LLM families, Adaptive-OPRO consistently outperforms fixed prompts, while reflection-based feedback fails to provide systematic gains.", "citations": ["@Papadakis2025Atlas"], "pointer": ""}, {"excerpt": "While role-playing large language models (LLMs) offer a promising way to simulate human-like interactions, existing research shows that single-agent alignment does not guarantee authentic multi-agent group dynamics.", "citations": ["@Chuang2025Debate"], "pointer": ""}], "must_use": {"min_anchor_facts": 1, "min_comparison_cards": 1, "min_limitation_hooks": 1, "require_cited_numeric_if_available": true, "require_multi_cite_synthesis_paragraph": true, "thesis_required": true}, "do_not_repeat_phrases": ["This subsection surveys", "This subsection argues", "In this subsection", "Next, we move from", "We now turn to", "claims remain provisional under abstract-only evidence", "abstract-only evidence", "Key takeaway:", "Main takeaway:"], "pack_warnings": [], "pack_stats": {"anchors": {"raw": 10, "considered": 8, "kept": 8, "dropped_no_cites": 0}, "comparisons": {"raw": 5, "considered": 4, "kept": 4, "dropped_no_highlights": 0, "highlights_dropped_no_cites": 0}, "evaluation_protocol": {"raw": 1, "considered": 1, "kept": 1, "dropped_no_cites": 0}, "limitation_hooks": {"raw": 4, "considered": 4, "kept": 4, "dropped_no_cites": 0}, "trim_policy": {"default": 400, "anchor_fact": 420, "highlight_excerpt": 280, "comparison_write_prompt": 420, "eval_bullet": 320, "limitation_excerpt": 320}}, "generated_at": "2026-01-18T01:21:06"}
{"sub_id": "6.1", "title": "Benchmarks and evaluation protocols", "section_id": "6", "section_title": "Evaluation & Risks", "rq": "Which design choices in Benchmarks and evaluation protocols drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Benchmarks and evaluation protocols methods emphasize tool interface (function calling, schemas, protocols) and tool selection / routing policy trade-offs, but synthesis is clearest when claims are tied to explicit evaluation settings and reporting conventions.", "axes": ["tool interface (function calling, schemas, protocols)", "tool selection / routing policy", "sandboxing / permissions / observability", "task suites (web / code / embodied / tools)", "metrics (success, cost, reliability, safety)"], "bridge_terms": ["function calling", "tool schema", "routing", "sandbox", "observability", "benchmarks"], "contrast_hook": "tool interfaces", "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "compute / cost (train/infer)", "threat model", "defense surface"], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Benchmarks and evaluation protocols drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "To ground this thesis, Agent frameworks / architectures approaches provide a natural starting point because they make the agent-loop decision explicit.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, task suites (web / code / embodied / tools), metrics (success, cost, reliability, safety)"], "connector_to_prev": "elaboration", "connector_phrase": "Building on this, these designs imply concrete interface/data assumptions that shape behavior.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Empirically, protocols and metrics clarify where Agent frameworks / architectures works, and where it fails or becomes costly.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Evaluation / benchmark-focused works", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "By contrast, Evaluation / benchmark-focused works approaches shift the emphasis and optimize for a different point in the trade-off space.", "use_clusters": ["Evaluation / benchmark-focused works"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Evaluation / benchmark-focused works", "data / training setup", "interface contract", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, task suites (web / code / embodied / tools), metrics (success, cost, reliability, safety)"], "connector_to_prev": "elaboration", "connector_phrase": "Building on this, the B-route relies on different interface/training assumptions, which changes failure modes and costs.", "use_clusters": ["Evaluation / benchmark-focused works"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Evaluation / benchmark-focused works", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Empirically, when comparable settings exist, evaluation evidence for B can be contrasted against A to surface the trade-offs.", "use_clusters": ["Evaluation / benchmark-focused works"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Evaluation / benchmark-focused works", "multiple citations in one paragraph", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, task suites (web / code / embodied / tools), metrics (success, cost, reliability, safety)"], "connector_to_prev": "synthesis", "connector_phrase": "Stepping back, the key distinction between Agent frameworks / architectures and Evaluation / benchmark-focused works is how they trade off tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, task suites (web / code / embodied / tools), metrics (success, cost, reliability, safety) under evaluation constraints.", "use_clusters": ["Agent frameworks / architectures", "Evaluation / benchmark-focused works", "Safety / security / guardrails"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "Consequently, a decision checklist can map evaluation signals and constraints to route selection.", "use_clusters": ["Agent frameworks / architectures", "Evaluation / benchmark-focused works", "Safety / security / guardrails"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Despite these advances, key claims hinge on assumptions that merit stress-testing, which motivates concrete verification targets.", "use_clusters": ["Agent frameworks / architectures", "Evaluation / benchmark-focused works", "Safety / security / guardrails"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "chapter_throughline": ["Pin scope to goal: LLM agents survey (tool-use, planning, memory, multi-agent).", "Compare approaches along: tool interface (function calling, schemas, protocols).", "Compare approaches along: tool selection / routing policy.", "Compare approaches along: sandboxing / permissions / observability.", "Compare approaches along: task suites (web / code / embodied / tools).", "Compare approaches along: metrics (success, cost, reliability, safety)."], "chapter_key_contrasts": ["tool interfaces", "security"], "chapter_synthesis_mode": "tradeoff_matrix", "allowed_bibkeys_selected": ["Zhang2025Security", "Mohammadi2025Evaluation", "Shi2025Progent", "Shang2024Agentsquare", "Fu2025Eval", "Kale2025Reliable", "Kim2026Beyond", "Li2026Autonomous", "Chen2025Towards"], "allowed_bibkeys_mapped": ["Mohammadi2025Evaluation", "Chen2025Towards", "Fu2025Eval", "Kim2026Beyond", "Ji2025Taxonomy", "Li2024Personal", "Zhan2025Sentinel", "Dagan2024Plancraft", "Li2026Autonomous", "Zhu2025Where", "Lidayan2025Abbel", "Shi2025Progent", "Zhang2025Security", "Shao2025Craken", "He2025Plan", "Kale2025Reliable", "Shang2024Agentsquare", "Liu2023Reason"], "allowed_bibkeys_chapter": ["An2025Ipiguard", "Bonagiri2025Check", "Chen2025Towards", "Dagan2024Plancraft", "Fu2025Eval", "Gasmi2025Bridging", "Hadeliya2025When", "He2025Plan", "Ji2025Taxonomy", "Kale2025Reliable", "Kim2026Beyond", "Lee2025Bench", "Li2024Personal", "Li2025Stac", "Li2026Autonomous", "Lichkovski2025Agent", "Lidayan2025Abbel", "Liu2023Reason", "Liu2026Agents", "Luo2025Agrail", "Mohammadi2025Evaluation", "Plaat2025Agentic", "Rosario2025Architecting", "Sha2025Agent", "Shang2024Agentsquare", "Shao2025Craken", "Shi2025Progent", "Zhan2025Sentinel", "Zhang2025Security", "Zhou2025Reasoning", "Zhu2025Where"], "evidence_ids": ["E-P0089-8bcb673a7d", "E-P0164-37f9ea924c", "E-P0032-6829c8b583", "E-P0043-38a26e4777", "E-P0089-d6095e10e9", "E-P0089-7a6ec4daed", "E-P0199-753416ce70", "E-P0203-e0345118bc", "E-P0054-79f88927fa", "E-P0032-68db58914f", "E-P0052-9980bf7642", "E-P0102-4fc221fdea"], "anchor_facts": [{"hook_type": "quant", "text": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed", "citations": ["@Zhang2025Security"], "paper_id": "P0089", "evidence_id": "E-P0089-d6095e10e9", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}, {"hook_type": "quant", "text": "RAS-Eval comprises 80 test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration (CWE) categories, with tools implemented in JSON, LangGraph, and Model Context Protocol (MCP) formats.", "citations": ["@Fu2025Eval"], "paper_id": "P0199", "evidence_id": "E-P0199-753416ce70", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#key_results[1]"}, {"hook_type": "quant", "text": "This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and", "citations": ["@Mohammadi2025Evaluation"], "paper_id": "P0164", "evidence_id": "E-P0164-37f9ea924c", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#key_results[0]"}, {"hook_type": "quant", "text": "Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed.", "citations": ["@Shi2025Progent"], "paper_id": "P0032", "evidence_id": "E-P0032-68db58914f", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#key_results[0]"}, {"hook_type": "eval", "text": "We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling.", "citations": ["@Zhang2025Security"], "paper_id": "P0089", "evidence_id": "E-P0089-8bcb673a7d", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#method"}, {"hook_type": "quant", "text": "This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and (", "citations": ["@Mohammadi2025Evaluation"], "paper_id": "P0164", "evidence_id": "E-P0164-37f9ea924c", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#key_results[0]"}, {"hook_type": "quant", "text": "Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs.", "citations": ["@Shang2024Agentsquare"], "paper_id": "P0043", "evidence_id": "E-P0043-38a26e4777", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#key_results[0]"}, {"hook_type": "quant", "text": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed a", "citations": ["@Zhang2025Security"], "paper_id": "P0089", "evidence_id": "E-P0089-d6095e10e9", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}], "comparison_cards": [{"axis": "tool interface (function calling, schemas, protocols)", "A_label": "Agent frameworks / architectures", "B_label": "Evaluation / benchmark-focused works", "citations": ["@Zhang2025Security", "@Fu2025Eval"], "A_highlights": [{"paper_id": "P0089", "evidence_id": "E-P0089-d6095e10e9", "excerpt": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}, {"paper_id": "P0089", "evidence_id": "E-P0089-8bcb673a7d", "excerpt": "We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling.", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#method"}], "B_highlights": [{"paper_id": "P0199", "evidence_id": "E-P0199-753416ce70", "excerpt": "RAS-Eval comprises 80 test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration (CWE) categories, with tools implemented in JSON, LangGraph, and Model Context Protocol (MCP) formats.", "citations": ["@Fu2025Eval"], "pointer": "papers/paper_notes.jsonl:paper_id=P0199#key_results[1]"}, {"paper_id": "P0089", "evidence_id": "E-P0089-d6095e10e9", "excerpt": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Evaluation / benchmark-focused works along 'tool interface (function calling, schemas, protocols)'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "tool selection / routing policy", "A_label": "Agent frameworks / architectures", "B_label": "Evaluation / benchmark-focused works", "citations": ["@Zhang2025Security", "@Fu2025Eval"], "A_highlights": [{"paper_id": "P0089", "evidence_id": "E-P0089-d6095e10e9", "excerpt": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}, {"paper_id": "P0089", "evidence_id": "E-P0089-8bcb673a7d", "excerpt": "We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling.", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#method"}], "B_highlights": [{"paper_id": "P0199", "evidence_id": "E-P0199-753416ce70", "excerpt": "RAS-Eval comprises 80 test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration (CWE) categories, with tools implemented in JSON, LangGraph, and Model Context Protocol (MCP) formats.", "citations": ["@Fu2025Eval"], "pointer": "papers/paper_notes.jsonl:paper_id=P0199#key_results[1]"}, {"paper_id": "P0089", "evidence_id": "E-P0089-d6095e10e9", "excerpt": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Evaluation / benchmark-focused works along 'tool selection / routing policy'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "sandboxing / permissions / observability", "A_label": "Agent frameworks / architectures", "B_label": "Evaluation / benchmark-focused works", "citations": ["@Zhang2025Security", "@Mohammadi2025Evaluation"], "A_highlights": [{"paper_id": "P0089", "evidence_id": "E-P0089-d6095e10e9", "excerpt": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}, {"paper_id": "P0089", "evidence_id": "E-P0089-8bcb673a7d", "excerpt": "We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling.", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#method"}], "B_highlights": [{"paper_id": "P0089", "evidence_id": "E-P0089-d6095e10e9", "excerpt": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}, {"paper_id": "P0164", "evidence_id": "E-P0164-37f9ea924c", "excerpt": "This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and", "citations": ["@Mohammadi2025Evaluation"], "pointer": "papers/paper_notes.jsonl:paper_id=P0164#key_results[0]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Evaluation / benchmark-focused works along 'sandboxing / permissions / observability'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "task suites (web / code / embodied / tools)", "A_label": "Agent frameworks / architectures", "B_label": "Evaluation / benchmark-focused works", "citations": ["@Zhang2025Security", "@Fu2025Eval"], "A_highlights": [{"paper_id": "P0089", "evidence_id": "E-P0089-d6095e10e9", "excerpt": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}, {"paper_id": "P0089", "evidence_id": "E-P0089-8bcb673a7d", "excerpt": "We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling.", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#method"}], "B_highlights": [{"paper_id": "P0199", "evidence_id": "E-P0199-753416ce70", "excerpt": "RAS-Eval comprises 80 test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration (CWE) categories, with tools implemented in JSON, LangGraph, and Model Context Protocol (MCP) formats.", "citations": ["@Fu2025Eval"], "pointer": "papers/paper_notes.jsonl:paper_id=P0199#key_results[1]"}, {"paper_id": "P0089", "evidence_id": "E-P0089-d6095e10e9", "excerpt": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Evaluation / benchmark-focused works along 'task suites (web / code / embodied / tools)'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}], "evaluation_protocol": [{"bullet": "Evaluation tokens mentioned in mapped evidence: DeepSeek-V3; API; LLMs; WildAGTEval; ALFWorld; GAIA; AgentErrorTaxonomy; AgentErrorBench; WebShop; AgentDebug.", "citations": ["@Li2026Autonomous", "@Kim2026Beyond", "@Zhu2025Where", "@Lidayan2025Abbel"]}], "limitation_hooks": [{"excerpt": "Analysis of failure modes reveals characteristic patterns across models, with the multi-agent configuration substantially reducing implementation errors and hallucinations compared to simpler architectures.", "citations": ["@Li2026Autonomous"], "pointer": ""}, {"excerpt": "Yet their sophisticated architectures amplify vulnerability to cascading failures, where a single root-cause error propagates through subsequent decisions, leading to task failure.", "citations": ["@Zhu2025Where"], "pointer": ""}, {"excerpt": "First, we introduce the AgentErrorTaxonomy, a modular classification of failure modes spanning memory, reflection, planning, action, and system-level operations.", "citations": ["@Zhu2025Where"], "pointer": ""}, {"excerpt": "Second, we construct AgentErrorBench, the first dataset of systematically annotated failure trajectories from ALFWorld, GAIA, and WebShop, grounding error analysis in real-world agent rollouts.", "citations": ["@Zhu2025Where"], "pointer": ""}], "must_use": {"min_anchor_facts": 1, "min_comparison_cards": 1, "min_limitation_hooks": 1, "require_cited_numeric_if_available": true, "require_multi_cite_synthesis_paragraph": true, "thesis_required": true}, "do_not_repeat_phrases": ["This subsection surveys", "This subsection argues", "In this subsection", "Next, we move from", "We now turn to", "claims remain provisional under abstract-only evidence", "abstract-only evidence", "Key takeaway:", "Main takeaway:"], "pack_warnings": [], "pack_stats": {"anchors": {"raw": 11, "considered": 8, "kept": 8, "dropped_no_cites": 0}, "comparisons": {"raw": 5, "considered": 4, "kept": 4, "dropped_no_highlights": 0, "highlights_dropped_no_cites": 0}, "evaluation_protocol": {"raw": 1, "considered": 1, "kept": 1, "dropped_no_cites": 0}, "limitation_hooks": {"raw": 4, "considered": 4, "kept": 4, "dropped_no_cites": 0}, "trim_policy": {"default": 400, "anchor_fact": 420, "highlight_excerpt": 280, "comparison_write_prompt": 420, "eval_bullet": 320, "limitation_excerpt": 320}}, "generated_at": "2026-01-18T01:21:06"}
{"sub_id": "6.2", "title": "Safety, security, and governance", "section_id": "6", "section_title": "Evaluation & Risks", "rq": "Which design choices in Safety, security, and governance drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Safety, security, and governance methods emphasize threat model (prompt / tool injection, exfiltration) and defense surface (policy, sandbox, monitoring) trade-offs, but synthesis is clearest when claims are tied to explicit evaluation settings and reporting conventions.", "axes": ["threat model (prompt / tool injection, exfiltration)", "defense surface (policy, sandbox, monitoring)", "security evaluation protocol", "mechanism / architecture", "data / training setup"], "bridge_terms": ["threat model", "prompt/tool injection", "monitoring", "guardrails"], "contrast_hook": "security", "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision", "threat model", "defense surface"], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Safety, security, and governance drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "To ground this thesis, Agent frameworks / architectures approaches provide a natural starting point because they make the agent-loop decision explicit.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: threat model (prompt / tool injection, exfiltration), defense surface (policy, sandbox, monitoring), security evaluation protocol, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "More concretely, these designs imply concrete interface/data assumptions that shape behavior.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Under standard benchmarks, protocols and metrics clarify where Agent frameworks / architectures works, and where it fails or becomes costly.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Safety / security / guardrails", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Unlike this route, Safety / security / guardrails approaches shift the emphasis and optimize for a different point in the trade-off space.", "use_clusters": ["Safety / security / guardrails"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Safety / security / guardrails", "data / training setup", "interface contract", "axes: threat model (prompt / tool injection, exfiltration), defense surface (policy, sandbox, monitoring), security evaluation protocol, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "More concretely, the B-route relies on different interface/training assumptions, which changes failure modes and costs.", "use_clusters": ["Safety / security / guardrails"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Safety / security / guardrails", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Under standard benchmarks, when comparable settings exist, evaluation evidence for B can be contrasted against A to surface the trade-offs.", "use_clusters": ["Safety / security / guardrails"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Safety / security / guardrails", "multiple citations in one paragraph", "axes: threat model (prompt / tool injection, exfiltration), defense surface (policy, sandbox, monitoring), security evaluation protocol, mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Stepping back, the key distinction between Agent frameworks / architectures and Safety / security / guardrails is how they trade off threat model (prompt / tool injection, exfiltration), defense surface (policy, sandbox, monitoring), security evaluation protocol, mechanism / architecture, data / training setup under evaluation constraints.", "use_clusters": ["Agent frameworks / architectures", "Safety / security / guardrails", "Code agents / software tasks"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "Therefore, a decision checklist can map evaluation signals and constraints to route selection.", "use_clusters": ["Agent frameworks / architectures", "Safety / security / guardrails", "Code agents / software tasks"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Despite these advances, key claims hinge on assumptions that merit stress-testing, which motivates concrete verification targets.", "use_clusters": ["Agent frameworks / architectures", "Safety / security / guardrails", "Code agents / software tasks"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "chapter_throughline": ["Pin scope to goal: LLM agents survey (tool-use, planning, memory, multi-agent).", "Compare approaches along: tool interface (function calling, schemas, protocols).", "Compare approaches along: tool selection / routing policy.", "Compare approaches along: sandboxing / permissions / observability.", "Compare approaches along: task suites (web / code / embodied / tools).", "Compare approaches along: metrics (success, cost, reliability, safety)."], "chapter_key_contrasts": ["tool interfaces", "security"], "chapter_synthesis_mode": "tradeoff_matrix", "allowed_bibkeys_selected": ["Zhang2025Security", "Lichkovski2025Agent", "Kale2025Reliable", "Fu2025Eval", "Shi2025Progent", "Lee2025Bench", "Li2025Stac", "Bonagiri2025Check"], "allowed_bibkeys_mapped": ["Bonagiri2025Check", "Gasmi2025Bridging", "Zhang2025Security", "Hadeliya2025When", "Luo2025Agrail", "Sha2025Agent", "An2025Ipiguard", "Fu2025Eval", "Kale2025Reliable", "Lichkovski2025Agent", "Lee2025Bench", "Li2025Stac", "Shi2025Progent", "Zhou2025Reasoning", "Liu2026Agents", "Plaat2025Agentic", "Rosario2025Architecting", "Liu2023Reason"], "allowed_bibkeys_chapter": ["An2025Ipiguard", "Bonagiri2025Check", "Chen2025Towards", "Dagan2024Plancraft", "Fu2025Eval", "Gasmi2025Bridging", "Hadeliya2025When", "He2025Plan", "Ji2025Taxonomy", "Kale2025Reliable", "Kim2026Beyond", "Lee2025Bench", "Li2024Personal", "Li2025Stac", "Li2026Autonomous", "Lichkovski2025Agent", "Lidayan2025Abbel", "Liu2023Reason", "Liu2026Agents", "Luo2025Agrail", "Mohammadi2025Evaluation", "Plaat2025Agentic", "Rosario2025Architecting", "Sha2025Agent", "Shang2024Agentsquare", "Shao2025Craken", "Shi2025Progent", "Zhan2025Sentinel", "Zhang2025Security", "Zhou2025Reasoning", "Zhu2025Where"], "evidence_ids": ["E-P0089-8bcb673a7d", "E-P0089-d6095e10e9", "E-P0161-a256400826", "E-P0203-e0345118bc", "E-P0199-753416ce70", "E-P0089-7a6ec4daed", "E-P0032-68db58914f", "E-P0205-32438dad15", "E-P0209-82fdf6d15e", "E-P0199-2895472ae1", "E-P0205-0a269c6135", "E-P0075-7edb91824f"], "anchor_facts": [{"hook_type": "quant", "text": "Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed.", "citations": ["@Shi2025Progent"], "paper_id": "P0032", "evidence_id": "E-P0032-68db58914f", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#key_results[0]"}, {"hook_type": "quant", "text": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed", "citations": ["@Zhang2025Security"], "paper_id": "P0089", "evidence_id": "E-P0089-d6095e10e9", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}, {"hook_type": "quant", "text": "We evaluate nine popular LLM agents across 10 domains and 400+ tools, producing 2,000 attack instances.", "citations": ["@Zhang2025Security"], "paper_id": "P0089", "evidence_id": "E-P0089-7a6ec4daed", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[1]"}, {"hook_type": "eval", "text": "We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling.", "citations": ["@Zhang2025Security"], "paper_id": "P0089", "evidence_id": "E-P0089-8bcb673a7d", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#method"}, {"hook_type": "quant", "text": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed a", "citations": ["@Zhang2025Security"], "paper_id": "P0089", "evidence_id": "E-P0089-d6095e10e9", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}, {"hook_type": "quant", "text": "To this end, we systematize a monitor red teaming (MRT) workflow that incorporates: (1) varying levels of agent and monitor situational awareness; (2) distinct adversarial strategies to evade the monitor, such as prompt injection; and (3) two datasets and environments -- SHADE-Ar", "citations": ["@Kale2025Reliable"], "paper_id": "P0203", "evidence_id": "E-P0203-e0345118bc", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#key_results[0]"}, {"hook_type": "quant", "text": "RAS-Eval comprises 80 test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration (CWE) categories, with tools implemented in JSON, LangGraph, and Model Context Protocol (MCP) formats.", "citations": ["@Fu2025Eval"], "paper_id": "P0199", "evidence_id": "E-P0199-753416ce70", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#key_results[1]"}, {"hook_type": "quant", "text": "A comprehensive evaluation of state-of-the-art LLM code agents reveals significant performance gaps, achieving at most 18.0% success in PoC generation and 34.0% in vulnerability patching on our complete dataset.", "citations": ["@Lee2025Bench"], "paper_id": "P0205", "evidence_id": "E-P0205-32438dad15", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#key_results[0]"}], "comparison_cards": [{"axis": "threat model (prompt / tool injection, exfiltration)", "A_label": "Agent frameworks / architectures", "B_label": "Safety / security / guardrails", "citations": ["@Shi2025Progent", "@Zhang2025Security"], "A_highlights": [{"paper_id": "P0032", "evidence_id": "E-P0032-68db58914f", "excerpt": "Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed.", "citations": ["@Shi2025Progent"], "pointer": "papers/paper_notes.jsonl:paper_id=P0032#key_results[0]"}], "B_highlights": [{"paper_id": "P0089", "evidence_id": "E-P0089-d6095e10e9", "excerpt": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}, {"paper_id": "P0089", "evidence_id": "E-P0089-8bcb673a7d", "excerpt": "We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling.", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#method"}], "write_prompt": "Contrast Agent frameworks / architectures vs Safety / security / guardrails along 'threat model (prompt / tool injection, exfiltration)'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "defense surface (policy, sandbox, monitoring)", "A_label": "Agent frameworks / architectures", "B_label": "Safety / security / guardrails", "citations": ["@Shi2025Progent", "@Zhang2025Security"], "A_highlights": [{"paper_id": "P0032", "evidence_id": "E-P0032-68db58914f", "excerpt": "Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed.", "citations": ["@Shi2025Progent"], "pointer": "papers/paper_notes.jsonl:paper_id=P0032#key_results[0]"}], "B_highlights": [{"paper_id": "P0089", "evidence_id": "E-P0089-d6095e10e9", "excerpt": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}, {"paper_id": "P0089", "evidence_id": "E-P0089-8bcb673a7d", "excerpt": "We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling.", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#method"}], "write_prompt": "Contrast Agent frameworks / architectures vs Safety / security / guardrails along 'defense surface (policy, sandbox, monitoring)'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "security evaluation protocol", "A_label": "Agent frameworks / architectures", "B_label": "Safety / security / guardrails", "citations": ["@Shi2025Progent", "@Zhang2025Security"], "A_highlights": [{"paper_id": "P0032", "evidence_id": "E-P0032-68db58914f", "excerpt": "Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed.", "citations": ["@Shi2025Progent"], "pointer": "papers/paper_notes.jsonl:paper_id=P0032#key_results[0]"}], "B_highlights": [{"paper_id": "P0089", "evidence_id": "E-P0089-d6095e10e9", "excerpt": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}, {"paper_id": "P0089", "evidence_id": "E-P0089-8bcb673a7d", "excerpt": "We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling.", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#method"}], "write_prompt": "Contrast Agent frameworks / architectures vs Safety / security / guardrails along 'security evaluation protocol'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}, {"axis": "mechanism / architecture", "A_label": "Agent frameworks / architectures", "B_label": "Safety / security / guardrails", "citations": ["@Shi2025Progent", "@Zhang2025Security"], "A_highlights": [{"paper_id": "P0032", "evidence_id": "E-P0032-68db58914f", "excerpt": "Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed.", "citations": ["@Shi2025Progent"], "pointer": "papers/paper_notes.jsonl:paper_id=P0032#key_results[0]"}], "B_highlights": [{"paper_id": "P0089", "evidence_id": "E-P0089-d6095e10e9", "excerpt": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}, {"paper_id": "P0089", "evidence_id": "E-P0089-7a6ec4daed", "excerpt": "We evaluate nine popular LLM agents across 10 domains and 400+ tools, producing 2,000 attack instances.", "citations": ["@Zhang2025Security"], "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[1]"}], "write_prompt": "Contrast Agent frameworks / architectures vs Safety / security / guardrails along 'mechanism / architecture'. Ground A and B using the highlight snippets; do not introduce new claims beyond the cited evidence."}], "evaluation_protocol": [{"bullet": "Evaluation tokens mentioned in mapped evidence: LLMs; ASB; AgentDojo; AgentPoison; RSP; GSI; RSV; FEVER; RSP-M; HotpotQA.", "citations": ["@Liu2026Agents", "@Plaat2025Agentic", "@Shi2025Progent", "@Zhou2025Reasoning"]}], "limitation_hooks": [{"excerpt": "Large language models (LLMs) have precipitated a dramatic improvement in the legal domain, yet the deployment of standalone models faces significant limitations regarding hallucination, outdated information, and verifiability.", "citations": ["@Liu2026Agents"], "pointer": ""}, {"excerpt": "We note that there is risk associated with LLM assistants taking action in the real world-safety, liability and security are open problems-while agentic LLMs are also likely to benefit society.", "citations": ["@Plaat2025Agentic"], "pointer": ""}, {"excerpt": "Thanks to our modular design, integrating Progent does not alter agent internals and only requires minimal changes to the existing agent implementation, enhancing its practicality and potential for widespread adoption.", "citations": ["@Shi2025Progent"], "pointer": ""}, {"excerpt": "LLM agents utilize Large Language Models as central components with diverse tools to complete various user tasks, but face significant security risks when interacting with external environments.", "citations": ["@Shi2025Progent"], "pointer": ""}], "must_use": {"min_anchor_facts": 1, "min_comparison_cards": 1, "min_limitation_hooks": 1, "require_cited_numeric_if_available": true, "require_multi_cite_synthesis_paragraph": true, "thesis_required": true}, "do_not_repeat_phrases": ["This subsection surveys", "This subsection argues", "In this subsection", "Next, we move from", "We now turn to", "claims remain provisional under abstract-only evidence", "abstract-only evidence", "Key takeaway:", "Main takeaway:"], "pack_warnings": [], "pack_stats": {"anchors": {"raw": 10, "considered": 8, "kept": 8, "dropped_no_cites": 0}, "comparisons": {"raw": 5, "considered": 4, "kept": 4, "dropped_no_highlights": 0, "highlights_dropped_no_cites": 0}, "evaluation_protocol": {"raw": 1, "considered": 1, "kept": 1, "dropped_no_cites": 0}, "limitation_hooks": {"raw": 4, "considered": 4, "kept": 4, "dropped_no_cites": 0}, "trim_policy": {"default": 400, "anchor_fact": 420, "highlight_excerpt": 280, "comparison_write_prompt": 420, "eval_bullet": 320, "limitation_excerpt": 320}}, "generated_at": "2026-01-18T01:21:06"}
