# Evidence draft: 4.2 Memory and retrieval (RAG)

## Evidence snippets (with provenance)
- (E-P0045-43287d5458) In our study, we introduce AriGraph, a novel method wherein the agent constructs and updates a memory graph that integrates semantic and episodic memories while exploring the environment. @Anokhin2024Arigraph (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0045#method)
- (E-P0184-1b99de5317) From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap tracker that explicitly renders the answering process transparent and tracks the evidence collection process. @Du2025Memr (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0184#key_results[1])
- (E-P0080-f1ec9700e7) In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time evolution, where LLMs retrieve, integrate, and update memory continuously during deployment. @Wei2025Memory (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0080#limitations[1])
- (E-P0031-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. @Tawosi2025Meta (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0031#key_results[1])
- (E-P0184-497b158080) Empirical results on the LoCoMo benchmark demonstrate that MemR$^3$ surpasses strong baselines on LLM-as-a-Judge score, and particularly, it improves existing retrievers across four categories with an overall improvement on RAG (+7.29%) and Zep (+1.94%) using GPT-4.1-mini backend, offering a plug-and-play controller for existing memory stores. @Du2025Memr (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0184#key_results[0])
- (E-P0187-e294aeefb5) To evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval and citation performance, and Reasoning-100 (Reas-100), focused on multistep reasoning in circuit design. @Abbineni2025Muallm (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0187#key_results[1])
- (E-P0080-06e45507a7) We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets. @Wei2025Memory (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0080#key_results[0])
- (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. @Yao2022React (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- (E-P0014-3bf4dab38c) Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns, outperforming ReAct. @Ye2025Task (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0014#key_results[0])
- (E-P0031-e3ebb83eb2) Meta-RAG scores 84.67 % and 53.0 % for file-level and function-level correct localization rates, respectively, achieving state-of-the-art performance. @Tawosi2025Meta (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0031#key_results[0])

## Definitions / setup

- Setup: Which design choices in Memory and retrieval (RAG) drive the major trade-offs, and how are those trade-offs measured? Scope: in-scope: Core topics directly relevant to 'Memory and retrieval (RAG)'.. Axes: memory type (episodic / semantic / scratchpad); retrieval source + index (docs / web / logs); write / update / forgetting policy; mechanism / architecture; data / training setup. @Yu2026Agentic @Tao2026Membox @Ye2025Task

## Claim candidates

- In our study, we introduce AriGraph, a novel method wherein the agent constructs and updates a memory graph that integrates semantic and episodic memories while exploring the environment. @Anokhin2024Arigraph
- From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap tracker that explicitly renders the answering process transparent and tracks the evidence collection process. @Du2025Memr
- In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time evolution, where LLMs retrieve, integrate, and update memory continuously during deployment. @Wei2025Memory
- Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. @Tawosi2025Meta
- Empirical results on the LoCoMo benchmark demonstrate that MemR$^3$ surpasses strong baselines on LLM-as-a-Judge score, and particularly, it improves existing retrievers across four categories with an overall improvement on RAG (+7.29%) and Zep (+1.94%) using GPT-4.1-mini backend, offering a plug-and-play controller for existing memory stores. @Du2025Memr

## Concrete comparisons

- Axis: memory type (episodic / semantic / scratchpad); A: Agent frameworks / architectures: `P0123`, `P0128`, `P0014`; B: Memory / retrieval augmentation: `P0123`, `P0128`, `P0014`. @Wei2025Memory @Tawosi2025Meta
  - A highlight: (E-P0080-06e45507a7) We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets. @Wei2025Memory (pointer: papers/paper_notes.jsonl:paper_id=P0080#key_results[0])
  - A highlight: (E-P0080-f1ec9700e7) In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time @Wei2025Memory (pointer: papers/paper_notes.jsonl:paper_id=P0080#limitations[1])
  - B highlight: (E-P0031-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. @Tawosi2025Meta (pointer: papers/paper_notes.jsonl:paper_id=P0031#key_results[1])
  - B highlight: (E-P0080-06e45507a7) We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets. @Wei2025Memory (pointer: papers/paper_notes.jsonl:paper_id=P0080#key_results[0])
- Axis: retrieval source + index (docs / web / logs); A: Agent frameworks / architectures: `P0123`, `P0128`, `P0014`; B: Memory / retrieval augmentation: `P0123`, `P0128`, `P0014`. @Wei2025Memory @Tawosi2025Meta
  - A highlight: (E-P0080-06e45507a7) We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets. @Wei2025Memory (pointer: papers/paper_notes.jsonl:paper_id=P0080#key_results[0])
  - A highlight: (E-P0080-f1ec9700e7) In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time @Wei2025Memory (pointer: papers/paper_notes.jsonl:paper_id=P0080#limitations[1])
  - B highlight: (E-P0031-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. @Tawosi2025Meta (pointer: papers/paper_notes.jsonl:paper_id=P0031#key_results[1])
  - B highlight: (E-P0080-06e45507a7) We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets. @Wei2025Memory (pointer: papers/paper_notes.jsonl:paper_id=P0080#key_results[0])
- Axis: write / update / forgetting policy; A: Agent frameworks / architectures: `P0123`, `P0128`, `P0014`; B: Memory / retrieval augmentation: `P0123`, `P0128`, `P0014`. @Ye2025Task @Wei2025Memory @Tawosi2025Meta
  - A highlight: (E-P0014-3bf4dab38c) Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns, @Ye2025Task (pointer: papers/paper_notes.jsonl:paper_id=P0014#key_results[0])
  - A highlight: (E-P0080-06e45507a7) We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets. @Wei2025Memory (pointer: papers/paper_notes.jsonl:paper_id=P0080#key_results[0])
  - B highlight: (E-P0014-3bf4dab38c) Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns, @Ye2025Task (pointer: papers/paper_notes.jsonl:paper_id=P0014#key_results[0])
  - B highlight: (E-P0031-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. @Tawosi2025Meta (pointer: papers/paper_notes.jsonl:paper_id=P0031#key_results[1])
- Axis: mechanism / architecture; A: Agent frameworks / architectures: `P0123`, `P0128`, `P0014`; B: Memory / retrieval augmentation: `P0123`, `P0128`, `P0014`. @Ye2025Task @Wei2025Memory @Tawosi2025Meta
  - A highlight: (E-P0014-3bf4dab38c) Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns, @Ye2025Task (pointer: papers/paper_notes.jsonl:paper_id=P0014#key_results[0])
  - A highlight: (E-P0080-06e45507a7) We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets. @Wei2025Memory (pointer: papers/paper_notes.jsonl:paper_id=P0080#key_results[0])
  - B highlight: (E-P0014-3bf4dab38c) Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns, @Ye2025Task (pointer: papers/paper_notes.jsonl:paper_id=P0014#key_results[0])
  - B highlight: (E-P0031-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. @Tawosi2025Meta (pointer: papers/paper_notes.jsonl:paper_id=P0031#key_results[1])
- Axis: data / training setup; A: Agent frameworks / architectures: `P0123`, `P0128`, `P0014`; B: Memory / retrieval augmentation: `P0123`, `P0128`, `P0014`. @Wei2025Memory @Ye2025Task
  - A highlight: (E-P0080-f1ec9700e7) In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time @Wei2025Memory (pointer: papers/paper_notes.jsonl:paper_id=P0080#limitations[1])
  - A highlight: (E-P0014-3bf4dab38c) Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns, @Ye2025Task (pointer: papers/paper_notes.jsonl:paper_id=P0014#key_results[0])
  - B highlight: (E-P0080-f1ec9700e7) In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time @Wei2025Memory (pointer: papers/paper_notes.jsonl:paper_id=P0080#limitations[1])
  - B highlight: (E-P0014-3bf4dab38c) Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns, @Ye2025Task (pointer: papers/paper_notes.jsonl:paper_id=P0014#key_results[0])

## Evaluation protocol

- Evaluation tokens mentioned in mapped evidence: LTM; STM; GRPO; AgeMem; MEM; LoCoMo; LLMs; TME; DAG; TRIM. @Yu2026Agentic @Tao2026Membox @Ye2025Task @Wu2025Meta

## Failures / limitations

- Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical. @Yu2026Agentic
- MPR (i) externalizes reusable corrective knowledge without model weight updates, (ii) enforces domain constraints to reduce unsafe or invalid actions, and (iii) retains the adaptability of language-based reflection. @Wu2025Meta
- We analyze mechanisms that explain these gains, discuss scalability and failure modes, and outline future directions for multimodal and multi-agent extensions. @Wu2025Meta
- In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time evolution, where LLMs retrieve, integrate, and update memory continuously during deployment. @Wei2025Memory

## Verify fields (non-blocking)

- named benchmarks/datasets used
- metrics/human-eval protocol
- training data and supervision signal
- baseline choices and ablation evidence
