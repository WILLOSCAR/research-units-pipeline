# Evidence draft: 4.1 Planning and reasoning loops

## Evidence snippets (with provenance)
- (E-P0039-f4d80ca542) Large Language Models (LLMs) have demonstrated remarkable capabilities in knowledge acquisition, reasoning, and tool use, making them promising candidates for autonomous agent applications. @Hu2025Training (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0039#method)
- (E-P0084-99359acdd7) Comparatively, the state-of-the-art LLM penetration testing tool using self-guided reasoning completed only 13.5\%, 16.5\%, and 75.7\% of subtasks and required 86.2\%, 118.7\%, and 205.9\% more model queries. @Nakano2025Guided (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0084#key_results[0])
- (E-P0212-e2e3b7fa97) Our evaluation of 16 agents under a unified ReAct framework reveals distinct capabilities and limitations across models. @Seo2025Simuhome (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0212#limitations[1])
- (E-P0013-1ad09376fe) We validate our method on tasks requiring interaction, including tool use, social deduction, and dialogue, demonstrating superior performance over both RL fine-tuning and prompting methods while maintaining efficiency and scalability. @Hong2025Planning (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0013#key_results[0])
- (E-P0011-04c60086db) Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design principles for trustworthy agents: modular decomposition, adaptive symbolic governance, and transparent state management. @Kim2025Bridging (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0011#key_results[0])
- (E-P0184-1b99de5317) From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap tracker that explicitly renders the answering process transparent and tracks the evidence collection process. @Du2025Memr (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0184#key_results[1])
- (E-P0034-c17bcfb7d4) It increases reasoning steps by up to 4.4 times or induces premature errors, successfully bypassing state-of-the-art content filters. @Zhou2025Reasoning (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0034#key_results[0])
- (E-P0039-771620f84f) Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning tasks. @Hu2025Training (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0039#key_results[0])
- (E-P0077-32d61c8fae) Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and performance further dropping by around 40% under dynamic conditions. @Liu2025Costbench (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0077#key_results[0])
- (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. @Yao2022React (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0001#key_results[0])

## Definitions / setup

- Setup: Which design choices in Planning and reasoning loops drive the major trade-offs, and how are those trade-offs measured? Scope: in-scope: Core topics directly relevant to 'Planning and reasoning loops'.. Axes: control loop design (planner / executor, search); deliberation method (CoT / ToT / MCTS); action grounding (tool calls vs environment actions); mechanism / architecture; data / training setup. @Hatalis2025Review @Kim2025Bridging @Silva2025Agents

## Claim candidates

- Large Language Models (LLMs) have demonstrated remarkable capabilities in knowledge acquisition, reasoning, and tool use, making them promising candidates for autonomous agent applications. @Hu2025Training
- Comparatively, the state-of-the-art LLM penetration testing tool using self-guided reasoning completed only 13.5\%, 16.5\%, and 75.7\% of subtasks and required 86.2\%, 118.7\%, and 205.9\% more model queries. @Nakano2025Guided
- Our evaluation of 16 agents under a unified ReAct framework reveals distinct capabilities and limitations across models. @Seo2025Simuhome
- We validate our method on tasks requiring interaction, including tool use, social deduction, and dialogue, demonstrating superior performance over both RL fine-tuning and prompting methods while maintaining efficiency and scalability. @Hong2025Planning
- Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design principles for trustworthy agents: modular decomposition, adaptive symbolic governance, and transparent state management. @Kim2025Bridging

## Concrete comparisons

- Axis: control loop design (planner / executor, search); A: Agent frameworks / architectures: `P0008`, `P0011`, `P0021`; B: Planning / reasoning loops: `P0008`, `P0011`, `P0013`. @Liu2025Costbench @Hu2025Training
  - A highlight: (E-P0077-32d61c8fae) Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and @Liu2025Costbench (pointer: papers/paper_notes.jsonl:paper_id=P0077#key_results[0])
  - A highlight: (E-P0039-771620f84f) Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning @Hu2025Training (pointer: papers/paper_notes.jsonl:paper_id=P0039#key_results[0])
  - B highlight: (E-P0077-32d61c8fae) Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and @Liu2025Costbench (pointer: papers/paper_notes.jsonl:paper_id=P0077#key_results[0])
  - B highlight: (E-P0039-771620f84f) Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning @Hu2025Training (pointer: papers/paper_notes.jsonl:paper_id=P0039#key_results[0])
- Axis: deliberation method (CoT / ToT / MCTS); A: Agent frameworks / architectures: `P0008`, `P0011`, `P0021`; B: Planning / reasoning loops: `P0008`, `P0011`, `P0013`. @Liu2025Costbench @Hu2025Training
  - A highlight: (E-P0077-32d61c8fae) Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and @Liu2025Costbench (pointer: papers/paper_notes.jsonl:paper_id=P0077#key_results[0])
  - A highlight: (E-P0039-771620f84f) Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning @Hu2025Training (pointer: papers/paper_notes.jsonl:paper_id=P0039#key_results[0])
  - B highlight: (E-P0077-32d61c8fae) Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and @Liu2025Costbench (pointer: papers/paper_notes.jsonl:paper_id=P0077#key_results[0])
  - B highlight: (E-P0039-771620f84f) Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning @Hu2025Training (pointer: papers/paper_notes.jsonl:paper_id=P0039#key_results[0])
- Axis: action grounding (tool calls vs environment actions); A: Agent frameworks / architectures: `P0008`, `P0011`, `P0021`; B: Planning / reasoning loops: `P0008`, `P0011`, `P0013`. @Kim2025Bridging @Liu2025Costbench
  - A highlight: (E-P0011-04c60086db) Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design @Kim2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0011#key_results[0])
  - A highlight: (E-P0077-32d61c8fae) Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and @Liu2025Costbench (pointer: papers/paper_notes.jsonl:paper_id=P0077#key_results[0])
  - B highlight: (E-P0011-04c60086db) Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design @Kim2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0011#key_results[0])
  - B highlight: (E-P0077-32d61c8fae) Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and @Liu2025Costbench (pointer: papers/paper_notes.jsonl:paper_id=P0077#key_results[0])
- Axis: mechanism / architecture; A: Agent frameworks / architectures: `P0008`, `P0011`, `P0021`; B: Planning / reasoning loops: `P0008`, `P0011`, `P0013`. @Kim2025Bridging @Liu2025Costbench
  - A highlight: (E-P0011-04c60086db) Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design @Kim2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0011#key_results[0])
  - A highlight: (E-P0077-32d61c8fae) Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and @Liu2025Costbench (pointer: papers/paper_notes.jsonl:paper_id=P0077#key_results[0])
  - B highlight: (E-P0011-04c60086db) Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design @Kim2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0011#key_results[0])
  - B highlight: (E-P0077-32d61c8fae) Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and @Liu2025Costbench (pointer: papers/paper_notes.jsonl:paper_id=P0077#key_results[0])
- Axis: data / training setup; A: Agent frameworks / architectures: `P0008`, `P0011`, `P0021`; B: Planning / reasoning loops: `P0008`, `P0011`, `P0013`. @Hu2025Training @Kim2025Bridging
  - A highlight: (E-P0039-771620f84f) Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning @Hu2025Training (pointer: papers/paper_notes.jsonl:paper_id=P0039#key_results[0])
  - A highlight: (E-P0011-04c60086db) Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design @Kim2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0011#key_results[0])
  - B highlight: (E-P0039-771620f84f) Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning @Hu2025Training (pointer: papers/paper_notes.jsonl:paper_id=P0039#key_results[0])
  - B highlight: (E-P0011-04c60086db) Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design @Kim2025Bridging (pointer: papers/paper_notes.jsonl:paper_id=P0011#key_results[0])

## Evaluation protocol

- Evaluation tokens mentioned in mapped evidence: LLMs; CBR; CBR-enhanced; SCL; CCAM; GPT-4o-powered; ReAct; AutoGPT; RSP; GSI. @Hatalis2025Review @Kim2025Bridging @Silva2025Agents @Zhou2025Reasoning

## Failures / limitations

- Still, they face limitations in tasks requiring specific, structured knowledge, flexibility, or accountable decision-making. @Hatalis2025Review
- This study offers new insights into the strengths and failure modes of LLMs in physically grounded multi-agent collaboration tasks, contributing to future benchmarks and architectural improvements. @Silva2025Agents
- While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. @Zhou2025Reasoning
- We introduce Generative Style Injection (GSI), an attack method that rewrites retrieved documents into pathological tones--specifically "analysis paralysis" or "cognitive haste"--without altering underlying facts or using explicit triggers. @Zhou2025Reasoning

## Verify fields (non-blocking)

- named benchmarks/datasets used
- metrics/human-eval protocol
- training data and supervision signal
- baseline choices and ablation evidence
