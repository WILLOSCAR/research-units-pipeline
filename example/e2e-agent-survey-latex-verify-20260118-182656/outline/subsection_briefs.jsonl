{"sub_id": "3.1", "title": "Agent loop and action spaces", "section_id": "3", "section_title": "Foundations & Interfaces", "rq": "Which design choices in Agent loop and action spaces drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Agent loop and action spaces highlights a tension around mechanism / architecture and data / training setup, motivating a protocol-aware synthesis rather than per-paper summaries.", "scope_rule": {"include": ["Core topics directly relevant to 'Agent loop and action spaces'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["mechanism / architecture", "data / training setup", "evaluation protocol (datasets / metrics / human)", "efficiency / compute", "failure modes / limitations"], "bridge_terms": ["benchmarks/metrics", "compute"], "contrast_hook": "evaluation", "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "compute / cost (train/infer)", "training signal / supervision", "failure modes / limitations"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0055", "P0059", "P0125", "P0011", "P0019", "P0024", "P0027", "P0030"], "bibkeys": ["Zhang2026Evoroute", "Xi2026Toolgym", "Song2026Envscaler", "Kim2025Bridging", "Li2025Agentswift", "Feng2025Group", "Luo2025Large", "Wu2025Meta"]}, {"label": "Planning / reasoning loops", "rationale": "Grouped by keyword tag `planning` from titles (bootstrap).", "paper_ids": ["P0011", "P0019", "P0166", "P0001"], "bibkeys": ["Kim2025Bridging", "Li2025Agentswift", "Xu2025Exemplar", "Yao2022React"]}, {"label": "Tool-use and function calling", "rationale": "Grouped by keyword tag `tool-use` from titles (bootstrap).", "paper_ids": ["P0059", "P0125", "P0090", "P0093"], "bibkeys": ["Xi2026Toolgym", "Song2026Envscaler", "Liu2025Mcpagentbench", "Ghose2025Orfs"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Agent loop and action spaces drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "To ground this thesis, Agent frameworks / architectures approaches provide a natural starting point because they make the agent-loop decision explicit.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: mechanism / architecture, data / training setup, evaluation protocol (datasets / metrics / human), efficiency / compute, failure modes / limitations"], "connector_to_prev": "elaboration", "connector_phrase": "More concretely, these designs imply concrete interface/data assumptions that shape behavior.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "To evaluate these trade-offs, protocols and metrics clarify where Agent frameworks / architectures works, and where it fails or becomes costly.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Planning / reasoning loops", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Unlike this route, Planning / reasoning loops approaches shift the emphasis and optimize for a different point in the trade-off space.", "use_clusters": ["Planning / reasoning loops"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Planning / reasoning loops", "data / training setup", "interface contract", "axes: mechanism / architecture, data / training setup, evaluation protocol (datasets / metrics / human), efficiency / compute, failure modes / limitations"], "connector_to_prev": "elaboration", "connector_phrase": "More concretely, the B-route relies on different interface/training assumptions, which changes failure modes and costs.", "use_clusters": ["Planning / reasoning loops"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Planning / reasoning loops", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "To evaluate these trade-offs, when comparable settings exist, evaluation evidence for B can be contrasted against A to surface the trade-offs.", "use_clusters": ["Planning / reasoning loops"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Planning / reasoning loops", "multiple citations in one paragraph", "axes: mechanism / architecture, data / training setup, evaluation protocol (datasets / metrics / human), efficiency / compute, failure modes / limitations"], "connector_to_prev": "synthesis", "connector_phrase": "Stepping back, the key distinction between Agent frameworks / architectures and Planning / reasoning loops is how they trade off mechanism / architecture, data / training setup, evaluation protocol (datasets / metrics / human), efficiency / compute, failure modes / limitations under evaluation constraints.", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Tool-use and function calling"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "As a result, a decision checklist can map evaluation signals and constraints to route selection.", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Tool-use and function calling"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "A key limitation is that key claims hinge on assumptions that merit stress-testing, which motivates concrete verification targets.", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Tool-use and function calling"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-18T01:21:06"}
{"sub_id": "3.2", "title": "Tool interfaces and orchestration", "section_id": "3", "section_title": "Foundations & Interfaces", "rq": "Which design choices in Tool interfaces and orchestration drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Tool interfaces and orchestration highlights a tension around tool interface (function calling, schemas, protocols) and tool selection / routing policy, motivating a protocol-aware synthesis rather than per-paper summaries.", "scope_rule": {"include": ["Core topics directly relevant to 'Tool interfaces and orchestration'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["tool interface (function calling, schemas, protocols)", "tool selection / routing policy", "sandboxing / permissions / observability", "mechanism / architecture", "data / training setup"], "bridge_terms": ["function calling", "tool schema", "routing", "sandbox", "observability"], "contrast_hook": "tool interfaces", "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision", "threat model", "defense surface"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0129", "P0029", "P0035", "P0042", "P0061", "P0070", "P0088", "P0090"], "bibkeys": ["Xuan2026Confidence", "Lumer2025Memtool", "Zhou2025Self", "Cheng2025Your", "Van2025Survey", "Jia2025Autotool", "Li2025Dissonances", "Liu2025Mcpagentbench"]}, {"label": "Tool-use and function calling", "rationale": "Grouped by keyword tag `tool-use` from titles (bootstrap).", "paper_ids": ["P0129", "P0028", "P0029", "P0042", "P0061", "P0070", "P0088", "P0090"], "bibkeys": ["Xuan2026Confidence", "Dong2025Bench", "Lumer2025Memtool", "Cheng2025Your", "Van2025Survey", "Jia2025Autotool", "Li2025Dissonances", "Liu2025Mcpagentbench"]}, {"label": "Evaluation / benchmark-focused works", "rationale": "Grouped by keyword tag `evaluation` from titles (bootstrap).", "paper_ids": ["P0028", "P0090", "P0164"], "bibkeys": ["Dong2025Bench", "Liu2025Mcpagentbench", "Mohammadi2025Evaluation"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Tool interfaces and orchestration drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "To make this concrete, Agent frameworks / architectures approaches provide a natural starting point because they make the agent-loop decision explicit.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Following this design, these designs imply concrete interface/data assumptions that shape behavior.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "In evaluations, protocols and metrics clarify where Agent frameworks / architectures works, and where it fails or becomes costly.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Tool-use and function calling", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "However, Tool-use and function calling approaches shift the emphasis and optimize for a different point in the trade-off space.", "use_clusters": ["Tool-use and function calling"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Tool-use and function calling", "data / training setup", "interface contract", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Following this design, the B-route relies on different interface/training assumptions, which changes failure modes and costs.", "use_clusters": ["Tool-use and function calling"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Tool-use and function calling", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "In evaluations, when comparable settings exist, evaluation evidence for B can be contrasted against A to surface the trade-offs.", "use_clusters": ["Tool-use and function calling"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Tool-use and function calling", "multiple citations in one paragraph", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Overall, the key distinction between Agent frameworks / architectures and Tool-use and function calling is how they trade off tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, mechanism / architecture, data / training setup under evaluation constraints.", "use_clusters": ["Agent frameworks / architectures", "Tool-use and function calling", "Evaluation / benchmark-focused works"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "This suggests that a decision checklist can map evaluation signals and constraints to route selection.", "use_clusters": ["Agent frameworks / architectures", "Tool-use and function calling", "Evaluation / benchmark-focused works"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Despite these advances, key claims hinge on assumptions that merit stress-testing, which motivates concrete verification targets.", "use_clusters": ["Agent frameworks / architectures", "Tool-use and function calling", "Evaluation / benchmark-focused works"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-18T01:21:06"}
{"sub_id": "4.1", "title": "Planning and reasoning loops", "section_id": "4", "section_title": "Core Components (Planning + Memory)", "rq": "Which design choices in Planning and reasoning loops drive the major trade-offs, and how are those trade-offs measured?", "thesis": "In Planning and reasoning loops, differences in control loop design (planner / executor, search) and deliberation method (CoT / ToT / MCTS) frequently imply different evaluation setups, so the key is to compare under consistent protocols where possible.", "scope_rule": {"include": ["Core topics directly relevant to 'Planning and reasoning loops'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["control loop design (planner / executor, search)", "deliberation method (CoT / ToT / MCTS)", "action grounding (tool calls vs environment actions)", "mechanism / architecture", "data / training setup"], "bridge_terms": ["planner/executor", "search", "deliberation", "action grounding"], "contrast_hook": "planning/control loop", "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0008", "P0011", "P0021", "P0034", "P0039", "P0060", "P0077", "P0079"], "bibkeys": ["Hatalis2025Review", "Kim2025Bridging", "Silva2025Agents", "Zhou2025Reasoning", "Hu2025Training", "Kiruluta2025Novel", "Liu2025Costbench", "Hu2025Evaluating"]}, {"label": "Planning / reasoning loops", "rationale": "Grouped by keyword tag `planning` from titles (bootstrap).", "paper_ids": ["P0008", "P0011", "P0013", "P0021", "P0034", "P0039", "P0060", "P0077"], "bibkeys": ["Hatalis2025Review", "Kim2025Bridging", "Hong2025Planning", "Silva2025Agents", "Zhou2025Reasoning", "Hu2025Training", "Kiruluta2025Novel", "Liu2025Costbench"]}, {"label": "Memory / retrieval augmentation", "rationale": "Grouped by keyword tag `memory` from titles (bootstrap).", "paper_ids": ["P0079", "P0152", "P0184"], "bibkeys": ["Hu2025Evaluating", "Yang2025Coarse", "Du2025Memr"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Planning and reasoning loops drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "To ground this thesis, Agent frameworks / architectures approaches provide a natural starting point because they make the agent-loop decision explicit.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: control loop design (planner / executor, search), deliberation method (CoT / ToT / MCTS), action grounding (tool calls vs environment actions), mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "More concretely, these designs imply concrete interface/data assumptions that shape behavior.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Under standard benchmarks, protocols and metrics clarify where Agent frameworks / architectures works, and where it fails or becomes costly.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Planning / reasoning loops", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "By contrast, Planning / reasoning loops approaches shift the emphasis and optimize for a different point in the trade-off space.", "use_clusters": ["Planning / reasoning loops"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Planning / reasoning loops", "data / training setup", "interface contract", "axes: control loop design (planner / executor, search), deliberation method (CoT / ToT / MCTS), action grounding (tool calls vs environment actions), mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "More concretely, the B-route relies on different interface/training assumptions, which changes failure modes and costs.", "use_clusters": ["Planning / reasoning loops"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Planning / reasoning loops", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Under standard benchmarks, when comparable settings exist, evaluation evidence for B can be contrasted against A to surface the trade-offs.", "use_clusters": ["Planning / reasoning loops"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Planning / reasoning loops", "multiple citations in one paragraph", "axes: control loop design (planner / executor, search), deliberation method (CoT / ToT / MCTS), action grounding (tool calls vs environment actions), mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Overall, the key distinction between Agent frameworks / architectures and Planning / reasoning loops is how they trade off control loop design (planner / executor, search), deliberation method (CoT / ToT / MCTS), action grounding (tool calls vs environment actions), mechanism / architecture, data / training setup under evaluation constraints.", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Memory / retrieval augmentation"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "This suggests that a decision checklist can map evaluation signals and constraints to route selection.", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Memory / retrieval augmentation"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "A key limitation is that key claims hinge on assumptions that merit stress-testing, which motivates concrete verification targets.", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Memory / retrieval augmentation"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-18T01:21:06"}
{"sub_id": "4.2", "title": "Memory and retrieval (RAG)", "section_id": "4", "section_title": "Core Components (Planning + Memory)", "rq": "Which design choices in Memory and retrieval (RAG) drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Memory and retrieval (RAG) highlights a tension around memory type (episodic / semantic / scratchpad) and retrieval source + index (docs / web / logs), motivating a protocol-aware synthesis rather than per-paper summaries.", "scope_rule": {"include": ["Core topics directly relevant to 'Memory and retrieval (RAG)'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["memory type (episodic / semantic / scratchpad)", "retrieval source + index (docs / web / logs)", "write / update / forgetting policy", "mechanism / architecture", "data / training setup"], "bridge_terms": ["retrieval", "index", "write policy", "long-term memory"], "contrast_hook": "memory/retrieval", "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0123", "P0128", "P0014", "P0030", "P0038", "P0079", "P0080", "P0134"], "bibkeys": ["Yu2026Agentic", "Tao2026Membox", "Ye2025Task", "Wu2025Meta", "Ye2025Taska", "Hu2025Evaluating", "Wei2025Memory", "Xu2025Agentic"]}, {"label": "Memory / retrieval augmentation", "rationale": "Grouped by keyword tag `memory` from titles (bootstrap).", "paper_ids": ["P0123", "P0128", "P0014", "P0030", "P0031", "P0038", "P0079", "P0080"], "bibkeys": ["Yu2026Agentic", "Tao2026Membox", "Ye2025Task", "Wu2025Meta", "Tawosi2025Meta", "Ye2025Taska", "Hu2025Evaluating", "Wei2025Memory"]}, {"label": "Planning / reasoning loops", "rationale": "Grouped by keyword tag `planning` from titles (bootstrap).", "paper_ids": ["P0184", "P0121", "P0001"], "bibkeys": ["Du2025Memr", "Liu2023Reason", "Yao2022React"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Memory and retrieval (RAG) drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "To ground this thesis, Agent frameworks / architectures approaches provide a natural starting point because they make the agent-loop decision explicit.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: memory type (episodic / semantic / scratchpad), retrieval source + index (docs / web / logs), write / update / forgetting policy, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "At the implementation level, these designs imply concrete interface/data assumptions that shape behavior.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "In evaluations, protocols and metrics clarify where Agent frameworks / architectures works, and where it fails or becomes costly.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Memory / retrieval augmentation", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Unlike this route, Memory / retrieval augmentation approaches shift the emphasis and optimize for a different point in the trade-off space.", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Memory / retrieval augmentation", "data / training setup", "interface contract", "axes: memory type (episodic / semantic / scratchpad), retrieval source + index (docs / web / logs), write / update / forgetting policy, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "At the implementation level, the B-route relies on different interface/training assumptions, which changes failure modes and costs.", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Memory / retrieval augmentation", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "In evaluations, when comparable settings exist, evaluation evidence for B can be contrasted against A to surface the trade-offs.", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Memory / retrieval augmentation", "multiple citations in one paragraph", "axes: memory type (episodic / semantic / scratchpad), retrieval source + index (docs / web / logs), write / update / forgetting policy, mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Taken together, the key distinction between Agent frameworks / architectures and Memory / retrieval augmentation is how they trade off memory type (episodic / semantic / scratchpad), retrieval source + index (docs / web / logs), write / update / forgetting policy, mechanism / architecture, data / training setup under evaluation constraints.", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Planning / reasoning loops"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "As a result, a decision checklist can map evaluation signals and constraints to route selection.", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Planning / reasoning loops"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "However, these routes remain limited in practice, since key claims hinge on assumptions that merit stress-testing, which motivates concrete verification targets.", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Planning / reasoning loops"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-18T01:21:06"}
{"sub_id": "5.1", "title": "Self-improvement and adaptation", "section_id": "5", "section_title": "Learning, Adaptation & Coordination", "rq": "Which design choices in Self-improvement and adaptation drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Self-improvement and adaptation methods emphasize training signal (SFT / preference / RL) and data synthesis + evaluator / reward trade-offs, but synthesis is clearest when claims are tied to explicit evaluation settings and reporting conventions.", "scope_rule": {"include": ["Core topics directly relevant to 'Self-improvement and adaptation'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["training signal (SFT / preference / RL)", "data synthesis + evaluator / reward", "generalization + regression control", "mechanism / architecture", "data / training setup"], "bridge_terms": ["preference", "reward", "feedback", "self-improvement"], "contrast_hook": "learning/feedback", "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0055", "P0020", "P0035", "P0061", "P0080", "P0081", "P0082", "P0083"], "bibkeys": ["Zhang2026Evoroute", "Belle2025Agents", "Zhou2025Self", "Van2025Survey", "Wei2025Memory", "Wu2025Evolver", "Nitin2025Faultline", "Chen2025Grounded"]}, {"label": "Memory / retrieval augmentation", "rationale": "Grouped by keyword tag `memory` from titles (bootstrap).", "paper_ids": ["P0080", "P0198"], "bibkeys": ["Wei2025Memory", "Wang2025Ragen"]}, {"label": "Planning / reasoning loops", "rationale": "Grouped by keyword tag `planning` from titles (bootstrap).", "paper_ids": ["P0020", "P0001"], "bibkeys": ["Belle2025Agents", "Yao2022React"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Self-improvement and adaptation drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "To make this concrete, Agent frameworks / architectures approaches provide a natural starting point because they make the agent-loop decision explicit.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: training signal (SFT / preference / RL), data synthesis + evaluator / reward, generalization + regression control, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Following this design, these designs imply concrete interface/data assumptions that shape behavior.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "In evaluations, protocols and metrics clarify where Agent frameworks / architectures works, and where it fails or becomes costly.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Memory / retrieval augmentation", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Unlike this route, Memory / retrieval augmentation approaches shift the emphasis and optimize for a different point in the trade-off space.", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Memory / retrieval augmentation", "data / training setup", "interface contract", "axes: training signal (SFT / preference / RL), data synthesis + evaluator / reward, generalization + regression control, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Following this design, the B-route relies on different interface/training assumptions, which changes failure modes and costs.", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Memory / retrieval augmentation", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "In evaluations, when comparable settings exist, evaluation evidence for B can be contrasted against A to surface the trade-offs.", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Memory / retrieval augmentation", "multiple citations in one paragraph", "axes: training signal (SFT / preference / RL), data synthesis + evaluator / reward, generalization + regression control, mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Taken together, the key distinction between Agent frameworks / architectures and Memory / retrieval augmentation is how they trade off training signal (SFT / preference / RL), data synthesis + evaluator / reward, generalization + regression control, mechanism / architecture, data / training setup under evaluation constraints.", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Planning / reasoning loops"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "Therefore, a decision checklist can map evaluation signals and constraints to route selection.", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Planning / reasoning loops"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Despite these advances, key claims hinge on assumptions that merit stress-testing, which motivates concrete verification targets.", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Planning / reasoning loops"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-18T01:21:06"}
{"sub_id": "5.2", "title": "Multi-agent coordination", "section_id": "5", "section_title": "Learning, Adaptation & Coordination", "rq": "Which design choices in Multi-agent coordination drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Multi-agent coordination highlights a tension around communication protocol + role assignment and aggregation (vote / debate / referee), motivating a protocol-aware synthesis rather than per-paper summaries.", "scope_rule": {"include": ["Core topics directly relevant to 'Multi-agent coordination'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["communication protocol + role assignment", "aggregation (vote / debate / referee)", "stability (collusion, mode collapse, incentives)", "mechanism / architecture", "data / training setup"], "bridge_terms": ["roles", "communication", "debate", "aggregation", "stability"], "contrast_hook": "coordination", "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0021", "P0029", "P0036", "P0037", "P0064", "P0087", "P0132", "P0136"], "bibkeys": ["Silva2025Agents", "Lumer2025Memtool", "Cao2025Skyrl", "Sarkar2025Survey", "Liu2025Aligning", "Zahedifar2025Agent", "Hao2025Multi", "Chang2025Alas"]}, {"label": "Multi-agent coordination", "rationale": "Grouped by keyword tag `multi-agent` from titles (bootstrap).", "paper_ids": ["P0021", "P0087", "P0137", "P0150", "P0157", "P0158", "P0189"], "bibkeys": ["Silva2025Agents", "Zahedifar2025Agent", "Papadakis2025Atlas", "Wu2025Agents", "Chuang2025Debate", "Li2025Draft", "Zhang2025Cognitive"]}, {"label": "Planning / reasoning loops", "rationale": "Grouped by keyword tag `planning` from titles (bootstrap).", "paper_ids": ["P0021", "P0136", "P0150", "P0158"], "bibkeys": ["Silva2025Agents", "Chang2025Alas", "Wu2025Agents", "Li2025Draft"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Multi-agent coordination drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "To make this concrete, Agent frameworks / architectures approaches provide a natural starting point because they make the agent-loop decision explicit.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: communication protocol + role assignment, aggregation (vote / debate / referee), stability (collusion, mode collapse, incentives), mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "At the implementation level, these designs imply concrete interface/data assumptions that shape behavior.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "In evaluations, protocols and metrics clarify where Agent frameworks / architectures works, and where it fails or becomes costly.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Multi-agent coordination", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Unlike this route, Multi-agent coordination approaches shift the emphasis and optimize for a different point in the trade-off space.", "use_clusters": ["Multi-agent coordination"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Multi-agent coordination", "data / training setup", "interface contract", "axes: communication protocol + role assignment, aggregation (vote / debate / referee), stability (collusion, mode collapse, incentives), mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "At the implementation level, the B-route relies on different interface/training assumptions, which changes failure modes and costs.", "use_clusters": ["Multi-agent coordination"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Multi-agent coordination", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "In evaluations, when comparable settings exist, evaluation evidence for B can be contrasted against A to surface the trade-offs.", "use_clusters": ["Multi-agent coordination"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Multi-agent coordination", "multiple citations in one paragraph", "axes: communication protocol + role assignment, aggregation (vote / debate / referee), stability (collusion, mode collapse, incentives), mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Stepping back, the key distinction between Agent frameworks / architectures and Multi-agent coordination is how they trade off communication protocol + role assignment, aggregation (vote / debate / referee), stability (collusion, mode collapse, incentives), mechanism / architecture, data / training setup under evaluation constraints.", "use_clusters": ["Agent frameworks / architectures", "Multi-agent coordination", "Planning / reasoning loops"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "Therefore, a decision checklist can map evaluation signals and constraints to route selection.", "use_clusters": ["Agent frameworks / architectures", "Multi-agent coordination", "Planning / reasoning loops"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Despite these advances, key claims hinge on assumptions that merit stress-testing, which motivates concrete verification targets.", "use_clusters": ["Agent frameworks / architectures", "Multi-agent coordination", "Planning / reasoning loops"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-18T01:21:06"}
{"sub_id": "6.1", "title": "Benchmarks and evaluation protocols", "section_id": "6", "section_title": "Evaluation & Risks", "rq": "Which design choices in Benchmarks and evaluation protocols drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Benchmarks and evaluation protocols methods emphasize tool interface (function calling, schemas, protocols) and tool selection / routing policy trade-offs, but synthesis is clearest when claims are tied to explicit evaluation settings and reporting conventions.", "scope_rule": {"include": ["Core topics directly relevant to 'Benchmarks and evaluation protocols'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["tool interface (function calling, schemas, protocols)", "tool selection / routing policy", "sandboxing / permissions / observability", "task suites (web / code / embodied / tools)", "metrics (success, cost, reliability, safety)"], "bridge_terms": ["function calling", "tool schema", "routing", "sandbox", "observability", "benchmarks"], "contrast_hook": "tool interfaces", "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "compute / cost (train/infer)", "threat model", "defense surface"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0052", "P0054", "P0015", "P0018", "P0032", "P0089", "P0101", "P0102"], "bibkeys": ["Li2026Autonomous", "Kim2026Beyond", "Zhu2025Where", "Lidayan2025Abbel", "Shi2025Progent", "Zhang2025Security", "Ji2025Taxonomy", "Chen2025Towards"]}, {"label": "Evaluation / benchmark-focused works", "rationale": "Grouped by keyword tag `evaluation` from titles (bootstrap).", "paper_ids": ["P0054", "P0089", "P0101", "P0102", "P0164", "P0199", "P0206", "P0116"], "bibkeys": ["Kim2026Beyond", "Zhang2025Security", "Ji2025Taxonomy", "Chen2025Towards", "Mohammadi2025Evaluation", "Fu2025Eval", "Zhan2025Sentinel", "Dagan2024Plancraft"]}, {"label": "Safety / security / guardrails", "rationale": "Grouped by keyword tag `security` from titles (bootstrap).", "paper_ids": ["P0089", "P0149", "P0199", "P0206", "P0009"], "bibkeys": ["Zhang2025Security", "Shao2025Craken", "Fu2025Eval", "Zhan2025Sentinel", "Li2024Personal"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Benchmarks and evaluation protocols drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "To ground this thesis, Agent frameworks / architectures approaches provide a natural starting point because they make the agent-loop decision explicit.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, task suites (web / code / embodied / tools), metrics (success, cost, reliability, safety)"], "connector_to_prev": "elaboration", "connector_phrase": "Building on this, these designs imply concrete interface/data assumptions that shape behavior.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Empirically, protocols and metrics clarify where Agent frameworks / architectures works, and where it fails or becomes costly.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Evaluation / benchmark-focused works", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "By contrast, Evaluation / benchmark-focused works approaches shift the emphasis and optimize for a different point in the trade-off space.", "use_clusters": ["Evaluation / benchmark-focused works"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Evaluation / benchmark-focused works", "data / training setup", "interface contract", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, task suites (web / code / embodied / tools), metrics (success, cost, reliability, safety)"], "connector_to_prev": "elaboration", "connector_phrase": "Building on this, the B-route relies on different interface/training assumptions, which changes failure modes and costs.", "use_clusters": ["Evaluation / benchmark-focused works"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Evaluation / benchmark-focused works", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Empirically, when comparable settings exist, evaluation evidence for B can be contrasted against A to surface the trade-offs.", "use_clusters": ["Evaluation / benchmark-focused works"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Evaluation / benchmark-focused works", "multiple citations in one paragraph", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, task suites (web / code / embodied / tools), metrics (success, cost, reliability, safety)"], "connector_to_prev": "synthesis", "connector_phrase": "Stepping back, the key distinction between Agent frameworks / architectures and Evaluation / benchmark-focused works is how they trade off tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, task suites (web / code / embodied / tools), metrics (success, cost, reliability, safety) under evaluation constraints.", "use_clusters": ["Agent frameworks / architectures", "Evaluation / benchmark-focused works", "Safety / security / guardrails"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "Consequently, a decision checklist can map evaluation signals and constraints to route selection.", "use_clusters": ["Agent frameworks / architectures", "Evaluation / benchmark-focused works", "Safety / security / guardrails"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Despite these advances, key claims hinge on assumptions that merit stress-testing, which motivates concrete verification targets.", "use_clusters": ["Agent frameworks / architectures", "Evaluation / benchmark-focused works", "Safety / security / guardrails"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-18T01:21:06"}
{"sub_id": "6.2", "title": "Safety, security, and governance", "section_id": "6", "section_title": "Evaluation & Risks", "rq": "Which design choices in Safety, security, and governance drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Safety, security, and governance methods emphasize threat model (prompt / tool injection, exfiltration) and defense surface (policy, sandbox, monitoring) trade-offs, but synthesis is clearest when claims are tied to explicit evaluation settings and reporting conventions.", "scope_rule": {"include": ["Core topics directly relevant to 'Safety, security, and governance'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["threat model (prompt / tool injection, exfiltration)", "defense surface (policy, sandbox, monitoring)", "security evaluation protocol", "mechanism / architecture", "data / training setup"], "bridge_terms": ["threat model", "prompt/tool injection", "monitoring", "guardrails"], "contrast_hook": "security", "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision", "threat model", "defense surface"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0056", "P0006", "P0032", "P0034", "P0040", "P0065", "P0074", "P0075"], "bibkeys": ["Liu2026Agents", "Plaat2025Agentic", "Shi2025Progent", "Zhou2025Reasoning", "Hadeliya2025When", "Rosario2025Architecting", "Gasmi2025Bridging", "Bonagiri2025Check"]}, {"label": "Safety / security / guardrails", "rationale": "Grouped by keyword tag `security` from titles (bootstrap).", "paper_ids": ["P0040", "P0065", "P0074", "P0075", "P0089", "P0135", "P0140", "P0175"], "bibkeys": ["Hadeliya2025When", "Rosario2025Architecting", "Gasmi2025Bridging", "Bonagiri2025Check", "Zhang2025Security", "Luo2025Agrail", "Sha2025Agent", "An2025Ipiguard"]}, {"label": "Code agents / software tasks", "rationale": "Grouped by keyword tag `code` from titles (bootstrap).", "paper_ids": ["P0032", "P0074", "P0205"], "bibkeys": ["Shi2025Progent", "Gasmi2025Bridging", "Lee2025Bench"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Safety, security, and governance drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "To ground this thesis, Agent frameworks / architectures approaches provide a natural starting point because they make the agent-loop decision explicit.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: threat model (prompt / tool injection, exfiltration), defense surface (policy, sandbox, monitoring), security evaluation protocol, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "More concretely, these designs imply concrete interface/data assumptions that shape behavior.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Under standard benchmarks, protocols and metrics clarify where Agent frameworks / architectures works, and where it fails or becomes costly.", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Safety / security / guardrails", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Unlike this route, Safety / security / guardrails approaches shift the emphasis and optimize for a different point in the trade-off space.", "use_clusters": ["Safety / security / guardrails"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Safety / security / guardrails", "data / training setup", "interface contract", "axes: threat model (prompt / tool injection, exfiltration), defense surface (policy, sandbox, monitoring), security evaluation protocol, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "More concretely, the B-route relies on different interface/training assumptions, which changes failure modes and costs.", "use_clusters": ["Safety / security / guardrails"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Safety / security / guardrails", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Under standard benchmarks, when comparable settings exist, evaluation evidence for B can be contrasted against A to surface the trade-offs.", "use_clusters": ["Safety / security / guardrails"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Safety / security / guardrails", "multiple citations in one paragraph", "axes: threat model (prompt / tool injection, exfiltration), defense surface (policy, sandbox, monitoring), security evaluation protocol, mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Stepping back, the key distinction between Agent frameworks / architectures and Safety / security / guardrails is how they trade off threat model (prompt / tool injection, exfiltration), defense surface (policy, sandbox, monitoring), security evaluation protocol, mechanism / architecture, data / training setup under evaluation constraints.", "use_clusters": ["Agent frameworks / architectures", "Safety / security / guardrails", "Code agents / software tasks"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "Therefore, a decision checklist can map evaluation signals and constraints to route selection.", "use_clusters": ["Agent frameworks / architectures", "Safety / security / guardrails", "Code agents / software tasks"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Despite these advances, key claims hinge on assumptions that merit stress-testing, which motivates concrete verification targets.", "use_clusters": ["Agent frameworks / architectures", "Safety / security / guardrails", "Code agents / software tasks"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-18T01:21:06"}
