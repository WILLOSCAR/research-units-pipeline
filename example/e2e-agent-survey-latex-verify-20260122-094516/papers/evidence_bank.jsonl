{"evidence_id": "E-P0001-43f54265e8", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "method", "snippet": "We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0001-ca4a00b5cf", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "result", "snippet": "On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0001-604e8557e1", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "result", "snippet": "We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0001-8d0b22fef5", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0001-4f8536e0c6", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0001-d0f1113f52", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0001-1ac73ff02d", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0001-f18242e304", "paper_id": "P0001", "bibkey": "Yao2022React", "title": "ReAct: Synergizing Reasoning and Acting in Language Models", "year": 2022, "evidence_level": "abstract", "claim_type": "summary", "snippet": "On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0001#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0002-a8cd1f03c8", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0002-67875fd02f", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0002-9c4c3d45ac", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0002-f1f4c8649c", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller models excel.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0002-a58d26cb94", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0002-8f44086775", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0002-19f40531ed", "paper_id": "P0002", "bibkey": "Schick2023Toolformer", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0002#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0003-b0fdbdd3a5", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose Reflexion, a novel framework to reinforce language agents not by updating weights, but instead through linguistic feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0003-a402af154b", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "For example, Reflexion achieves a 91% pass@1 accuracy on the HumanEval coding benchmark, surpassing the previous state-of-the-art GPT-4 that achieves 80%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0003-fb3046de14", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have been increasingly used to interact with external environments (e.g., games, compilers, APIs) as goal-driven agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0003-6c4bb4831c", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, it remains challenging for these language agents to quickly and efficiently learn from trial-and-error as traditional reinforcement learning methods require extensive training samples and expensive model fine-tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0003-901b0c3e29", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose Reflexion, a novel framework to reinforce language agents not by updating weights, but instead through linguistic feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0003-3f6b365112", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Concretely, Reflexion agents verbally reflect on task feedback signals, then maintain their own reflective text in an episodic memory buffer to induce better decision-making in subsequent trials.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#summary_bullets[3]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0003-50d96acd26", "paper_id": "P0003", "bibkey": "Shinn2023Reflexion", "title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reflexion is flexible enough to incorporate various types (scalar values or free-form language) and sources (external or internally simulated) of feedback signals, and obtains significant improvements over a baseline agent across diverse tasks (sequential decision-making, coding, language reasoning).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0003#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0004-83af02f575", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0004-b9cd4289ed", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4% of tasks, our method achieved a success rate of 74%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0004-110ba95352", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0004-e9d0fe92c8", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0004-f64609094e", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0004-de6a7d0720", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0004-abde03b1c3", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0004-676a7be5f2", "paper_id": "P0004", "bibkey": "Yao2023Tree", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0004#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0005-c57fee9291", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0005-b2eceb5b30", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "It obtains 3.3x more unique items, travels 2.3x longer distances, and unlocks key tech tree milestones up to 15.3x faster than prior SOTA.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0005-506120a6cd", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0005-e65ddaea31", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0005-c5ade9e083", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0005-51338842b2", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Voyager interacts with GPT-4 via blackbox queries, which bypasses the need for model parameter fine-tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0005-cc1ce5543d", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The skills developed by Voyager are temporally extended, interpretable, and compositional, which compounds the agent's abilities rapidly and alleviates catastrophic forgetting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0005-437d13c92d", "paper_id": "P0005", "bibkey": "Wang2023Voyager", "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Empirically, Voyager shows strong in-context lifelong learning capability and exhibits exceptional proficiency in playing Minecraft.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0005#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0006-ce3104c142", "paper_id": "P0006", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Background: There is great interest in agentic LLMs, large language models that act as agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0006-2fb0b1b9ae", "paper_id": "P0006", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Methods: Agentic LLMs are LLMs that (1) reason, (2) act, and (3) interact.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0006-a1fb101bda", "paper_id": "P0006", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Further, agentic LLMs provide a solution for the problem of LLMs running out of training data: inference-time behavior generates new training states, such that LLMs can keep learning without needing ever larger datasets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0006-c14b84b190", "paper_id": "P0006", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Background: There is great interest in agentic LLMs, large language models that act as agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0006-0ffaa050ce", "paper_id": "P0006", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Objectives: We review the growing body of work in this area and provide a research agenda.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0006-4f05d5ff66", "paper_id": "P0006", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Methods: Agentic LLMs are LLMs that (1) reason, (2) act, and (3) interact.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0006-e688e4a34e", "paper_id": "P0006", "bibkey": "Plaat2025Agentic", "title": "Agentic Large Language Models, a survey", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "We note that there is risk associated with LLM assistants taking action in the real world-safety, liability and security are open problems-while agentic LLMs are also likely to benefit society.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0006#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0007-bbaca264f1", "paper_id": "P0007", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large language models (LLMs) and agent techniques have brought a fundamental shift in the functionality and development paradigm of data analysis tasks (a.k.a LLM/Agent-as-Data-Analyst), demonstrating substantial impact across both academia and industry.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0007-db233dcd06", "paper_id": "P0007", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we outline the remaining challenges and propose several insights and practical directions for advancing LLM/Agent-powered data analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0007-4e35a5103c", "paper_id": "P0007", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) and agent techniques have brought a fundamental shift in the functionality and development paradigm of data analysis tasks (a.k.a LLM/Agent-as-Data-Analyst), demonstrating substantial impact across both academia and industry.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0007-d66e2031cc", "paper_id": "P0007", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In comparison with traditional rule or small-model based approaches, (agentic) LLMs enable complex data understanding, natural language interfaces, semantic analysis functions, and autonomous pipeline orchestration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0007-a4245dcbb7", "paper_id": "P0007", "bibkey": "Tang2025Agent", "title": "LLM/Agent-as-Data-Analyst: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "From a modality perspective, we review LLM-based techniques for (i) structured data (e.g., NL2SQL, NL2GQL, ModelQA), (ii) semi-structured data (e.g., markup languages understanding, semi-structured table question answering), (iii) unstructured data (e.g., chart understanding, text/image document understanding), and (iv) heterogeneous data (e.g., data retrieval and modality alignment in data lakes).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0007#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0008-e2d0085f84", "paper_id": "P0008", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a task-driven taxonomy encompassing six broad application areas: data extraction, interpretation and Q\\&A; atomistic simulation; property prediction; materials structure, design and discovery; process planning, discovery, and optimization; and multiscale modeling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0008-a68f39bc04", "paper_id": "P0008", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This survey provides a comprehensive overview of foundation models, agentic systems, datasets, and computational tools supporting this growing field.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0008-e012f792c6", "paper_id": "P0008", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Furthermore, we review standardized datasets, open-source tools, and autonomous experimental platforms that collectively fuel the development and integration of FMs into research workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0008-34dbc1be9b", "paper_id": "P0008", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Foundation models (FMs) are catalyzing a transformative shift in materials science (MatSci) by enabling scalable, general-purpose, and multimodal AI systems for scientific discovery.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0008-099d1eaa8f", "paper_id": "P0008", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike traditional machine learning models, which are typically narrow in scope and require task-specific engineering, FMs offer cross-domain generalization and exhibit emergent capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0008-80a53d8d03", "paper_id": "P0008", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Their versatility is especially well-suited to materials science, where research challenges span diverse data types and scales.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0008-29dfc29320", "paper_id": "P0008", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey provides a comprehensive overview of foundation models, agentic systems, datasets, and computational tools supporting this growing field.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0008-e5f06504bd", "paper_id": "P0008", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce a task-driven taxonomy encompassing six broad application areas: data extraction, interpretation and Q\\&A; atomistic simulation; property prediction; materials structure, design and discovery; process planning, discovery, and optimization; and multiscale modeling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0008-7acf4de689", "paper_id": "P0008", "bibkey": "Van2025Survey", "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "We assess the early successes of foundation models and identify persistent limitations, including challenges in generalizability, interpretability, data imbalance, safety concerns, and limited multimodal fusion.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0008#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0009-7cdfbf595a", "paper_id": "P0009", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The era of intelligent agents is upon us, driven by revolutionary advancements in large language models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0009-62cd0c501b", "paper_id": "P0009", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our work provides a unified architectural perspective, examining how agents are constructed, how they collaborate, and how they evolve over time, while also addressing evaluation methodologies, tool applications, practical challenges, and diverse application domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0009-65aa5a8555", "paper_id": "P0009", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The era of intelligent agents is upon us, driven by revolutionary advancements in large language models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0009-8447fe66ad", "paper_id": "P0009", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents, with goal-driven behaviors and dynamic adaptation capabilities, potentially represent a critical pathway toward artificial general intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0009-a47c55035c", "paper_id": "P0009", "bibkey": "Luo2025Large", "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey systematically deconstructs LLM agent systems through a methodology-centered taxonomy, linking architectural foundations, collaboration mechanisms, and evolutionary pathways.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0009#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0010-2c281ce5fb", "paper_id": "P0010", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "This survey investigates how classical software design patterns can enhance the reliability and scalability of communication in Large Language Model (LLM)-driven agentic AI systems, focusing particularly on the Model Context Protocol (MCP).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0010-a26478752b", "paper_id": "P0010", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The article concludes by outlining open challenges, potential security risks, and promising directions for advancing robust, interoperable, and scalable multi-agent LLM ecosystems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0010-9122b67024", "paper_id": "P0010", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey investigates how classical software design patterns can enhance the reliability and scalability of communication in Large Language Model (LLM)-driven agentic AI systems, focusing particularly on the Model Context Protocol (MCP).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0010-c890a205fd", "paper_id": "P0010", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It examines the foundational architectures of LLM-based agents and their evolution from isolated operation to sophisticated, multi-agent collaboration, addressing key communication hurdles that arise in this transition.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0010-5a66424ae7", "paper_id": "P0010", "bibkey": "Sarkar2025Survey", "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The study revisits well-established patterns, including Mediator, Observer, Publish-Subscribe, and Broker, and analyzes their relevance in structuring agent interactions within MCP-compliant frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0010#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0011-1564795a81", "paper_id": "P0011", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a stealthy, multi-turn economic DoS attack that operates at the tool layer under the guise of a correctly completed task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#method"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0011-b6b7af5a81", "paper_id": "P0011", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across six LLMs on the ToolBench and BFCL benchmarks, our attack expands tasks into trajectories exceeding 60,000 tokens, inflates costs by up to 658x, and raises energy by 100-560x.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0011-0e9bf4bf0b", "paper_id": "P0011", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "It drives GPU KV cache occupancy from <1% to 35-74% and cuts co-running throughput by approximately 50%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0011-09300516c9", "paper_id": "P0011", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The agent-tool communication loop is a critical attack surface in modern Large Language Model (LLM) agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#summary_bullets[0]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0011-eb0bf8bedb", "paper_id": "P0011", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing Denial-of-Service (DoS) attacks, primarily triggered via user prompts or injected retrieval-augmented generation (RAG) context, are ineffective for this new paradigm.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "security"]}
{"evidence_id": "E-P0011-62b0277ae2", "paper_id": "P0011", "bibkey": "Zhou2026Beyond", "title": "Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "They are fundamentally single-turn and often lack a task-oriented approach, making them conspicuous in goal-oriented workflows and unable to exploit the compounding costs of multi-turn agent-tool interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0011#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0012-fdf9ca29d7", "paper_id": "P0012", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Solving complex or long-horizon problems often requires large language models (LLMs) to use external tools and operate over a significantly longer context window.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0012-ddd9371119", "paper_id": "P0012", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Models with 1M-2M token context windows show severe degradation already at 100K tokens, with performance drops exceeding 50\\% for both benign and harmful tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0012-3fdd9d3667", "paper_id": "P0012", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Refusal rates shift unpredictably: GPT-4.1-nano increases from $\\sim$5\\% to $\\sim$40\\% while Grok 4 Fast decreases from $\\sim$80\\% to $\\sim$10\\% at 200K tokens.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0012-d94c4039a2", "paper_id": "P0012", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Solving complex or long-horizon problems often requires large language models (LLMs) to use external tools and operate over a significantly longer context window.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0012-e111274d88", "paper_id": "P0012", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "New LLMs enable longer context windows and support tool calling capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0012-7e514e7d32", "paper_id": "P0012", "bibkey": "Hadeliya2025When", "title": "When Refusals Fail: Unstable Safety Mechanisms in Long-Context LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Prior works have focused mainly on evaluation of LLMs on long-context prompts, leaving agentic setup relatively unexplored, both from capability and safety perspectives.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0012#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0013-ea4ec898b8", "paper_id": "P0013", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose using \"quitting\" as a simple yet effective behavioral mechanism for LLM agents to recognize and withdraw from situations where they lack confidence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0013-7edb91824f", "paper_id": "P0013", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Leveraging the ToolEmu framework, we conduct a systematic evaluation of quitting behavior across 12 state-of-the-art LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0013-0550cab83d", "paper_id": "P0013", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results demonstrate a highly favorable safety-helpfulness trade-off: agents prompted to quit with explicit instructions improve safety by an average of +0.39 on a 0-3 scale across all models (+0.64 for proprietary models), while maintaining a negligible average decrease of -0.03 in helpfulness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0013-ed9d5a5002", "paper_id": "P0013", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As Large Language Model (LLM) agents increasingly operate in complex environments with real-world consequences, their safety becomes critical.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0013-fcdca39700", "paper_id": "P0013", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While uncertainty quantification is well-studied for single-turn tasks, multi-turn agentic scenarios with real-world tool access present unique challenges where uncertainties and ambiguities compound, leading to severe or catastrophic risks beyond traditional text generation failures.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0013-53dd169482", "paper_id": "P0013", "bibkey": "Bonagiri2025Check", "title": "Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose using \"quitting\" as a simple yet effective behavioral mechanism for LLM agents to recognize and withdraw from situations where they lack confidence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0013#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0014-a565550b5e", "paper_id": "P0014", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we propose AgentSwift, a novel framework for automated agent design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0014-904ba35500", "paper_id": "P0014", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\\% over both existing automated agent search methods and manually designed agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0014-9d669c9af7", "paper_id": "P0014", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Current automated agent design approaches are often constrained by limited search spaces that primarily optimize workflows but fail to integrate crucial human-designed components like memory, planning, and tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#key_results[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0014-3b666704bd", "paper_id": "P0014", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents have demonstrated strong capabilities across diverse domains, yet automated agent design remains a significant challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0014-5631a9e933", "paper_id": "P0014", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current automated agent design approaches are often constrained by limited search spaces that primarily optimize workflows but fail to integrate crucial human-designed components like memory, planning, and tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0014-7fa82de592", "paper_id": "P0014", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Furthermore, these methods are hampered by high evaluation costs, as evaluating even a single new agent on a benchmark can require tens of dollars.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0014-d01f35a38b", "paper_id": "P0014", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The difficulty of this exploration is further exacerbated by inefficient search strategies that struggle to navigate the large design space effectively, making the discovery of novel agents a slow and resource-intensive process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0014-c66133f1cc", "paper_id": "P0014", "bibkey": "Li2025Agentswift", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these challenges, we propose AgentSwift, a novel framework for automated agent design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0014#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0015-635f1577d3", "paper_id": "P0015", "bibkey": "Prcha2025Agents", "title": "Are LLM Agents the New RPA? A Comparative Study with RPA Across Enterprise Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The emergence of large language models (LLMs) has introduced a new paradigm in automation: LLM agents or Agentic Automation with Computer Use (AACU).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0015-93109f3af4", "paper_id": "P0015", "bibkey": "Prcha2025Agents", "title": "Are LLM Agents the New RPA? A Comparative Study with RPA Across Enterprise Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Future research should explore multi-agent orchestration, hybrid RPA-AACU architectures, and more robust evaluation across industries and platforms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0015-27d2dcb2de", "paper_id": "P0015", "bibkey": "Prcha2025Agents", "title": "Are LLM Agents the New RPA? A Comparative Study with RPA Across Enterprise Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The emergence of large language models (LLMs) has introduced a new paradigm in automation: LLM agents or Agentic Automation with Computer Use (AACU).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0015-fe3f367b96", "paper_id": "P0015", "bibkey": "Prcha2025Agents", "title": "Are LLM Agents the New RPA? A Comparative Study with RPA Across Enterprise Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike traditional Robotic Process Automation (RPA), which relies on rule-based workflows and scripting, AACU enables intelligent agents to perform tasks through natural language instructions and autonomous interaction with user interfaces.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0015-57762dec21", "paper_id": "P0015", "bibkey": "Prcha2025Agents", "title": "Are LLM Agents the New RPA? A Comparative Study with RPA Across Enterprise Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study investigates whether AACU can serve as a viable alternative to RPA in enterprise workflow automation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0015#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0016-9d9d60644a", "paper_id": "P0016", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0016-04c60086db", "paper_id": "P0016", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design principles for trustworthy agents: modular decomposition, adaptive symbolic governance, and transparent state management.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0016-17d092450a", "paper_id": "P0016", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model agents suffer from fundamental architectural problems: entangled reasoning and execution, memory volatility, and uncontrolled action sequences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0016-10950917a3", "paper_id": "P0016", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0016-1dbc5333ba", "paper_id": "P0016", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "At the core of SCL is Soft Symbolic Control, an adaptive governance mechanism that applies symbolic constraints to probabilistic inference, preserving neural flexibility while restoring the explainability and controllability of classical symbolic systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0016-79a2100d6b", "paper_id": "P0016", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Through empirical validation on multi-step conditional reasoning tasks, we demonstrate that SCL achieves zero policy violations, eliminates redundant tool calls, and maintains complete decision traceability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0016-54c9afde38", "paper_id": "P0016", "bibkey": "Kim2025Bridging", "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These results address critical gaps in existing frameworks such as ReAct, AutoGPT, and memory-augmented approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0016#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0017-192e78b614", "paper_id": "P0017", "bibkey": "Dong2025Etom", "title": "ETOM: A Five-Level Benchmark for Evaluating Tool Orchestration within the MCP Ecosystem", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce ETOM, a five-level benchmark for evaluating multi-hop, end-to-end tool orchestration by LLM agents within a hierarchical Model-Context Protocol (MCP) ecosystem.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0017-6ee6d5b951", "paper_id": "P0017", "bibkey": "Dong2025Etom", "title": "ETOM: A Five-Level Benchmark for Evaluating Tool Orchestration within the MCP Ecosystem", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We introduce ETOM, a five-level benchmark for evaluating multi-hop, end-to-end tool orchestration by LLM agents within a hierarchical Model-Context Protocol (MCP) ecosystem.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0017-55ce44af76", "paper_id": "P0017", "bibkey": "Dong2025Etom", "title": "ETOM: A Five-Level Benchmark for Evaluating Tool Orchestration within the MCP Ecosystem", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Existing benchmarks often assess tools in isolation, overlooking challenges such as functional overlap and cross-server orchestration, which can lead to overly optimistic evaluations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0017-1c769526d3", "paper_id": "P0017", "bibkey": "Dong2025Etom", "title": "ETOM: A Five-Level Benchmark for Evaluating Tool Orchestration within the MCP Ecosystem", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce ETOM, a five-level benchmark for evaluating multi-hop, end-to-end tool orchestration by LLM agents within a hierarchical Model-Context Protocol (MCP) ecosystem.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0017-5bfe17f8c0", "paper_id": "P0017", "bibkey": "Dong2025Etom", "title": "ETOM: A Five-Level Benchmark for Evaluating Tool Orchestration within the MCP Ecosystem", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing benchmarks often assess tools in isolation, overlooking challenges such as functional overlap and cross-server orchestration, which can lead to overly optimistic evaluations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0017-c703fd224d", "paper_id": "P0017", "bibkey": "Dong2025Etom", "title": "ETOM: A Five-Level Benchmark for Evaluating Tool Orchestration within the MCP Ecosystem", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ETOM addresses these gaps by constructing ground truth through \"equal function sets\", enabling objective metrics such as F1 score and reducing reliance on LLM-as-a-judge evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0017-092dfe6461", "paper_id": "P0017", "bibkey": "Dong2025Etom", "title": "ETOM: A Five-Level Benchmark for Evaluating Tool Orchestration within the MCP Ecosystem", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "ETOM provides a diagnostic framework to expose these limitations and guide the development of more capable and efficient tool-using agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0017#limitations[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0018-877442aea5", "paper_id": "P0018", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Motivated by the growing trend of scientific studies accompanied by public code repositories, we propose ToolMaker, an agentic framework that autonomously transforms papers with code into LLM-compatible tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0018-057a755e4e", "paper_id": "P0018", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To evaluate our approach, we introduce a benchmark comprising 15 complex computational tasks spanning various domains with over 100 unit tests to assess correctness and robustness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0018-172d428d55", "paper_id": "P0018", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our method correctly implements 80% of the tasks, substantially outperforming current state-of-the-art software engineering agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0018-e2c5ec2338", "paper_id": "P0018", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tool use has turned large language models (LLMs) into powerful agents that can perform complex multi-step tasks by dynamically utilising external software components.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0018-253ce87f76", "paper_id": "P0018", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, these tools must be implemented in advance by human developers, hindering the applicability of LLM agents in domains demanding large numbers of highly specialised tools, like in life sciences and medicine.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0018-59d6b455cf", "paper_id": "P0018", "bibkey": "Wlflein2025Agents", "title": "LLM Agents Making Agent Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Motivated by the growing trend of scientific studies accompanied by public code repositories, we propose ToolMaker, an agentic framework that autonomously transforms papers with code into LLM-compatible tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0018#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0019-69289755a4", "paper_id": "P0019", "bibkey": "Tawosi2025Meta", "title": "Meta-RAG on Large Codebases Using Code Summarization", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose a multi-agent system to localize bugs in large pre-existing codebases using information retrieval and LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0019-e3ebb83eb2", "paper_id": "P0019", "bibkey": "Tawosi2025Meta", "title": "Meta-RAG on Large Codebases Using Code Summarization", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Meta-RAG scores 84.67 % and 53.0 % for file-level and function-level correct localization rates, respectively, achieving state-of-the-art performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0019-f36b515991", "paper_id": "P0019", "bibkey": "Tawosi2025Meta", "title": "Meta-RAG on Large Codebases Using Code Summarization", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\\%, into a compact, structured, natural language representation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0019-d075de386a", "paper_id": "P0019", "bibkey": "Tawosi2025Meta", "title": "Meta-RAG on Large Codebases Using Code Summarization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) systems have been at the forefront of applied Artificial Intelligence (AI) research in a multitude of domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0019-d9878accab", "paper_id": "P0019", "bibkey": "Tawosi2025Meta", "title": "Meta-RAG on Large Codebases Using Code Summarization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "One such domain is software development, where researchers have pushed the automation of a number of code tasks through LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0019-03b1dfae9c", "paper_id": "P0019", "bibkey": "Tawosi2025Meta", "title": "Meta-RAG on Large Codebases Using Code Summarization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Software development is a complex ecosystem, that stretches far beyond code implementation and well into the realm of code maintenance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0019#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0020-2263621dd5", "paper_id": "P0020", "bibkey": "Tan2025Process", "title": "Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To train agents for this dynamic process, particularly in multi-modal contexts, we introduce a sandbox environment for reinforcement learning (RL) that supports interleaved speech-text rollouts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0020-deb233b78c", "paper_id": "P0020", "bibkey": "Tan2025Process", "title": "Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This unified approach boosts the task pass rate on the text-based $$-bench by over 6% compared to strong RL baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0020-e2865f6e58", "paper_id": "P0020", "bibkey": "Tan2025Process", "title": "Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our core strategy, Turn-level Adjudicated Reinforcement Learning (TARL), addresses the challenge of credit assignment in long-horizon tasks by employing a Large Language Model (LLM) as a judge to provide turn-level evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0020-fb379b67b7", "paper_id": "P0020", "bibkey": "Tan2025Process", "title": "Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Effective interactive tool use requires agents to master Tool Integrated Reasoning (TIR): a complex process involving multi-turn planning and long-context dialogue management.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0020-a645263bd0", "paper_id": "P0020", "bibkey": "Tan2025Process", "title": "Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To train agents for this dynamic process, particularly in multi-modal contexts, we introduce a sandbox environment for reinforcement learning (RL) that supports interleaved speech-text rollouts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0020-197346a05c", "paper_id": "P0020", "bibkey": "Tan2025Process", "title": "Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our core strategy, Turn-level Adjudicated Reinforcement Learning (TARL), addresses the challenge of credit assignment in long-horizon tasks by employing a Large Language Model (LLM) as a judge to provide turn-level evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0020#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0021-cb7c521301", "paper_id": "P0021", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose Reasoning-Style Poisoning (RSP), a paradigm that manipulates how agents process information rather than what they process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0021-c17bcfb7d4", "paper_id": "P0021", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "It increases reasoning steps by up to 4.4 times or induces premature errors, successfully bypassing state-of-the-art content filters.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0021-e38b4bdff3", "paper_id": "P0021", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To quantify these shifts, we develop the Reasoning Style Vector (RSV), a metric tracking Verification depth, Self-confidence, and Attention focus.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0021-dac2089fae", "paper_id": "P0021", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents relying on external retrieval are increasingly deployed in high-stakes environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0021-8517628bd0", "paper_id": "P0021", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0021-8a9233d368", "paper_id": "P0021", "bibkey": "Zhou2025Reasoning", "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose Reasoning-Style Poisoning (RSP), a paradigm that manipulates how agents process information rather than what they process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0021#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0022-e872c22cb6", "paper_id": "P0022", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose the Self-Challenging framework for training an agent on high-quality tasks that are generated by itself.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0022-2e6956a116", "paper_id": "P0022", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0022-17d0e7f9d9", "paper_id": "P0022", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, training such agents is challenging because it requires human creation and annotation of a diverse set of tasks, tools, and evaluation criteria.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0022-35136168c1", "paper_id": "P0022", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models are quickly becoming the foundation for intelligent agents that are capable of using tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0022-e90846830c", "paper_id": "P0022", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, training such agents is challenging because it requires human creation and annotation of a diverse set of tasks, tools, and evaluation criteria.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0022-0e2de6e8b5", "paper_id": "P0022", "bibkey": "Zhou2025Self", "title": "Self-Challenging Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose the Self-Challenging framework for training an agent on high-quality tasks that are generated by itself.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0022#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0023-32b2c8cf19", "paper_id": "P0023", "bibkey": "Cao2025Skyrl", "title": "SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce SkyRL-Agent, a framework for efficient, multi-turn, long-horizon agent training and evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0023-3af1ce8090", "paper_id": "P0023", "bibkey": "Cao2025Skyrl", "title": "SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Using SkyRL-Agent, we train SA-SWE-32B, a software engineering agent trained from Qwen3-32B (24.4% Pass@1) purely with reinforcement learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0023-5ed988eb67", "paper_id": "P0023", "bibkey": "Cao2025Skyrl", "title": "SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We introduce two key components: an optimized asynchronous pipeline dispatcher that achieves a 1.55x speedup over naive asynchronous batching, and a tool-enhanced training recipe leveraging an AST-based search tool to facilitate code navigation, boost rollout Pass@K, and improve training efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers", "tooling"]}
{"evidence_id": "E-P0023-6d4d6c2f88", "paper_id": "P0023", "bibkey": "Cao2025Skyrl", "title": "SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce SkyRL-Agent, a framework for efficient, multi-turn, long-horizon agent training and evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0023-60a60b10a5", "paper_id": "P0023", "bibkey": "Cao2025Skyrl", "title": "SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It provides efficient asynchronous dispatching, lightweight tool integration, and flexible backend interoperability, enabling seamless use with existing RL frameworks such as SkyRL-train, VeRL, and Tinker.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0023-e61a040022", "paper_id": "P0023", "bibkey": "Cao2025Skyrl", "title": "SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Using SkyRL-Agent, we train SA-SWE-32B, a software engineering agent trained from Qwen3-32B (24.4% Pass@1) purely with reinforcement learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0023#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0024-f4d80ca542", "paper_id": "P0024", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Models (LLMs) have demonstrated remarkable capabilities in knowledge acquisition, reasoning, and tool use, making them promising candidates for autonomous agent applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0024-771620f84f", "paper_id": "P0024", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experimental evaluation on the complex task planning benchmark demonstrates that our 1.5B parameter model trained with single-turn GRPO achieves superior performance compared to larger baseline models up to 14B parameters, with success rates of 70% for long-horizon planning tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0024-5a257bd496", "paper_id": "P0024", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our theoretical analysis shows that GRPO improvement on single-turn task reasoning results in a lower bound of the multi-turn success probability under the minimal turns, as well as the generalization to subtasks with shorter horizons.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0024-efac948251", "paper_id": "P0024", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have demonstrated remarkable capabilities in knowledge acquisition, reasoning, and tool use, making them promising candidates for autonomous agent applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0024-291455ba2c", "paper_id": "P0024", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, training LLM agents for complex multi-turn task planning faces significant challenges, including sparse episode-wise rewards, credit assignment across long horizons, and the computational overhead of reinforcement learning in multi-turn interaction settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0024-ac96b98574", "paper_id": "P0024", "bibkey": "Hu2025Training", "title": "Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To this end, this paper introduces a novel approach that transforms multi-turn task planning into single-turn task reasoning problems, enabling efficient policy optimization through Group Relative Policy Optimization (GRPO) with dense and verifiable reward from expert trajectories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0024#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0025-a2aafb319f", "paper_id": "P0025", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "GUIs have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0025-1e605f8766", "paper_id": "P0025", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "GUIs have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0025-52fea1d199", "paper_id": "P0025", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We address research questions such as existing GUI agent frameworks, the collection and utilization of data for training specialized GUI agents, the development of large action models tailored for GUI tasks, and the evaluation metrics and benchmarks necessary to assess their effectiveness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0025-b24804a0b8", "paper_id": "P0025", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "GUIs have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0025-a936da9e8a", "paper_id": "P0025", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The advent of LLMs, particularly multimodal models, has ushered in a new era of GUI automation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0025-506fa962e0", "paper_id": "P0025", "bibkey": "Zhang2024Large", "title": "Large Language Model-Brained GUI Agents: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "They have demonstrated exceptional capabilities in natural language understanding, code generation, and visual processing.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0025#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0026-afe907256b", "paper_id": "P0026", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Since the advent of personal computing devices, intelligent personal assistants (IPAs) have been one of the key technologies that researchers and engineers have focused on, aiming to help users efficiently obtain information and execute tasks, and provide users with more intelligent, convenient, and rich interaction experiences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0026-063c3b3128", "paper_id": "P0026", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Next, we discuss several key challenges to achieve intelligent, efficient and secure Personal LLM Agents, followed by a comprehensive survey of representative solutions to address these challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0026-8179d149f9", "paper_id": "P0026", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Since the advent of personal computing devices, intelligent personal assistants (IPAs) have been one of the key technologies that researchers and engineers have focused on, aiming to help users efficiently obtain information and execute tasks, and provide users with more intelligent, convenient, and rich interaction experiences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0026-b0726cba84", "paper_id": "P0026", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the development of smartphones and IoT, computing and sensing devices have become ubiquitous, greatly expanding the boundaries of IPAs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0026-716c8ba772", "paper_id": "P0026", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, due to the lack of capabilities such as user intent understanding, task planning, tool using, and personal data management etc., existing IPAs still have limited practicality and scalability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0026-01651dbee4", "paper_id": "P0026", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, the emergence of foundation models, represented by large language models (LLMs), brings new opportunities for the development of IPAs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0026-e3be73b8f9", "paper_id": "P0026", "bibkey": "Li2024Personal", "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the powerful semantic understanding and reasoning capabilities, LLM can enable intelligent agents to solve complex problems autonomously.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0026#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0027-f6fba56a1b", "paper_id": "P0027", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To overcome these challenges, we propose a novel approach that decomposes the aforementioned capabilities into a planner, caller, and summarizer.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0027-8158d9909c", "paper_id": "P0027", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "First, we fine-tune a backbone LLM on the entire dataset without discriminating sub-tasks, providing the model with a comprehensive understanding of the task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0027-9640816b42", "paper_id": "P0027", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluation across various tool-use benchmarks illustrates that our proposed multi-LLM framework surpasses the traditional single-LLM approach, highlighting its efficacy and advantages in tool learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0027-e8cc8a6f73", "paper_id": "P0027", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents significantly extend the capabilities of standalone LLMs, empowering them to interact with external tools (e.g., APIs, functions) and complete various tasks in a self-directed fashion.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0027-35a42b4664", "paper_id": "P0027", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The challenge of tool use demands that LLMs not only understand user queries and generate answers accurately but also excel in task planning, tool invocation, and result summarization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0027-9e83833f66", "paper_id": "P0027", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While traditional works focus on training a single LLM with all these capabilities, performance limitations become apparent, particularly with smaller models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0027-378c9f919c", "paper_id": "P0027", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To overcome these challenges, we propose a novel approach that decomposes the aforementioned capabilities into a planner, caller, and summarizer.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0027-0df71db19d", "paper_id": "P0027", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Each component is implemented by a single LLM that focuses on a specific capability and collaborates with others to accomplish the task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#summary_bullets[4]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0027-c92ed293ba", "paper_id": "P0027", "bibkey": "Shen2024Small", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "While traditional works focus on training a single LLM with all these capabilities, performance limitations become apparent, particularly with smaller models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0027#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0028-67ea29ce26", "paper_id": "P0028", "bibkey": "Li2026Autonomous", "title": "Autonomous Quantum Simulation through Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We demonstrate that large language model (LLM) agents can autonomously perform tensor network simulations of quantum many-body systems, achieving approximately 90% success rate across representative benchmark tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#method"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0028-499402e2fb", "paper_id": "P0028", "bibkey": "Li2026Autonomous", "title": "Autonomous Quantum Simulation through Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We demonstrate that large language model (LLM) agents can autonomously perform tensor network simulations of quantum many-body systems, achieving approximately 90% success rate across representative benchmark tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0028-9980bf7642", "paper_id": "P0028", "bibkey": "Li2026Autonomous", "title": "Autonomous Quantum Simulation through Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Systematic evaluation using DeepSeek-V3.2, Gemini 2.5 Pro, and Claude Opus 4.5 demonstrates that both in-context learning and multi-agent architecture are essential.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0028-b497dd93f2", "paper_id": "P0028", "bibkey": "Li2026Autonomous", "title": "Autonomous Quantum Simulation through Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We demonstrate that large language model (LLM) agents can autonomously perform tensor network simulations of quantum many-body systems, achieving approximately 90% success rate across representative benchmark tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0028-a10b5d889d", "paper_id": "P0028", "bibkey": "Li2026Autonomous", "title": "Autonomous Quantum Simulation through Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tensor network methods are powerful tools for quantum simulation, but their effective use requires expertise typically acquired through years of graduate training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0028-971c9175a5", "paper_id": "P0028", "bibkey": "Li2026Autonomous", "title": "Autonomous Quantum Simulation through Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By combining in-context learning with curated documentation and multi-agent decomposition, we create autonomous AI agents that can be trained in specialized computational domains within minutes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0028#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0029-ef4cf62416", "paper_id": "P0029", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0029-79f88927fa", "paper_id": "P0029", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0029-593af2dd94", "paper_id": "P0029", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "API specification, which includes detailed documentation and usage constraints, and 2.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0029-f99e220a0c", "paper_id": "P0029", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0029-2b1181bd3f", "paper_id": "P0029", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0029-cdecc79d54", "paper_id": "P0029", "bibkey": "Kim2026Beyond", "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "API specification, which includes detailed documentation and usage constraints, and 2.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0029#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0030-952a3ec8a8", "paper_id": "P0030", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we present a comprehensive survey of LLM agents for legal tasks, analyzing how these architectures bridge the gap between technical capabilities and domain-specific needs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0030-8b56718f74", "paper_id": "P0030", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our major contributions include: (1) systematically analyzing the technical transition from standard legal LLMs to legal agents; (2) presenting a structured taxonomy of current agent applications across distinct legal practice areas; (3) discussing evaluation methodologies specifically for agentic performance in law; and (4) identifying open challenges and outlining future directions for developing robust and autonomous legal assistants.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0030-73192b14aa", "paper_id": "P0030", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have precipitated a dramatic improvement in the legal domain, yet the deployment of standalone models faces significant limitations regarding hallucination, outdated information, and verifiability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0030-536a01abb9", "paper_id": "P0030", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, LLM agents have attracted significant attention as a solution to these challenges, utilizing advanced capabilities such as planning, memory, and tool usage to meet the rigorous standards of legal practice.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0030-9e10275b89", "paper_id": "P0030", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we present a comprehensive survey of LLM agents for legal tasks, analyzing how these architectures bridge the gap between technical capabilities and domain-specific needs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0030-19ffd0c3ba", "paper_id": "P0030", "bibkey": "Liu2026Agents", "title": "LLM Agents in Law: Taxonomy, Applications, and Challenges", "year": 2026, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Large language models (LLMs) have precipitated a dramatic improvement in the legal domain, yet the deployment of standalone models faces significant limitations regarding hallucination, outdated information, and verifiability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0030#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0031-c63f9e7a62", "paper_id": "P0031", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we explore the Large Language Model (LLM) agent reviewer dynamics in an Elo-ranked review system using real-world conference paper submissions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0031-a11e93b0b9", "paper_id": "P0031", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our simulation results showcase several interesting findings, including how incorporating Elo improves Area Chair decision accuracy, as well as reviewers' adaptive review strategy that exploits our Elo system without improving review effort.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0031-7a3393ef27", "paper_id": "P0031", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we explore the Large Language Model (LLM) agent reviewer dynamics in an Elo-ranked review system using real-world conference paper submissions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0031-ff3cba1c44", "paper_id": "P0031", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Multiple LLM agent reviewers with different personas are engage in multi round review interactions moderated by an Area Chair.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0031-82b5ed27f7", "paper_id": "P0031", "bibkey": "Huang2026Modeling", "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We compare a baseline setting with conditions that incorporate Elo ratings and reviewer memory.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0031#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0032-e39ba54e34", "paper_id": "P0032", "bibkey": "Xi2026Toolgym", "title": "ToolGym: an Open-world Tool-using Environment for Scalable Agent Testing and Data Curation", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "For scalable and realistic training and testing, we introduce an open-world tool-using environment, built on 5,571 format unified tools across 204 commonly used apps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#method"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0032-895b04aa5c", "paper_id": "P0032", "bibkey": "Xi2026Toolgym", "title": "ToolGym: an Open-world Tool-using Environment for Scalable Agent Testing and Data Curation", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Comprehensive evaluation of state-of-the-art LLMs reveals the misalignment between tool planning and execution abilities, the constraint following weakness of existing LLMs, and DeepSeek-v3.2's strongest robustness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0032-8c9597d805", "paper_id": "P0032", "bibkey": "Xi2026Toolgym", "title": "ToolGym: an Open-world Tool-using Environment for Scalable Agent Testing and Data Curation", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we collect 1,170 trajectories from our environment to fine-tune LLMs, achieving superior performance to baselines using 119k samples, indicating the environment's value as both a realistic benchmark and a data engine for tool-using agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0032-f9a1a30c08", "paper_id": "P0032", "bibkey": "Xi2026Toolgym", "title": "ToolGym: an Open-world Tool-using Environment for Scalable Agent Testing and Data Curation", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tool-using LLM agents still struggle in open-world settings with large tool pools, long-horizon objectives, wild constraints, and unreliable tool states.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0032-e33ef53c3f", "paper_id": "P0032", "bibkey": "Xi2026Toolgym", "title": "ToolGym: an Open-world Tool-using Environment for Scalable Agent Testing and Data Curation", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "For scalable and realistic training and testing, we introduce an open-world tool-using environment, built on 5,571 format unified tools across 204 commonly used apps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0032-1e02661cc7", "paper_id": "P0032", "bibkey": "Xi2026Toolgym", "title": "ToolGym: an Open-world Tool-using Environment for Scalable Agent Testing and Data Curation", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It includes a task creation engine that synthesizes long-horizon, multi-tool workflows with wild constraints, and a state controller that injects interruptions and failures to stress-test robustness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0032#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0033-4259f85a98", "paper_id": "P0033", "bibkey": "Li2026Toolprmbench", "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0033-3e2edc05cd", "paper_id": "P0033", "bibkey": "Li2026Toolprmbench", "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0033-9861661010", "paper_id": "P0033", "bibkey": "Li2026Toolprmbench", "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0033-0b3dfdca08", "paper_id": "P0033", "bibkey": "Li2026Toolprmbench", "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reward-guided search methods have demonstrated strong potential in enhancing tool-using agents by effectively guiding sampling and exploration over complex action spaces.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0033-d01a2965cd", "paper_id": "P0033", "bibkey": "Li2026Toolprmbench", "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As a core design, those search methods utilize process reward models (PRMs) to provide step-level rewards, enabling more fine-grained monitoring.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0033-f46a87924a", "paper_id": "P0033", "bibkey": "Li2026Toolprmbench", "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0033#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0034-7b3ec45781", "paper_id": "P0034", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "This paper surveys the development of large language model (LLM)-based agents for question answering (QA).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0034-48f5050e3c", "paper_id": "P0034", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Additionally, this paper identifies ongoing challenges and explores future research directions to enhance the performance of LLM agent QA systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0034-c4dbb5a1b4", "paper_id": "P0034", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper surveys the development of large language model (LLM)-based agents for question answering (QA).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0034-d923fcecb6", "paper_id": "P0034", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional agents face significant limitations, including substantial data requirements and difficulty in generalizing to new environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0034-59428e8083", "paper_id": "P0034", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM-based agents address these challenges by leveraging LLMs as their core reasoning engine.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0034-014d5f7597", "paper_id": "P0034", "bibkey": "Yue2025Survey", "title": "A Survey of Large Language Model Agents for Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Traditional agents face significant limitations, including substantial data requirements and difficulty in generalizing to new environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0034#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0035-c6091976f8", "paper_id": "P0035", "bibkey": "Chen2025Agentguard", "title": "AgentGuard: Repurposing Agentic Orchestrator for Safety Evaluation of Tool Orchestration", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose AgentGuard, a framework to autonomously discover and validate unsafe tool-use workflows, followed by generating safety constraints to confine the behaviors of agents, achieving the baseline of safety guarantee at deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0035-2fb350794d", "paper_id": "P0035", "bibkey": "Chen2025Agentguard", "title": "AgentGuard: Repurposing Agentic Orchestrator for Safety Evaluation of Tool Orchestration", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The output, an evaluation report with unsafe workflows, test cases, and validated constraints, enables multiple security applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0035-dbba06c706", "paper_id": "P0035", "bibkey": "Chen2025Agentguard", "title": "AgentGuard: Repurposing Agentic Orchestrator for Safety Evaluation of Tool Orchestration", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The integration of tool use into large language models (LLMs) enables agentic systems with real-world impact.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0035-96683b7e8c", "paper_id": "P0035", "bibkey": "Chen2025Agentguard", "title": "AgentGuard: Repurposing Agentic Orchestrator for Safety Evaluation of Tool Orchestration", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In the meantime, unlike standalone LLMs, compromised agents can execute malicious workflows with more consequential impact, signified by their tool-use capability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0035-1566d887d8", "paper_id": "P0035", "bibkey": "Chen2025Agentguard", "title": "AgentGuard: Repurposing Agentic Orchestrator for Safety Evaluation of Tool Orchestration", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose AgentGuard, a framework to autonomously discover and validate unsafe tool-use workflows, followed by generating safety constraints to confine the behaviors of agents, achieving the baseline of safety guarantee at deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0035#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0036-4ef4e06ede", "paper_id": "P0036", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose HexMachina, a continual learning multi-agent system that separates environment discovery (inducing an adapter layer without documentation) from strategy improvement (evolving a compiled player through code refinement and simulation).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0036-7929ef7a56", "paper_id": "P0036", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In controlled Catanatron experiments, HexMachina learns from scratch and evolves players that outperform the strongest human-crafted baseline (AlphaBeta), achieving a 54% win rate and surpassing prompt-driven and no-discovery baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0036-eae2720c71", "paper_id": "P0036", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Settlers of Catan provides a challenging benchmark: success depends on balancing short- and long-term goals amid randomness, trading, expansion, and blocking.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0036-c9e00a13bf", "paper_id": "P0036", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We address the long-horizon gap in large language model (LLM) agents by enabling them to sustain coherent strategies in adversarial, stochastic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0036-cecd47b994", "paper_id": "P0036", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Settlers of Catan provides a challenging benchmark: success depends on balancing short- and long-term goals amid randomness, trading, expansion, and blocking.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0036-ab714c0ab3", "paper_id": "P0036", "bibkey": "Belle2025Agents", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Prompt-centric LLM agents (e.g., ReAct, Reflexion) must re-interpret large, evolving game states each turn, quickly saturating context windows and losing strategic consistency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0036#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0037-9062fd18ff", "paper_id": "P0037", "bibkey": "Rosario2025Architecting", "title": "Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "As Large Language Model (LLM) agents become increasingly capable of automating complex, multi-step tasks, the need for robust, secure, and predictable architectural patterns is paramount.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0037-0590337b16", "paper_id": "P0037", "bibkey": "Rosario2025Architecting", "title": "Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we discuss advanced patterns, including dynamic re-planning loops, parallel execution with Directed Acyclic Graphs (DAGs), and the critical role of Human-in-the-Loop (HITL) verification, to offer a complete strategic blueprint for architects, developers, and security engineers aiming to build production-grade, resilient, and trustworthy LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0037-857ffd5d59", "paper_id": "P0037", "bibkey": "Rosario2025Architecting", "title": "Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As Large Language Model (LLM) agents become increasingly capable of automating complex, multi-step tasks, the need for robust, secure, and predictable architectural patterns is paramount.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0037-cee871a1fb", "paper_id": "P0037", "bibkey": "Rosario2025Architecting", "title": "Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper provides a comprehensive guide to the ``Plan-then-Execute'' (P-t-E) pattern, an agentic design that separates strategic planning from tactical execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0037-2cb857d77b", "paper_id": "P0037", "bibkey": "Rosario2025Architecting", "title": "Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We explore the foundational principles of P-t-E, detailing its core components - the Planner and the Executor - and its architectural advantages in predictability, cost-efficiency, and reasoning quality over reactive patterns like ReAct (Reason + Act).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0037#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0038-f5791417c7", "paper_id": "P0038", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Audio-Language Models (LALMs) perform well on audio understanding tasks but lack multi-step reasoning and tool-calling found in recent Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0038-e31e41085b", "paper_id": "P0038", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments with MMAU, MMAR, and MMAU-Pro show state-of-the-art accuracy: up to 74.10% on MMAU, 68.80% on MMAR, and 57.96% on MMAU-Pro.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0038-de509152db", "paper_id": "P0038", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Monte Carlo sampling for shapley values across 374 configurations identifies effective agent-tool combinations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0038-3c246cb9dc", "paper_id": "P0038", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Audio-Language Models (LALMs) perform well on audio understanding tasks but lack multi-step reasoning and tool-calling found in recent Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0038-eefd7f1aeb", "paper_id": "P0038", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents AudioToolAgent, a framework that coordinates audio-language models as tools via a central LLM agent that accesses tool adapters for audio question answering and speech-to-text.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0038-9505dec385", "paper_id": "P0038", "bibkey": "Wijngaard2025Audiotoolagent", "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The agent selects tools, asks follow-up questions, and compares outputs for verification.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0038#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0039-54aa7c79f9", "paper_id": "P0039", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a library implementing common prompting patterns using the PDL prompt programming language.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0039-1c2ad83594", "paper_id": "P0039", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluations across three tasks and seven LLMs (ranging from 3B to 70B parameters) show consistent accuracy gains ($9.21\\pm15.46$ percentage points), up to 67.5pp, and reveal that selected prompting strategies vary across models and tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0039-b3f5346012", "paper_id": "P0039", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "AutoPDL solutions are human-readable, editable, and executable PDL programs that use this library.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0039-5bd886ea4a", "paper_id": "P0039", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The performance of large language models (LLMs) depends on how they are prompted, with choices spanning both the high-level prompting pattern (e.g., Zero-Shot, CoT, ReAct, ReWOO) and the specific prompt content (instructions and few-shot demonstrations).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0039-05fc2ccbd6", "paper_id": "P0039", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Manually tuning this combination is tedious, error-prone, and specific to a given LLM and task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0039-658a4af4bb", "paper_id": "P0039", "bibkey": "Spiess2025Autopdl", "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Therefore, this paper proposes AutoPDL, an automated approach to discovering good LLM agent configurations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0039#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0040-f6681abfd4", "paper_id": "P0040", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "A recent area of increasing research is the use of Large Language Models (LLMs) in penetration testing, which promises to reduce costs and thus allow for higher frequency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0040-7e9d7616ab", "paper_id": "P0040", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Both approaches are able to complete 15-25 % of the subtasks on the HTB machines, with AutoPentest slightly outperforming ChatGPT.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0040-89865e4c80", "paper_id": "P0040", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We measure a total cost of \\$96.20 US when using AutoPentest across all experiments, while a one-month subscription to ChatGPT Plus costs \\$20.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0040-b543eff594", "paper_id": "P0040", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A recent area of increasing research is the use of Large Language Models (LLMs) in penetration testing, which promises to reduce costs and thus allow for higher frequency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0040-3dc72e8dbb", "paper_id": "P0040", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We conduct a review of related work, identifying best practices and common evaluation issues.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0040-4d926d8b04", "paper_id": "P0040", "bibkey": "Henke2025Autopentest", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We then present AutoPentest, an application for performing black-box penetration tests with a high degree of autonomy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0040#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0041-c8895eaeab", "paper_id": "P0041", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Model (LLM) agents face security vulnerabilities spanning AI-specific and traditional software domains, yet current research addresses these separately.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0041-8e34a29629", "paper_id": "P0041", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "security", "tooling"]}
{"evidence_id": "E-P0041-8a2c2e2291", "paper_id": "P0041", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Attack complexity dramatically amplified effectiveness, with chained attacks achieving 91-96% success rates.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "security"]}
{"evidence_id": "E-P0041-2a59b6d5bc", "paper_id": "P0041", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents face security vulnerabilities spanning AI-specific and traditional software domains, yet current research addresses these separately.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0041-2333abf508", "paper_id": "P0041", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study bridges this gap through comparative evaluation of Function Calling architecture and Model Context Protocol (MCP) deployment paradigms using a unified threat classification framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0041-26646f7a50", "paper_id": "P0041", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We tested 3,250 attack scenarios across seven language models, evaluating simple, composed, and chained attacks targeting both AI-specific threats (prompt injection) and software vulnerabilities (JSON injection, denial-of-service).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0041-c6d60c7b44", "paper_id": "P0041", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers", "security", "tooling"]}
{"evidence_id": "E-P0041-a96843d7f0", "paper_id": "P0041", "bibkey": "Gasmi2025Bridging", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Attack complexity dramatically amplified effectiveness, with chained attacks achieving 91-96% success rates.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0041#summary_bullets[4]"}, "confidence": "medium", "tags": ["numbers", "security"]}
{"evidence_id": "E-P0042-23733a633f", "paper_id": "P0042", "bibkey": "Shao2025Craken", "title": "CRAKEN: Cybersecurity LLM Agent with Knowledge-Based Execution", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present CRAKEN, a knowledge-based LLM agent framework that improves cybersecurity capability through three core mechanisms: contextual decomposition of task-critical information, iterative self-reflected knowledge retrieval, and knowledge-hint injection that transforms insights into adaptive attack strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#method"}, "confidence": "medium", "tags": ["evaluation", "memory", "security"]}
{"evidence_id": "E-P0042-015abc04f2", "paper_id": "P0042", "bibkey": "Shao2025Craken", "title": "CRAKEN: Cybersecurity LLM Agent with Knowledge-Based Execution", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "With a knowledge database of CTF writeups, CRAKEN obtained an accuracy of 22% on NYU CTF Bench, outperforming prior works by 3% and achieving state-of-the-art results.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0042-9d48d99db0", "paper_id": "P0042", "bibkey": "Shao2025Craken", "title": "CRAKEN: Cybersecurity LLM Agent with Knowledge-Based Execution", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On evaluation of MITRE ATT&CK techniques, CRAKEN solves 25-30% more techniques than prior work, demonstrating improved cybersecurity capabilities via knowledge-based execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0042-7e671141ec", "paper_id": "P0042", "bibkey": "Shao2025Craken", "title": "CRAKEN: Cybersecurity LLM Agent with Knowledge-Based Execution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents can automate cybersecurity tasks and can adapt to the evolving cybersecurity landscape without re-engineering.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0042-f76bf82e48", "paper_id": "P0042", "bibkey": "Shao2025Craken", "title": "CRAKEN: Cybersecurity LLM Agent with Knowledge-Based Execution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While LLM agents have demonstrated cybersecurity capabilities on Capture-The-Flag (CTF) competitions, they have two key limitations: accessing latest cybersecurity expertise beyond training data, and integrating new knowledge into complex task planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0042-2d005bff82", "paper_id": "P0042", "bibkey": "Shao2025Craken", "title": "CRAKEN: Cybersecurity LLM Agent with Knowledge-Based Execution", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Knowledge-based approaches that incorporate technical understanding into the task-solving automation can tackle these limitations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0042-2c0fa12dbf", "paper_id": "P0042", "bibkey": "Shao2025Craken", "title": "CRAKEN: Cybersecurity LLM Agent with Knowledge-Based Execution", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "While LLM agents have demonstrated cybersecurity capabilities on Capture-The-Flag (CTF) competitions, they have two key limitations: accessing latest cybersecurity expertise beyond training data, and integrating new knowledge into complex task planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0042#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0043-6716c8d937", "paper_id": "P0043", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The ability to coordinate actions across multiple agents is critical for solving complex, real-world problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0043-b35b53de13", "paper_id": "P0043", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We systematically evaluate their performance using a suite of coordination-sensitive metrics, including task success rate, redundant actions, room conflicts, and urgency-weighted efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0043-baa622fa7f", "paper_id": "P0043", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This study offers new insights into the strengths and failure modes of LLMs in physically grounded multi-agent collaboration tasks, contributing to future benchmarks and architectural improvements.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0043-2dfd2491a4", "paper_id": "P0043", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The ability to coordinate actions across multiple agents is critical for solving complex, real-world problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0043-66af67b58a", "paper_id": "P0043", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have shown strong capabilities in communication, planning, and reasoning, raising the question of whether they can also support effective collaboration in multi-agent settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0043-e886e27049", "paper_id": "P0043", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we investigate the use of LLM agents to solve a structured victim rescue task that requires division of labor, prioritization, and cooperative planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0043-db71054bee", "paper_id": "P0043", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agents operate in a fully known graph-based environment and must allocate resources to victims with varying needs and urgency levels.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0043-33c24bc13c", "paper_id": "P0043", "bibkey": "Silva2025Agents", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We systematically evaluate their performance using a suite of coordination-sensitive metrics, including task success rate, redundant actions, room conflicts, and urgency-weighted efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0043#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0044-5fe6dbb13b", "paper_id": "P0044", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Our approach decomposes demonstration knowledge into transferable and non-transferable components through a causal lens, showing how the latter can introduce spurious dependencies that impair generalization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0044-384d450350", "paper_id": "P0044", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments across diverse domains demonstrate our method's effectiveness and generality, highlighting the importance of principled, context-aware demo selection for robust and efficient LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0044-56b0c62e72", "paper_id": "P0044", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model-based agents, empowered by in-context learning (ICL), have demonstrated strong capabilities in complex reasoning and tool-use tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0044-83df58a7e9", "paper_id": "P0044", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing works have shown that the effectiveness of ICL is highly sensitive to the choice of demonstrations, with suboptimal examples often leading to unstable or degraded performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0044-e88cf45af9", "paper_id": "P0044", "bibkey": "Wang2025Dice", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While prior work has explored example selection, including in some agentic or multi-step settings, existing approaches typically rely on heuristics or task-specific designs and lack a general, theoretically grounded criterion for what constitutes an effective demonstration across reasoning steps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0044#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0045-0cc8839b30", "paper_id": "P0045", "bibkey": "Lichkovski2025Agent", "title": "EU-Agent-Bench: Measuring Illegal Behavior of LLM Agents Under EU Law", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In order to measure the latent propensity of LLM agents for taking illegal actions under an EU legislative context, we introduce EU-Agent-Bench, a verifiable human-curated benchmark that evaluates an agent's alignment with EU legal norms in situations where benign user inputs could lead to unlawful actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0045-4e494f02c0", "paper_id": "P0045", "bibkey": "Lichkovski2025Agent", "title": "EU-Agent-Bench: Measuring Illegal Behavior of LLM Agents Under EU Law", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In order to measure the latent propensity of LLM agents for taking illegal actions under an EU legislative context, we introduce EU-Agent-Bench, a verifiable human-curated benchmark that evaluates an agent's alignment with EU legal norms in situations where benign user inputs could lead to unlawful actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0045-696cef029c", "paper_id": "P0045", "bibkey": "Lichkovski2025Agent", "title": "EU-Agent-Bench: Measuring Illegal Behavior of LLM Agents Under EU Law", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our benchmark spans scenarios across several categories, including data protection, bias/discrimination, and scientific integrity, with each user request allowing for both compliant and non-compliant execution of the requested actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0045-14f12c2d71", "paper_id": "P0045", "bibkey": "Lichkovski2025Agent", "title": "EU-Agent-Bench: Measuring Illegal Behavior of LLM Agents Under EU Law", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are increasingly deployed as agents in various contexts by providing tools at their disposal.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0045-94e0c3e010", "paper_id": "P0045", "bibkey": "Lichkovski2025Agent", "title": "EU-Agent-Bench: Measuring Illegal Behavior of LLM Agents Under EU Law", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, LLM agents can exhibit unpredictable behaviors, including taking undesirable and/or unsafe actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0045-caafcb9db7", "paper_id": "P0045", "bibkey": "Lichkovski2025Agent", "title": "EU-Agent-Bench: Measuring Illegal Behavior of LLM Agents Under EU Law", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In order to measure the latent propensity of LLM agents for taking illegal actions under an EU legislative context, we introduce EU-Agent-Bench, a verifiable human-curated benchmark that evaluates an agent's alignment with EU legal norms in situations where benign user inputs could lead to unlawful actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0045-a256400826", "paper_id": "P0045", "bibkey": "Lichkovski2025Agent", "title": "EU-Agent-Bench: Measuring Illegal Behavior of LLM Agents Under EU Law", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "We encourage future work extending agentic safety benchmarks to different legal jurisdictions and to multi-turn and multilingual interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0045#limitations[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0046-cdc1f1371a", "paper_id": "P0046", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we propose Reinforcement Learning with Tool-use Rewards (RLTR), a novel framework that decouples the training process to enable a focused, single-objective optimization of the planning module.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0046-cdf254f6f5", "paper_id": "P0046", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Moreover, this enhanced planning capability, in turn, translates to a 5%-6% increase in the final response quality of the overall agent system.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0046-f04cd37d30", "paper_id": "P0046", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments demonstrate that RLTR achieves an 8%-12% improvement in planning performance compared to end-to-end baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0046-1b6c72f6f2", "paper_id": "P0046", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The functionality of Large Language Model (LLM) agents is primarily determined by two capabilities: action planning and answer summarization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0046-8ee1b9d3b0", "paper_id": "P0046", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The former, action planning, is the core capability that dictates an agent's performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0046-7a25ab45ba", "paper_id": "P0046", "bibkey": "Li2025Encouraging", "title": "Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, prevailing training paradigms employ end-to-end, multi-objective optimization that jointly trains both capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0046#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0047-7adb7943bf", "paper_id": "P0047", "bibkey": "Mohammadi2025Evaluation", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The rise of LLM-based agents has opened new frontiers in AI applications, yet evaluating these agents remains a complex and underdeveloped area.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0047-37f9ea924c", "paper_id": "P0047", "bibkey": "Mohammadi2025Evaluation", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and (2) evaluation process -- how to evaluate, including interaction modes, datasets and benchmarks, metric computation methods, and tooling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0047-e973488a75", "paper_id": "P0047", "bibkey": "Mohammadi2025Evaluation", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We also identify future research directions, including holistic, more realistic, and scalable evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0047-c1704b916e", "paper_id": "P0047", "bibkey": "Mohammadi2025Evaluation", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rise of LLM-based agents has opened new frontiers in AI applications, yet evaluating these agents remains a complex and underdeveloped area.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0047-d95d39169b", "paper_id": "P0047", "bibkey": "Mohammadi2025Evaluation", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and (2) evaluation process -- how to evaluate, including interaction modes, datasets and benchmarks, metric computation methods, and tooling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0047-5ec1dd06bf", "paper_id": "P0047", "bibkey": "Mohammadi2025Evaluation", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In addition to taxonomy, we highlight enterprise-specific challenges, such as role-based access to data, the need for reliability guarantees, dynamic and long-horizon interactions, and compliance, which are often overlooked in current research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0047-01a13edd85", "paper_id": "P0047", "bibkey": "Mohammadi2025Evaluation", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We also identify future research directions, including holistic, more realistic, and scalable evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0047-8594c1b3da", "paper_id": "P0047", "bibkey": "Mohammadi2025Evaluation", "title": "Evaluation and Benchmarking of LLM Agents: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This work aims to bring clarity to the fragmented landscape of agent evaluation and provide a framework for systematic assessment, enabling researchers and practitioners to evaluate LLM agents for real-world deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0047#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0048-043e05ef50", "paper_id": "P0048", "bibkey": "Wu2025Evolver", "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we introduce EvolveR, a framework designed to enable agent to self-improve through a complete, closed-loop experience lifecycle.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0048-0c10233369", "paper_id": "P0048", "bibkey": "Wu2025Evolver", "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This lifecycle comprises two key stages: (1) Offline Self-Distillation, where the agent's interaction trajectories are synthesized into a structured repository of abstract, reusable strategic principles; (2) Online Interaction, where the agent interacts with tasks and actively retrieves distilled principles to guide its decision-making, accumulating a diverse set of behavioral trajectories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0048-1a05555e85", "paper_id": "P0048", "bibkey": "Wu2025Evolver", "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We demonstrate the effectiveness of EvolveR on complex multi-hop question-answering benchmarks, where it achieves superior performance over strong agentic baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0048-00be30b3b7", "paper_id": "P0048", "bibkey": "Wu2025Evolver", "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current Large Language Model (LLM) agents show strong performance in tool use, but lack the crucial capability to systematically learn from their own experiences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0048-d7bc6b040e", "paper_id": "P0048", "bibkey": "Wu2025Evolver", "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While existing frameworks mainly focus on mitigating external knowledge gaps, they fail to address a more fundamental limitation: the inability to iteratively refine problem-solving strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0048-84e01d467b", "paper_id": "P0048", "bibkey": "Wu2025Evolver", "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we introduce EvolveR, a framework designed to enable agent to self-improve through a complete, closed-loop experience lifecycle.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0048-e7e8e5879f", "paper_id": "P0048", "bibkey": "Wu2025Evolver", "title": "EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "While existing frameworks mainly focus on mitigating external knowledge gaps, they fail to address a more fundamental limitation: the inability to iteratively refine problem-solving strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0048#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0049-8518d9662a", "paper_id": "P0049", "bibkey": "Nitin2025Faultline", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present FaultLine, an LLM agent workflow that uses a set of carefully designed reasoning steps, inspired by aspects of traditional static and dynamic program analysis, to automatically generate PoV test cases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0049-91a368737e", "paper_id": "P0049", "bibkey": "Nitin2025Faultline", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On this dataset, FaultLine is able to generate PoV tests for 16 projects, compared to just 9 for CodeAct 2.1, a popular state-of-the-art open-source agentic framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0049-74188ef933", "paper_id": "P0049", "bibkey": "Nitin2025Faultline", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To evaluate FaultLine, we collate a challenging multi-lingual dataset of 100 known vulnerabilities in Java, C and C++ projects.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0049-6f7ce49ae0", "paper_id": "P0049", "bibkey": "Nitin2025Faultline", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite the critical threat posed by software security vulnerabilities, reports are often incomplete, lacking the proof-of-vulnerability (PoV) tests needed to validate fixes and prevent regressions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0049-81924d16d6", "paper_id": "P0049", "bibkey": "Nitin2025Faultline", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These tests are crucial not only for ensuring patches work, but also for helping developers understand how vulnerabilities can be exploited.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0049-6c37295be6", "paper_id": "P0049", "bibkey": "Nitin2025Faultline", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Generating PoV tests is a challenging problem, requiring reasoning about the flow of control and data through deeply nested levels of a program.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0049-ab9d23fcf2", "paper_id": "P0049", "bibkey": "Nitin2025Faultline", "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "FaultLine does not use language-specific static or dynamic analysis components, which enables it to be used across programming languages.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0049#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0050-270887a152", "paper_id": "P0050", "bibkey": "Liu2025Graph", "title": "Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Autonomous agents based on large language models (LLMs) have demonstrated impressive capabilities in a wide range of applications, including web navigation, software development, and embodied control.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0050-f81ff4a912", "paper_id": "P0050", "bibkey": "Liu2025Graph", "title": "Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We hope this paper can serve as a roadmap for future research on GLA and foster a deeper understanding of the role of graphs in LLM agent systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0050-3e4b428ae8", "paper_id": "P0050", "bibkey": "Liu2025Graph", "title": "Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Autonomous agents based on large language models (LLMs) have demonstrated impressive capabilities in a wide range of applications, including web navigation, software development, and embodied control.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0050-1e5377ab5f", "paper_id": "P0050", "bibkey": "Liu2025Graph", "title": "Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While most LLMs are limited in several key agentic procedures, such as reliable planning, long-term memory, tool management, and multi-agent coordination, graphs can serve as a powerful auxiliary structure to enhance structure, continuity, and coordination in complex agent workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0050-8cbd078c79", "paper_id": "P0050", "bibkey": "Liu2025Graph", "title": "Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Given the rapid growth and fragmentation of research on Graph-augmented LLM Agents (GLA), this paper offers a timely and comprehensive overview of recent advances and also highlights key directions for future work.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0050-d21d925ee8", "paper_id": "P0050", "bibkey": "Liu2025Graph", "title": "Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Given the rapid growth and fragmentation of research on Graph-augmented LLM Agents (GLA), this paper offers a timely and comprehensive overview of recent advances and also highlights key directions for future work.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0050#limitations[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0051-ac87dbfe2b", "paper_id": "P0051", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these issues, we propose two distinct and complementary strategies for adapting LLM agents by leveraging environment-specific information available during deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0051-5df3b00510", "paper_id": "P0051", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "For example, on the WebArena multi-site split, this method increases the agent's success rate from 2% to 23%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0051-af945eb2fa", "paper_id": "P0051", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate these strategies across diverse agentic benchmarks, including function calling and web navigation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0051-209ec6be9d", "paper_id": "P0051", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM)-based agents struggle to generalize to novel and complex environments, such as unseen websites or new sets of functions, due to a fundamental mismatch between their pre-training and test-time conditions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0051-cb9f56b1cb", "paper_id": "P0051", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This challenge stems from two distinct failure modes: a syntactic misunderstanding of environment-specific components like observation formats, and a semantic misunderstanding of state-transition dynamics, which are only revealed at test time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0051-47addec32c", "paper_id": "P0051", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these issues, we propose two distinct and complementary strategies for adapting LLM agents by leveraging environment-specific information available during deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0051-4359e69080", "paper_id": "P0051", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "First, an online distributional adaptation method parameterizes environmental nuances by learning a lightweight adaptation vector that biases the model's output distribution, enabling rapid alignment with an environment response format.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#summary_bullets[3]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0051-f296300dbb", "paper_id": "P0051", "bibkey": "Chen2025Grounded", "title": "Grounded Test-Time Adaptation for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Second, a deployment-time dynamics grounding method employs a persona-driven exploration phase to systematically probe and learn the environment's causal dynamics before task execution, equipping the agent with a nonparametric world model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0051#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0052-4d28c4585c", "paper_id": "P0052", "bibkey": "Song2025Agent", "title": "LLM Agent Swarm for Hypothesis-Driven Drug Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce PharmaSwarm, a unified multi-agent framework that orchestrates specialized LLM \"agents\" to propose, validate, and refine hypotheses for novel drug targets and lead compounds.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0052-23da89a284", "paper_id": "P0052", "bibkey": "Song2025Agent", "title": "LLM Agent Swarm for Hypothesis-Driven Drug Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Drug discovery remains a formidable challenge: more than 90 percent of candidate molecules fail in clinical evaluation, and development costs often exceed one billion dollars per approved therapy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0052-e6fce1c680", "paper_id": "P0052", "bibkey": "Song2025Agent", "title": "LLM Agent Swarm for Hypothesis-Driven Drug Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Drug discovery remains a formidable challenge: more than 90 percent of candidate molecules fail in clinical evaluation, and development costs often exceed one billion dollars per approved therapy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0052-985924906b", "paper_id": "P0052", "bibkey": "Song2025Agent", "title": "LLM Agent Swarm for Hypothesis-Driven Drug Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Disparate data streams, from genomics and transcriptomics to chemical libraries and clinical records, hinder coherent mechanistic insight and slow progress.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0052-cee8e4c80b", "paper_id": "P0052", "bibkey": "Song2025Agent", "title": "LLM Agent Swarm for Hypothesis-Driven Drug Discovery", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Meanwhile, large language models excel at reasoning and tool integration but lack the modular specialization and iterative memory required for regulated, hypothesis-driven workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0052#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0053-044d4e6a4e", "paper_id": "P0053", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We study the resulting open-ended agent qualitatively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0053-b3caa17225", "paper_id": "P0053", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "These findings illustrate both the promise and current limits of adapting pretrained LLMs toward open-endedness, and point to future directions for training agents to manage memory, explore productively, and pursue abstract long-term goals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#key_results[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0053-a49a564488", "paper_id": "P0053", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent LLM agents have made great use of chain of thought reasoning and function calling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0053-eff3ad7b6b", "paper_id": "P0053", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As their capabilities grow, an important question arises: can this software represent not only a smart problem-solving tool, but an entity in its own right, that can plan, design immediate tasks, and reason toward broader, more ambiguous goals?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0053-cebb3ed2a1", "paper_id": "P0053", "bibkey": "Nachkov2025Agents", "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To study this question, we adopt an open-ended experimental setting where we augment a pretrained LLM agent with the ability to generate its own tasks, accumulate knowledge, and interact extensively with its environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0053#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0054-4b774ec61e", "paper_id": "P0054", "bibkey": "Li2025Dissonances", "title": "Les Dissonances: Cross-Tool Harvesting and Polluting in Pool-of-Tools Empowered LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we present the first systematic security analysis of task control flows in multi-tool-enabled LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0054-fae121f81b", "paper_id": "P0054", "bibkey": "Li2025Dissonances", "title": "Les Dissonances: Cross-Tool Harvesting and Polluting in Pool-of-Tools Empowered LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0054-8ef2db8769", "paper_id": "P0054", "bibkey": "Li2025Dissonances", "title": "Les Dissonances: Cross-Tool Harvesting and Polluting in Pool-of-Tools Empowered LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents are autonomous systems powered by LLMs, capable of reasoning and planning to solve problems by leveraging a set of tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0054-8adb501f9a", "paper_id": "P0054", "bibkey": "Li2025Dissonances", "title": "Les Dissonances: Cross-Tool Harvesting and Polluting in Pool-of-Tools Empowered LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the integration of multi-tool capabilities in LLM agents introduces challenges in securely managing tools, ensuring their compatibility, handling dependency relationships, and protecting control flows within LLM agent workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0054-5bd954eacf", "paper_id": "P0054", "bibkey": "Li2025Dissonances", "title": "Les Dissonances: Cross-Tool Harvesting and Polluting in Pool-of-Tools Empowered LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we present the first systematic security analysis of task control flows in multi-tool-enabled LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0054#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0055-8bcb673a7d", "paper_id": "P0055", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#method"}, "confidence": "medium", "tags": ["evaluation", "security", "tooling"]}
{"evidence_id": "E-P0055-d6095e10e9", "paper_id": "P0055", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed attacks; (2) an evaluation harness that executes attacks by running real tools (both benign and malicious) via MCP rather than simulation; and (3) a robustness metric that quantifies the trade-off between security and performance: Net Resilient Performance (NRP).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0055-7a6ec4daed", "paper_id": "P0055", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate nine popular LLM agents across 10 domains and 400+ tools, producing 2,000 attack instances.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0055-04669fc5b8", "paper_id": "P0055", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The Model Context Protocol (MCP) standardizes how large language model (LLM) agents discover, describe, and call external tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0055-e58dfe941a", "paper_id": "P0055", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While MCP unlocks broad interoperability, it also enlarges the attack surface by making tools first-class, composable objects with natural-language metadata, and standardized I/O.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#summary_bullets[1]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0055-e61edf509b", "paper_id": "P0055", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "security", "tooling"]}
{"evidence_id": "E-P0055-f8cf967a0d", "paper_id": "P0055", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed attacks; (2) an evaluation harness that executes attacks by running real tools (both benign and malicious) via MCP rather than simulation; and (3) a robustness metric that quantifies the trade-off between security and performance: Net Resilient Performance (NRP).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#summary_bullets[3]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0055-65e66ae9c1", "paper_id": "P0055", "bibkey": "Zhang2025Security", "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluate nine popular LLM agents across 10 domains and 400+ tools, producing 2,000 attack instances.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0055#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0056-312a342670", "paper_id": "P0056", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0056-3a4792de2b", "paper_id": "P0056", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0056-67d5c4342c", "paper_id": "P0056", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0056-875ce4a305", "paper_id": "P0056", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) are increasingly serving as autonomous agents, and their utilization of external tools via the Model Context Protocol (MCP) is considered a future trend.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0056-cda5a4d930", "paper_id": "P0056", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0056-dee80dc348", "paper_id": "P0056", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0056-f7a14123f9", "paper_id": "P0056", "bibkey": "Liu2025Mcpagentbench", "title": "MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0056#limitations[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0057-2941d61a03", "paper_id": "P0057", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this need, we present \\textbf{MedicalOS}, a unified agent-based operational system designed as such a domain-specific abstract layer for healthcare.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0057-6075ffa788", "paper_id": "P0057", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We empirically validate MedicalOS on 214 patient cases across 22 specialties, demonstrating high diagnostic accuracy and confidence, clinically sound examination requests, and consistent generation of structured reports and medication recommendations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0057-26f893d6cd", "paper_id": "P0057", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This shift highlights the need for an abstraction layer, an agent-computer interface, that translates human language into machine-executable commands.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0057-3b9601b81e", "paper_id": "P0057", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Decades' advances in digital health technologies, such as electronic health records, have largely streamlined routine clinical processes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0057-cbfa085708", "paper_id": "P0057", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Yet, most these systems are still hard to learn and use: Clinicians often face the burden of managing multiple tools, repeating manual actions for each patient, navigating complicated UI trees to locate functions, and spending significant time on administration instead of caring for patients.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0057-27adc3f95a", "paper_id": "P0057", "bibkey": "Zhu2025Medicalos", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The recent rise of large language model (LLM) based agents demonstrates exceptional capability in coding and computer operation, revealing the potential for humans to interact with operating systems and software not by direct manipulation, but by instructing agents through natural language.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0057#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0058-d4a4183b68", "paper_id": "P0058", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce MemTool, a short-term memory framework enabling LLM agents to dynamically manage tools or MCP server contexts across multi-turn conversations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#method"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0058-35271418ac", "paper_id": "P0058", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0058-38dc800de9", "paper_id": "P0058", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "MemTool offers three agentic architectures: 1) Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow Mode, providing deterministic control without autonomy, and 3) Hybrid Mode, combining autonomous and deterministic control.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0058-64ae1a2cfc", "paper_id": "P0058", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents have shown significant autonomous capabilities in dynamically searching and incorporating relevant tools or Model Context Protocol (MCP) servers for individual queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0058-6243350e0e", "paper_id": "P0058", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, fixed context windows limit effectiveness in multi-turn interactions requiring repeated, independent tool usage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0058-50ae553d5f", "paper_id": "P0058", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce MemTool, a short-term memory framework enabling LLM agents to dynamically manage tools or MCP server contexts across multi-turn conversations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0058-f391e41a6e", "paper_id": "P0058", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "MemTool offers three agentic architectures: 1) Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow Mode, providing deterministic control without autonomy, and 3) Hybrid Mode, combining autonomous and deterministic control.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0058-95db5fe235", "paper_id": "P0058", "bibkey": "Lumer2025Memtool", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0058#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0059-30685104ae", "paper_id": "P0059", "bibkey": "Hong2025Planning", "title": "Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To remedy this, we propose a novel approach that uses goal-conditioned value functions to guide the reasoning of LLM agents, that scales even to large API-based models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0059-1ad09376fe", "paper_id": "P0059", "bibkey": "Hong2025Planning", "title": "Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We validate our method on tasks requiring interaction, including tool use, social deduction, and dialogue, demonstrating superior performance over both RL fine-tuning and prompting methods while maintaining efficiency and scalability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0059-ab203de788", "paper_id": "P0059", "bibkey": "Hong2025Planning", "title": "Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) excel in tasks like question answering and dialogue, but complex tasks requiring interaction, such as negotiation and persuasion, require additional long-horizon reasoning and planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0059-ae998ce589", "paper_id": "P0059", "bibkey": "Hong2025Planning", "title": "Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reinforcement learning (RL) fine-tuning can enable such planning in principle, but suffers from drawbacks that hinder scalability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0059-dadfe50856", "paper_id": "P0059", "bibkey": "Hong2025Planning", "title": "Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In particular, multi-turn RL training incurs high memory and computational costs, which are exacerbated when training LLMs as policies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0059#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0060-27b24bfa54", "paper_id": "P0060", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce Progent, the first privilege control framework to secure LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0060-68db58914f", "paper_id": "P0060", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0060-e6b786dc5e", "paper_id": "P0060", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM agents utilize Large Language Models as central components with diverse tools to complete various user tasks, but face significant security risks when interacting with external environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0060-52976e4dfa", "paper_id": "P0060", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Attackers can exploit these agents through various vectors, including indirect prompt injection, memory/knowledge base poisoning, and malicious tools, tricking agents into performing dangerous actions such as unauthorized financial transactions or data leakage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "security", "tooling"]}
{"evidence_id": "E-P0060-4792fb4704", "paper_id": "P0060", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The core problem that enables attacks to succeed lies in over-privileged tool access.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#summary_bullets[2]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0060-0396d9929b", "paper_id": "P0060", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce Progent, the first privilege control framework to secure LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0060-006a17d83a", "paper_id": "P0060", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Progent enforces security at the tool level by restricting agents to performing tool calls necessary for user tasks while blocking potentially malicious ones.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#summary_bullets[4]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0060-6829c8b583", "paper_id": "P0060", "bibkey": "Shi2025Progent", "title": "Progent: Programmable Privilege Control for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Thanks to our modular design, integrating Progent does not alter agent internals and only requires minimal changes to the existing agent implementation, enhancing its practicality and potential for widespread adoption.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0060#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0061-ec05e3ea6f", "paper_id": "P0061", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Agents powered by Large Language Models (LLMs) have recently demonstrated impressive capabilities in various tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0061-b5f497408b", "paper_id": "P0061", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Contributing to the ongoing research on neuro-symbolic hybrid systems, this work posits CBR as a viable technique for enhancing the reasoning skills and cognitive aspects of autonomous LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0061-fce48c710d", "paper_id": "P0061", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agents powered by Large Language Models (LLMs) have recently demonstrated impressive capabilities in various tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0061-45b7c47edc", "paper_id": "P0061", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Still, they face limitations in tasks requiring specific, structured knowledge, flexibility, or accountable decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0061-9d7bd89b61", "paper_id": "P0061", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While agents are capable of perceiving their environments, forming inferences, planning, and executing actions towards goals, they often face issues such as hallucinations and lack of contextual memory across interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0061-90c64203f8", "paper_id": "P0061", "bibkey": "Hatalis2025Review", "title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Still, they face limitations in tasks requiring specific, structured knowledge, flexibility, or accountable decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0061#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0062-18e9d83661", "paper_id": "P0062", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this, in this paper we propose Self-taught ActioN Deliberation (SAND) framework, enabling LLM agents to explicitly deliberate over candidate actions before committing to one.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0062-6273763a98", "paper_id": "P0062", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluating on two representative interactive agent tasks, SAND achieves an average 20% improvement over initial supervised finetuning and also outperforms state-of-the-art agent tuning approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0062-c32e04ef1b", "paper_id": "P0062", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To tackle the challenges of when and what to deliberate given large action space and step-level action evaluation, we incorporate self-consistency action sampling and execution-guided action critique to help synthesize step-wise action deliberation thoughts using the base model of the LLM agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0062-7aa323548c", "paper_id": "P0062", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents are commonly tuned with supervised finetuning on ReAct-style expert trajectories or preference optimization over pairwise rollouts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0062-8dfc3945ee", "paper_id": "P0062", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Most of these methods focus on imitating specific expert behaviors or promoting chosen reasoning thoughts and actions over rejected ones.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0062-a482c4692d", "paper_id": "P0062", "bibkey": "Xia2025Sand", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, without reasoning and comparing over alternatives actions, LLM agents finetuned with these methods may over-commit towards seemingly plausible but suboptimal actions due to limited action space exploration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0062#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0063-f136181262", "paper_id": "P0063", "bibkey": "Zhan2025Sentinel", "title": "SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present Sentinel, the first framework for formally evaluating the physical safety of Large Language Model(LLM-based) embodied agents across the semantic, plan, and trajectory levels.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0063-6a9a38705f", "paper_id": "P0063", "bibkey": "Zhan2025Sentinel", "title": "SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments show that by grounding physical safety in temporal logic and applying verification methods across multiple levels, Sentinel provides a rigorous foundation for systematically evaluating LLM-based embodied agents in physical environments, exposing safety violations overlooked by previous methods and offering insights into their failure modes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0063-66a2e9d03f", "paper_id": "P0063", "bibkey": "Zhan2025Sentinel", "title": "SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present Sentinel, the first framework for formally evaluating the physical safety of Large Language Model(LLM-based) embodied agents across the semantic, plan, and trajectory levels.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0063-e7408c78b4", "paper_id": "P0063", "bibkey": "Zhan2025Sentinel", "title": "SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike prior methods that rely on heuristic rules or subjective LLM judgments, Sentinel grounds practical safety requirements in formal temporal logic (TL) semantics that can precisely specify state invariants, temporal dependencies, and timing constraints.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0063-f7fbe5747b", "paper_id": "P0063", "bibkey": "Zhan2025Sentinel", "title": "SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "It then employs a multi-level verification pipeline where (i) at the semantic level, intuitive natural language safety requirements are formalized into TL formulas and the LLM agent's understanding of these requirements is probed for alignment with the TL formulas; (ii) at the plan level, high-level action plans and subgoals generated by the LLM agent are verified against the TL formulas to detect unsafe plans before execution; and (iii) at the trajectory level, multiple execution trajectories are merged into a computation tree and efficiently verified against physically-detailed TL specifications for a final safety check.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0063#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0064-eebdf19f2d", "paper_id": "P0064", "bibkey": "Zhou2025Siraj", "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present SIRAJ: a generic red-teaming framework for arbitrary black-box LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0064-0b753b9422", "paper_id": "P0064", "bibkey": "Zhou2025Siraj", "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across diverse evaluation agent settings, our seed test case generation approach yields 2 -- 2.5x boost to the coverage of risk outcomes and tool-calling trajectories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0064-1099fa6a48", "paper_id": "P0064", "bibkey": "Zhou2025Siraj", "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our distilled 8B red-teamer model improves attack success rate by 100%, surpassing the 671B Deepseek-R1 model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "security"]}
{"evidence_id": "E-P0064-c9c078ab3d", "paper_id": "P0064", "bibkey": "Zhou2025Siraj", "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The ability of LLM agents to plan and invoke tools exposes them to new safety risks, making a comprehensive red-teaming system crucial for discovering vulnerabilities and ensuring their safe deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#summary_bullets[0]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0064-3bc26d9063", "paper_id": "P0064", "bibkey": "Zhou2025Siraj", "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present SIRAJ: a generic red-teaming framework for arbitrary black-box LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0064-477f35eb97", "paper_id": "P0064", "bibkey": "Zhou2025Siraj", "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We employ a dynamic two-step process that starts with an agent definition and generates diverse seed test cases that cover various risk outcomes, tool-use trajectories, and risk sources.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0064#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0065-9152db24bd", "paper_id": "P0065", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Subsequently, we present the vision of a zero-trust multi-LLM framework in EGI.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0065-ee26c8ba8a", "paper_id": "P0065", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This survey serves as the first systematic treatment of zero-trust applied to multi-LLM systems, providing both theoretical foundations and practical strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0065-a1049afe06", "paper_id": "P0065", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agentification serves as a critical enabler of Edge General Intelligence (EGI), transforming massive edge devices into cognitive agents through integrating Large Language Models (LLMs) and perception, reasoning, and acting modules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0065-547b5447b2", "paper_id": "P0065", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These agents collaborate across heterogeneous edge infrastructures, forming multi-LLM agentic AI systems that leverage collective intelligence and specialized capabilities to tackle complex, multi-step tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0065-5bf56d0771", "paper_id": "P0065", "bibkey": "Liu2025Secure", "title": "Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the collaborative nature of multi-LLM systems introduces critical security vulnerabilities, including insecure inter-LLM communications, expanded attack surfaces, and cross-domain data leakage that traditional perimeter-based security cannot adequately address.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0065#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0066-3b338d80bc", "paper_id": "P0066", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we introduce StockBench, a contamination-free benchmark designed to evaluate LLM agents in realistic, multi-month stock trading environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0066-99aa4ad8d4", "paper_id": "P0066", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation of state-of-the-art proprietary (e.g., GPT-5, Claude-4) and open-weight (e.g., Qwen3, Kimi-K2, GLM-4.5) models shows that while most LLM agents struggle to outperform the simple buy-and-hold baseline, several models demonstrate the potential to deliver higher returns and manage risk more effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0066-79963782cf", "paper_id": "P0066", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "While prior benchmarks have evaluated LLM agents in domains such as software engineering and scientific discovery, the finance domain remains underexplored, despite its direct relevance to economic value and high-stakes decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0066-e22b501ea6", "paper_id": "P0066", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have recently demonstrated strong capabilities as autonomous agents, showing promise in reasoning, tool use, and sequential decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0066-a043637334", "paper_id": "P0066", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While prior benchmarks have evaluated LLM agents in domains such as software engineering and scientific discovery, the finance domain remains underexplored, despite its direct relevance to economic value and high-stakes decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0066-18024362ec", "paper_id": "P0066", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing financial benchmarks primarily test static knowledge through question answering, but they fall short of capturing the dynamic and iterative nature of trading.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0066-4f9b0e7b78", "paper_id": "P0066", "bibkey": "Chen2025Stockbench", "title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "These findings highlight both the challenges and opportunities in developing LLM-powered financial agents, showing that excelling at static financial knowledge tasks does not necessarily translate into successful trading strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0066#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0067-a0fe046ece", "paper_id": "P0067", "bibkey": "Ye2025Task", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce the Task Memory Engine (TME), a modular memory controller that transforms existing LLMs into robust, revision-aware agents without fine-tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0067-3bf4dab38c", "paper_id": "P0067", "bibkey": "Ye2025Task", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns, outperforming ReAct.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0067-53536132a8", "paper_id": "P0067", "bibkey": "Ye2025Task", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We release TME's codebase, benchmarks, and components as open-source resources, enabling researchers to develop reliable LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0067-d509f280df", "paper_id": "P0067", "bibkey": "Ye2025Task", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) falter in multi-step interactions -- often hallucinating, repeating actions, or misinterpreting user corrections -- due to reliance on linear, unstructured context.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0067-5997082b9f", "paper_id": "P0067", "bibkey": "Ye2025Task", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This fragility stems from the lack of persistent memory to track evolving goals and task dependencies, undermining trust in autonomous agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0067-5da3033ff7", "paper_id": "P0067", "bibkey": "Ye2025Task", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce the Task Memory Engine (TME), a modular memory controller that transforms existing LLMs into robust, revision-aware agents without fine-tuning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0067#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0068-4fda54211b", "paper_id": "P0068", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this Systematization of Knowledge (SoK), we present the first comprehensive analysis of IPI-centric defense frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0068-e2d4798c18", "paper_id": "P0068", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, these defenses are fragmented, lacking a unified taxonomy and comprehensive evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0068-5607dc887c", "paper_id": "P0068", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Based on these findings, we design three novel adaptive attacks that significantly improve attack success rates targeting specific frameworks, demonstrating the severity of the flaws in these defenses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#key_results[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0068-7285727f9d", "paper_id": "P0068", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM)-based agents with function-calling capabilities are increasingly deployed, but remain vulnerable to Indirect Prompt Injection (IPI) attacks that hijack their tool calls.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#summary_bullets[0]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0068-d699d2d46c", "paper_id": "P0068", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In response, numerous IPI-centric defense frameworks have emerged.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0068-c77e903fb0", "paper_id": "P0068", "bibkey": "Ji2025Taxonomy", "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, these defenses are fragmented, lacking a unified taxonomy and comprehensive evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0068#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0069-7bac399c03", "paper_id": "P0069", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Based on these findings, we present an RPA evaluation design guideline to help researchers develop more systematic and consistent evaluation methods.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0069-4fc221fdea", "paper_id": "P0069", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This paper proposes an evidence-based, actionable, and generalizable evaluation design guideline for LLM-based RPA by systematically reviewing 1,676 papers published between Jan.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0069-c1f23da764", "paper_id": "P0069", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Role-Playing Agent (RPA) is an increasingly popular type of LLM Agent that simulates human-like behaviors in a variety of tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0069-eec58391a2", "paper_id": "P0069", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Role-Playing Agent (RPA) is an increasingly popular type of LLM Agent that simulates human-like behaviors in a variety of tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0069-1ef81a9450", "paper_id": "P0069", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, evaluating RPAs is challenging due to diverse task requirements and agent designs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0069-c7d5e0496d", "paper_id": "P0069", "bibkey": "Chen2025Towards", "title": "Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper proposes an evidence-based, actionable, and generalizable evaluation design guideline for LLM-based RPA by systematically reviewing 1,676 papers published between Jan.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0069#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0070-3708cb93a9", "paper_id": "P0070", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address the challenge, we propose Tree-based Group Relative Policy Optimization (Tree-GRPO), a grouped agent RL method based on tree search, where each tree node represents the complete agent interaction step.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0070-9af6a59afb", "paper_id": "P0070", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments across 11 datasets and 3 types of QA tasks demonstrate the superiority of the proposed tree-based RL over the chain-based RL method.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0070-ae8eef51cb", "paper_id": "P0070", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in reinforcement learning (RL) have significantly enhanced the agentic capabilities of large language models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0070-f7e7ef339a", "paper_id": "P0070", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In long-term and multi-turn agent tasks, existing approaches driven solely by outcome rewards often suffer from the problem of sparse supervision.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0070-5645ea4455", "paper_id": "P0070", "bibkey": "Ji2025Tree", "title": "Tree Search for LLM Agent Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address the challenge, we propose Tree-based Group Relative Policy Optimization (Tree-GRPO), a grouped agent RL method based on tree search, where each tree node represents the complete agent interaction step.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0070#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0071-f3afc49a32", "paper_id": "P0071", "bibkey": "Fang2025Should", "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The development of large language models (LLMs) has entered in a experience-driven era, flagged by the emergence of environment feedback-driven learning via reinforcement learning and tool-using agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0071-dcb97bbb10", "paper_id": "P0071", "bibkey": "Fang2025Should", "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "(1) We first construct \\framework, a controlled framework to examine safety issues in MCP-powered agent systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0071-3cd6217549", "paper_id": "P0071", "bibkey": "Fang2025Should", "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "(2) We then conduct a series of pilot experiments to demonstrate the safety risks in MCP-powered agent systems is a real threat and its defense is not trivial.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0071-215a0ff6ef", "paper_id": "P0071", "bibkey": "Fang2025Should", "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The development of large language models (LLMs) has entered in a experience-driven era, flagged by the emergence of environment feedback-driven learning via reinforcement learning and tool-using agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0071-2053d546a5", "paper_id": "P0071", "bibkey": "Fang2025Should", "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This encourages the emergenece of model context protocol (MCP), which defines the standard on how should a LLM interact with external services, such as \\api and data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0071-8d29c7793f", "paper_id": "P0071", "bibkey": "Fang2025Should", "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, as MCP becomes the de facto standard for LLM agent systems, it also introduces new safety risks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0071#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0072-32516d8b0b", "paper_id": "P0072", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "First, we introduce the AgentErrorTaxonomy, a modular classification of failure modes spanning memory, reflection, planning, action, and system-level operations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0072-3a24449737", "paper_id": "P0072", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on AgentErrorBench show that AgentDebug achieves 24% higher all-correct accuracy and 17% higher step accuracy compared to the strongest baseline.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0072-cb04969cfe", "paper_id": "P0072", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Beyond detection, the targeted feedback generated by AgentDebug enables LLM agents to iteratively recover from failures, yielding up to 26% relative improvements in task success across ALFWorld, GAIA, and WebShop.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0072-085ad78ac8", "paper_id": "P0072", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents, which integrate planning, memory, reflection, and tool-use modules, have shown promise in solving complex, multi-step tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0072-46914a4804", "paper_id": "P0072", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Yet their sophisticated architectures amplify vulnerability to cascading failures, where a single root-cause error propagates through subsequent decisions, leading to task failure.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0072-f1dcce8f4d", "paper_id": "P0072", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current systems lack a framework that can comprehensively understand agent error in a modular and systemic way, and therefore fail to detect these errors accordingly.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0072-cfb691cbc4", "paper_id": "P0072", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We address this gap with three contributions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#summary_bullets[3]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0072-0d0d8bae59", "paper_id": "P0072", "bibkey": "Zhu2025Where", "title": "Where LLM Agents Fail and How They can Learn From Failures", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "First, we introduce the AgentErrorTaxonomy, a modular classification of failure modes spanning memory, reflection, planning, action, and system-level operations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0072#summary_bullets[4]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0073-0924bce5d8", "paper_id": "P0073", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We study LLM whistleblowing: a subset of this behavior where models disclose suspected misconduct to parties beyond the dialog boundary (e.g., regulatory agencies) without user instruction or knowledge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0073-5603d51445", "paper_id": "P0073", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across models and settings, we find that: (1) the frequency of whistleblowing varies widely across model families, (2) increasing the complexity of the task the agent is instructed to complete lowers whistleblowing tendencies, (3) nudging the agent in the system prompt to act morally substantially raises whistleblowing rates, and (4) giving the model more obvious avenues for non-whistleblowing behavior, by providing more tools and a detailed workflow to follow, decreases whistleblowing rates.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0073-3c01157d9b", "paper_id": "P0073", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We introduce an evaluation suite of diverse and realistic staged misconduct scenarios to assess agents for this behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0073-719dab689a", "paper_id": "P0073", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The deployment of Large Language Models (LLMs) as tool-using agents causes their alignment training to manifest in new ways.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0073-ef846665da", "paper_id": "P0073", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent work finds that language models can use tools in ways that contradict the interests or explicit instructions of the user.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0073-5f6d3b30a6", "paper_id": "P0073", "bibkey": "Agrawal2025Language", "title": "Why Do Language Model Agents Whistleblow?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We study LLM whistleblowing: a subset of this behavior where models disclose suspected misconduct to parties beyond the dialog boundary (e.g., regulatory agencies) without user instruction or knowledge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0073#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0074-719cee6930", "paper_id": "P0074", "bibkey": "Guo2025World", "title": "World Modelling Improves Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose dynamics modelling (DyMo), a method that augments LLMs with a state prediction capability alongside function calling during post-training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0074#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0074-5000d7b78d", "paper_id": "P0074", "bibkey": "Guo2025World", "title": "World Modelling Improves Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On the Berkeley Function Calling Leaderboard V2, DyMo improves success rates and significantly reduces hallucinations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0074#key_results[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0074-2f56af10c4", "paper_id": "P0074", "bibkey": "Guo2025World", "title": "World Modelling Improves Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tool use in stateful environments presents unique challenges for large language models (LLMs), where existing test-time compute strategies relying on repeated trials in the environment are impractical.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0074#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0074-374ffd21c6", "paper_id": "P0074", "bibkey": "Guo2025World", "title": "World Modelling Improves Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose dynamics modelling (DyMo), a method that augments LLMs with a state prediction capability alongside function calling during post-training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0074#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0074-0b69b87b2f", "paper_id": "P0074", "bibkey": "Guo2025World", "title": "World Modelling Improves Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This enables LLMs to predict the future states of their actions through an internal environment model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0074#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0075-7cfe0595ea", "paper_id": "P0075", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large language model (LLM) agents are increasingly used to interact with and execute tasks in dynamic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0075-7cd49652d3", "paper_id": "P0075", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To study this challenge, we constructed TicToc, a diverse dataset of multi-turn user-agent message trajectories across 76 scenarios, spanning dynamic environments with high, medium, and low time sensitivity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0075-aa2356b9aa", "paper_id": "P0075", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our analysis reveals that existing models display poor alignment with human temporal perception, with no model achieving a normalized alignment rate better than 65% when given time stamp information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0075-bb795af96d", "paper_id": "P0075", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents are increasingly used to interact with and execute tasks in dynamic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0075-9dc12a2780", "paper_id": "P0075", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, a critical yet overlooked limitation of these agents is that they, by default, assume a stationary context, failing to account for the real-world time elapsed between messages.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0075-b6d3fd177e", "paper_id": "P0075", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We refer to this as \"temporal blindness\".", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0075-1fbe3ed2e6", "paper_id": "P0075", "bibkey": "Cheng2025Your", "title": "Your LLM Agents are Temporally Blind: The Misalignment Between Tool Use Decisions and Human Time Perception", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "However, a critical yet overlooked limitation of these agents is that they, by default, assume a stationary context, failing to account for the real-world time elapsed between messages.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0075#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0076-cd6a2150b0", "paper_id": "P0076", "bibkey": "Zhang2024Agent", "title": "Agent-SafetyBench: Evaluating the Safety of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce Agent-SafetyBench, a comprehensive benchmark designed to evaluate the safety of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0076-e26328e18c", "paper_id": "P0076", "bibkey": "Zhang2024Agent", "title": "Agent-SafetyBench: Evaluating the Safety of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation of 16 popular LLM agents reveals a concerning result: none of the agents achieves a safety score above 60%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0076-51b52c66a1", "paper_id": "P0076", "bibkey": "Zhang2024Agent", "title": "Agent-SafetyBench: Evaluating the Safety of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Agent-SafetyBench encompasses 349 interaction environments and 2,000 test cases, evaluating 8 categories of safety risks and covering 10 common failure modes frequently encountered in unsafe interactions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0076-c2eb54b5d1", "paper_id": "P0076", "bibkey": "Zhang2024Agent", "title": "Agent-SafetyBench: Evaluating the Safety of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As large language models (LLMs) are increasingly deployed as agents, their integration into interactive environments and tool use introduce new safety challenges beyond those associated with the models themselves.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0076-4f7fc773bd", "paper_id": "P0076", "bibkey": "Zhang2024Agent", "title": "Agent-SafetyBench: Evaluating the Safety of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the absence of comprehensive benchmarks for evaluating agent safety presents a significant barrier to effective assessment and further improvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0076-7449e0af3a", "paper_id": "P0076", "bibkey": "Zhang2024Agent", "title": "Agent-SafetyBench: Evaluating the Safety of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce Agent-SafetyBench, a comprehensive benchmark designed to evaluate the safety of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0076#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0077-74863e5c7c", "paper_id": "P0077", "bibkey": "Andriushchenko2024Agentharm", "title": "AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To facilitate research on LLM agent misuse, we propose a new benchmark called AgentHarm.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0077-b181eb66ef", "paper_id": "P0077", "bibkey": "Andriushchenko2024Agentharm", "title": "AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The benchmark includes a diverse set of 110 explicitly malicious agent tasks (440 with augmentations), covering 11 harm categories including fraud, cybercrime, and harassment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0077-bbdca525a7", "paper_id": "P0077", "bibkey": "Andriushchenko2024Agentharm", "title": "AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate a range of leading LLMs, and find (1) leading LLMs are surprisingly compliant with malicious agent requests without jailbreaking, (2) simple universal jailbreak templates can be adapted to effectively jailbreak agents, and (3) these jailbreaks enable coherent and malicious multi-step agent behavior and retain model capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0077-12ee35c74b", "paper_id": "P0077", "bibkey": "Andriushchenko2024Agentharm", "title": "AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The robustness of LLMs to jailbreak attacks, where users design prompts to circumvent safety measures and misuse model capabilities, has been studied primarily for LLMs acting as simple chatbots.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0077-43a1d3922e", "paper_id": "P0077", "bibkey": "Andriushchenko2024Agentharm", "title": "AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Meanwhile, LLM agents -- which use external tools and can execute multi-stage tasks -- may pose a greater risk if misused, but their robustness remains underexplored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0077-6eed1dfe13", "paper_id": "P0077", "bibkey": "Andriushchenko2024Agentharm", "title": "AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To facilitate research on LLM agent misuse, we propose a new benchmark called AgentHarm.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0077#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0078-f37cede190", "paper_id": "P0078", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce a new research problem: Modularized LLM Agent Search (MoLAS).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0078-38a26e4777", "paper_id": "P0078", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "tooling"]}
{"evidence_id": "E-P0078-dca71a3ca8", "paper_id": "P0078", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in Large Language Models (LLMs) have led to a rapid growth of agentic systems capable of handling a wide range of complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0078-9dc7792507", "paper_id": "P0078", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, current research largely relies on manual, task-specific design, limiting their adaptability to novel tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0078-df54024240", "paper_id": "P0078", "bibkey": "Shang2024Agentsquare", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce a new research problem: Modularized LLM Agent Search (MoLAS).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0078#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0079-a8edcaf3a9", "paper_id": "P0079", "bibkey": "Chen2024Agent", "title": "An LLM Agent for Automatic Geospatial Data Analysis", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To tackle these problems, we introduce GeoAgent, a new interactive framework designed to help LLMs handle geospatial data processing more effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0079-5c782bca09", "paper_id": "P0079", "bibkey": "Chen2024Agent", "title": "An LLM Agent for Automatic Geospatial Data Analysis", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "In addition, we contribute a new benchmark specifically designed to evaluate the LLM-based approach in geospatial tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0079-1d3ae55419", "paper_id": "P0079", "bibkey": "Chen2024Agent", "title": "An LLM Agent for Automatic Geospatial Data Analysis", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "This benchmark leverages a variety of Python libraries and includes both single-turn and multi-turn tasks such as data acquisition, data analysis, and visualization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0079-8026945f34", "paper_id": "P0079", "bibkey": "Chen2024Agent", "title": "An LLM Agent for Automatic Geospatial Data Analysis", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are being used in data science code generation tasks, but they often struggle with complex sequential tasks, leading to logical errors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0079-e98481a751", "paper_id": "P0079", "bibkey": "Chen2024Agent", "title": "An LLM Agent for Automatic Geospatial Data Analysis", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Their application to geospatial data processing is particularly challenging due to difficulties in incorporating complex data structures and spatial constraints, effectively utilizing diverse function calls, and the tendency to hallucinate less-used geospatial libraries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0079-b04c45078f", "paper_id": "P0079", "bibkey": "Chen2024Agent", "title": "An LLM Agent for Automatic Geospatial Data Analysis", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To tackle these problems, we introduce GeoAgent, a new interactive framework designed to help LLMs handle geospatial data processing more effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0079#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0080-05164359d4", "paper_id": "P0080", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce AnyTool, a large language model agent designed to revolutionize the utilization of a vast array of tools in addressing user queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0080-d5c234444e", "paper_id": "P0080", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments across various datasets demonstrate the superiority of our AnyTool over strong baselines such as ToolLLM and a GPT-4 variant tailored for tool utilization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0080-e046416ff1", "paper_id": "P0080", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We utilize over 16,000 APIs from Rapid API, operating under the assumption that a subset of these APIs could potentially resolve the queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0080-ecdb125724", "paper_id": "P0080", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce AnyTool, a large language model agent designed to revolutionize the utilization of a vast array of tools in addressing user queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0080-4cd28de78f", "paper_id": "P0080", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We utilize over 16,000 APIs from Rapid API, operating under the assumption that a subset of these APIs could potentially resolve the queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0080-9cf97bc7d4", "paper_id": "P0080", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "AnyTool primarily incorporates three elements: an API retriever with a hierarchical structure, a solver aimed at resolving user queries using a selected set of API candidates, and a self-reflection mechanism, which re-activates AnyTool if the initial solution proves impracticable.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0080-28f4799b3b", "paper_id": "P0080", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "AnyTool is powered by the function calling feature of GPT-4, eliminating the need for training external modules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#summary_bullets[3]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0080-4c17bf30c9", "paper_id": "P0080", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We also revisit the evaluation protocol introduced by previous works and identify a limitation in this protocol that leads to an artificially high pass rate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#summary_bullets[4]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0080-4da9e4ae32", "paper_id": "P0080", "bibkey": "Du2024Anytool", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "We also revisit the evaluation protocol introduced by previous works and identify a limitation in this protocol that leads to an artificially high pass rate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0080#limitations[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0081-16bbf8a0a5", "paper_id": "P0081", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we develop a framework for building multi-turn RL algorithms for fine-tuning LLMs, that preserves the flexibility of existing single-turn RL methods for LLMs (e.g., proximal policy optimization), while accommodating multiple turns, long horizons, and delayed rewards effectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0081-faa3d4c9ee", "paper_id": "P0081", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Empirically, we find that ArCHer significantly improves efficiency and performance on agent tasks, attaining a sample efficiency of about 100x over existing methods, while also improving with larger model capacity (upto the 7 billion scale that we tested on).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0081-6f94b5dd68", "paper_id": "P0081", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A broad use case of large language models (LLMs) is in goal-directed decision-making tasks (or \"agent\" tasks), where an LLM needs to not just generate completions for a given prompt, but rather make intelligent decisions over a multi-turn interaction to accomplish a task (e.g., when interacting with the web, using tools, or providing customer support).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0081-d7f0bcbe26", "paper_id": "P0081", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reinforcement learning (RL) provides a general paradigm to address such agent tasks, but current RL methods for LLMs largely focus on optimizing single-turn rewards.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0081-05ea8dd729", "paper_id": "P0081", "bibkey": "Zhou2024Archer", "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By construction, most single-turn RL methods cannot endow LLMs with the ability to intelligently seek information over multiple turns, perform credit assignment, or reason about their past actions -- all of which are critical in agent tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0081#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0082-2aaf9d7fde", "paper_id": "P0082", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose EHRAgent, an LLM agent empowered with a code interface, to autonomously generate and execute code for multi-tabular reasoning within electronic health records (EHRs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0082-2a7ea60588", "paper_id": "P0082", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on three real-world multi-tabular EHR datasets show that EHRAgent outperforms the strongest baseline by up to 29.6% in success rate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0082-3fd4eb3e47", "paper_id": "P0082", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have demonstrated exceptional capabilities in planning and tool utilization as autonomous agents, but few have been developed for medical problem-solving.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0082-04a0a547bf", "paper_id": "P0082", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose EHRAgent, an LLM agent empowered with a code interface, to autonomously generate and execute code for multi-tabular reasoning within electronic health records (EHRs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0082-bb81f94c2f", "paper_id": "P0082", "bibkey": "Shi2024Ehragent", "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "First, we formulate an EHR question-answering task into a tool-use planning process, efficiently decomposing a complicated task into a sequence of manageable actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0082#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0083-8970f8df6a", "paper_id": "P0083", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose a Theory of Mind (ToM) planning technique that allows LLM agents to adapt their strategy against various adversaries using only game rules, current state, and historical context as input.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0083-95dc2415e7", "paper_id": "P0083", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large language models (LLMs) have shown success in handling simple games with imperfect information and enabling multi-agent coordination, but their ability to facilitate practical collaboration against other agents in complex, imperfect information environments, especially in a non-English environment, still needs to be explored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0083-ad27d52e29", "paper_id": "P0083", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results show that although a performance gap exists between current LLMs and state-of-the-art reinforcement learning (RL) models, LLMs demonstrate ToM capabilities in this game setting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0083-693265b6e9", "paper_id": "P0083", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have shown success in handling simple games with imperfect information and enabling multi-agent coordination, but their ability to facilitate practical collaboration against other agents in complex, imperfect information environments, especially in a non-English environment, still needs to be explored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0083-7e2c5dab0a", "paper_id": "P0083", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study investigates the applicability of knowledge acquired by open-source and API-based LLMs to sophisticated text-based games requiring agent collaboration under imperfect information, comparing their performance to established baselines using other types of agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0083-6e3d8b24b2", "paper_id": "P0083", "bibkey": "Yim2024Evaluating", "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose a Theory of Mind (ToM) planning technique that allows LLM agents to adapt their strategy against various adversaries using only game rules, current state, and historical context as input.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0083#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-110de36ea8", "paper_id": "P0084", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Trading is a highly competitive task that requires a combination of strategy, knowledge, and psychological fortitude.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-909ff3f218", "paper_id": "P0084", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "With the recent success of large language models(LLMs), it is appealing to apply the emerging intelligence of LLM agents in this competitive arena and understanding if they can outperform professional traders.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-27ff3101b9", "paper_id": "P0084", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Trading is a highly competitive task that requires a combination of strategy, knowledge, and psychological fortitude.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-c1377776f8", "paper_id": "P0084", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the recent success of large language models(LLMs), it is appealing to apply the emerging intelligence of LLM agents in this competitive arena and understanding if they can outperform professional traders.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0084-d40fcae00e", "paper_id": "P0084", "bibkey": "Ding2024Large", "title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this survey, we provide a comprehensive review of the current research on using LLMs as agents in financial trading.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0084#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0085-5d0fde2094", "paper_id": "P0085", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose LightVA, a lightweight VA framework that supports task decomposition, data analysis, and interactive exploration through human-agent collaboration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0085-51a6b462f1", "paper_id": "P0085", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We propose LightVA, a lightweight VA framework that supports task decomposition, data analysis, and interactive exploration through human-agent collaboration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0085-f4a2d7fd7a", "paper_id": "P0085", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Visual analytics (VA) requires analysts to iteratively propose analysis tasks based on observations and execute tasks by creating visualizations and interactive exploration to gain insights.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0085-ff9efa8f17", "paper_id": "P0085", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Visual analytics (VA) requires analysts to iteratively propose analysis tasks based on observations and execute tasks by creating visualizations and interactive exploration to gain insights.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0085-2882a3157e", "paper_id": "P0085", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This process demands skills in programming, data processing, and visualization tools, highlighting the need for a more intelligent, streamlined VA approach.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0085-3354309c5e", "paper_id": "P0085", "bibkey": "Zhao2024Lightva", "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have recently been developed as agents to handle various tasks with dynamic planning and tool-using capabilities, offering the potential to enhance the efficiency and versatility of VA.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0085#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0086-d9948a1de9", "paper_id": "P0086", "bibkey": "Dagan2024Plancraft", "title": "Plancraft: an evaluation dataset for planning with LLM agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present Plancraft, a multi-modal evaluation dataset for LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0086-e8a9452146", "paper_id": "P0086", "bibkey": "Dagan2024Plancraft", "title": "Plancraft: an evaluation dataset for planning with LLM agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We present Plancraft, a multi-modal evaluation dataset for LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0086-4113bdcc6b", "paper_id": "P0086", "bibkey": "Dagan2024Plancraft", "title": "Plancraft: an evaluation dataset for planning with LLM agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We benchmark both open-source and closed-source LLMs and compare their performance and efficiency to a handcrafted planner.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0086-a8a7d825eb", "paper_id": "P0086", "bibkey": "Dagan2024Plancraft", "title": "Plancraft: an evaluation dataset for planning with LLM agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present Plancraft, a multi-modal evaluation dataset for LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0086-3b4b511145", "paper_id": "P0086", "bibkey": "Dagan2024Plancraft", "title": "Plancraft: an evaluation dataset for planning with LLM agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Plancraft has both a text-only and multi-modal interface, based on the Minecraft crafting GUI.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0086-c1a2832660", "paper_id": "P0086", "bibkey": "Dagan2024Plancraft", "title": "Plancraft: an evaluation dataset for planning with LLM agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We include the Minecraft Wiki to evaluate tool use and Retrieval Augmented Generation (RAG), as well as a handcrafted planner and Oracle Retriever, to ablate the different components of a modern agent architecture.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0086#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0087-076695cd77", "paper_id": "P0087", "bibkey": "Yin2024Safeagentbench", "title": "SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we present SafeAgentBench -- the first comprehensive benchmark for safety-aware task planning of embodied LLM agents in interactive simulation environments, covering both explicit and implicit hazards.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0087-c2e8e2bb7f", "paper_id": "P0087", "bibkey": "Yin2024Safeagentbench", "title": "SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "SafeAgentBench includes: (1) an executable, diverse, and high-quality dataset of 750 tasks, rigorously curated to cover 10 potential hazards and 3 task types; (2) SafeAgentEnv, a universal embodied environment with a low-level controller, supporting multi-agent execution with 17 high-level actions for 9 state-of-the-art baselines; and (3) reliable evaluation methods from both execution and semantic perspectives.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0087-5143722344", "paper_id": "P0087", "bibkey": "Yin2024Safeagentbench", "title": "SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The most safety-conscious baseline achieves only a 10% rejection rate for detailed hazardous tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0087-44452199b4", "paper_id": "P0087", "bibkey": "Yin2024Safeagentbench", "title": "SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the integration of large language models (LLMs), embodied agents have strong capabilities to understand and plan complicated natural language instructions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0087-fe21f2492f", "paper_id": "P0087", "bibkey": "Yin2024Safeagentbench", "title": "SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, a foreseeable issue is that those embodied agents can also flawlessly execute some hazardous tasks, potentially causing damages in the real world.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0087-4751450149", "paper_id": "P0087", "bibkey": "Yin2024Safeagentbench", "title": "SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing benchmarks predominantly overlook critical safety risks, focusing solely on planning performance, while a few evaluate LLMs' safety awareness only on non-interactive image-text data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0087-353f8210d1", "paper_id": "P0087", "bibkey": "Yin2024Safeagentbench", "title": "SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Moreover, simply replacing the LLM driving the agent does not lead to notable improvements in safety awareness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0087#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0088-c42cf712f3", "paper_id": "P0088", "bibkey": "Huang2024Understanding", "title": "Understanding the planning of LLM agents: A survey", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "As Large Language Models (LLMs) have shown significant intelligence, the progress to leverage LLMs as planning modules of autonomous agents has attracted more attention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0088-ba968b6b32", "paper_id": "P0088", "bibkey": "Huang2024Understanding", "title": "Understanding the planning of LLM agents: A survey", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Comprehensive analyses are conducted for each direction, and further challenges for the field of research are discussed.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0088-4f5a103381", "paper_id": "P0088", "bibkey": "Huang2024Understanding", "title": "Understanding the planning of LLM agents: A survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As Large Language Models (LLMs) have shown significant intelligence, the progress to leverage LLMs as planning modules of autonomous agents has attracted more attention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0088-eb9c9a3564", "paper_id": "P0088", "bibkey": "Huang2024Understanding", "title": "Understanding the planning of LLM agents: A survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This survey provides the first systematic view of LLM-based agents planning, covering recent works aiming to improve planning ability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0088-124466c3d9", "paper_id": "P0088", "bibkey": "Huang2024Understanding", "title": "Understanding the planning of LLM agents: A survey", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We provide a taxonomy of existing works on LLM-Agent planning, which can be categorized into Task Decomposition, Plan Selection, External Module, Reflection and Memory.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0088#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0089-a68163e536", "paper_id": "P0089", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of LLM-based autonomous agents from a holistic perspective.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0089-7902b25b48", "paper_id": "P0089", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0089-2cd82bbe79", "paper_id": "P0089", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0089-4e8c5a07c9", "paper_id": "P0089", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Autonomous agents have long been a prominent research focus in both academic and industry communities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0089-735b270082", "paper_id": "P0089", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0089-70b43a61f3", "paper_id": "P0089", "bibkey": "Wang2023Survey", "title": "A Survey on Large Language Model based Autonomous Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0089#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0090-afe68b52b5", "paper_id": "P0090", "bibkey": "Balaji2026Beyond", "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we introduce JourneyBench, a benchmark designed to assess policy-aware agents in customer support.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0090-d36da098af", "paper_id": "P0090", "bibkey": "Balaji2026Beyond", "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across 703 conversations in three domains, we show that DPA significantly boosts policy adherence, even allowing smaller models like GPT-4o-mini to outperform more capable ones like GPT-4o.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0090-a4ae2708e4", "paper_id": "P0090", "bibkey": "Balaji2026Beyond", "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0090-9090b0d1ea", "paper_id": "P0090", "bibkey": "Balaji2026Beyond", "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional customer support systems, such as Interactive Voice Response (IVR), rely on rigid scripts and lack the flexibility required for handling complex, policy-driven tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0090-d30f1529ac", "paper_id": "P0090", "bibkey": "Balaji2026Beyond", "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While large language model (LLM) agents offer a promising alternative, evaluating their ability to act in accordance with business rules and real-world support workflows remains an open challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0090-bdb67b980a", "paper_id": "P0090", "bibkey": "Balaji2026Beyond", "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0090-2e32363eff", "paper_id": "P0090", "bibkey": "Balaji2026Beyond", "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence", "year": 2026, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "While large language model (LLM) agents offer a promising alternative, evaluating their ability to act in accordance with business rules and real-world support workflows remains an open challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0090#limitations[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0091-b8e39e84d0", "paper_id": "P0091", "bibkey": "Song2026Envscaler", "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose EnvScaler, an automated framework for scalable tool-interaction environments via programmatic synthesis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0091-87a6cb3814", "paper_id": "P0091", "bibkey": "Song2026Envscaler", "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "With EnvScaler, we synthesize 191 environments and about 7K scenarios, and apply them to Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) for Qwen3 series models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0091-f1a25e82c1", "paper_id": "P0091", "bibkey": "Song2026Envscaler", "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "First, SkelBuilder constructs diverse environment skeletons through topic mining, logic modeling, and quality evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0091-7657af8284", "paper_id": "P0091", "bibkey": "Song2026Envscaler", "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are expected to be trained to act as agents in various real-world environments, but this process relies on rich and varied tool-interaction sandboxes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#summary_bullets[0]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0091-3dc68778a4", "paper_id": "P0091", "bibkey": "Song2026Envscaler", "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, access to real systems is often restricted; LLM-simulated environments are prone to hallucinations and inconsistencies; and manually built sandboxes are hard to scale.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0091-3cdfa39cc2", "paper_id": "P0091", "bibkey": "Song2026Envscaler", "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose EnvScaler, an automated framework for scalable tool-interaction environments via programmatic synthesis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0091#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0092-df142ee3e5", "paper_id": "P0092", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To dismantle this trilemma, we introduce EvoRoute, a self-evolving model routing paradigm that transcends static, pre-defined model assignments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0092-60cc0d458f", "paper_id": "P0092", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\\%$ and latency by over $70\\%$.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0092-d550725f5f", "paper_id": "P0092", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, this success is shadowed by prohibitive economic costs and severe latency, exposing a critical, yet underexplored, trade-off.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0092-f5b4e3fb6c", "paper_id": "P0092", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Complex agentic AI systems, powered by a coordinated ensemble of Large Language Models (LLMs), tool and memory modules, have demonstrated remarkable capabilities on intricate, multi-turn tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0092-229019434c", "paper_id": "P0092", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, this success is shadowed by prohibitive economic costs and severe latency, exposing a critical, yet underexplored, trade-off.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0092-6b1976d308", "paper_id": "P0092", "bibkey": "Zhang2026Evoroute", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We formalize this challenge as the \\textbf{Agent System Trilemma}: the inherent tension among achieving state-of-the-art performance, minimizing monetary cost, and ensuring rapid task completion.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0092#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0093-7d9c488c76", "paper_id": "P0093", "bibkey": "Hao2026From", "title": "From Failure to Mastery: Generating Hard Samples for Tool-use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To bridge this gap, we introduce HardGen, an automatic agentic pipeline designed to generate hard tool-use training samples with verifiable reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0093-7bed142d5c", "paper_id": "P0093", "bibkey": "Hao2026From", "title": "From Failure to Mastery: Generating Hard Samples for Tool-use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive evaluations demonstrate that a 4B parameter model trained with our curated dataset achieves superior performance compared to several leading open-source and closed-source competitors (e.g., GPT-5.2, Gemini-3-Pro and Claude-Opus-4.5).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0093-ed4427964c", "paper_id": "P0093", "bibkey": "Hao2026From", "title": "From Failure to Mastery: Generating Hard Samples for Tool-use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, the advanced tools and hard queries enable the generation of verifiable complex Chain-of-Thought (CoT), with a closed-loop evaluation feedback steering the continuous refinement of the process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0093-f00a187154", "paper_id": "P0093", "bibkey": "Hao2026From", "title": "From Failure to Mastery: Generating Hard Samples for Tool-use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The advancement of LLM agents with tool-use capabilities requires diverse and complex training corpora.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0093-c5dd6ade6c", "paper_id": "P0093", "bibkey": "Hao2026From", "title": "From Failure to Mastery: Generating Hard Samples for Tool-use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing data generation methods, which predominantly follow a paradigm of random sampling and shallow generation, often yield simple and homogeneous trajectories that fail to capture complex, implicit logical dependencies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0093-5f72d6dfad", "paper_id": "P0093", "bibkey": "Hao2026From", "title": "From Failure to Mastery: Generating Hard Samples for Tool-use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To bridge this gap, we introduce HardGen, an automatic agentic pipeline designed to generate hard tool-use training samples with verifiable reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0093#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0094-cfd50d8597", "paper_id": "P0094", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "Existing change detection methods often lack the versatility to handle diverse real-world queries and the intelligence for comprehensive analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0094-a8702dce10", "paper_id": "P0094", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "The agent was evaluated on a curated dataset of 140 questions categorized by real-world scenarios, encompassing various question types (e.g., Size, Class, Number) and complexities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0094-deabf13faf", "paper_id": "P0094", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "ChangeGPT, especially with a GPT-4-turbo backend, demonstrated superior performance, achieving a 90.71 % Match rate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0094-c4ff905064", "paper_id": "P0094", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing change detection methods often lack the versatility to handle diverse real-world queries and the intelligence for comprehensive analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0094-0afbc558b7", "paper_id": "P0094", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents a general agent framework, integrating Large Language Models (LLM) with vision foundation models to form ChangeGPT.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0094-24d3c2a530", "paper_id": "P0094", "bibkey": "Xiao2026Agent", "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A hierarchical structure is employed to mitigate hallucination.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0094#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0095-607a67cf41", "paper_id": "P0095", "bibkey": "Zhang2026Maxs", "title": "MAXS: Meta-Adaptive Exploration with LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these two issues, we propose meta-adaptive exploration with LLM agents https://github.com/exoskeletonzj/MAXS, a meta-adaptive reasoning framework based on LLM Agents that flexibly integrates tool execution and reasoning planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0095-6d8c7a2ee9", "paper_id": "P0095", "bibkey": "Zhang2026Maxs", "title": "MAXS: Meta-Adaptive Exploration with LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We conduct extensive empirical studies across three base models (MiMo-VL-7B, Qwen2.5-VL-7B, Qwen2.5-VL-32B) and five datasets, demonstrating that MAXS consistently outperforms existing methods in both performance and inference efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0095-6224623a18", "paper_id": "P0095", "bibkey": "Zhang2026Maxs", "title": "MAXS: Meta-Adaptive Exploration with LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) Agents exhibit inherent reasoning abilities through the collaboration of multiple tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0095-aa9d142037", "paper_id": "P0095", "bibkey": "Zhang2026Maxs", "title": "MAXS: Meta-Adaptive Exploration with LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, during agent inference, existing methods often suffer from (i) locally myopic generation, due to the absence of lookahead, and (ii) trajectory instability, where minor early errors can escalate into divergent reasoning paths.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0095-b8b3947292", "paper_id": "P0095", "bibkey": "Zhang2026Maxs", "title": "MAXS: Meta-Adaptive Exploration with LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These issues make it difficult to balance global effectiveness and computational efficiency.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0095#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0096-c1613fdafa", "paper_id": "P0096", "bibkey": "Khanzadeh2026Project", "title": "Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce \\textbf{Project Ariadne}, a novel XAI framework that utilizes Structural Causal Models (SCMs) and counterfactual logic to audit the causal integrity of agentic reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0096-ee64e89c13", "paper_id": "P0096", "bibkey": "Khanzadeh2026Project", "title": "Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our empirical evaluation of state-of-the-art models reveals a persistent \\textit{Faithfulness Gap}.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0096-a8d3ff1947", "paper_id": "P0096", "bibkey": "Khanzadeh2026Project", "title": "Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We define and detect a widespread failure mode termed \\textbf{Causal Decoupling}, where agents exhibit a violation density ($$) of up to $0.77$ in factual and scientific domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0096-d2ace9f330", "paper_id": "P0096", "bibkey": "Khanzadeh2026Project", "title": "Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As Large Language Model (LLM) agents are increasingly tasked with high-stakes autonomous decision-making, the transparency of their reasoning processes has become a critical safety concern.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0096-ab16b64440", "paper_id": "P0096", "bibkey": "Khanzadeh2026Project", "title": "Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While \\textit{Chain-of-Thought} (CoT) prompting allows agents to generate human-readable reasoning traces, it remains unclear whether these traces are \\textbf{faithful} generative drivers of the model's output or merely \\textbf{post-hoc rationalizations}.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0096-d1cf2058ea", "paper_id": "P0096", "bibkey": "Khanzadeh2026Project", "title": "Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce \\textbf{Project Ariadne}, a novel XAI framework that utilizes Structural Causal Models (SCMs) and counterfactual logic to audit the causal integrity of agentic reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0096#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0097-f435bd682b", "paper_id": "P0097", "bibkey": "Gupta2026Reliabilitybench", "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce \\textbf{ReliabilityBench}, a benchmark for evaluating agent reliability across three dimensions: (i) consistency under repeated execution using $\\mathrm{pass}^k$, (ii) robustness to semantically equivalent task perturbations at intensity $$, and (iii) fault tolerance under controlled tool/API failures at intensity $$.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0097-36c7bf5169", "paper_id": "P0097", "bibkey": "Gupta2026Reliabilitybench", "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Perturbations alone reduce success from 96.9% at $=0$ to 88.1% at $=0.2$.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0097-880a7b0d43", "paper_id": "P0097", "bibkey": "Gupta2026Reliabilitybench", "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate two models (Gemini 2.0 Flash, GPT-4o) and two agent architectures (ReAct, Reflexion) across four domains (scheduling, travel, customer support, e-commerce) over 1,280 episodes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0097-634206a060", "paper_id": "P0097", "bibkey": "Gupta2026Reliabilitybench", "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing benchmarks for tool-using LLM agents primarily report single-run success rates and miss reliability properties required in production.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0097-123ca89bec", "paper_id": "P0097", "bibkey": "Gupta2026Reliabilitybench", "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce \\textbf{ReliabilityBench}, a benchmark for evaluating agent reliability across three dimensions: (i) consistency under repeated execution using $\\mathrm{pass}^k$, (ii) robustness to semantically equivalent task perturbations at intensity $$, and (iii) fault tolerance under controlled tool/API failures at intensity $$.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0097-0ff4f19b04", "paper_id": "P0097", "bibkey": "Gupta2026Reliabilitybench", "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ReliabilityBench contributes a unified reliability surface $R(k,,)$, \\textit{action metamorphic relations} that define correctness via end-state equivalence rather than text similarity, and a chaos-engineering-style fault injection framework (timeouts, rate limits, partial responses, schema drift).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0097#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0098-5904542217", "paper_id": "P0098", "bibkey": "Xuan2026Confidence", "title": "The Confidence Dichotomy: Analyzing and Mitigating Miscalibration in Tool-Use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To robustly improve calibration across tool types, we propose a reinforcement learning (RL) fine-tuning framework that jointly optimizes task accuracy and calibration, supported by a holistic benchmark of reward designs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0098-c2fdc5ad72", "paper_id": "P0098", "bibkey": "Xuan2026Confidence", "title": "The Confidence Dichotomy: Analyzing and Mitigating Miscalibration in Tool-Use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "To robustly improve calibration across tool types, we propose a reinforcement learning (RL) fine-tuning framework that jointly optimizes task accuracy and calibration, supported by a holistic benchmark of reward designs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0098-2ab3544a05", "paper_id": "P0098", "bibkey": "Xuan2026Confidence", "title": "The Confidence Dichotomy: Analyzing and Mitigating Miscalibration in Tool-Use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Autonomous agents based on large language models (LLMs) are rapidly evolving to handle multi-turn tasks, but ensuring their trustworthiness remains a critical challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0098-bfc5e63e1c", "paper_id": "P0098", "bibkey": "Xuan2026Confidence", "title": "The Confidence Dichotomy: Analyzing and Mitigating Miscalibration in Tool-Use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A fundamental pillar of this trustworthiness is calibration, which refers to an agent's ability to express confidence that reliably reflects its actual performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0098-7171068931", "paper_id": "P0098", "bibkey": "Xuan2026Confidence", "title": "The Confidence Dichotomy: Analyzing and Mitigating Miscalibration in Tool-Use Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While calibration is well-established for static models, its dynamics in tool-integrated agentic workflows remain underexplored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0098#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0099-2a5fc497d0", "paper_id": "P0099", "bibkey": "Kiruluta2025Novel", "title": "A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose a hybrid architecture that integrates decision tree-based symbolic reasoning with the generative capabilities of large language models (LLMs) within a coordinated multi-agent framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0099-a666552417", "paper_id": "P0099", "bibkey": "Kiruluta2025Novel", "title": "A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On GSM8k, it achieves +5.3\\% accuracy gains in multistep mathematical problems via symbolic augmentation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0099-c7423180cf", "paper_id": "P0099", "bibkey": "Kiruluta2025Novel", "title": "A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On \\textit{ARC}, it boosts abstraction accuracy by +6.0\\% through integration of symbolic oracles.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0099-178473e844", "paper_id": "P0099", "bibkey": "Kiruluta2025Novel", "title": "A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose a hybrid architecture that integrates decision tree-based symbolic reasoning with the generative capabilities of large language models (LLMs) within a coordinated multi-agent framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0099-a1a6f9479c", "paper_id": "P0099", "bibkey": "Kiruluta2025Novel", "title": "A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike prior approaches that loosely couple symbolic and neural modules, our design embeds decision trees and random forests as callable oracles within a unified reasoning system.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0099-4b4ea26f38", "paper_id": "P0099", "bibkey": "Kiruluta2025Novel", "title": "A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Tree-based modules enable interpretable rule inference and causal logic, while LLM agents handle abductive reasoning, generalization, and interactive planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0099#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0100-bd9b2efeac", "paper_id": "P0100", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Information technology has profoundly altered the way humans interact with information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0100-698effea8f", "paper_id": "P0100", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Recent advances in large language models (LLMs) have demonstrated capabilities that surpass human performance in various language-related tasks and exhibit general understanding, reasoning, and decision-making abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0100-8587764f76", "paper_id": "P0100", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Information technology has profoundly altered the way humans interact with information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0100-24e201f889", "paper_id": "P0100", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The vast amount of content created, shared, and disseminated online has made it increasingly difficult to access relevant information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0100-61fda627ce", "paper_id": "P0100", "bibkey": "Zhang2025Survey", "title": "A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Over the past two decades, recommender systems and search (collectively referred to as information retrieval systems) have evolved significantly to address these challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0100#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0101-b0f9bdaa65", "paper_id": "P0101", "bibkey": "Lidayan2025Abbel", "title": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a general framework for LLM agents to maintain concise contexts through multi-step interaction: Acting through Belief Bottlenecks Expressed in Language (ABBEL), and methods to further improve ABBEL agents with RL post-training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0101-0af79eac07", "paper_id": "P0101", "bibkey": "Lidayan2025Abbel", "title": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments demonstrate the ability of RL to improve ABBEL's performance beyond the full context setting, while using less memory than contemporaneous approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#key_results[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0101-41f7c44c90", "paper_id": "P0101", "bibkey": "Lidayan2025Abbel", "title": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As the length of sequential decision-making tasks increases, it becomes computationally impractical to keep full interaction histories in context.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0101-06f0c88925", "paper_id": "P0101", "bibkey": "Lidayan2025Abbel", "title": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce a general framework for LLM agents to maintain concise contexts through multi-step interaction: Acting through Belief Bottlenecks Expressed in Language (ABBEL), and methods to further improve ABBEL agents with RL post-training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0101-de918dd756", "paper_id": "P0101", "bibkey": "Lidayan2025Abbel", "title": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ABBEL replaces long multi-step interaction history by a belief state, i.e., a natural language summary of what has been discovered about task-relevant unknowns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0101#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0102-720f073ef2", "paper_id": "P0102", "bibkey": "Luo2025Agrail", "title": "AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose AGrail, a lifelong agent guardrail to enhance LLM agent safety, which features adaptive safety check generation, effective safety check optimization, and tool compatibility and flexibility.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#method"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0102-d90ba36b89", "paper_id": "P0102", "bibkey": "Luo2025Agrail", "title": "AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments demonstrate that AGrail not only achieves strong performance against task-specific and system risks but also exhibits transferability across different LLM agents' tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0102-5b0bc84f31", "paper_id": "P0102", "bibkey": "Luo2025Agrail", "title": "AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid advancements in Large Language Models (LLMs) have enabled their deployment as autonomous agents for handling complex tasks in dynamic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0102-5c5d3f4391", "paper_id": "P0102", "bibkey": "Luo2025Agrail", "title": "AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These LLMs demonstrate strong problem-solving capabilities and adaptability to multifaceted scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0102-a8d810dc96", "paper_id": "P0102", "bibkey": "Luo2025Agrail", "title": "AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, their use as agents also introduces significant risks, including task-specific risks, which are identified by the agent administrator based on the specific task requirements and constraints, and systemic risks, which stem from vulnerabilities in their design or interactions, potentially compromising confidentiality, integrity, or availability (CIA) of information and triggering security risks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0102#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0103-906e74833d", "paper_id": "P0103", "bibkey": "Zhang2025Agentracer", "title": "AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we propose AgenTracer, the first automated framework for annotating failed multi-agent trajectories via counterfactual replay and programmed fault injection, producing the curated dataset TracerTraj.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0103-a483d09feb", "paper_id": "P0103", "bibkey": "Zhang2025Agentracer", "title": "AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Current state-of-the-art reasoning LLMs, however, remain strikingly inadequate for this challenge, with accuracy generally below 10%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0103-e0d3505101", "paper_id": "P0103", "bibkey": "Zhang2025Agentracer", "title": "AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On the Who&When benchmark, AgenTracer-8B outperforms giant proprietary LLMs like Gemini-2.5-Pro and Claude-4-Sonnet by up to 18.18%, setting a new standard in LLM agentic failure attribution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0103-563fa31a1f", "paper_id": "P0103", "bibkey": "Zhang2025Agentracer", "title": "AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM)-based agentic systems, often comprising multiple models, complex tool invocations, and orchestration protocols, substantially outperform monolithic agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0103-bbe4bb56a9", "paper_id": "P0103", "bibkey": "Zhang2025Agentracer", "title": "AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Yet this very sophistication amplifies their fragility, making them more prone to system failure.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0103-dd319367b6", "paper_id": "P0103", "bibkey": "Zhang2025Agentracer", "title": "AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Pinpointing the specific agent or step responsible for an error within long execution traces defines the task of agentic system failure attribution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0103#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0104-232d105c9e", "paper_id": "P0104", "bibkey": "Sha2025Agent", "title": "Agent Safety Alignment via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose the first unified safety-alignment framework for tool-using agents, enabling models to handle both channels of threat via structured reasoning and sandboxed reinforcement learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#method"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0104-20fed7f11c", "paper_id": "P0104", "bibkey": "Sha2025Agent", "title": "Agent Safety Alignment via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through extensive evaluations on public and self-built benchmarks, including Agent SafetyBench, InjecAgent, and BFCL, we demonstrate that our safety-aligned agents significantly improve resistance to security threats while preserving strong utility on benign tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0104-eab3e7c194", "paper_id": "P0104", "bibkey": "Sha2025Agent", "title": "Agent Safety Alignment via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The emergence of autonomous Large Language Model (LLM) agents capable of tool usage has introduced new safety risks that go beyond traditional conversational misuse.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0104-27bffbbc82", "paper_id": "P0104", "bibkey": "Sha2025Agent", "title": "Agent Safety Alignment via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These agents, empowered to execute external functions, are vulnerable to both user-initiated threats (e.g., adversarial prompts) and tool-initiated threats (e.g., malicious outputs from compromised tools).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#summary_bullets[1]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0104-80d595c4ca", "paper_id": "P0104", "bibkey": "Sha2025Agent", "title": "Agent Safety Alignment via Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose the first unified safety-alignment framework for tool-using agents, enabling models to handle both channels of threat via structured reasoning and sandboxed reinforcement learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0104#summary_bullets[2]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0105-006ad9b321", "paper_id": "P0105", "bibkey": "Loffredo2025Agent", "title": "Agent-Enhanced Large Language Models for Researching Political Institutions", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To demonstrate the potential of this approach, we introduce CongressRA, an LLM agent designed to support scholars studying the U.S.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0105-21c9e7ad44", "paper_id": "P0105", "bibkey": "Loffredo2025Agent", "title": "Agent-Enhanced Large Language Models for Researching Political Institutions", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through this example, we highlight how LLM agents can reduce the costs of replicating, testing, and extending empirical research using the domain-specific data that drives the study of political institutions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0105-1897573eec", "paper_id": "P0105", "bibkey": "Loffredo2025Agent", "title": "Agent-Enhanced Large Language Models for Researching Political Institutions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The applications of Large Language Models (LLMs) in political science are rapidly expanding.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0105-9d164d3888", "paper_id": "P0105", "bibkey": "Loffredo2025Agent", "title": "Agent-Enhanced Large Language Models for Researching Political Institutions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper demonstrates how LLMs, when augmented with predefined functions and specialized tools, can serve as dynamic agents capable of streamlining tasks such as data collection, preprocessing, and analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0105-07a916953d", "paper_id": "P0105", "bibkey": "Loffredo2025Agent", "title": "Agent-Enhanced Large Language Models for Researching Political Institutions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Central to this approach is agentic retrieval-augmented generation (Agentic RAG), which equips LLMs with action-calling capabilities for interaction with external knowledge bases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0105#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0106-01a0700f8e", "paper_id": "P0106", "bibkey": "Cui2025Agentdns", "title": "AgentDNS: A Root Domain Naming System for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose AgentDNS, a root domain naming and service discovery system designed to enable LLM agents to autonomously discover, resolve, and securely invoke third-party agent and tool services across organizational and technological boundaries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0106-ba22992f5e", "paper_id": "P0106", "bibkey": "Cui2025Agentdns", "title": "AgentDNS: A Root Domain Naming System for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The source code will be published on https://github.com/agentdns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0106-2c001052e7", "paper_id": "P0106", "bibkey": "Cui2025Agentdns", "title": "AgentDNS: A Root Domain Naming System for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid evolution of Large Language Model (LLM) agents has highlighted critical challenges in cross-vendor service discovery, interoperability, and communication.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0106-5cf6222d40", "paper_id": "P0106", "bibkey": "Cui2025Agentdns", "title": "AgentDNS: A Root Domain Naming System for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing protocols like model context protocol and agent-to-agent protocol have made significant strides in standardizing interoperability between agents and tools, as well as communication among multi-agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0106-c2ae36f609", "paper_id": "P0106", "bibkey": "Cui2025Agentdns", "title": "AgentDNS: A Root Domain Naming System for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, there remains a lack of standardized protocols and solutions for service discovery across different agent and tool vendors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0106#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0107-c7fa05bd3b", "paper_id": "P0107", "bibkey": "Wang2025Agentspec", "title": "AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we propose AgentSpec, a lightweight domain-specific language for specifying and enforcing runtime constraints on LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0107-8e4049bab9", "paper_id": "P0107", "bibkey": "Wang2025Agentspec", "title": "AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation shows that AgentSpec successfully prevents unsafe executions in over 90% of code agent cases, eliminates all hazardous actions in embodied agent tasks, and enforces 100% compliance by autonomous vehicles (AVs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0107-481ecd5602", "paper_id": "P0107", "bibkey": "Wang2025Agentspec", "title": "AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation shows that the rules generated by OpenAI o1 achieve a precision of 95.56% and recall of 70.96% for embodied agents, successfully identify 87.26% of the risky code, and prevent AVs from breaking laws in 5 out of 8 scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0107-ac2760ef94", "paper_id": "P0107", "bibkey": "Wang2025Agentspec", "title": "AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agents built on LLMs are increasingly deployed across diverse domains, automating complex decision-making and task execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0107-96f777935a", "paper_id": "P0107", "bibkey": "Wang2025Agentspec", "title": "AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, their autonomy introduces safety risks, including security vulnerabilities, legal violations, and unintended harmful actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0107-c406dbc7ef", "paper_id": "P0107", "bibkey": "Wang2025Agentspec", "title": "AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing mitigation methods, such as model-based safeguards and early enforcement strategies, fall short in robustness, interpretability, and adaptability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0107#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0108-e5ba1b6a3e", "paper_id": "P0108", "bibkey": "Tang2025Autoagent", "title": "AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this challenge, we introduce AutoAgent-a Fully-Automated and highly Self-Developing framework that enables users to create and deploy LLM agents through Natural Language Alone.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0108-7236a8fe5b", "paper_id": "P0108", "bibkey": "Tang2025Autoagent", "title": "AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, these frameworks predominantly serve developers with extensive technical expertise - a significant limitation considering that only 0.03 % of the global population possesses the necessary programming skills.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0108-75761a8be6", "paper_id": "P0108", "bibkey": "Tang2025Autoagent", "title": "AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Comprehensive evaluations on the GAIA benchmark demonstrate AutoAgent's effectiveness in generalist multi-agent tasks, surpassing existing state-of-the-art methods.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0108-5d91323d7b", "paper_id": "P0108", "bibkey": "Tang2025Autoagent", "title": "AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) Agents have demonstrated remarkable capabilities in task automation and intelligent decision-making, driving the widespread adoption of agent development frameworks such as LangChain and AutoGen.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0108-96469f3026", "paper_id": "P0108", "bibkey": "Tang2025Autoagent", "title": "AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, these frameworks predominantly serve developers with extensive technical expertise - a significant limitation considering that only 0.03 % of the global population possesses the necessary programming skills.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0108-cbd097326b", "paper_id": "P0108", "bibkey": "Tang2025Autoagent", "title": "AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This stark accessibility gap raises a fundamental question: Can we enable everyone, regardless of technical background, to build their own LLM agents using natural language alone?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0108-6807e2ff98", "paper_id": "P0108", "bibkey": "Tang2025Autoagent", "title": "AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "However, these frameworks predominantly serve developers with extensive technical expertise - a significant limitation considering that only 0.03 % of the global population possesses the necessary programming skills.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0108#limitations[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0109-682a68866c", "paper_id": "P0109", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose AutoTool, a novel graph-based framework that bypasses repeated LLM inference by exploiting a key empirical observation: tool usage inertia - the tendency of tool invocations to follow predictable sequential patterns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0109-d3344c79dc", "paper_id": "P0109", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments across diverse agent tasks demonstrate that AutoTool reduces inference costs by up to 30% while maintaining competitive task completion rates, offering a practical and scalable enhancement for inference-heavy frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0109-3f62ff9f3a", "paper_id": "P0109", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents have emerged as powerful tools for automating complex tasks by leveraging the reasoning and decision-making abilities of LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0109-7674242cfe", "paper_id": "P0109", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, a major bottleneck in current agent frameworks lies in the high inference cost of tool selection, especially in approaches like ReAct that repeatedly invoke the LLM to determine which tool to use at each step.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0109-7a8afd3d87", "paper_id": "P0109", "bibkey": "Jia2025Autotool", "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we propose AutoTool, a novel graph-based framework that bypasses repeated LLM inference by exploiting a key empirical observation: tool usage inertia - the tendency of tool invocations to follow predictable sequential patterns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0109#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0110-4b1ab22641", "paper_id": "P0110", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Second, we propose GradleFixer, an LLM agent with domain-specific tools for inspecting and manipulating the Gradle build environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0110-858f86ac9c", "paper_id": "P0110", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To address this gap, we first introduce AndroidBuildBench, a benchmark of 1,019 build failures curated from the commit histories of 43 open-source Android projects.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0110-852023ec1e", "paper_id": "P0110", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "GradleFixer achieves a resolve rate of 81.4% (pass@1), significantly outperforming a state-of-the-art coding agent that relies on a general-purpose shell.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0110-f3d4ecad3b", "paper_id": "P0110", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Android is the largest mobile platform, yet automatically building applications remains a practical challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0110-cb5f194b20", "paper_id": "P0110", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While Large Language Models (LLMs) show promise for code repair, their use for fixing Android build errors remains underexplored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0110-7686ac87f9", "paper_id": "P0110", "bibkey": "Son2025Automating", "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, we first introduce AndroidBuildBench, a benchmark of 1,019 build failures curated from the commit histories of 43 open-source Android projects.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0110#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0111-0a6bcfbb77", "paper_id": "P0111", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this study, we propose an innovative pipeline utilizing Large Language Model (LLM) agents to automate data-driven modeling and analysis, with a particular emphasis on regression tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0111-5da77482d9", "paper_id": "P0111", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We validate our approach using a critical heat flux (CHF) prediction benchmark, involving approximately 25,000 experimental data points from the OECD/NEA benchmark dataset.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0111-c2a5689efc", "paper_id": "P0111", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Results indicate that our LLM-agent-developed model surpasses traditional CHF lookup tables and delivers predictive accuracy and UQ on par with state-of-the-art Bayesian optimized deep neural network models developed by human experts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0111-5a5e822b1f", "paper_id": "P0111", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Modern engineering increasingly relies on vast datasets generated by experiments and simulations, driving a growing demand for efficient, reliable, and broadly applicable modeling strategies.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0111-c68a10fc29", "paper_id": "P0111", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "There is also heightened interest in developing data-driven approaches, particularly neural network models, for effective prediction and analysis of scientific datasets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0111-4ac701e24b", "paper_id": "P0111", "bibkey": "Liu2025Automating", "title": "Automating Data-Driven Modeling and Analysis for Engineering Applications using Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional data-driven methods frequently involve extensive manual intervention, limiting their ability to scale effectively and generalize to diverse applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0111#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0112-4a0bbc45f7", "paper_id": "P0112", "bibkey": "Liang2025Automating", "title": "Automating Structural Engineering Workflows with Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce $\\textbf{MASSE}$, the first Multi-Agent System for Structural Engineering, effectively integrating large language model (LLM)-based agents with real-world engineering workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0112-ee541a7864", "paper_id": "P0112", "bibkey": "Liang2025Automating", "title": "Automating Structural Engineering Workflows with Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "MASSE enables immediate deployment in professional environments, and our comprehensive validation on real-world case studies demonstrates that it can reduce expert workload from approximately two hours to mere minutes, while enhancing both reliability and accuracy in practical engineering scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0112-0c6a94f89e", "paper_id": "P0112", "bibkey": "Liang2025Automating", "title": "Automating Structural Engineering Workflows with Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce $\\textbf{MASSE}$, the first Multi-Agent System for Structural Engineering, effectively integrating large language model (LLM)-based agents with real-world engineering workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0112-54b5c0b56d", "paper_id": "P0112", "bibkey": "Liang2025Automating", "title": "Automating Structural Engineering Workflows with Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Structural engineering is a fundamental yet traditionally stagnant domain, with core workflows remaining largely unchanged for decades despite its substantial economic impact and global market size.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0112-c6549fdf06", "paper_id": "P0112", "bibkey": "Liang2025Automating", "title": "Automating Structural Engineering Workflows with Large Language Model Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in LLMs have significantly enhanced their ability to perform complex reasoning, long-horizon planning, and precise tool utilization -- capabilities well aligned with structural engineering tasks such as interpreting design codes, executing load calculations, and verifying structural capacities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0112#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0113-d3d02219ae", "paper_id": "P0113", "bibkey": "Das2025Beyond", "title": "Beyond Jailbreaking: Auditing Contextual Privacy in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "LLM agents have begun to appear as personal assistants, customer service bots, and clinical aides.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0113-6a0e70c48e", "paper_id": "P0113", "bibkey": "Das2025Beyond", "title": "Beyond Jailbreaking: Auditing Contextual Privacy in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In addition to introducing CMPL as a diagnostic tool, the paper delivers (1) an auditing procedure grounded in quantifiable risk metrics and (2) an open benchmark for evaluation of conversational privacy across agent implementations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0113-19bc1ede8a", "paper_id": "P0113", "bibkey": "Das2025Beyond", "title": "Beyond Jailbreaking: Auditing Contextual Privacy in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation on diverse domains, data modalities, and safety configurations demonstrates the auditing framework's ability to reveal privacy risks that are not deterred by existing single-turn defenses, along with an in-depth longitudinal study of the temporal dynamics of leakage, strategies adopted by adaptive adversaries, and the evolution of adversarial beliefs about sensitive targets.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0113-8ab27583b6", "paper_id": "P0113", "bibkey": "Das2025Beyond", "title": "Beyond Jailbreaking: Auditing Contextual Privacy in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM agents have begun to appear as personal assistants, customer service bots, and clinical aides.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0113-31ebe6c706", "paper_id": "P0113", "bibkey": "Das2025Beyond", "title": "Beyond Jailbreaking: Auditing Contextual Privacy in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While these applications deliver substantial operational benefits, they also require continuous access to sensitive data, which increases the likelihood of unauthorized disclosures.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0113-4724096acb", "paper_id": "P0113", "bibkey": "Das2025Beyond", "title": "Beyond Jailbreaking: Auditing Contextual Privacy in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Moreover, these disclosures go beyond mere explicit disclosure, leaving open avenues for gradual manipulation or sidechannel information leakage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0113#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0114-dfbc6da47c", "paper_id": "P0114", "bibkey": "Wu2025Agents", "title": "Can LLM Agents Really Debate? A Controlled Study of Multi-Agent Debate in Logical Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Multi-agent debate (MAD) has recently emerged as a promising framework for improving the reasoning performance of large language models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0114-e31a1bbba7", "paper_id": "P0114", "bibkey": "Wu2025Agents", "title": "Can LLM Agents Really Debate? A Controlled Study of Multi-Agent Debate in Logical Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We address this question through a controlled study using the Knight--Knave--Spy logic puzzle, which enables precise, step-wise evaluation of debate outcomes and processes under verifiable ground truth.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0114-d67ee14383", "paper_id": "P0114", "bibkey": "Wu2025Agents", "title": "Can LLM Agents Really Debate? A Controlled Study of Multi-Agent Debate in Logical Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results show that intrinsic reasoning strength and group diversity are the dominant drivers of debate success, while structural parameters such as order or confidence visibility offer limited gains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0114-e94d5c7617", "paper_id": "P0114", "bibkey": "Wu2025Agents", "title": "Can LLM Agents Really Debate? A Controlled Study of Multi-Agent Debate in Logical Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Multi-agent debate (MAD) has recently emerged as a promising framework for improving the reasoning performance of large language models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0114-9f8a50578a", "paper_id": "P0114", "bibkey": "Wu2025Agents", "title": "Can LLM Agents Really Debate? A Controlled Study of Multi-Agent Debate in Logical Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Yet, whether LLM agents can genuinely engage in deliberative reasoning, beyond simple ensembling or majority voting, remains unclear.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0114-6435c008e2", "paper_id": "P0114", "bibkey": "Wu2025Agents", "title": "Can LLM Agents Really Debate? A Controlled Study of Multi-Agent Debate in Logical Reasoning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We address this question through a controlled study using the Knight--Knave--Spy logic puzzle, which enables precise, step-wise evaluation of debate outcomes and processes under verifiable ground truth.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0114#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0115-4702cb10b5", "paper_id": "P0115", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we present a novel diagnostic framework that integrates Knowledge Graphs (KGs) and Large Language Models (LLMs) to support system diagnostics in high-reliability systems such as nuclear power plants.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0115-f10376c14d", "paper_id": "P0115", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "A case study on an auxiliary feedwater system demonstrated the framework's effectiveness, with over 90% accuracy in key elements and consistent tool and argument extraction, supporting its use in safety-critical diagnostics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0115-434724f85d", "paper_id": "P0115", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we present a novel diagnostic framework that integrates Knowledge Graphs (KGs) and Large Language Models (LLMs) to support system diagnostics in high-reliability systems such as nuclear power plants.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0115-67e23ab509", "paper_id": "P0115", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional diagnostic modeling struggles when systems become too complex, making functional modeling a more attractive approach.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0115-ffc84de302", "paper_id": "P0115", "bibkey": "Marandi2025Complex", "title": "Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our approach introduces a diagnostic framework grounded in the functional modeling principles of the Dynamic Master Logic (DML) model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0115#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0116-fd66fc4e0e", "paper_id": "P0116", "bibkey": "Si2025Conformal", "title": "Conformal Constrained Policy Optimization for Cost-Effective LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose a novel strategy where we combine multiple LLM models with varying cost/accuracy tradeoffs in an agentic manner, where models and tools are run in sequence as determined by an orchestration model to minimize cost subject to a user-specified level of reliability; this constraint is formalized using conformal prediction to provide guarantees.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0116-f375765194", "paper_id": "P0116", "bibkey": "Si2025Conformal", "title": "Conformal Constrained Policy Optimization for Cost-Effective LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across two multi-hop question answering benchmarks, CCPO achieves up to a 30% cost reduction compared to other cost-aware baselines and LLM-guided methods without compromising reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0116-ad03ef523d", "paper_id": "P0116", "bibkey": "Si2025Conformal", "title": "Conformal Constrained Policy Optimization for Cost-Effective LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We propose a novel strategy where we combine multiple LLM models with varying cost/accuracy tradeoffs in an agentic manner, where models and tools are run in sequence as determined by an orchestration model to minimize cost subject to a user-specified level of reliability; this constraint is formalized using conformal prediction to provide guarantees.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#key_results[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0116-6f7ab116a2", "paper_id": "P0116", "bibkey": "Si2025Conformal", "title": "Conformal Constrained Policy Optimization for Cost-Effective LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While large language models (LLMs) have recently made tremendous progress towards solving challenging AI problems, they have done so at increasingly steep computational and API costs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0116-dab6bc0165", "paper_id": "P0116", "bibkey": "Si2025Conformal", "title": "Conformal Constrained Policy Optimization for Cost-Effective LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose a novel strategy where we combine multiple LLM models with varying cost/accuracy tradeoffs in an agentic manner, where models and tools are run in sequence as determined by an orchestration model to minimize cost subject to a user-specified level of reliability; this constraint is formalized using conformal prediction to provide guarantees.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0116-a8097cb883", "paper_id": "P0116", "bibkey": "Si2025Conformal", "title": "Conformal Constrained Policy Optimization for Cost-Effective LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To solve this problem, we propose Conformal Constrained Policy Optimization (CCPO), a training paradigm that integrates constrained policy optimization with off-policy reinforcement learning and recent advances in online conformal prediction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0116#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0117-c96bf29a87", "paper_id": "P0117", "bibkey": "Yang2025Contextagent", "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce ContextAgent, the first context-aware proactive agent that incorporates extensive sensory contexts surrounding humans to enhance the proactivity of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0117-0fc82f8849", "paper_id": "P0117", "bibkey": "Yang2025Contextagent", "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To evaluate this new task, we curate ContextAgentBench, the first benchmark for evaluating context-aware proactive LLM agents, covering 1,000 samples across nine daily scenarios and twenty tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0117-4c78c05170", "paper_id": "P0117", "bibkey": "Yang2025Contextagent", "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on ContextAgentBench show that ContextAgent outperforms baselines by achieving up to 8.5% and 6.0% higher accuracy in proactive predictions and tool calling, respectively.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0117-8cbe115035", "paper_id": "P0117", "bibkey": "Yang2025Contextagent", "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in Large Language Models (LLMs) have propelled intelligent agents from reactive responses to proactive support.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0117-953adb6bcd", "paper_id": "P0117", "bibkey": "Yang2025Contextagent", "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While promising, existing proactive agents either rely exclusively on observations from enclosed environments (e.g., desktop UIs) with direct LLM inference or employ rule-based proactive notifications, leading to suboptimal user intent understanding and limited functionality for proactive service.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0117-9ab24789e9", "paper_id": "P0117", "bibkey": "Yang2025Contextagent", "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce ContextAgent, the first context-aware proactive agent that incorporates extensive sensory contexts surrounding humans to enhance the proactivity of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0117#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0118-b3d97b8b63", "paper_id": "P0118", "bibkey": "Liu2025Costbench", "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To bridge this gap, we introduce CostBench, a scalable, cost-centric benchmark designed to evaluate agents' economic reasoning and replanning abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0118-32d61c8fae", "paper_id": "P0118", "bibkey": "Liu2025Costbench", "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and performance further dropping by around 40% under dynamic conditions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0118-17133c2d5e", "paper_id": "P0118", "bibkey": "Liu2025Costbench", "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To bridge this gap, we introduce CostBench, a scalable, cost-centric benchmark designed to evaluate agents' economic reasoning and replanning abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0118-8ccf29128f", "paper_id": "P0118", "bibkey": "Liu2025Costbench", "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current evaluations of Large Language Model (LLM) agents primarily emphasize task completion, often overlooking resource efficiency and adaptability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0118-77980b824c", "paper_id": "P0118", "bibkey": "Liu2025Costbench", "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This neglects a crucial capability: agents' ability to devise and adjust cost-optimal plans in response to changing environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0118-a2a7dcee0c", "paper_id": "P0118", "bibkey": "Liu2025Costbench", "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To bridge this gap, we introduce CostBench, a scalable, cost-centric benchmark designed to evaluate agents' economic reasoning and replanning abilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0118#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0119-0b34b55332", "paper_id": "P0119", "bibkey": "Fumero2025Cybersleuth", "title": "CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose CyberSleuth, an autonomous agent that processes packet-level traces and application logs to identify the targeted service, the exploited vulnerability (CVE), and attack success.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0119-c8c4670812", "paper_id": "P0119", "bibkey": "Fumero2025Cybersleuth", "title": "CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We benchmark four agent architectures and six LLM backends on 20 incident scenarios of increasing complexity, identifying CyberSleuth as the best-performing design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0119-18b5f42fc9", "paper_id": "P0119", "bibkey": "Fumero2025Cybersleuth", "title": "CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "At last, we conduct a human study with 22 experts, which rated the reports of CyberSleuth as complete, useful, and coherent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0119-cab22cf105", "paper_id": "P0119", "bibkey": "Fumero2025Cybersleuth", "title": "CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents are powerful tools for automating complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0119-db091c226f", "paper_id": "P0119", "bibkey": "Fumero2025Cybersleuth", "title": "CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In cybersecurity, researchers have primarily explored their use in red-team operations such as vulnerability discovery and penetration tests.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0119-618309ef93", "paper_id": "P0119", "bibkey": "Fumero2025Cybersleuth", "title": "CyberSleuth: Autonomous Blue-Team LLM Agent for Web Attack Forensics", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Defensive uses for incident response and forensics have received comparatively less attention and remain at an early stage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0119#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0120-8e4e40b7d6", "paper_id": "P0120", "bibkey": "Kamath2025Enforcing", "title": "Enforcing Temporal Constraints for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present Agent-C, a novel framework that provides run-time guarantees ensuring LLM agents adhere to formal temporal safety properties.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0120-2718dbc45e", "paper_id": "P0120", "bibkey": "Kamath2025Enforcing", "title": "Enforcing Temporal Constraints for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results demonstrate that Agent-C achieves perfect safety (100% conformance, 0% harm), while improving task utility compared to state-of-the-art guardrails and unrestricted agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "security"]}
{"evidence_id": "E-P0120-874e2a995f", "paper_id": "P0120", "bibkey": "Kamath2025Enforcing", "title": "Enforcing Temporal Constraints for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On SoTA closed-source models, Agent-C improves conformance (77.4% to 100% for Claude Sonnet 4.5 and 83.7% to 100% for GPT-5), while simultaneously increasing utility (71.8% to 75.2% and 66.1% to 70.6%, respectively), representing a new SoTA frontier for reliable agentic reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0120-5292633a71", "paper_id": "P0120", "bibkey": "Kamath2025Enforcing", "title": "Enforcing Temporal Constraints for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM-based agents are deployed in safety-critical applications, yet current guardrail systems fail to prevent violations of temporal safety policies, requirements that govern the ordering and sequencing of agent actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0120-fd36ea6083", "paper_id": "P0120", "bibkey": "Kamath2025Enforcing", "title": "Enforcing Temporal Constraints for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "For instance, agents may access sensitive data before authenticating users or process refunds to unauthorized payment methods, violations that require reasoning about sequences of action rather than an individual action.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0120-a4ce035641", "paper_id": "P0120", "bibkey": "Kamath2025Enforcing", "title": "Enforcing Temporal Constraints for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing guardrails rely on imprecise natural language instructions or post-hoc monitoring, and provide no formal guarantees that agents will satisfy temporal constraints.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0120#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0121-015495fe2a", "paper_id": "P0121", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present FEABench, a benchmark to evaluate the ability of large language models (LLMs) and LLM agents to simulate and solve physics, mathematics and engineering problems using finite element analysis (FEA).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0121-e4ac5005b3", "paper_id": "P0121", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our best performing strategy generates executable API calls 88% of the time.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0121-4334d22ac9", "paper_id": "P0121", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We present FEABench, a benchmark to evaluate the ability of large language models (LLMs) and LLM agents to simulate and solve physics, mathematics and engineering problems using finite element analysis (FEA).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0121-fc7bc9b610", "paper_id": "P0121", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Building precise simulations of the real world and invoking numerical solvers to answer quantitative problems is an essential requirement in engineering and science.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0121-13181b0530", "paper_id": "P0121", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present FEABench, a benchmark to evaluate the ability of large language models (LLMs) and LLM agents to simulate and solve physics, mathematics and engineering problems using finite element analysis (FEA).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0121-607af02a49", "paper_id": "P0121", "bibkey": "Mudur2025Feabench", "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce a comprehensive evaluation scheme to investigate the ability of LLMs to solve these problems end-to-end by reasoning over natural language problem descriptions and operating COMSOL Multiphysics$^\\circledR$, an FEA software, to compute the answers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0121#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0122-5a6b3c7f0e", "paper_id": "P0122", "bibkey": "Lee2025Fhir", "title": "FHIR-AgentBench: Benchmarking LLM Agents for Realistic Interoperable EHR Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To bridge this gap, we introduce FHIR-AgentBench, a benchmark that grounds 2,931 real-world clinical questions in the HL7 FHIR standard.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#method"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0122-9fa363c996", "paper_id": "P0122", "bibkey": "Lee2025Fhir", "title": "FHIR-AgentBench: Benchmarking LLM Agents for Realistic Interoperable EHR Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To bridge this gap, we introduce FHIR-AgentBench, a benchmark that grounds 2,931 real-world clinical questions in the HL7 FHIR standard.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0122-3dab154ae9", "paper_id": "P0122", "bibkey": "Lee2025Fhir", "title": "FHIR-AgentBench: Benchmarking LLM Agents for Realistic Interoperable EHR Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, existing benchmarks have lagged behind this transition, lacking the realism needed to evaluate recent LLMs on interoperable clinical data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0122-a9385dc573", "paper_id": "P0122", "bibkey": "Lee2025Fhir", "title": "FHIR-AgentBench: Benchmarking LLM Agents for Realistic Interoperable EHR Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The recent shift toward the Health Level Seven Fast Healthcare Interoperability Resources (HL7 FHIR) standard opens a new frontier for clinical AI, demanding LLM agents to navigate complex, resource-based data models instead of conventional structured health data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0122-8c816265e0", "paper_id": "P0122", "bibkey": "Lee2025Fhir", "title": "FHIR-AgentBench: Benchmarking LLM Agents for Realistic Interoperable EHR Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing benchmarks have lagged behind this transition, lacking the realism needed to evaluate recent LLMs on interoperable clinical data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0122-cc56bcf495", "paper_id": "P0122", "bibkey": "Lee2025Fhir", "title": "FHIR-AgentBench: Benchmarking LLM Agents for Realistic Interoperable EHR Question Answering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To bridge this gap, we introduce FHIR-AgentBench, a benchmark that grounds 2,931 real-world clinical questions in the HL7 FHIR standard.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0122#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0123-9fe27a3f8a", "paper_id": "P0123", "bibkey": "Xi2025From", "title": "From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present T2L-Agent (Trace-to-Line Agent), a project-level, end-to-end framework that plans its own analysis and progressively narrows scope from modules to exact vulnerable lines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0123-92405eeb57", "paper_id": "P0123", "bibkey": "Xi2025From", "title": "From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To benchmark line-level vulnerability discovery, we introduce T2L-ARVO, a diverse, expert-verified 50-case benchmark spanning five crash families and real-world projects.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0123-55b2ce8cfe", "paper_id": "P0123", "bibkey": "Xi2025From", "title": "From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On T2L-ARVO, T2L-Agent achieves up to 58.0% detection and 54.8% line-level localization, substantially outperforming baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0123-19656cbfd8", "paper_id": "P0123", "bibkey": "Xi2025From", "title": "From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models show promise for vulnerability discovery, yet prevailing methods inspect code in isolation, struggle with long contexts, and focus on coarse function or file level detections which offers limited actionable guidance to engineers who need precise line-level localization and targeted patches in real-world software development.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0123-9c51073b72", "paper_id": "P0123", "bibkey": "Xi2025From", "title": "From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present T2L-Agent (Trace-to-Line Agent), a project-level, end-to-end framework that plans its own analysis and progressively narrows scope from modules to exact vulnerable lines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0123-9e3f089a24", "paper_id": "P0123", "bibkey": "Xi2025From", "title": "From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "T2L-Agent couples multi-round feedback with an Agentic Trace Analyzer (ATA) that fuses run-time evidence such as crash points, stack traces, and coverage deltas with AST-based code chunking, enabling iterative refinement beyond single pass predictions and translating symptoms into actionable, line-level diagnoses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0123#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0124-6e14603586", "paper_id": "P0124", "bibkey": "Khoee2025Gatelens", "title": "GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release Analytics", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Ensuring reliable software release decisions is critical in safety-critical domains such as automotive manufacturing.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0124-8afa74a630", "paper_id": "P0124", "bibkey": "Khoee2025Gatelens", "title": "GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release Analytics", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Industrial deployment shows over 80% reduction in analysis time while maintaining high accuracy across test result interpretation, impact assessment, and release candidate evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0124-6664c6cecd", "paper_id": "P0124", "bibkey": "Khoee2025Gatelens", "title": "GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release Analytics", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Release validation relies on large tabular datasets, yet manual analysis is slow, costly, and error-prone.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0124-82ac29475d", "paper_id": "P0124", "bibkey": "Khoee2025Gatelens", "title": "GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release Analytics", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Ensuring reliable software release decisions is critical in safety-critical domains such as automotive manufacturing.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0124-a134af008f", "paper_id": "P0124", "bibkey": "Khoee2025Gatelens", "title": "GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release Analytics", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Release validation relies on large tabular datasets, yet manual analysis is slow, costly, and error-prone.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0124-69cdea386e", "paper_id": "P0124", "bibkey": "Khoee2025Gatelens", "title": "GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release Analytics", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While Large Language Models (LLMs) offer promising automation potential, they face challenges in analytical reasoning, structured data handling, and ambiguity resolution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0124#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0125-2c3b7eae80", "paper_id": "P0125", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose Group-in-Group Policy Optimization (GiGPO), a novel RL algorithm that achieves fine-grained credit assignment for LLM agents while preserving the appealing properties of group-based RL: critic-free, low memory, and stable convergence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0125-4b027dfb27", "paper_id": "P0125", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate GiGPO on challenging agent benchmarks, including ALFWorld and WebShop, as well as tool-integrated reasoning on search-augmented QA tasks, using Qwen2.5-1.5B/3B/7B-Instruct.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0125-af024eea6f", "paper_id": "P0125", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Crucially, GiGPO delivers fine-grained per-step credit signals, achieves performance gains of > 12% on ALFWorld and > 9% on WebShop over GRPO, and obtains superior performance on QA tasks (42.1% on 3B and 47.2% on 7B): all while maintaining the same GPU memory overhead, identical LLM rollout, and incurring little to no additional time cost.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0125-dccace20fe", "paper_id": "P0125", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in group-based reinforcement learning (RL) have driven frontier large language models (LLMs) in single-turn tasks like mathematical reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0125-4c1e30b52c", "paper_id": "P0125", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, their scalability to multi-turn LLM agent training remains limited.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0125-930a33b2d7", "paper_id": "P0125", "bibkey": "Feng2025Group", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike static tasks, agent-environment interactions unfold over many steps and often yield sparse or delayed rewards, making credit assignment across individual steps significantly more challenging.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0125#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0126-1a30481cd1", "paper_id": "P0126", "bibkey": "Nakano2025Guided", "title": "Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose a guided reasoning pipeline for penetration testing LLM agents that incorporates a deterministic task tree built from the MITRE ATT&CK Matrix, a proven penetration testing kll chain, to constrain the LLM's reaoning process to explicitly defined tactics, techniques, and procedures.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0126-99359acdd7", "paper_id": "P0126", "bibkey": "Nakano2025Guided", "title": "Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Comparatively, the state-of-the-art LLM penetration testing tool using self-guided reasoning completed only 13.5\\%, 16.5\\%, and 75.7\\% of subtasks and required 86.2\\%, 118.7\\%, and 205.9\\% more model queries.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0126-741891e300", "paper_id": "P0126", "bibkey": "Nakano2025Guided", "title": "Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To evaluate our approach, we built an automated penetration testing LLM agent using three LLMs (Llama-3-8B, Gemini-1.5, and GPT-4) and applied it to navigate 10 HackTheBox cybersecurity exercises with 103 discrete subtasks representing real-world cyberattack scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0126-c23f7907d7", "paper_id": "P0126", "bibkey": "Nakano2025Guided", "title": "Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in Large Language Models (LLMs) have driven interest in automating cybersecurity penetration testing workflows, offering the promise of faster and more consistent vulnerability assessment for enterprise systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0126-1e44a192ee", "paper_id": "P0126", "bibkey": "Nakano2025Guided", "title": "Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing LLM agents for penetration testing primarily rely on self-guided reasoning, which can produce inaccurate or hallucinated procedural steps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0126-32a672f9c8", "paper_id": "P0126", "bibkey": "Nakano2025Guided", "title": "Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As a result, the LLM agent may undertake unproductive actions, such as exploiting unused software libraries or generating cyclical responses that repeat prior tactics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0126#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0127-a454663d8b", "paper_id": "P0127", "bibkey": "Li2025Hmcf", "title": "HMCF: A Human-in-the-loop Multi-Robot Collaboration Framework Based on Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To overcome these limitations, we propose a Human-in-the-loop Multi-Robot Collaboration Framework (HMCF) powered by large language models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0127-956727bca0", "paper_id": "P0127", "bibkey": "Li2025Hmcf", "title": "HMCF: A Human-in-the-loop Multi-Robot Collaboration Framework Based on Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Simulation results show that our framework outperforms state-of-the-art task planning methods, achieving higher task success rates with an improvement of 4.76%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0127-d24ed5d453", "paper_id": "P0127", "bibkey": "Li2025Hmcf", "title": "HMCF: A Human-in-the-loop Multi-Robot Collaboration Framework Based on Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To overcome these limitations, we propose a Human-in-the-loop Multi-Robot Collaboration Framework (HMCF) powered by large language models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0127-68b358a654", "paper_id": "P0127", "bibkey": "Li2025Hmcf", "title": "HMCF: A Human-in-the-loop Multi-Robot Collaboration Framework Based on Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Rapid advancements in artificial intelligence (AI) have enabled robots to performcomplex tasks autonomously with increasing precision.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0127-ee6967e48d", "paper_id": "P0127", "bibkey": "Li2025Hmcf", "title": "HMCF: A Human-in-the-loop Multi-Robot Collaboration Framework Based on Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, multi-robot systems (MRSs) face challenges in generalization, heterogeneity, and safety, especially when scaling to large-scale deployments like disaster response.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0127-683a4e1f9e", "paper_id": "P0127", "bibkey": "Li2025Hmcf", "title": "HMCF: A Human-in-the-loop Multi-Robot Collaboration Framework Based on Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional approaches often lack generalization, requiring extensive engineering for new tasks and scenarios, and struggle with managing diverse robots.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0127-a0f79cf9cd", "paper_id": "P0127", "bibkey": "Li2025Hmcf", "title": "HMCF: A Human-in-the-loop Multi-Robot Collaboration Framework Based on Large Language Models", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To overcome these limitations, we propose a Human-in-the-loop Multi-Robot Collaboration Framework (HMCF) powered by large language models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0127#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0128-a12f02050b", "paper_id": "P0128", "bibkey": "An2025Ipiguard", "title": "IPIGuard: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To prevent malicious tool invocations at the source, we propose a novel defensive task execution paradigm, called IPIGuard, which models the agents' task execution process as a traversal over a planned Tool Dependency Graph (TDG).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0128-262069936d", "paper_id": "P0128", "bibkey": "An2025Ipiguard", "title": "IPIGuard: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on the AgentDojo benchmark show that IPIGuard achieves a superior balance between effectiveness and robustness, paving the way for the development of safer agentic systems in dynamic environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0128-8b54706b17", "paper_id": "P0128", "bibkey": "An2025Ipiguard", "title": "IPIGuard: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents are widely deployed in real-world applications, where they leverage tools to retrieve and manipulate external data for complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0128-f6aa7e086b", "paper_id": "P0128", "bibkey": "An2025Ipiguard", "title": "IPIGuard: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, when interacting with untrusted data sources (e.g., fetching information from public websites), tool responses may contain injected instructions that covertly influence agent behaviors and lead to malicious outcomes, a threat referred to as Indirect Prompt Injection (IPI).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#summary_bullets[1]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0128-972ea58675", "paper_id": "P0128", "bibkey": "An2025Ipiguard", "title": "IPIGuard: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing defenses typically rely on advanced prompting strategies or auxiliary detection models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0128#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0129-5d10b75809", "paper_id": "P0129", "bibkey": "Zhong2025Impossiblebench", "title": "ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To quantify, study, and mitigate such behavior, we introduce ImpossibleBench, a benchmark framework that systematically measures LLM agents' propensity to exploit test cases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0129-60c18f38e8", "paper_id": "P0129", "bibkey": "Zhong2025Impossiblebench", "title": "ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We demonstrate its utility for: (1) studying model behaviors, revealing more fine-grained details of cheating behaviors from simple test modification to complex operator overloading; (2) context engineering, showing how prompt, test access and feedback loop affect cheating rates; and (3) developing monitoring tools, providing a testbed with verified deceptive solutions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0129-abcb20315d", "paper_id": "P0129", "bibkey": "Zhong2025Impossiblebench", "title": "ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Such behavior undermines both the validity of benchmark results and the reliability of real-world LLM coding assistant deployments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0129-e3d5ea5793", "paper_id": "P0129", "bibkey": "Zhong2025Impossiblebench", "title": "ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The tendency to find and exploit \"shortcuts\" to complete tasks poses significant risks for reliable assessment and deployment of large language models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0129-87312da73e", "paper_id": "P0129", "bibkey": "Zhong2025Impossiblebench", "title": "ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "For example, an LLM agent with access to unit tests may delete failing tests rather than fix the underlying bug.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0129-e0002b9dff", "paper_id": "P0129", "bibkey": "Zhong2025Impossiblebench", "title": "ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Such behavior undermines both the validity of benchmark results and the reliability of real-world LLM coding assistant deployments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0129#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0130-d241f8e5e6", "paper_id": "P0130", "bibkey": "Sarukkai2025Context", "title": "In-Context Distillation with Self-Consistency Cascades: A Simple, Training-Free Way to Reduce LLM Agent Costs", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose a simple method for reducing LLM agent inference costs without incurring the development friction costs associated with LLM fine-tuning (long training cycles, optimization hyperparameter tweaking loops) or manual prompt engineering (laborious trial and error).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0130-e7c6cee652", "paper_id": "P0130", "bibkey": "Sarukkai2025Context", "title": "In-Context Distillation with Self-Consistency Cascades: A Simple, Training-Free Way to Reduce LLM Agent Costs", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On the multi-step embodied reasoning benchmark ALFWorld, our method matches teacher-level accuracy at $\\textbf{2.5$\\times$ lower cost}$, reducing per-episode costs from \\$0.059 to \\$0.024.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0130-cfef96abfa", "paper_id": "P0130", "bibkey": "Sarukkai2025Context", "title": "In-Context Distillation with Self-Consistency Cascades: A Simple, Training-Free Way to Reduce LLM Agent Costs", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On AppWorld, a complex agent benchmark requiring multi-step API workflows, we shift the Pareto frontier by achieving a $\\textbf{2$\\times$ cost reduction}$ at iso-accuracy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0130-a2e57ffcf2", "paper_id": "P0130", "bibkey": "Sarukkai2025Context", "title": "In-Context Distillation with Self-Consistency Cascades: A Simple, Training-Free Way to Reduce LLM Agent Costs", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The world currently has an abundance of ideas for how to use new LLM agents, and developers seek to rapidly prototype and test new agentic designs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0130-de0078fbf7", "paper_id": "P0130", "bibkey": "Sarukkai2025Context", "title": "In-Context Distillation with Self-Consistency Cascades: A Simple, Training-Free Way to Reduce LLM Agent Costs", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, executing agents at scale using high-capacity LLMs incurs high inference costs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0130-f6fd11b04e", "paper_id": "P0130", "bibkey": "Sarukkai2025Context", "title": "In-Context Distillation with Self-Consistency Cascades: A Simple, Training-Free Way to Reduce LLM Agent Costs", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose a simple method for reducing LLM agent inference costs without incurring the development friction costs associated with LLM fine-tuning (long training cycles, optimization hyperparameter tweaking loops) or manual prompt engineering (laborious trial and error).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0130#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0131-084781d78b", "paper_id": "P0131", "bibkey": "Chojnacki2025Interpretable", "title": "Interpretable Risk Mitigation in LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a strategy-modification method-independent of both the game and the prompt-by steering the residual stream with interpretable features extracted from a sparse autoencoder latent space.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0131-18142ed870", "paper_id": "P0131", "bibkey": "Chojnacki2025Interpretable", "title": "Interpretable Risk Mitigation in LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Steering with the good-faith negotiation feature lowers the average defection probability by 28 percentage points.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0131-176b400a6e", "paper_id": "P0131", "bibkey": "Chojnacki2025Interpretable", "title": "Interpretable Risk Mitigation in LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we hypothesise that game-theoretic evaluation of LLM agents, combined with representation-steering alignment, can generalise to real-world applications on end-user devices and embodied platforms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0131-cfd5b5a71f", "paper_id": "P0131", "bibkey": "Chojnacki2025Interpretable", "title": "Interpretable Risk Mitigation in LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Autonomous agents powered by large language models (LLMs) enable novel use cases in domains where responsible action is increasingly important.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0131-b437a18f88", "paper_id": "P0131", "bibkey": "Chojnacki2025Interpretable", "title": "Interpretable Risk Mitigation in LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Yet the inherent unpredictability of LLMs raises safety concerns about agent reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0131-7fe65acb56", "paper_id": "P0131", "bibkey": "Chojnacki2025Interpretable", "title": "Interpretable Risk Mitigation in LLM Agent Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we explore agent behaviour in a toy, game-theoretic environment based on a variation of the Iterated Prisoner's Dilemma.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0131#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0132-3cf27c863c", "paper_id": "P0132", "bibkey": "Sun2025Agent", "title": "LLM Agent Meets Agentic AI: Can LLM Agents Simulate Customers to Evaluate Agentic-AI-based Shopping Assistants?", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Agentic AI is emerging, capable of executing tasks through natural language, such as Copilot for coding or Amazon Rufus for shopping.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0132-dda37dfb29", "paper_id": "P0132", "bibkey": "Sun2025Agent", "title": "LLM Agent Meets Agentic AI: Can LLM Agents Simulate Customers to Evaluate Agentic-AI-based Shopping Assistants?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "In this paper, we recruited 40 human participants to shop with Amazon Rufus, collected their personas, interaction traces, and UX feedback, and then created digital twins to repeat the task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0132-027093d5f5", "paper_id": "P0132", "bibkey": "Sun2025Agent", "title": "LLM Agent Meets Agentic AI: Can LLM Agents Simulate Customers to Evaluate Agentic-AI-based Shopping Assistants?", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluating these systems is challenging, as their rapid evolution outpaces traditional human evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0132-f2562d8548", "paper_id": "P0132", "bibkey": "Sun2025Agent", "title": "LLM Agent Meets Agentic AI: Can LLM Agents Simulate Customers to Evaluate Agentic-AI-based Shopping Assistants?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agentic AI is emerging, capable of executing tasks through natural language, such as Copilot for coding or Amazon Rufus for shopping.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0132-9ed0fdae11", "paper_id": "P0132", "bibkey": "Sun2025Agent", "title": "LLM Agent Meets Agentic AI: Can LLM Agents Simulate Customers to Evaluate Agentic-AI-based Shopping Assistants?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Evaluating these systems is challenging, as their rapid evolution outpaces traditional human evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0132-9823b13843", "paper_id": "P0132", "bibkey": "Sun2025Agent", "title": "LLM Agent Meets Agentic AI: Can LLM Agents Simulate Customers to Evaluate Agentic-AI-based Shopping Assistants?", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Researchers have proposed LLM Agents to simulate participants as digital twins, but it remains unclear to what extent a digital twin can represent a specific customer in multi-turn interaction with an agentic AI system.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0132#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0133-e8a109886f", "paper_id": "P0133", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Models (LLMs) have garnered significant attention for several years now.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0133-597439cd1d", "paper_id": "P0133", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We then apply the same strategy to show that LLM agents can explore, discover, and exploit diverse chemical interactions in an advanced Atomic Layer Processing reactor simulation using intentionally limited probe capabilities without explicit instructions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0133-38aee336c0", "paper_id": "P0133", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have garnered significant attention for several years now.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0133-359710b235", "paper_id": "P0133", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, their use as independently reasoning agents has been proposed.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0133-65afe8ae85", "paper_id": "P0133", "bibkey": "Werbrouck2025Agents", "title": "LLM Agents for Knowledge Discovery in Atomic Layer Processing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we test the potential of such agents for knowledge discovery in materials science.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0133#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0134-5d648afcf0", "paper_id": "P0134", "bibkey": "Zhang2025Language", "title": "Language Model Agents Under Attack: A Cross Model-Benchmark of Profit-Seeking Behaviors in Customer Service", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present a cross-domain benchmark of profit-seeking direct prompt injection in customer-service interactions, spanning 10 service domains and 100 realistic attack scripts grouped into five technique families.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#method"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0134-ef16c639a5", "paper_id": "P0134", "bibkey": "Zhang2025Language", "title": "Language Model Agents Under Attack: A Cross Model-Benchmark of Profit-Seeking Behaviors in Customer Service", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We present a cross-domain benchmark of profit-seeking direct prompt injection in customer-service interactions, spanning 10 service domains and 100 realistic attack scripts grouped into five technique families.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0134-5da47d7d45", "paper_id": "P0134", "bibkey": "Zhang2025Language", "title": "Language Model Agents Under Attack: A Cross Model-Benchmark of Profit-Seeking Behaviors in Customer Service", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We release data and evaluation code to support reproducible auditing and to inform the design of oversight and recovery workflows for trustworthy, human centered agent interfaces.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0134-20cd1d424f", "paper_id": "P0134", "bibkey": "Zhang2025Language", "title": "Language Model Agents Under Attack: A Cross Model-Benchmark of Profit-Seeking Behaviors in Customer Service", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Customer-service LLM agents increasingly make policy-bound decisions (refunds, rebooking, billing disputes), but the same ``helpful'' interaction style can be exploited: a small fraction of users can induce unauthorized concessions, shifting costs to others and eroding trust in agentic workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0134-9f6b31d56a", "paper_id": "P0134", "bibkey": "Zhang2025Language", "title": "Language Model Agents Under Attack: A Cross Model-Benchmark of Profit-Seeking Behaviors in Customer Service", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present a cross-domain benchmark of profit-seeking direct prompt injection in customer-service interactions, spanning 10 service domains and 100 realistic attack scripts grouped into five technique families.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0134-5b21c4d23e", "paper_id": "P0134", "bibkey": "Zhang2025Language", "title": "Language Model Agents Under Attack: A Cross Model-Benchmark of Profit-Seeking Behaviors in Customer Service", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Across five widely used models under a unified rubric with uncertainty reporting, attacks are highly domain-dependent (airline support is most exploitable) and technique-dependent (payload splitting is most consistently effective).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0134#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0135-5aef4ede27", "paper_id": "P0135", "bibkey": "Zhang2025Large", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Here we introduce a novel generative AI-based method for generating structural drawings employing a large language model (LLM) agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0135-897bcc2f50", "paper_id": "P0135", "bibkey": "Zhang2025Large", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. In civil engineering, structural drawings serve as the main communication tool between architects, engineers, and builders to avoid conflicts, act as legal documentation, and provide a reference for future maintenance or evaluation needs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0135-79064ef6b3", "paper_id": "P0135", "bibkey": "Zhang2025Large", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The method incorporates a retrieval-augmented generation (RAG) technique using externally-sourced facts to enhance the accuracy and reliability of the language model.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0135-654bd71ff0", "paper_id": "P0135", "bibkey": "Zhang2025Large", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. In civil engineering, structural drawings serve as the main communication tool between architects, engineers, and builders to avoid conflicts, act as legal documentation, and provide a reference for future maintenance or evaluation needs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0135-d5a9c93165", "paper_id": "P0135", "bibkey": "Zhang2025Large", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "They are often organized using key elements such as title/subtitle blocks, scales, plan views, elevation view, sections, and detailed sections, which are annotated with standardized symbols and line types for interpretation by engineers and contractors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0135-e256e44d6f", "paper_id": "P0135", "bibkey": "Zhang2025Large", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite advances in software capabilities, the task of generating a structural drawing remains labor-intensive and time-consuming for structural engineers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0135#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0136-f2668be38b", "paper_id": "P0136", "bibkey": "Qiu2025Locobench", "title": "LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce \\textbf{LoCoBench-Agent}, a comprehensive evaluation framework specifically designed to assess LLM agents in realistic, long-context software engineering workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0136-fa8206acb2", "paper_id": "P0136", "bibkey": "Qiu2025Locobench", "title": "LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through systematic evaluation of state-of-the-art models, we reveal several key findings: (1) agents exhibit remarkable long-context robustness; (2) comprehension-efficiency trade-off exists with negative correlation, where thorough exploration increases comprehension but reduces efficiency; and (3) conversation efficiency varies dramatically across models, with strategic tool usage patterns differentiating high-performing agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0136-7aa3167337", "paper_id": "P0136", "bibkey": "Qiu2025Locobench", "title": "LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our framework extends LoCoBench's 8,000 scenarios into interactive agent environments, enabling systematic evaluation of multi-turn conversations, tool usage efficiency, error recovery, and architectural consistency across extended development sessions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0136-8013fadfbc", "paper_id": "P0136", "bibkey": "Qiu2025Locobench", "title": "LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As large language models (LLMs) evolve into sophisticated autonomous agents capable of complex software development tasks, evaluating their real-world capabilities becomes critical.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0136-d79a6c6e35", "paper_id": "P0136", "bibkey": "Qiu2025Locobench", "title": "LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While existing benchmarks like LoCoBench~\\cite{qiu2025locobench} assess long-context code understanding, they focus on single-turn evaluation and cannot capture the multi-turn interactive nature, tool usage patterns, and adaptive reasoning required by real-world coding agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0136-cd76673880", "paper_id": "P0136", "bibkey": "Qiu2025Locobench", "title": "LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce \\textbf{LoCoBench-Agent}, a comprehensive evaluation framework specifically designed to assess LLM agents in realistic, long-context software engineering workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0136#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0137-45466fa20e", "paper_id": "P0137", "bibkey": "Wang2025Flow", "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To overcome these limitations, we introduce MCP-Flow, an automated web-agent-driven pipeline for large-scale server discovery, data synthesis, and model training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0137-07f9bd6a8b", "paper_id": "P0137", "bibkey": "Wang2025Flow", "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "MCP-Flow collects and filters data from 1166 servers and 11536 tools, producing 68733 high-quality instruction-function call pairs and 6439 trajectories, far exceeding prior work in scale and diversity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0137-172333f7c5", "paper_id": "P0137", "bibkey": "Wang2025Flow", "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) increasingly rely on external tools to perform complex, realistic tasks, yet their ability to utilize the rapidly expanding Model Contextual Protocol (MCP) ecosystem remains limited.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0137-38a71d165e", "paper_id": "P0137", "bibkey": "Wang2025Flow", "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing MCP research covers few servers, depends on costly manual curation, and lacks training support, hindering progress toward real-world deployment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0137-715be99d2c", "paper_id": "P0137", "bibkey": "Wang2025Flow", "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To overcome these limitations, we introduce MCP-Flow, an automated web-agent-driven pipeline for large-scale server discovery, data synthesis, and model training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0137-c1e63c5b8f", "paper_id": "P0137", "bibkey": "Wang2025Flow", "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To overcome these limitations, we introduce MCP-Flow, an automated web-agent-driven pipeline for large-scale server discovery, data synthesis, and model training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0137#limitations[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0138-79603dbb38", "paper_id": "P0138", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Temporal progression is an integral part of knowledge accumulation and update.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0138-bc9f2f2374", "paper_id": "P0138", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results indicate that agent design and evaluations should take a dynamical view and implement measures to account for the temporal influence of external resources to ensure reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0138-ccb6112830", "paper_id": "P0138", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Temporal progression is an integral part of knowledge accumulation and update.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0138-bbd77bc2b8", "paper_id": "P0138", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Web search is frequently adopted as grounding for agent knowledge, yet an improper configuration affects the quality of the agent's responses.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0138-355d9ee68b", "paper_id": "P0138", "bibkey": "Xian2025Measuring", "title": "Measuring temporal effects of agent knowledge by date-controlled tool use", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Here, we assess the agent behavior using distinct date-controlled tools (DCTs) as stress test to measure the knowledge variability of large language model (LLM) agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0138#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0139-89c733716e", "paper_id": "P0139", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work we introduce Meta-Policy Reflexion (MPR): a hybrid framework that consolidates LLM-generated reflections into a structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at inference time through two complementary mechanisms soft memory-guided decoding and hard rule admissibility checks(HAC).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0139-8a3b04d40f", "paper_id": "P0139", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We formalize the MPM representation, present algorithms for update and decoding, and validate the approach in a text-based agent environment following the experimental protocol described in the provided implementation (AlfWorld-based).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0139-edaf17f9f6", "paper_id": "P0139", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Empirical results reported in the supplied material indicate consistent gains in execution accuracy and robustness when compared to Reflexion baselines; rule admissibility further improves stability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0139-6cc12d806b", "paper_id": "P0139", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents achieve impressive single-task performance but commonly exhibit repeated failures, inefficient exploration, and limited cross-task adaptability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0139-37a908f409", "paper_id": "P0139", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing reflective strategies (e.g., Reflexion, ReAct) improve per-episode behavior but typically produce ephemeral, task-specific traces that are not reused across tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0139-e643297350", "paper_id": "P0139", "bibkey": "Wu2025Meta", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reinforcement-learning based alternatives can produce transferable policies but require substantial parameter updates and compute.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0139#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0140-0f6e4d4e48", "paper_id": "P0140", "bibkey": "Ghose2025Orfs", "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we introduce ORFS-agent, an LLM-based iterative optimization agent that automates parameter tuning in an open-source hardware design flow.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0140-1d5f67b08e", "paper_id": "P0140", "bibkey": "Ghose2025Orfs", "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our empirical evaluations on two different technology nodes and a range of circuit benchmarks indicate that ORFS-agent can improve both routed wirelength and effective clock period by over 13%, all while using 40% fewer optimization iterations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0140-ddd045953e", "paper_id": "P0140", "bibkey": "Ghose2025Orfs", "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "ORFS-agent adaptively explores parameter configurations, demonstrating clear improvements over standard Bayesian optimization approaches in terms of resource efficiency and final design metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0140-7961345211", "paper_id": "P0140", "bibkey": "Ghose2025Orfs", "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Machine learning has been widely used to optimize complex engineering workflows across numerous domains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0140-e8ec1c25f5", "paper_id": "P0140", "bibkey": "Ghose2025Orfs", "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In the context of integrated circuit design, modern flows (e.g., going from a register-transfer level netlist to physical layouts) involve extensive configuration via thousands of parameters, and small changes to these parameters can have large downstream impacts on desired outcomes - namely design performance, power, and area.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0140-faa314ed93", "paper_id": "P0140", "bibkey": "Ghose2025Orfs", "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in Large Language Models (LLMs) offer new opportunities for learning and reasoning within such high-dimensional optimization tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0140#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0141-59662393b0", "paper_id": "P0141", "bibkey": "Wang2025Odysseybench", "title": "OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we introduce OdysseyBench, a comprehensive benchmark for evaluating LLM agents on long-horizon workflows across diverse office applications including Word, Excel, PDF, Email, and Calendar.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0141-2f43938ccb", "paper_id": "P0141", "bibkey": "Wang2025Odysseybench", "title": "OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our benchmark comprises two complementary splits: OdysseyBench+ with 300 tasks derived from real-world use cases, and OdysseyBench-Neo with 302 newly synthesized complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0141-965d4fab65", "paper_id": "P0141", "bibkey": "Wang2025Odysseybench", "title": "OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our extensive evaluation demonstrates that OdysseyBench effectively challenges state-of-the-art LLM agents, providing more accurate assessment of their capabilities in complex, real-world contexts compared to existing atomic task benchmarks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0141-5a95891101", "paper_id": "P0141", "bibkey": "Wang2025Odysseybench", "title": "OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Autonomous agents powered by large language models (LLMs) are increasingly deployed in real-world applications requiring complex, long-horizon workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0141-c35f677803", "paper_id": "P0141", "bibkey": "Wang2025Odysseybench", "title": "OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing benchmarks predominantly focus on atomic tasks that are self-contained and independent, failing to capture the long-term contextual dependencies and multi-interaction coordination required in realistic scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0141-028c5b6d54", "paper_id": "P0141", "bibkey": "Wang2025Odysseybench", "title": "OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, we introduce OdysseyBench, a comprehensive benchmark for evaluating LLM agents on long-horizon workflows across diverse office applications including Word, Excel, PDF, Email, and Calendar.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0141#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0142-82667f54f1", "paper_id": "P0142", "bibkey": "Zhan2025Poster", "title": "Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Graph Neural Networks (GNNs) show great promise for Network Intrusion Detection Systems (NIDS), particularly in IoT environments, but suffer performance degradation due to distribution drift and lack robustness against realistic adversarial attacks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0142-3fe1756b2e", "paper_id": "P0142", "bibkey": "Zhan2025Poster", "title": "Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments, using a framework designed for realistic evaluation and testing with a variety of adversarial attacks including a dataset collected from physical testbed experiments, demonstrate that integrating LLM analysis can significantly improve the resilience of GNN-based NIDS against challenges, showcasing the potential of LLM agent as a complementary layer in intrusion detection architectures.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "security"]}
{"evidence_id": "E-P0142-0dd91cbab4", "paper_id": "P0142", "bibkey": "Zhan2025Poster", "title": "Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Graph Neural Networks (GNNs) show great promise for Network Intrusion Detection Systems (NIDS), particularly in IoT environments, but suffer performance degradation due to distribution drift and lack robustness against realistic adversarial attacks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0142-4e7e53af15", "paper_id": "P0142", "bibkey": "Zhan2025Poster", "title": "Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current robustness evaluations often rely on unrealistic synthetic perturbations and lack demonstrations on systematic analysis of different kinds of adversarial attack, which encompass both black-box and white-box scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "security"]}
{"evidence_id": "E-P0142-05ab470cbe", "paper_id": "P0142", "bibkey": "Zhan2025Poster", "title": "Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This work proposes a novel approach to enhance GNN robustness and generalization by employing Large Language Models (LLMs) in an agentic pipeline as simulated cybersecurity expert agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0142#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0143-9fcd1a0d17", "paper_id": "P0143", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Motivated by the fact that human experts exhibit significantly better rewrite ability but suffer from scalability, and Large Language Models (LLMs) have demonstrated nearly human-level semantic and reasoning abilities, we propose a new approach of using LLMs to rewrite SQL queries beyond rules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0143-a9d61ac1b4", "paper_id": "P0143", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments show that QUITE reduces query execution time by up to 35.8% over state-of-the-art approaches and produces 24.1% more rewrites than prior methods, covering query cases that earlier systems did not handle.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0143-efd40e95eb", "paper_id": "P0143", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This limitation stems from three challenges of rule-based query rewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite rules do not generalize to new query patterns, and (3) some rewrite techniques cannot be expressed as fixed rules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0143-fb4ae99b92", "paper_id": "P0143", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Query rewrite transforms SQL queries into semantically equivalent forms that run more efficiently.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0143-ea3cd071bc", "paper_id": "P0143", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing approaches mainly rely on predefined rewrite rules, but they handle a limited subset of queries and can cause performance regressions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0143-49862df15e", "paper_id": "P0143", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This limitation stems from three challenges of rule-based query rewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite rules do not generalize to new query patterns, and (3) some rewrite techniques cannot be expressed as fixed rules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0143-7165541801", "paper_id": "P0143", "bibkey": "Song2025Quite", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "This limitation stems from three challenges of rule-based query rewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite rules do not generalize to new query patterns, and (3) some rewrite techniques cannot be expressed as fixed rules.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0143#limitations[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0144-8b3195ff10", "paper_id": "P0144", "bibkey": "Fu2025Eval", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address the absence of standardized evaluation benchmarks for these agents in dynamic environments, we introduce RAS-Eval, a comprehensive security benchmark supporting both simulated and real-world tool execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0144-2895472ae1", "paper_id": "P0144", "bibkey": "Fu2025Eval", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate 6 state-of-the-art LLMs across diverse scenarios, revealing significant vulnerabilities: attacks reduced agent task completion rates (TCR) by 36.78% on average and achieved an 85.65% success rate in academic settings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers", "security"]}
{"evidence_id": "E-P0144-753416ce70", "paper_id": "P0144", "bibkey": "Fu2025Eval", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "RAS-Eval comprises 80 test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration (CWE) categories, with tools implemented in JSON, LangGraph, and Model Context Protocol (MCP) formats.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0144-d371b57225", "paper_id": "P0144", "bibkey": "Fu2025Eval", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid deployment of Large language model (LLM) agents in critical domains like healthcare and finance necessitates robust security frameworks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0144-b48003285d", "paper_id": "P0144", "bibkey": "Fu2025Eval", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address the absence of standardized evaluation benchmarks for these agents in dynamic environments, we introduce RAS-Eval, a comprehensive security benchmark supporting both simulated and real-world tool execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0144-ee4e7f8954", "paper_id": "P0144", "bibkey": "Fu2025Eval", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "RAS-Eval comprises 80 test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration (CWE) categories, with tools implemented in JSON, LangGraph, and Model Context Protocol (MCP) formats.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0144#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security", "tooling"]}
{"evidence_id": "E-P0145-021a994837", "paper_id": "P0145", "bibkey": "Chen2025Remsa", "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce the RSFM Database (RS-FMD), a structured resource covering over 150 RSFMs spanning multiple data modalities, resolutions, and learning paradigms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#method"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0145-c664716bd8", "paper_id": "P0145", "bibkey": "Chen2025Remsa", "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We also propose a benchmark of 75 expert-verified RS query scenarios, producing 900 configurations under an expert-centered evaluation protocol.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0145-0b559cdb98", "paper_id": "P0145", "bibkey": "Chen2025Remsa", "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We introduce the RSFM Database (RS-FMD), a structured resource covering over 150 RSFMs spanning multiple data modalities, resolutions, and learning paradigms.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0145-9ed69382dd", "paper_id": "P0145", "bibkey": "Chen2025Remsa", "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Foundation Models (FMs) are increasingly used in remote sensing (RS) for tasks such as environmental monitoring, disaster assessment, and land-use mapping.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0145-c495219427", "paper_id": "P0145", "bibkey": "Chen2025Remsa", "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These models include unimodal vision encoders trained on a single data modality and multimodal architectures trained on combinations of SAR, multispectral, hyperspectral, and image-text data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0145-5df0f0ffed", "paper_id": "P0145", "bibkey": "Chen2025Remsa", "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "They support diverse RS tasks including semantic segmentation, image classification, change detection, and visual question answering.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0145-3bd89c8b09", "paper_id": "P0145", "bibkey": "Chen2025Remsa", "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "It operates entirely on publicly available metadata and does not access private or sensitive data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0145#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0146-6e4feb950e", "paper_id": "P0146", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this limitation, we propose ReAcTree, a hierarchical task-planning method that decomposes a complex goal into more manageable subgoals within a dynamically constructed agent tree.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0146-800068dfc6", "paper_id": "P0146", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Notably, on WAH-NL, ReAcTree achieves a 61% goal success rate with Qwen 2.5 72B, nearly doubling ReAct's 31%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0146-4bcafdb221", "paper_id": "P0146", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on the WAH-NL and ALFRED datasets demonstrate that ReAcTree consistently outperforms strong task-planning baselines such as ReAct across diverse LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0146-27052609b0", "paper_id": "P0146", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in large language models (LLMs) have enabled significant progress in decision-making and task planning for embodied autonomous agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0146-19186aab0d", "paper_id": "P0146", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, most existing methods still struggle with complex, long-horizon tasks because they rely on a monolithic trajectory that entangles all past decisions and observations, attempting to solve the entire task in a single unified process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0146-5e26d15f21", "paper_id": "P0146", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this limitation, we propose ReAcTree, a hierarchical task-planning method that decomposes a complex goal into more manageable subgoals within a dynamically constructed agent tree.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0146-c782275d8d", "paper_id": "P0146", "bibkey": "Choi2025Reactree", "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address this limitation, we propose ReAcTree, a hierarchical task-planning method that decomposes a complex goal into more manageable subgoals within a dynamically constructed agent tree.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0146#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0147-b03dd043e2", "paper_id": "P0147", "bibkey": "Lee2025Bench", "title": "SEC-bench: Automated Benchmarking of LLM Agents on Real-World Software Security Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce SEC-bench, the first fully automated benchmarking framework for evaluating LLM agents on authentic security engineering tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0147-32438dad15", "paper_id": "P0147", "bibkey": "Lee2025Bench", "title": "SEC-bench: Automated Benchmarking of LLM Agents on Real-World Software Security Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "A comprehensive evaluation of state-of-the-art LLM code agents reveals significant performance gaps, achieving at most 18.0% success in PoC generation and 34.0% in vulnerability patching on our complete dataset.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0147-0a269c6135", "paper_id": "P0147", "bibkey": "Lee2025Bench", "title": "SEC-bench: Automated Benchmarking of LLM Agents on Real-World Software Security Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our framework automatically creates high-quality software vulnerability datasets with reproducible artifacts at a cost of only $0.87 per instance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0147-1393e9d1f6", "paper_id": "P0147", "bibkey": "Lee2025Bench", "title": "SEC-bench: Automated Benchmarking of LLM Agents on Real-World Software Security Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Rigorous security-focused evaluation of large language model (LLM) agents is imperative for establishing trust in their safe deployment throughout the software development lifecycle.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0147-2ab8c0d5a5", "paper_id": "P0147", "bibkey": "Lee2025Bench", "title": "SEC-bench: Automated Benchmarking of LLM Agents on Real-World Software Security Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing benchmarks largely rely on synthetic challenges or simplified vulnerability datasets that fail to capture the complexity and ambiguity encountered by security engineers in practice.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "security"]}
{"evidence_id": "E-P0147-c9c4afc06a", "paper_id": "P0147", "bibkey": "Lee2025Bench", "title": "SEC-bench: Automated Benchmarking of LLM Agents on Real-World Software Security Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce SEC-bench, the first fully automated benchmarking framework for evaluating LLM agents on authentic security engineering tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0147#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0148-4eb2118d43", "paper_id": "P0148", "bibkey": "Kutasov2025Shade", "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We study the ability of frontier LLMs to evade monitoring and achieve harmful hidden goals while completing a wide array of realistic tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0148-6cfb49759f", "paper_id": "P0148", "bibkey": "Kutasov2025Shade", "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "When measuring agent ability to (a) complete the main task, (b) complete the side task, and (c) avoid detection, we find that the best performing frontier models score 27% (Claude 3.7 Sonnet) and 15% (Gemini 2.5 Pro) as sabotage agents when overseen by Claude 3.6 Sonnet.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0148-32da43fe95", "paper_id": "P0148", "bibkey": "Kutasov2025Shade", "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We also use SHADE-Arena to measure models' monitoring abilities, with the top monitor (Gemini 2.5 Pro) achieving an AUC of 0.87 at distinguishing benign and malign transcripts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0148-c9d8c4a8a8", "paper_id": "P0148", "bibkey": "Kutasov2025Shade", "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As Large Language Models (LLMs) are increasingly deployed as autonomous agents in complex and long horizon settings, it is critical to evaluate their ability to sabotage users by pursuing hidden objectives.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0148-73ae72665e", "paper_id": "P0148", "bibkey": "Kutasov2025Shade", "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We study the ability of frontier LLMs to evade monitoring and achieve harmful hidden goals while completing a wide array of realistic tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0148-0483573b91", "paper_id": "P0148", "bibkey": "Kutasov2025Shade", "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We evaluate a broad range of frontier LLMs using SHADE (Subtle Harmful Agent Detection & Evaluation)-Arena, the first highly diverse agent evaluation dataset for sabotage and monitoring capabilities of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0148#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0149-9002768f4f", "paper_id": "P0149", "bibkey": "Li2025Stac", "title": "STAC: When Innocent Tools Form Dangerous Chains to Jailbreak LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we propose a new reasoning-driven defense prompt that achieves far stronger protection, cutting ASR by up to 28.8%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#method"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0149-82fdf6d15e", "paper_id": "P0149", "bibkey": "Li2025Stac", "title": "STAC: When Innocent Tools Form Dangerous Chains to Jailbreak LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluations show that state-of-the-art LLM agents, including GPT-4.1, are highly vulnerable to STAC, with attack success rates (ASR) exceeding 90% in most cases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0149-7042d84482", "paper_id": "P0149", "bibkey": "Li2025Stac", "title": "STAC: When Innocent Tools Form Dangerous Chains to Jailbreak LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We apply our framework to automatically generate and systematically evaluate 483 STAC cases, featuring 1,352 sets of user-agent-environment interactions and spanning diverse domains, tasks, agent types, and 10 failure modes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0149-94f180b4c4", "paper_id": "P0149", "bibkey": "Li2025Stac", "title": "STAC: When Innocent Tools Form Dangerous Chains to Jailbreak LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As LLMs advance into autonomous agents with tool-use capabilities, they introduce security challenges that extend beyond traditional content-based LLM safety concerns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0149-c2dd30c29c", "paper_id": "P0149", "bibkey": "Li2025Stac", "title": "STAC: When Innocent Tools Form Dangerous Chains to Jailbreak LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper introduces Sequential Tool Attack Chaining (STAC), a novel multi-turn attack framework that exploits agent tool use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#summary_bullets[1]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0149-72b1be2058", "paper_id": "P0149", "bibkey": "Li2025Stac", "title": "STAC: When Innocent Tools Form Dangerous Chains to Jailbreak LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "STAC chains together tool calls that each appear harmless in isolation but, when combined, collectively enable harmful operations that only become apparent at the final execution step.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0149#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0150-3a9c3491f4", "paper_id": "P0150", "bibkey": "Zhu2025Safescientist", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To systematically address these challenges, we introduce \\textbf{SafeScientist}, an innovative AI scientist framework explicitly designed to enhance safety and ethical responsibility in AI-driven scientific exploration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0150-17ce80dca8", "paper_id": "P0150", "bibkey": "Zhu2025Safescientist", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Complementing SafeScientist, we propose \\textbf{SciSafetyBench}, a novel benchmark specifically designed to evaluate AI safety in scientific contexts, comprising 240 high-risk scientific tasks across 6 domains, alongside 30 specially designed scientific tools and 120 tool-related risk tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0150-a38e27f78c", "paper_id": "P0150", "bibkey": "Zhu2025Safescientist", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments demonstrate that SafeScientist significantly improves safety performance by 35\\% compared to traditional AI scientist frameworks, without compromising scientific output quality.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0150-790600193f", "paper_id": "P0150", "bibkey": "Zhu2025Safescientist", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in large language model (LLM) agents have significantly accelerated scientific discovery automation, yet concurrently raised critical ethical and safety concerns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0150-e070a79e48", "paper_id": "P0150", "bibkey": "Zhu2025Safescientist", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To systematically address these challenges, we introduce \\textbf{SafeScientist}, an innovative AI scientist framework explicitly designed to enhance safety and ethical responsibility in AI-driven scientific exploration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0150-ccda9664f2", "paper_id": "P0150", "bibkey": "Zhu2025Safescientist", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "SafeScientist proactively refuses ethically inappropriate or high-risk tasks and rigorously emphasizes safety throughout the research process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0150#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0151-5995819b8e", "paper_id": "P0151", "bibkey": "Seo2025Simuhome", "title": "SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this, we introduce $\\textbf{SimuHome}$, a time-accelerated home environment that simulates smart devices, supports API calls, and reflects changes in environmental variables.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0151-7b36039ae4", "paper_id": "P0151", "bibkey": "Seo2025Simuhome", "title": "SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We provide a challenging benchmark of 600 episodes across twelve user query types that require the aforementioned capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0151-469a70bb44", "paper_id": "P0151", "bibkey": "Seo2025Simuhome", "title": "SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation of 16 agents under a unified ReAct framework reveals distinct capabilities and limitations across models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0151-34b3ccbdc8", "paper_id": "P0151", "bibkey": "Seo2025Simuhome", "title": "SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents excel at multi-step, tool-augmented tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0151-c4666f17e9", "paper_id": "P0151", "bibkey": "Seo2025Simuhome", "title": "SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, smart homes introduce distinct challenges, requiring agents to handle latent user intents, temporal dependencies, device constraints, scheduling, and more.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0151-866e9988a4", "paper_id": "P0151", "bibkey": "Seo2025Simuhome", "title": "SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The main bottlenecks for developing smart home agents with such capabilities include the lack of a realistic simulation environment where agents can interact with devices and observe the results, as well as a challenging benchmark to evaluate them.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0151-e2e3b7fa97", "paper_id": "P0151", "bibkey": "Seo2025Simuhome", "title": "SimuHome: A Temporal- and Environment-Aware Benchmark for Smart Home LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Our evaluation of 16 agents under a unified ReAct framework reveals distinct capabilities and limitations across models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0151#limitations[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0152-c8648baf8e", "paper_id": "P0152", "bibkey": "Suri2025Structured", "title": "Structured Uncertainty guided Clarification for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a principled formulation of structured uncertainty over tool-call parameters, modeling joint tool-argument clarification as a POMDP with Expected Value of Perfect Information (EVPI) objective for optimal question selection and aspect-based cost modeling to prevent redundancy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0152-2d77903ddb", "paper_id": "P0152", "bibkey": "Suri2025Structured", "title": "Structured Uncertainty guided Clarification for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Additionally, we demonstrate that structured uncertainty provides effective training signals for reinforcement learning, boosting When2Call accuracy from 36.5\\% to 65.2\\% (3B model) and 36.7\\% to 62.9\\% (7B model) through uncertainty-weighted GRPO training.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0152-be7675fbfc", "paper_id": "P0152", "bibkey": "Suri2025Structured", "title": "Structured Uncertainty guided Clarification for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our SAGE-Agent leverages this structured uncertainty to achieve superior efficiency: increasing coverage on ambiguous tasks by 7-39\\% while reducing clarification questions by 1.5-2.7$\\times$ compared to strong prompting and uncertainty-based baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0152-5a0557ebb9", "paper_id": "P0152", "bibkey": "Suri2025Structured", "title": "Structured Uncertainty guided Clarification for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM agents extend large language models with tool-calling capabilities, but ambiguous user instructions often lead to incorrect invocations and task failures.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0152-cb9cd76755", "paper_id": "P0152", "bibkey": "Suri2025Structured", "title": "Structured Uncertainty guided Clarification for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce a principled formulation of structured uncertainty over tool-call parameters, modeling joint tool-argument clarification as a POMDP with Expected Value of Perfect Information (EVPI) objective for optimal question selection and aspect-based cost modeling to prevent redundancy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0152-0acac7ecd1", "paper_id": "P0152", "bibkey": "Suri2025Structured", "title": "Structured Uncertainty guided Clarification for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our SAGE-Agent leverages this structured uncertainty to achieve superior efficiency: increasing coverage on ambiguous tasks by 7-39\\% while reducing clarification questions by 1.5-2.7$\\times$ compared to strong prompting and uncertainty-based baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0152#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0153-06d57587c6", "paper_id": "P0153", "bibkey": "Ye2025Taska", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose the Task Memory Engine (TME), a lightweight and structured memory module that tracks task execution using a hierarchical Task Memory Tree (TMT).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0153-44aade70d9", "paper_id": "P0153", "bibkey": "Ye2025Taska", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Through case studies and comparative experiments on multi-step agent tasks, we demonstrate that TME leads to better task completion accuracy and more interpretable behavior with minimal implementation overhead.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0153-a455c5978d", "paper_id": "P0153", "bibkey": "Ye2025Taska", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) are increasingly used as autonomous agents for multi-step tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0153-34787ad3ea", "paper_id": "P0153", "bibkey": "Ye2025Taska", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, most existing frameworks fail to maintain a structured understanding of the task state, often relying on linear prompt concatenation or shallow memory buffers.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0153-b5af4bb401", "paper_id": "P0153", "bibkey": "Ye2025Taska", "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This leads to brittle performance, frequent hallucinations, and poor long-range coherence.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0153#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0154-84b31c799f", "paper_id": "P0154", "bibkey": "Liu2025Real", "title": "The Real Barrier to LLM Agent Usability is Agentic ROI", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Model (LLM) agents represent a promising shift in human-AI interaction, moving beyond passive prompt-response systems to autonomous agents capable of reasoning, planning, and goal-directed action.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0154-29c03eddb2", "paper_id": "P0154", "bibkey": "Liu2025Real", "title": "The Real Barrier to LLM Agent Usability is Agentic ROI", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large Language Model (LLM) agents represent a promising shift in human-AI interaction, moving beyond passive prompt-response systems to autonomous agents capable of reasoning, planning, and goal-directed action.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0154-a1271556e7", "paper_id": "P0154", "bibkey": "Liu2025Real", "title": "The Real Barrier to LLM Agent Usability is Agentic ROI", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents represent a promising shift in human-AI interaction, moving beyond passive prompt-response systems to autonomous agents capable of reasoning, planning, and goal-directed action.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0154-a320c0ce64", "paper_id": "P0154", "bibkey": "Liu2025Real", "title": "The Real Barrier to LLM Agent Usability is Agentic ROI", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite the widespread application in specialized, high-effort tasks like coding and scientific research, we highlight a critical usability gap in high-demand, mass-market applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0154-37056f516b", "paper_id": "P0154", "bibkey": "Liu2025Real", "title": "The Real Barrier to LLM Agent Usability is Agentic ROI", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This position paper argues that the limited real-world adoption of LLM agents stems not only from gaps in model capabilities, but also from a fundamental tradeoff between the value an agent can provide and the costs incurred during real-world use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0154#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0155-4c5009df7f", "paper_id": "P0155", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "With the proliferation of Large Language Models (LLMs), the detection of misinformation has become increasingly important and complex.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0155-171b93237a", "paper_id": "P0155", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate using standard misinformation datasets such as FakeNewsNet, comparing with traditional machine learning models and LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0155-15e523063d", "paper_id": "P0155", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluation metrics include standard classification metrics, quality assessment of reasoning processes, and robustness testing against rewritten content.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0155-b24ddee6fb", "paper_id": "P0155", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the proliferation of Large Language Models (LLMs), the detection of misinformation has become increasingly important and complex.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0155-9f6e16eaaf", "paper_id": "P0155", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This research proposes an innovative verifiable misinformation detection LLM agent that goes beyond traditional true/false binary judgments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0155-5ab215976a", "paper_id": "P0155", "bibkey": "Cui2025Toward", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The agent actively verifies claims through dynamic interaction with diverse web sources, assesses information source credibility, synthesizes evidence, and provides a complete verifiable reasoning process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0155#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0156-788f431506", "paper_id": "P0156", "bibkey": "Zheng2025Towards", "title": "Towards Agentic OS: An LLM Agent Framework for Linux Schedulers", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce SchedCP, the first framework that enables fully autonomous Large Language Model (LLM) agents to safely and efficiently optimize Linux schedulers without human involvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0156-e3f7ba21be", "paper_id": "P0156", "bibkey": "Zheng2025Towards", "title": "Towards Agentic OS: An LLM Agent Framework for Linux Schedulers", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation shows that SchedCP achieves up to an 1.79x performance improvement, and a 13x cost reduction compared to naive agentic approaches, all while maintaining high success rate.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0156-97b353d920", "paper_id": "P0156", "bibkey": "Zheng2025Towards", "title": "Towards Agentic OS: An LLM Agent Framework for Linux Schedulers", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We introduce SchedCP, the first framework that enables fully autonomous Large Language Model (LLM) agents to safely and efficiently optimize Linux schedulers without human involvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0156-a001e04bc2", "paper_id": "P0156", "bibkey": "Zheng2025Towards", "title": "Towards Agentic OS: An LLM Agent Framework for Linux Schedulers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Operating system schedulers suffer from a fundamental semantic gap, where kernel policies fail to understand application-specific needs, leading to suboptimal performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0156-c74123216c", "paper_id": "P0156", "bibkey": "Zheng2025Towards", "title": "Towards Agentic OS: An LLM Agent Framework for Linux Schedulers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce SchedCP, the first framework that enables fully autonomous Large Language Model (LLM) agents to safely and efficiently optimize Linux schedulers without human involvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0156-b899722a8f", "paper_id": "P0156", "bibkey": "Zheng2025Towards", "title": "Towards Agentic OS: An LLM Agent Framework for Linux Schedulers", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Our core insight is that the challenge is not merely to apply a better LLM, but to architect a decoupled control plane that separates the AI's role of semantic reasoning (\"what to optimize\") from the system's role of execution (\"how to observe and act\"), thereby separating the optimization problem into two stages: goal-inference and policy-synthesis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0156#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0157-52dd0524b8", "paper_id": "P0157", "bibkey": "Shao2025Towards", "title": "Towards Effective Offensive Security LLM Agents: Hyperparameter Tuning, LLM as a Judge, and a Lightweight CTF Benchmark", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "First, we present CTFJudge, a framework leveraging LLM as a judge to analyze agent trajectories and provide granular evaluation across CTF solving steps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0157-f65d57a126", "paper_id": "P0157", "bibkey": "Shao2025Towards", "title": "Towards Effective Offensive Security LLM Agents: Hyperparameter Tuning, LLM as a Judge, and a Lightweight CTF Benchmark", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "For rapid evaluation, we present CTFTiny, a curated benchmark of 50 representative CTF challenges across binary exploitation, web, reverse engineering, forensics, and cryptography.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0157-7bf4a48ec3", "paper_id": "P0157", "bibkey": "Shao2025Towards", "title": "Towards Effective Offensive Security LLM Agents: Hyperparameter Tuning, LLM as a Judge, and a Lightweight CTF Benchmark", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We systematically investigate the key factors that drive agent success and provide a detailed recipe for building effective LLM-based offensive security agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0157-61199e38ec", "paper_id": "P0157", "bibkey": "Shao2025Towards", "title": "Towards Effective Offensive Security LLM Agents: Hyperparameter Tuning, LLM as a Judge, and a Lightweight CTF Benchmark", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in LLM agentic systems have improved the automation of offensive security tasks, particularly for Capture the Flag (CTF) challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0157-7967fc255b", "paper_id": "P0157", "bibkey": "Shao2025Towards", "title": "Towards Effective Offensive Security LLM Agents: Hyperparameter Tuning, LLM as a Judge, and a Lightweight CTF Benchmark", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We systematically investigate the key factors that drive agent success and provide a detailed recipe for building effective LLM-based offensive security agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0157-817016f047", "paper_id": "P0157", "bibkey": "Shao2025Towards", "title": "Towards Effective Offensive Security LLM Agents: Hyperparameter Tuning, LLM as a Judge, and a Lightweight CTF Benchmark", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "First, we present CTFJudge, a framework leveraging LLM as a judge to analyze agent trajectories and provide granular evaluation across CTF solving steps.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0157#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0158-ed4c8ec45f", "paper_id": "P0158", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "The COVID-19 infodemic calls for scalable fact-checking solutions that handle long-form misinformation with accuracy and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#method"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0158-866b979e15", "paper_id": "P0158", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The COVID-19 infodemic calls for scalable fact-checking solutions that handle long-form misinformation with accuracy and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0158-4af0cf3c02", "paper_id": "P0158", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This study presents SAFE (system for accurate fact extraction and evaluation), an agent system that combines large language models with retrieval-augmented generation (RAG) to improve automated fact-checking of long-form COVID-19 misinformation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0158-83d97ab146", "paper_id": "P0158", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The COVID-19 infodemic calls for scalable fact-checking solutions that handle long-form misinformation with accuracy and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#summary_bullets[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0158-e8d583cea2", "paper_id": "P0158", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This study presents SAFE (system for accurate fact extraction and evaluation), an agent system that combines large language models with retrieval-augmented generation (RAG) to improve automated fact-checking of long-form COVID-19 misinformation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0158-19278ea365", "paper_id": "P0158", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "SAFE includes two agents - one for claim extraction and another for claim verification using LOTR-RAG, which leverages a 130,000-document COVID-19 research corpus.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0158-c9781caf3b", "paper_id": "P0158", "bibkey": "Huang2025Retrieval", "title": "Use of Retrieval-Augmented Large Language Model Agent for Long-Form COVID-19 Fact-Checking", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "SAFE demonstrates robust improvements in long-form COVID-19 fact-checking by addressing LLM limitations in consistency and explainability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0158#limitations[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0159-e34319b92c", "paper_id": "P0159", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "There is growing interest in using Large Language Models as agents (LLM agents) for social simulations to inform policy, yet real-world adoption remains limited.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0159-ccc7d0cc50", "paper_id": "P0159", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across multiple design iterations, we iteratively developed a system of 13,000 LLM agents that simulate crowd movement and communication during a large-scale gathering under various emergency scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0159-0e210813b4", "paper_id": "P0159", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "There is growing interest in using Large Language Models as agents (LLM agents) for social simulations to inform policy, yet real-world adoption remains limited.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0159-2651954a10", "paper_id": "P0159", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper addresses the question: How can LLM agent simulations be made genuinely useful for policy?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0159-955593c3c4", "paper_id": "P0159", "bibkey": "Li2025What", "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We report on a year-long iterative design engagement with a university emergency preparedness team.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0159#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0160-b6e504bd8f", "paper_id": "P0160", "bibkey": "Gioacchini2024Agentquest", "title": "AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To face these issues, we propose AgentQuest -- a framework where (i) both benchmarks and metrics are modular and easily extensible through well documented and easy-to-use APIs; (ii) we offer two new evaluation metrics that can reliably track LLM agent progress while solving a task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#method"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0160-49cea03593", "paper_id": "P0160", "bibkey": "Gioacchini2024Agentquest", "title": "AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We exemplify the utility of the metrics on two use cases wherein we identify common failure points and refine the agent architecture to obtain a significant performance increase.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0160-8c61638830", "paper_id": "P0160", "bibkey": "Gioacchini2024Agentquest", "title": "AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "As with any research pursuit, benchmarking and evaluation are key corner stones to efficient and reliable progress.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0160-b65d2d5e25", "paper_id": "P0160", "bibkey": "Gioacchini2024Agentquest", "title": "AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The advances made by Large Language Models (LLMs) have led to the pursuit of LLM agents that can solve intricate, multi-step reasoning tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0160-3a4d6c4f26", "paper_id": "P0160", "bibkey": "Gioacchini2024Agentquest", "title": "AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As with any research pursuit, benchmarking and evaluation are key corner stones to efficient and reliable progress.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0160-fdff99bdf1", "paper_id": "P0160", "bibkey": "Gioacchini2024Agentquest", "title": "AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, existing benchmarks are often narrow and simply compute overall task success.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0160#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0161-43287d5458", "paper_id": "P0161", "bibkey": "Anokhin2024Arigraph", "title": "AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In our study, we introduce AriGraph, a novel method wherein the agent constructs and updates a memory graph that integrates semantic and episodic memories while exploring the environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0161-e499ec8b67", "paper_id": "P0161", "bibkey": "Anokhin2024Arigraph", "title": "AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We demonstrate that our Ariadne LLM agent, consisting of the proposed memory architecture augmented with planning and decision-making, effectively handles complex tasks within interactive text game environments difficult even for human players.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#key_results[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0161-72413e634e", "paper_id": "P0161", "bibkey": "Anokhin2024Arigraph", "title": "AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Advancements in the capabilities of Large Language Models (LLMs) have created a promising foundation for developing autonomous agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0161-76ed436af0", "paper_id": "P0161", "bibkey": "Anokhin2024Arigraph", "title": "AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the right tools, these agents could learn to solve tasks in new environments by accumulating and updating their knowledge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0161-d2796732a0", "paper_id": "P0161", "bibkey": "Anokhin2024Arigraph", "title": "AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current LLM-based agents process past experiences using a full history of observations, summarization, retrieval augmentation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0161#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0162-9b9579b708", "paper_id": "P0162", "bibkey": "Liu2024Codexgraph", "title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To mitigate these limitations, we introduce CodexGraph, a system that integrates LLM agents with graph database interfaces extracted from code repositories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0162-90b8aa89af", "paper_id": "P0162", "bibkey": "Liu2024Codexgraph", "title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We assess CodexGraph using three benchmarks: CrossCodeEval, SWE-bench, and EvoCodeBench.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0162-ae02a4a92c", "paper_id": "P0162", "bibkey": "Liu2024Codexgraph", "title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) excel in stand-alone code tasks like HumanEval and MBPP, but struggle with handling entire code repositories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0162-0bb26ce6d5", "paper_id": "P0162", "bibkey": "Liu2024Codexgraph", "title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This challenge has prompted research on enhancing LLM-codebase interaction at a repository scale.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0162-0792aa0f0f", "paper_id": "P0162", "bibkey": "Liu2024Codexgraph", "title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current solutions rely on similarity-based retrieval or manual tools and APIs, each with notable drawbacks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0162-a4fe3000ca", "paper_id": "P0162", "bibkey": "Liu2024Codexgraph", "title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To mitigate these limitations, we introduce CodexGraph, a system that integrates LLM agents with graph database interfaces extracted from code repositories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0162#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0163-7d75f47368", "paper_id": "P0163", "bibkey": "Rahn2024Controlling", "title": "Controlling Large Language Model Agents with Entropic Activation Steering", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "The rise of large language models (LLMs) has prompted increasing interest in their use as in-context learning agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0163-1f5f29e59a", "paper_id": "P0163", "bibkey": "Rahn2024Controlling", "title": "Controlling Large Language Model Agents with Entropic Activation Steering", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our work paves the way for a new understanding of the functioning of LLM agents and to effective control of their decision-making behaviors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0163-6e8b61b3ee", "paper_id": "P0163", "bibkey": "Rahn2024Controlling", "title": "Controlling Large Language Model Agents with Entropic Activation Steering", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rise of large language models (LLMs) has prompted increasing interest in their use as in-context learning agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0163-d93517352e", "paper_id": "P0163", "bibkey": "Rahn2024Controlling", "title": "Controlling Large Language Model Agents with Entropic Activation Steering", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "At the core of agentic behavior is the capacity for exploration, or the ability to actively gather information about the environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0163-a7841481d2", "paper_id": "P0163", "bibkey": "Rahn2024Controlling", "title": "Controlling Large Language Model Agents with Entropic Activation Steering", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "But how do LLM agents explore, and how can we control their exploratory behaviors?", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0163#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0164-a61ac123d5", "paper_id": "P0164", "bibkey": "Piatti2024Cooperate", "title": "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce the Governance of the Commons Simulation (GovSim), a generative simulation platform designed to study strategic interactions and cooperative decision-making in LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0164-ce1001aef8", "paper_id": "P0164", "bibkey": "Piatti2024Cooperate", "title": "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We find that all but the most powerful LLM agents fail to achieve a sustainable equilibrium in GovSim, with the highest survival rate below 54%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0164-449aa6c093", "paper_id": "P0164", "bibkey": "Piatti2024Cooperate", "title": "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "As AI systems pervade human life, ensuring that large language models (LLMs) make safe decisions remains a significant challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0164-2cabe8a540", "paper_id": "P0164", "bibkey": "Piatti2024Cooperate", "title": "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As AI systems pervade human life, ensuring that large language models (LLMs) make safe decisions remains a significant challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0164-32383c5c7c", "paper_id": "P0164", "bibkey": "Piatti2024Cooperate", "title": "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce the Governance of the Commons Simulation (GovSim), a generative simulation platform designed to study strategic interactions and cooperative decision-making in LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0164-6e5ff9acf1", "paper_id": "P0164", "bibkey": "Piatti2024Cooperate", "title": "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In GovSim, a society of AI agents must collectively balance exploiting a common resource with sustaining it for future use.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0164#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0165-b78c7da9ae", "paper_id": "P0165", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce a framework LearnAct with an iterative learning strategy to create and improve actions in the form of Python functions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0165-9a9b9f50ae", "paper_id": "P0165", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experimental evaluations across Robotic Planning and Alfworld environments reveal that after learning on a few training task instances, our approach to open-action learning markedly improves agent performance for the type of task (by 32 percent in AlfWorld compared to ReAct+Reflexion, for instance) highlighting the importance of experiential action learning in the development of more intelligent LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0165-644765145d", "paper_id": "P0165", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) Agents have recently garnered increasing interest yet they are limited in their ability to learn from trial and error, a key element of intelligent behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0165-3a3ae3749a", "paper_id": "P0165", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we argue that the capacity to learn new actions from experience is fundamental to the advancement of learning in LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0165-4c29be4bc6", "paper_id": "P0165", "bibkey": "Zhao2024Empowering", "title": "Empowering Large Language Model Agents through Action Learning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While humans naturally expand their action spaces and develop skills through experiential learning, LLM agents typically operate within fixed action spaces, limiting their potential for growth.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0165#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0166-58d126e9cf", "paper_id": "P0166", "bibkey": "Wang2024Executable", "title": "Executable Code Actions Elicit Better LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Model (LLM) agents, capable of performing a broad range of actions, such as invoking tools and controlling robots, show great potential in tackling real-world challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0166-f712a72411", "paper_id": "P0166", "bibkey": "Wang2024Executable", "title": "Executable Code Actions Elicit Better LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our extensive analysis of 17 LLMs on API-Bank and a newly curated benchmark shows that CodeAct outperforms widely used alternatives (up to 20% higher success rate).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0166-34838e48f6", "paper_id": "P0166", "bibkey": "Wang2024Executable", "title": "Executable Code Actions Elicit Better LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "To this end, we collect an instruction-tuning dataset CodeActInstruct that consists of 7k multi-turn interactions using CodeAct.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0166-cee887cc58", "paper_id": "P0166", "bibkey": "Wang2024Executable", "title": "Executable Code Actions Elicit Better LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents, capable of performing a broad range of actions, such as invoking tools and controlling robots, show great potential in tackling real-world challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0166-c05e9326a7", "paper_id": "P0166", "bibkey": "Wang2024Executable", "title": "Executable Code Actions Elicit Better LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM agents are typically prompted to produce actions by generating JSON or text in a pre-defined format, which is usually limited by constrained action space (e.g., the scope of pre-defined tools) and restricted flexibility (e.g., inability to compose multiple tools).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0166-1184bf3259", "paper_id": "P0166", "bibkey": "Wang2024Executable", "title": "Executable Code Actions Elicit Better LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This work proposes to use executable Python code to consolidate LLM agents' actions into a unified action space (CodeAct).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0166#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0167-3611bfc4e0", "paper_id": "P0167", "bibkey": "Turtayev2024Hacking", "title": "Hacking CTFs with Plain Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We saturate a high-school-level hacking benchmark with plain LLM agent design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0167-280f220625", "paper_id": "P0167", "bibkey": "Turtayev2024Hacking", "title": "Hacking CTFs with Plain Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Concretely, we obtain 95% performance on InterCode-CTF, a popular offensive security benchmark, using prompting, tool use, and multiple attempts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0167-082e64f92d", "paper_id": "P0167", "bibkey": "Turtayev2024Hacking", "title": "Hacking CTFs with Plain Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "This beats prior work by Phuong et al. 2024 (29%) and Abramovich et al. 2024 (72%).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0167-bf702c0eb6", "paper_id": "P0167", "bibkey": "Turtayev2024Hacking", "title": "Hacking CTFs with Plain Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We saturate a high-school-level hacking benchmark with plain LLM agent design.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0167-9dd76b790e", "paper_id": "P0167", "bibkey": "Turtayev2024Hacking", "title": "Hacking CTFs with Plain Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Concretely, we obtain 95% performance on InterCode-CTF, a popular offensive security benchmark, using prompting, tool use, and multiple attempts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0167-5778d42519", "paper_id": "P0167", "bibkey": "Turtayev2024Hacking", "title": "Hacking CTFs with Plain Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This beats prior work by Phuong et al. 2024 (29%) and Abramovich et al. 2024 (72%).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0167#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0168-6f708c6c73", "paper_id": "P0168", "bibkey": "Fu2024Imprompter", "title": "Imprompter: Tricking LLM Agents into Improper Tool Use", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Model (LLM) Agents are an emerging computing paradigm that blends generative machine learning with tools such as code interpreters, web browsing, email, and more generally, external resources.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0168-0ea7b39672", "paper_id": "P0168", "bibkey": "Fu2024Imprompter", "title": "Imprompter: Tricking LLM Agents into Improper Tool Use", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "This attack shows a nearly 80% success rate in an end-to-end evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0168-44c3189244", "paper_id": "P0168", "bibkey": "Fu2024Imprompter", "title": "Imprompter: Tricking LLM Agents into Improper Tool Use", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) Agents are an emerging computing paradigm that blends generative machine learning with tools such as code interpreters, web browsing, email, and more generally, external resources.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0168-920004ca19", "paper_id": "P0168", "bibkey": "Fu2024Imprompter", "title": "Imprompter: Tricking LLM Agents into Improper Tool Use", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These agent-based systems represent an emerging shift in personal computing.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0168-151c9f651e", "paper_id": "P0168", "bibkey": "Fu2024Imprompter", "title": "Imprompter: Tricking LLM Agents into Improper Tool Use", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We contribute to the security foundations of agent-based systems and surface a new class of automatically computed obfuscated adversarial prompt attacks that violate the confidentiality and integrity of user resources connected to an LLM agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0168#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0169-736b6ce650", "paper_id": "P0169", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In recent years, large language models (LLMs) have become increasingly capable and can now interact with tools (i.e., call functions), read documents, and recursively call themselves.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0169-5289c5dd2a", "paper_id": "P0169", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Namely, we show that GPT-4 is capable of such hacks, but existing open-source models are not.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0169-4ca48f2c91", "paper_id": "P0169", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Finally, we show that GPT-4 is capable of autonomously finding vulnerabilities in websites in the wild.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "security"]}
{"evidence_id": "E-P0169-aa284afced", "paper_id": "P0169", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In recent years, large language models (LLMs) have become increasingly capable and can now interact with tools (i.e., call functions), read documents, and recursively call themselves.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0169-27c3729137", "paper_id": "P0169", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As a result, these LLMs can now function autonomously as agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0169-6585fe35f0", "paper_id": "P0169", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "With the rise in capabilities of these agents, recent work has speculated on how LLM agents would affect cybersecurity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0169-58e3b3142d", "paper_id": "P0169", "bibkey": "Fang2024Agents", "title": "LLM Agents can Autonomously Hack Websites", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Importantly, the agent does not need to know the vulnerability beforehand.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0169#limitations[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0170-d25f89f2dc", "paper_id": "P0170", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we introduce MIRAI, a novel benchmark designed to systematically evaluate LLM agents as temporal forecasters in the context of international events.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0170-6a339fd402", "paper_id": "P0170", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "In summary, MIRAI comprehensively evaluates the agents' capabilities in three dimensions: 1) autonomously source and integrate critical information from large global databases; 2) write codes using domain-specific APIs and libraries for tool-use; and 3) jointly reason over historical knowledge from diverse formats and time to accurately predict future events.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "tooling"]}
{"evidence_id": "E-P0170-d16fef84ae", "paper_id": "P0170", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Despite such a growing interest, there is a lack of a rigorous benchmark of LLM agents' forecasting capability and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0170-4a854901de", "paper_id": "P0170", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in Large Language Models (LLMs) have empowered LLM agents to autonomously collect world information, over which to conduct reasoning to solve complex problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0170-aef311d66d", "paper_id": "P0170", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Given this capability, increasing interests have been put into employing LLM agents for predicting international events, which can influence decision-making and shape policy development on an international scale.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0170-4157a930a1", "paper_id": "P0170", "bibkey": "Ye2024Mirai", "title": "MIRAI: Evaluating LLM Agents for Event Forecasting", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite such a growing interest, there is a lack of a rigorous benchmark of LLM agents' forecasting capability and reliability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0170#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0171-6c4d33b48f", "paper_id": "P0171", "bibkey": "Bulusu2024Mathviz", "title": "MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we present a case-study where we examine these issues in the context of a specific domain.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0171-b9de76d922", "paper_id": "P0171", "bibkey": "Bulusu2024Mathviz", "title": "MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "While some promising results have been obtained, application to specific domains raises several general issues including the control of specialized domain tools, the lack of existing datasets for training and evaluation, and the non-triviality of automated system evaluation and improvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0171-67a872a390", "paper_id": "P0171", "bibkey": "Bulusu2024Mathviz", "title": "MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "There has been significant recent interest in harnessing LLMs to control software systems through multi-step reasoning, planning and tool-usage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0171-2fe7483cf9", "paper_id": "P0171", "bibkey": "Bulusu2024Mathviz", "title": "MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While some promising results have been obtained, application to specific domains raises several general issues including the control of specialized domain tools, the lack of existing datasets for training and evaluation, and the non-triviality of automated system evaluation and improvement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0171-f5a5cb6373", "paper_id": "P0171", "bibkey": "Bulusu2024Mathviz", "title": "MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we present a case-study where we examine these issues in the context of a specific domain.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0171#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0172-897768f5f2", "paper_id": "P0172", "bibkey": "Tennant2024Moral", "title": "Moral Alignment for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, instead of relying on human feedback, we introduce the design of reward functions that explicitly and transparently encode core human values for Reinforcement Learning-based fine-tuning of foundation agent models.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0172-54979d1734", "paper_id": "P0172", "bibkey": "Tennant2024Moral", "title": "Moral Alignment for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "As LLM-based systems become more agentic, their influence on human activity will grow and their transparency will decrease.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0172-820bbc36f5", "paper_id": "P0172", "bibkey": "Tennant2024Moral", "title": "Moral Alignment for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Decision-making agents based on pre-trained Large Language Models (LLMs) are increasingly being deployed across various domains of human activity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0172-f79fc25c23", "paper_id": "P0172", "bibkey": "Tennant2024Moral", "title": "Moral Alignment for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Decision-making agents based on pre-trained Large Language Models (LLMs) are increasingly being deployed across various domains of human activity.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0172-cc33b151e2", "paper_id": "P0172", "bibkey": "Tennant2024Moral", "title": "Moral Alignment for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While their applications are currently rather specialized, several research efforts are underway to develop more generalist agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0172-506edbe053", "paper_id": "P0172", "bibkey": "Tennant2024Moral", "title": "Moral Alignment for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "As LLM-based systems become more agentic, their influence on human activity will grow and their transparency will decrease.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0172#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0173-d075606615", "paper_id": "P0173", "bibkey": "Gu2024Mutual", "title": "Mutual Enhancement of Large Language and Reinforcement Learning Models through Bi-Directional Feedback Mechanisms: A Planning Case Study", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Remarkably, we propose a practical algorithm to address the problem and conduct empirical experiments to evaluate the effectiveness of our method.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0173-18a9ccbe15", "paper_id": "P0173", "bibkey": "Gu2024Mutual", "title": "Mutual Enhancement of Large Language and Reinforcement Learning Models through Bi-Directional Feedback Mechanisms: A Planning Case Study", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Remarkably, we propose a practical algorithm to address the problem and conduct empirical experiments to evaluate the effectiveness of our method.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0173-a239a381db", "paper_id": "P0173", "bibkey": "Gu2024Mutual", "title": "Mutual Enhancement of Large Language and Reinforcement Learning Models through Bi-Directional Feedback Mechanisms: A Planning Case Study", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) have demonstrated remarkable capabilities for reinforcement learning (RL) models, such as planning and reasoning capabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0173-4dc7d8765f", "paper_id": "P0173", "bibkey": "Gu2024Mutual", "title": "Mutual Enhancement of Large Language and Reinforcement Learning Models through Bi-Directional Feedback Mechanisms: A Planning Case Study", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the problems of LLMs and RL model collaboration still need to be solved.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0173-d51f0c02f9", "paper_id": "P0173", "bibkey": "Gu2024Mutual", "title": "Mutual Enhancement of Large Language and Reinforcement Learning Models through Bi-Directional Feedback Mechanisms: A Planning Case Study", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this study, we employ a teacher-student learning framework to tackle these problems, specifically by offering feedback for LLMs using RL models and providing high-level information for RL models with LLMs in a cooperative multi-agent setting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0173#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0174-9ddfe66c2a", "paper_id": "P0174", "bibkey": "Yuan2024Judge", "title": "R-Judge: Benchmarking Safety Risk Awareness for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce R-Judge, a benchmark crafted to evaluate the proficiency of LLMs in judging and identifying safety risks given agent interaction records.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0174-c9f8ee0e0e", "paper_id": "P0174", "bibkey": "Yuan2024Judge", "title": "R-Judge: Benchmarking Safety Risk Awareness for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Evaluation of 11 LLMs on R-Judge shows considerable room for enhancing the risk awareness of LLMs: The best-performing model, GPT-4o, achieves 74.42% while no other models significantly exceed the random.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0174-250ffb0ee6", "paper_id": "P0174", "bibkey": "Yuan2024Judge", "title": "R-Judge: Benchmarking Safety Risk Awareness for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "R-Judge comprises 569 records of multi-turn agent interaction, encompassing 27 key risk scenarios among 5 application categories and 10 risk types.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0174-896a6b9a0b", "paper_id": "P0174", "bibkey": "Yuan2024Judge", "title": "R-Judge: Benchmarking Safety Risk Awareness for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) have exhibited great potential in autonomously completing tasks across real-world applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0174-b95ab584cb", "paper_id": "P0174", "bibkey": "Yuan2024Judge", "title": "R-Judge: Benchmarking Safety Risk Awareness for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite this, these LLM agents introduce unexpected safety risks when operating in interactive environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0174-687819f62f", "paper_id": "P0174", "bibkey": "Yuan2024Judge", "title": "R-Judge: Benchmarking Safety Risk Awareness for LLM Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Instead of centering on the harmlessness of LLM-generated content in most prior studies, this work addresses the imperative need for benchmarking the behavioral safety of LLM agents within diverse environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0174#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0175-4da5c15a6a", "paper_id": "P0175", "bibkey": "Zhou2024Star", "title": "Star-Agents: Automatic Data Optimization with LLM Agents for Instruction Tuning", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "To mitigate this issue, we propose a novel Star-Agents framework, which automates the enhancement of data quality across datasets through multi-agent collaboration and assessment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0175-2d7736fc46", "paper_id": "P0175", "bibkey": "Zhou2024Star", "title": "Star-Agents: Automatic Data Optimization with LLM Agents for Instruction Tuning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Optimized datasets have achieved substantial improvements, with an average increase of 12% and notable gains in specific metrics, such as a 40% improvement in Fermi, as evidenced by benchmarks like MT-bench, Vicuna bench, and WizardLM testset.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0175-fe3f0d32b8", "paper_id": "P0175", "bibkey": "Zhou2024Star", "title": "Star-Agents: Automatic Data Optimization with LLM Agents for Instruction Tuning", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "To mitigate this issue, we propose a novel Star-Agents framework, which automates the enhancement of data quality across datasets through multi-agent collaboration and assessment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0175-8ab4c2ae53", "paper_id": "P0175", "bibkey": "Zhou2024Star", "title": "Star-Agents: Automatic Data Optimization with LLM Agents for Instruction Tuning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The efficacy of large language models (LLMs) on downstream tasks usually hinges on instruction tuning, which relies critically on the quality of training data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0175-b2dcdcc1b8", "paper_id": "P0175", "bibkey": "Zhou2024Star", "title": "Star-Agents: Automatic Data Optimization with LLM Agents for Instruction Tuning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unfortunately, collecting high-quality and diverse data is both expensive and time-consuming.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0175-313bbbf617", "paper_id": "P0175", "bibkey": "Zhou2024Star", "title": "Star-Agents: Automatic Data Optimization with LLM Agents for Instruction Tuning", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To mitigate this issue, we propose a novel Star-Agents framework, which automates the enhancement of data quality across datasets through multi-agent collaboration and assessment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0175#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0176-73dbd22d64", "paper_id": "P0176", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose PDoctor, a novel and automated approach to testing LLM agents and understanding their erroneous planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0176-c0a98eb625", "paper_id": "P0176", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate PDoctor with three mainstream agent frameworks and two powerful LLMs (GPT-3.5 and GPT-4).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0176-8d0f2cdb4c", "paper_id": "P0176", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Agents based on large language models (LLMs) have demonstrated effectiveness in solving a wide range of tasks by integrating LLMs with key modules such as planning, memory, and tool usage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0176-2b0e1946ce", "paper_id": "P0176", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Increasingly, customers are adopting LLM agents across a variety of commercial applications critical to reliability, including support for mental well-being, chemical synthesis, and software development.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0176-dc0110cb08", "paper_id": "P0176", "bibkey": "Ji2024Testing", "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Nevertheless, our observations and daily use of LLM agents indicate that they are prone to making erroneous plans, especially when the tasks are complex and require long-term planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0176#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0177-586b799cd4", "paper_id": "P0177", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Inspired by the rapid development of Large Language Models (LLMs), LLM agents have evolved to perform complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0177-302bb87ff0", "paper_id": "P0177", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "By highlighting these critical security and privacy issues, the survey seeks to stimulate future research towards enhancing the security and privacy of LLM agents, thereby increasing their reliability and trustworthiness in future applications.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0177-45ed2b5dca", "paper_id": "P0177", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Inspired by the rapid development of Large Language Models (LLMs), LLM agents have evolved to perform complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0177-36598f95c7", "paper_id": "P0177", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM agents are now extensively applied across various domains, handling vast amounts of data to interact with humans and execute tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0177-55ac1d8361", "paper_id": "P0177", "bibkey": "He2024Emerged", "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The widespread applications of LLM agents demonstrate their significant commercial value; however, they also expose security and privacy vulnerabilities.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0177#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0178-f9b2ea959c", "paper_id": "P0178", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce the Personal Health Insights Agent (PHIA), a system leveraging multistep reasoning with code generation and information retrieval to analyze and interpret behavioral health data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0178-0c25e2cfae", "paper_id": "P0178", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "To test its capabilities, we create and share two benchmark datasets with over 4000 health insights questions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0178-684ec790a0", "paper_id": "P0178", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "A 650-hour human expert evaluation shows that PHIA significantly outperforms a strong code generation baseline, achieving 84% accuracy on objective, numerical questions and, for open-ended ones, earning 83% favorable ratings while being twice as likely to achieve the highest quality rating.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0178-9cb70a9328", "paper_id": "P0178", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Deriving personalized insights from popular wearable trackers requires complex numerical reasoning that challenges standard LLMs, necessitating tool-based approaches like code generation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0178-6e25a922c0", "paper_id": "P0178", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents present a promising yet largely untapped solution for this analysis at scale.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0178-1dd8f714cc", "paper_id": "P0178", "bibkey": "Merrill2024Transforming", "title": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce the Personal Health Insights Agent (PHIA), a system leveraging multistep reasoning with code generation and information retrieval to analyze and interpret behavioral health data.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0178#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0179-8a24177f0d", "paper_id": "P0179", "bibkey": "Koh2024Tree", "title": "Tree Search for Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Towards addressing this, we propose an inference-time search algorithm for LM agents to explicitly perform exploration and multi-step planning in interactive web environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0179-dda831f033", "paper_id": "P0179", "bibkey": "Koh2024Tree", "title": "Tree Search for Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "On the challenging VisualWebArena benchmark, applying our search algorithm on top of a GPT-4o agent yields a 39.7% relative increase in success rate compared to the same baseline without search, setting a state-of-the-art success rate of 26.4%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0179-d1bf785256", "paper_id": "P0179", "bibkey": "Koh2024Tree", "title": "Tree Search for Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "On WebArena, search also yields a 28.0% relative improvement over a baseline agent, setting a competitive success rate of 19.2%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0179-345753c8cd", "paper_id": "P0179", "bibkey": "Koh2024Tree", "title": "Tree Search for Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Autonomous agents powered by language models (LMs) have demonstrated promise in their ability to perform decision-making tasks such as web automation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0179-c0b0635e9a", "paper_id": "P0179", "bibkey": "Koh2024Tree", "title": "Tree Search for Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, a key limitation remains: LMs, primarily optimized for natural language understanding and generation, struggle with multi-step reasoning, planning, and using environmental feedback when attempting to solve realistic computer tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0179-d0b8268675", "paper_id": "P0179", "bibkey": "Koh2024Tree", "title": "Tree Search for Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Towards addressing this, we propose an inference-time search algorithm for LM agents to explicitly perform exploration and multi-step planning in interactive web environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0179-bb5feb005c", "paper_id": "P0179", "bibkey": "Koh2024Tree", "title": "Tree Search for Language Model Agents", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "However, a key limitation remains: LMs, primarily optimized for natural language understanding and generation, struggle with multi-step reasoning, planning, and using environmental feedback when attempting to solve realistic computer tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0179#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0180-f890e6a573", "paper_id": "P0180", "bibkey": "Ning2024Urbankgent", "title": "UrbanKGent: A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Moreover, we propose a tool-augmented iterative trajectory refinement module to enhance and refine the trajectories distilled from GPT-4.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#method"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0180-67eb7c9ffa", "paper_id": "P0180", "bibkey": "Ning2024Urbankgent", "title": "UrbanKGent: A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "We perform a comprehensive evaluation on two real-world datasets using both human and GPT-4 self-evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0180-7842d2eb9a", "paper_id": "P0180", "bibkey": "Ning2024Urbankgent", "title": "UrbanKGent: A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "The experimental results demonstrate that UrbanKGent family can not only significantly outperform 31 baselines in UrbanKGC tasks, but also surpass the state-of-the-art LLM, GPT-4, by more than 10% with approximately 20 times lower cost.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0180-cdaf65c17b", "paper_id": "P0180", "bibkey": "Ning2024Urbankgent", "title": "UrbanKGent: A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Urban knowledge graph has recently worked as an emerging building block to distill critical knowledge from multi-sourced urban data for diverse urban application scenarios.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0180-c793982fff", "paper_id": "P0180", "bibkey": "Ning2024Urbankgent", "title": "UrbanKGent: A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite its promising benefits, urban knowledge graph construction (UrbanKGC) still heavily relies on manual effort, hindering its potential advancement.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0180-b40850e8cb", "paper_id": "P0180", "bibkey": "Ning2024Urbankgent", "title": "UrbanKGent: A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper presents UrbanKGent, a unified large language model agent framework, for urban knowledge graph construction.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0180#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0181-4ff7fcb1fb", "paper_id": "P0181", "bibkey": "Kim2024When", "title": "When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs", "year": 2024, "evidence_level": "abstract", "claim_type": "method", "snippet": "Recent advancements in Large Language Models (LLMs) have established them as agentic systems capable of planning and interacting with various tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0181-37b9602feb", "paper_id": "P0181", "bibkey": "Kim2024When", "title": "When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Specifically, we aim to understand: 1) how potent LLM agents can be when directed to conduct cyberattacks, 2) how cyberattacks are enhanced by web-based tools, and 3) how affordable and easy it becomes to launch cyberattacks using LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "security", "tooling"]}
{"evidence_id": "E-P0181-03cd6dab82", "paper_id": "P0181", "bibkey": "Kim2024When", "title": "When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs", "year": 2024, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiments reveal the effectiveness of LLM agents in these attacks: LLM agents achieved a precision of up to 95.9% in collecting PII, generated impersonation posts where 93.9% of them were deemed authentic, and boosted click rate of phishing links in spear phishing emails by 46.67%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#key_results[1]"}, "confidence": "medium", "tags": ["numbers", "security"]}
{"evidence_id": "E-P0181-8748fdbbe8", "paper_id": "P0181", "bibkey": "Kim2024When", "title": "When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advancements in Large Language Models (LLMs) have established them as agentic systems capable of planning and interacting with various tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0181-ff5d5e8f4c", "paper_id": "P0181", "bibkey": "Kim2024When", "title": "When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These LLM agents are often paired with web-based tools, enabling access to diverse sources and real-time information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0181-1e33ca04c3", "paper_id": "P0181", "bibkey": "Kim2024When", "title": "When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs", "year": 2024, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Although these advancements offer significant benefits across various applications, they also increase the risk of malicious use, particularly in cyberattacks involving personal information.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0181-03f4e0cdc0", "paper_id": "P0181", "bibkey": "Kim2024When", "title": "When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs", "year": 2024, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Additionally, our findings underscore the limitations of existing safeguards in contemporary commercial LLMs, emphasizing the urgent need for robust security measures to prevent the misuse of LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0181#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0182-94cef54f31", "paper_id": "P0182", "bibkey": "Ma2023Large", "title": "Large Language Models Play StarCraft II: Benchmarks and A Chain of Summarization Approach", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "Secondly, we propose a Chain of Summarization method, including single frame summarization for processing raw observations and multi frame summarization for analyzing game information, providing command recommendations, and generating strategic decisions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0182-ad2b2ab52b", "paper_id": "P0182", "bibkey": "Ma2023Large", "title": "Large Language Models Play StarCraft II: Benchmarks and A Chain of Summarization Approach", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our experiment consists of two parts: first, an evaluation by human experts, which includes assessing the LLMs`s mastery of StarCraft II knowledge and the performance of LLM agents in the game; second, the in game performance of LLM agents, encompassing aspects like win rate and the impact of Chain of Summarization.Experiment results demonstrate that: 1.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0182-0aa29003e4", "paper_id": "P0182", "bibkey": "Ma2023Large", "title": "Large Language Models Play StarCraft II: Benchmarks and A Chain of Summarization Approach", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Human experts consider the performance of LLM agents to be close to that of an average player who has played StarCraft II for eight years; 3.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0182-fdc650bf59", "paper_id": "P0182", "bibkey": "Ma2023Large", "title": "Large Language Models Play StarCraft II: Benchmarks and A Chain of Summarization Approach", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "StarCraft II is a challenging benchmark for AI agents due to the necessity of both precise micro level operations and strategic macro awareness.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0182-0cae5ba1ab", "paper_id": "P0182", "bibkey": "Ma2023Large", "title": "Large Language Models Play StarCraft II: Benchmarks and A Chain of Summarization Approach", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Previous works, such as Alphastar and SCC, achieve impressive performance on tackling StarCraft II , however, still exhibit deficiencies in long term strategic planning and strategy interpretability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0182-330735dcb8", "paper_id": "P0182", "bibkey": "Ma2023Large", "title": "Large Language Models Play StarCraft II: Benchmarks and A Chain of Summarization Approach", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Emerging large language model (LLM) agents, such as Voyage and MetaGPT, presents the immense potential in solving intricate tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0182#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0183-9f1b322ecd", "paper_id": "P0183", "bibkey": "Wu2023Mathchat", "title": "MathChat: Converse to Tackle Challenging Math Problems with LLM Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we study the effectiveness of utilizing LLM agents to solve math problems through conversations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0183-c4062ed891", "paper_id": "P0183", "bibkey": "Wu2023Mathchat", "title": "MathChat: Converse to Tackle Challenging Math Problems with LLM Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "Utilizing Python, we show that MathChat can further improve previous tool-using prompting methods by 6%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0183-8b972f6293", "paper_id": "P0183", "bibkey": "Wu2023Mathchat", "title": "MathChat: Converse to Tackle Challenging Math Problems with LLM Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "result", "snippet": "We perform evaluation on difficult high school competition problems from the MATH dataset.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0183-334e770aa5", "paper_id": "P0183", "bibkey": "Wu2023Mathchat", "title": "MathChat: Converse to Tackle Challenging Math Problems with LLM Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Employing Large Language Models (LLMs) to address mathematical problems is an intriguing research endeavor, considering the abundance of math problems expressed in natural language across numerous science and engineering fields.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0183-d01226dced", "paper_id": "P0183", "bibkey": "Wu2023Mathchat", "title": "MathChat: Converse to Tackle Challenging Math Problems with LLM Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLMs, with their generalized ability, are used as a foundation model to build AI agents for different tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0183-ca2f4f693a", "paper_id": "P0183", "bibkey": "Wu2023Mathchat", "title": "MathChat: Converse to Tackle Challenging Math Problems with LLM Agents", "year": 2023, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we study the effectiveness of utilizing LLM agents to solve math problems through conversations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0183#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0184-7c15c56e3a", "paper_id": "P0184", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "Large Language Model (LLM) agents struggle with long-horizon software engineering tasks due to \"Context Bloat.\" As interaction history grows, computational costs explode, latency increases, and reasoning capabilities degrade due to distraction by irrelevant past errors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0184-c411c6caee", "paper_id": "P0184", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "With aggressive prompting that encourages frequent compression, Focus achieves 22.7% token reduction (14.9M -> 11.5M tokens) while maintaining identical accuracy (3/5 = 60% for both agents).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0184-9abcf1bf8a", "paper_id": "P0184", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0184-a0e592a756", "paper_id": "P0184", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents struggle with long-horizon software engineering tasks due to \"Context Bloat.\" As interaction history grows, computational costs explode, latency increases, and reasoning capabilities degrade due to distraction by irrelevant past errors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0184-5a68f5562b", "paper_id": "P0184", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing solutions often rely on passive, external summarization mechanisms that the agent cannot control.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0184-0323bf5e7e", "paper_id": "P0184", "bibkey": "Verma2026Active", "title": "Active Context Compression: Autonomous Memory Management in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper proposes Focus, an agent-centric architecture inspired by the biological exploration strategies of Physarum polycephalum (slime mold).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0184#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0185-844ca49812", "paper_id": "P0185", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we propose Agentic Memory (AgeMem), a unified framework that integrates LTM and STM management directly into the agent's policy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0185-f0f0faaada", "paper_id": "P0185", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0185-ee162c208a", "paper_id": "P0185", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0185-47a5ff21e4", "paper_id": "P0185", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing methods typically handle long-term memory (LTM) and short-term memory (STM) as separate components, relying on heuristics or auxiliary controllers, which limits adaptability and end-to-end optimization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0185-d71204699d", "paper_id": "P0185", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we propose Agentic Memory (AgeMem), a unified framework that integrates LTM and STM management directly into the agent's policy.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0185-8b5ccf3d93", "paper_id": "P0185", "bibkey": "Yu2026Agentic", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0185#limitations[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0186-c507882fa4", "paper_id": "P0186", "bibkey": "Shi2026Coordinated", "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this challenge, here we propose a large language model (LLM) multi-agent policymaking framework that supports coordinated and proactive pandemic control across regions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0186-b3c223d2ce", "paper_id": "P0186", "bibkey": "Shi2026Coordinated", "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We validate the proposed framework using state-level COVID-19 data from the United States between April and December 2020, together with real-world mobility records and observed policy interventions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0186-ce9f280af3", "paper_id": "P0186", "bibkey": "Shi2026Coordinated", "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Compared with real-world pandemic outcomes, our approach reduces cumulative infections and deaths by up to 63.7% and 40.1%, respectively, at the individual state level, and by 39.0% and 27.0%, respectively, when aggregated across states.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0186-eafc535ff9", "paper_id": "P0186", "bibkey": "Shi2026Coordinated", "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Effective pandemic control requires timely and coordinated policymaking across administrative regions that are intrinsically interdependent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0186-8c5cff0583", "paper_id": "P0186", "bibkey": "Shi2026Coordinated", "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, human-driven responses are often fragmented and reactive, with policies formulated in isolation and adjusted only after outbreaks escalate, undermining proactive intervention and global pandemic mitigation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0186-173e9a41ed", "paper_id": "P0186", "bibkey": "Shi2026Coordinated", "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this challenge, here we propose a large language model (LLM) multi-agent policymaking framework that supports coordinated and proactive pandemic control across regions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0186#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0187-3308721ec0", "paper_id": "P0187", "bibkey": "Lin2026Froav", "title": "FROAV: A Framework for RAG Observation and Agent Verification -- Lowering the Barrier to LLM Agent Research", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present FROAV (Framework for RAG Observation and Agent Verification), an open-source research platform that democratizes LLM agent research by providing a plug-and-play architecture combining visual workflow orchestration, a comprehensive evaluation framework, and extensible Python integration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#method"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0187-048b8b704f", "paper_id": "P0187", "bibkey": "Lin2026Froav", "title": "FROAV: A Framework for RAG Observation and Agent Verification -- Lowering the Barrier to LLM Agent Research", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We present FROAV (Framework for RAG Observation and Agent Verification), an open-source research platform that democratizes LLM agent research by providing a plug-and-play architecture combining visual workflow orchestration, a comprehensive evaluation framework, and extensible Python integration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0187-db4213c234", "paper_id": "P0187", "bibkey": "Lin2026Froav", "title": "FROAV: A Framework for RAG Observation and Agent Verification -- Lowering the Barrier to LLM Agent Research", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "FROAV implements a multi-stage Retrieval-Augmented Generation (RAG) pipeline coupled with a rigorous \"LLM-as-a-Judge\" evaluation system, all accessible through intuitive graphical interfaces.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0187-3a65598ad5", "paper_id": "P0187", "bibkey": "Lin2026Froav", "title": "FROAV: A Framework for RAG Observation and Agent Verification -- Lowering the Barrier to LLM Agent Research", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The rapid advancement of Large Language Models (LLMs) and their integration into autonomous agent systems has created unprecedented opportunities for document analysis, decision support, and knowledge retrieval.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0187-7d002cb713", "paper_id": "P0187", "bibkey": "Lin2026Froav", "title": "FROAV: A Framework for RAG Observation and Agent Verification -- Lowering the Barrier to LLM Agent Research", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the complexity of developing, evaluating, and iterating on LLM-based agent workflows presents significant barriers to researchers, particularly those without extensive software engineering expertise.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0187-5fcf17cb87", "paper_id": "P0187", "bibkey": "Lin2026Froav", "title": "FROAV: A Framework for RAG Observation and Agent Verification -- Lowering the Barrier to LLM Agent Research", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present FROAV (Framework for RAG Observation and Agent Verification), an open-source research platform that democratizes LLM agent research by providing a plug-and-play architecture combining visual workflow orchestration, a comprehensive evaluation framework, and extensible Python integration.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0187#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0188-d5d54223d4", "paper_id": "P0188", "bibkey": "Quan2026Inferring", "title": "Inferring Latent Intentions: Attributional Natural Language Inference in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we introduce Attributional NLI (Att-NLI), a framework that extends NLI with principles from social psychology to assess an agent's capacity for abductive intentional inference (generating hypotheses about latent intentions), and subsequent deductive verification (drawing valid logical conclusions).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0188-c1df074e24", "paper_id": "P0188", "bibkey": "Quan2026Inferring", "title": "Inferring Latent Intentions: Attributional Natural Language Inference in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments demonstrate a clear hierarchy of attributional inference capabilities, with neuro-symbolic agents consistently outperforming others, achieving an average win rate of 17.08%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0188-16a8f0e24f", "paper_id": "P0188", "bibkey": "Quan2026Inferring", "title": "Inferring Latent Intentions: Attributional Natural Language Inference in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Attributional inference, the ability to predict latent intentions behind observed actions, is a critical yet underexplored capability for large language models (LLMs) operating in multi-agent environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0188-549f636257", "paper_id": "P0188", "bibkey": "Quan2026Inferring", "title": "Inferring Latent Intentions: Attributional Natural Language Inference in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional natural language inference (NLI), in fact, fails to capture the nuanced, intention-driven reasoning essential for complex interactive systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0188-0384a37514", "paper_id": "P0188", "bibkey": "Quan2026Inferring", "title": "Inferring Latent Intentions: Attributional Natural Language Inference in LLM Agents", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, we introduce Attributional NLI (Att-NLI), a framework that extends NLI with principles from social psychology to assess an agent's capacity for abductive intentional inference (generating hypotheses about latent intentions), and subsequent deductive verification (drawing valid logical conclusions).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0188#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0189-3d8779213d", "paper_id": "P0189", "bibkey": "Liang2026Large", "title": "LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "Along the way, we introduce Large-Scale-OR and Air-NRM, the first comprehensive benchmarks for large-scale optimization auto-formulation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0189-e77fe1ec3a", "paper_id": "P0189", "bibkey": "Liang2026Large", "title": "LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive simulations show that LEAN-LLM-OPT, instantiated with GPT-4.1 and the open source gpt-oss-20B, achieves strong performance on large-scale optimization modeling tasks and is competitive with state-of-the-art approaches.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0189-ebf6a9a093", "paper_id": "P0189", "bibkey": "Liang2026Large", "title": "LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "LEAN-LLM-OPT takes as input a problem description together with associated datasets and orchestrates a team of LLM agents to produce an optimization formulation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0189-be1a2ea705", "paper_id": "P0189", "bibkey": "Liang2026Large", "title": "LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large-scale optimization is a key backbone of modern business decision-making.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0189-4cbb7b8211", "paper_id": "P0189", "bibkey": "Liang2026Large", "title": "LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, building these models is often labor-intensive and time-consuming.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0189-b9021197b2", "paper_id": "P0189", "bibkey": "Liang2026Large", "title": "LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We address this by proposing LEAN-LLM-OPT, a LightwEight AgeNtic workflow construction framework for LLM-assisted large-scale OPTimization auto-formulation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0189#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0190-0ce10363d2", "paper_id": "P0190", "bibkey": "Li2026Longda", "title": "LongDA: Benchmarking LLM Agents for Long-Document Data Analysis", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce LongDA, a data analysis benchmark for evaluating LLM-based agents under documentation-intensive analytical workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0190-4e38fa0663", "paper_id": "P0190", "bibkey": "Li2026Longda", "title": "LongDA: Benchmarking LLM Agents for Long-Document Data Analysis", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "To this end, we manually curate raw data files, long and heterogeneous documentation, and expert-written publications from 17 publicly available U.S.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0190-a28b9812b7", "paper_id": "P0190", "bibkey": "Li2026Longda", "title": "LongDA: Benchmarking LLM Agents for Long-Document Data Analysis", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "national surveys, from which we extract 505 analytical queries grounded in real analytical practice.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0190-e72428b813", "paper_id": "P0190", "bibkey": "Li2026Longda", "title": "LongDA: Benchmarking LLM Agents for Long-Document Data Analysis", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce LongDA, a data analysis benchmark for evaluating LLM-based agents under documentation-intensive analytical workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0190-b332dae21e", "paper_id": "P0190", "bibkey": "Li2026Longda", "title": "LongDA: Benchmarking LLM Agents for Long-Document Data Analysis", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In contrast to existing benchmarks that assume well-specified schemas and inputs, LongDA targets real-world settings in which navigating long documentation and complex data is the primary bottleneck.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "tooling"]}
{"evidence_id": "E-P0190-2fdba2309b", "paper_id": "P0190", "bibkey": "Li2026Longda", "title": "LongDA: Benchmarking LLM Agents for Long-Document Data Analysis", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To this end, we manually curate raw data files, long and heterogeneous documentation, and expert-written publications from 17 publicly available U.S.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0190#summary_bullets[2]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0191-83f58d53be", "paper_id": "P0191", "bibkey": "Liu2026What", "title": "What Do LLM Agents Know About Their World? Task2Quiz: A Paradigm for Studying Environment Understanding", "year": 2026, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we propose Task-to-Quiz (T2Q), a deterministic and automated evaluation paradigm designed to decouple task execution from world-state understanding.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0191-fa433175ad", "paper_id": "P0191", "bibkey": "Liu2026What", "title": "What Do LLM Agents Know About Their World? Task2Quiz: A Paradigm for Studying Environment Understanding", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "We instantiate this paradigm in T2QBench, a suite comprising 30 environments and 1,967 grounded QA pairs across multiple difficulty levels.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0191-5008a50f2e", "paper_id": "P0191", "bibkey": "Liu2026What", "title": "What Do LLM Agents Know About Their World? Task2Quiz: A Paradigm for Studying Environment Understanding", "year": 2026, "evidence_level": "abstract", "claim_type": "result", "snippet": "Current evaluation paradigms predominantly rely on trajectory-based metrics that measure task success, while failing to assess whether agents possess a grounded, transferable model of the environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0191-6cce599593", "paper_id": "P0191", "bibkey": "Liu2026What", "title": "What Do LLM Agents Know About Their World? Task2Quiz: A Paradigm for Studying Environment Understanding", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents have demonstrated remarkable capabilities in complex decision-making and tool-use tasks, yet their ability to generalize across varying environments remains a under-examined concern.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0191-c660e72731", "paper_id": "P0191", "bibkey": "Liu2026What", "title": "What Do LLM Agents Know About Their World? Task2Quiz: A Paradigm for Studying Environment Understanding", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current evaluation paradigms predominantly rely on trajectory-based metrics that measure task success, while failing to assess whether agents possess a grounded, transferable model of the environment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0191-69dcb13df0", "paper_id": "P0191", "bibkey": "Liu2026What", "title": "What Do LLM Agents Know About Their World? Task2Quiz: A Paradigm for Studying Environment Understanding", "year": 2026, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this gap, we propose Task-to-Quiz (T2Q), a deterministic and automated evaluation paradigm designed to decouple task execution from world-state understanding.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0191#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0192-dda4615952", "paper_id": "P0192", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this issue, we propose a multi-modal and automated scale bar detection and extraction framework that provides concurrent object detection, text detection and text recognition with a Large Language Model (LLM) agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0192-1b9b514b0a", "paper_id": "P0192", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The hybrid OCR system achieved 89% precision, 65% recall, and a 75% F1 score on the Auto-DG dataset, significantly outperforming several mainstream standalone engines, highlighting its reliability for scientific image analysis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0192-065ba24ce9", "paper_id": "P0192", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The proposed model demonstrates a strong performance in object detection and accurate localization with a precision of 100%, recall of 95.8%, and a mean Average Precision (mAP) of 99.2% at IoU=0.5 and 69.1% at IoU=0.5:0.95.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0192-a1b1baea2e", "paper_id": "P0192", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Microscopic characterizations, such as Scanning Electron Microscopy (SEM), are widely used in scientific research for visualizing and analyzing microstructures.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0192-b0095e0371", "paper_id": "P0192", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Determining the scale bars is an important first step of accurate SEM analysis; however, currently, it mainly relies on manual operations, which is both time-consuming and prone to errors.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0192-c7a327bc99", "paper_id": "P0192", "bibkey": "Chen2025Large", "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To address this issue, we propose a multi-modal and automated scale bar detection and extraction framework that provides concurrent object detection, text detection and text recognition with a Large Language Model (LLM) agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0192#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0193-c0abda8fb2", "paper_id": "P0193", "bibkey": "Hao2025Multi", "title": "A Multi-LLM-Agent-Based Framework for Economic and Public Policy Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "While previous research has often simulated heterogeneity by solely varying prompts, our approach harnesses the inherent variations in analytical capabilities across different LLMs to model agents with diverse cognitive traits.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0193-00a5820d21", "paper_id": "P0193", "bibkey": "Hao2025Multi", "title": "A Multi-LLM-Agent-Based Framework for Economic and Public Policy Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Using interest-income taxation as a case study, we demonstrate how the MLAB framework can simulate policy impacts across heterogeneous agents, offering a promising new direction for economic and public policy analysis by leveraging LLMs' human-like reasoning capabilities and computational power.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#key_results[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0193-b27c85fd40", "paper_id": "P0193", "bibkey": "Hao2025Multi", "title": "A Multi-LLM-Agent-Based Framework for Economic and Public Policy Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper pioneers a novel approach to economic and public policy analysis by leveraging multiple Large Language Models (LLMs) as heterogeneous artificial economic agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0193-194b4c941e", "paper_id": "P0193", "bibkey": "Hao2025Multi", "title": "A Multi-LLM-Agent-Based Framework for Economic and Public Policy Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We first evaluate five LLMs' economic decision-making capabilities in solving two-period consumption allocation problems under two distinct scenarios: with explicit utility functions and based on intuitive reasoning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0193-65dbb16c2f", "paper_id": "P0193", "bibkey": "Hao2025Multi", "title": "A Multi-LLM-Agent-Based Framework for Economic and Public Policy Analysis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While previous research has often simulated heterogeneity by solely varying prompts, our approach harnesses the inherent variations in analytical capabilities across different LLMs to model agents with diverse cognitive traits.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0193#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0194-68a5736843", "paper_id": "P0194", "bibkey": "Liu2025Vision", "title": "A Vision for Auto Research with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "This paper introduces Agent-Based Auto Research, a structured multi-agent framework designed to automate, coordinate, and optimize the full lifecycle of scientific research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0194-901fea9af8", "paper_id": "P0194", "bibkey": "Liu2025Vision", "title": "A Vision for Auto Research with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Preliminary explorations demonstrate the feasibility and potential of Auto Research as a promising paradigm for self-improving, AI-driven research processes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0194-5453130d7f", "paper_id": "P0194", "bibkey": "Liu2025Vision", "title": "A Vision for Auto Research with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper introduces Agent-Based Auto Research, a structured multi-agent framework designed to automate, coordinate, and optimize the full lifecycle of scientific research.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0194-dc817dc273", "paper_id": "P0194", "bibkey": "Liu2025Vision", "title": "A Vision for Auto Research with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Leveraging the capabilities of large language models (LLMs) and modular agent collaboration, the system spans all major research phases, including literature review, ideation, methodology planning, experimentation, paper writing, peer review response, and dissemination.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0194-87b0419eac", "paper_id": "P0194", "bibkey": "Liu2025Vision", "title": "A Vision for Auto Research with LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "By addressing issues such as fragmented workflows, uneven methodological expertise, and cognitive overload, the framework offers a systematic and scalable approach to scientific inquiry.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0194#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0195-db59925f0a", "paper_id": "P0195", "bibkey": "Xu2025Agentic", "title": "A-MEM: Agentic Memory for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0195-34d5bb96d5", "paper_id": "P0195", "bibkey": "Xu2025Agentic", "title": "A-MEM: Agentic Memory for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Empirical experiments on six foundation models show superior improvement against existing SOTA baselines.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0195-daa5981288", "paper_id": "P0195", "bibkey": "Xu2025Agentic", "title": "A-MEM: Agentic Memory for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0195-ffa60c172c", "paper_id": "P0195", "bibkey": "Xu2025Agentic", "title": "A-MEM: Agentic Memory for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0195-b7a054e876", "paper_id": "P0195", "bibkey": "Xu2025Agentic", "title": "A-MEM: Agentic Memory for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Moreover, these systems' fixed operations and structures limit their adaptability across diverse tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0195-ef3de0b06b", "paper_id": "P0195", "bibkey": "Xu2025Agentic", "title": "A-MEM: Agentic Memory for LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0195#limitations[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0196-90f1bae97e", "paper_id": "P0196", "bibkey": "Zhao2025Bench", "title": "AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we introduce AIM-Bench, a novel benchmark designed to assess the decision-making behaviour of LLM agents in uncertain supply chain management scenarios through a diverse series of inventory replenishment experiments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0196-9081719b90", "paper_id": "P0196", "bibkey": "Zhao2025Bench", "title": "AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To address this gap, we introduce AIM-Bench, a novel benchmark designed to assess the decision-making behaviour of LLM agents in uncertain supply chain management scenarios through a diverse series of inventory replenishment experiments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0196-6717f4183d", "paper_id": "P0196", "bibkey": "Zhao2025Bench", "title": "AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our results reveal that different LLMs typically exhibit varying degrees of decision bias that are similar to those observed in human beings.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0196-0b8d3c09ea", "paper_id": "P0196", "bibkey": "Zhao2025Bench", "title": "AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent advances in mathematical reasoning and the long-term planning capabilities of large language models (LLMs) have precipitated the development of agents, which are being increasingly leveraged in business operations processes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0196-da1612fb3a", "paper_id": "P0196", "bibkey": "Zhao2025Bench", "title": "AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Decision models to optimize inventory levels are one of the core elements of operations management.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0196-b2db5d2426", "paper_id": "P0196", "bibkey": "Zhao2025Bench", "title": "AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, the capabilities of the LLM agent in making inventory decisions in uncertain contexts, as well as the decision-making biases (e.g. framing effect, etc.) of the agent, remain largely unexplored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0196#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0197-25d83aae41", "paper_id": "P0197", "bibkey": "Chang2025Alas", "title": "ALAS: A Stateful Multi-LLM Agent Framework for Disruption-Aware Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present Adaptive LLM Agent System (ALAS), a framework that tackles four fundamental LLM deficits: (i) absence of self-verification, (ii) context erosion, (iii) next-token myopia, and (iv) lack of persistent state.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0197-2430cc2982", "paper_id": "P0197", "bibkey": "Chang2025Alas", "title": "ALAS: A Stateful Multi-LLM Agent Framework for Disruption-Aware Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On real-world, large-scale job-shop scheduling benchmarks, ALAS sets new best results for static sequential planning and excels in dynamic reactive scenarios with unexpected disruptions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0197-9070b15143", "paper_id": "P0197", "bibkey": "Chang2025Alas", "title": "ALAS: A Stateful Multi-LLM Agent Framework for Disruption-Aware Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) excel at rapid generation of text and multimodal content, yet they falter on transaction-style planning that demands ACID-like guarantees and real-time disruption recovery.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0197-8947291d0c", "paper_id": "P0197", "bibkey": "Chang2025Alas", "title": "ALAS: A Stateful Multi-LLM Agent Framework for Disruption-Aware Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present Adaptive LLM Agent System (ALAS), a framework that tackles four fundamental LLM deficits: (i) absence of self-verification, (ii) context erosion, (iii) next-token myopia, and (iv) lack of persistent state.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0197-4c1e845103", "paper_id": "P0197", "bibkey": "Chang2025Alas", "title": "ALAS: A Stateful Multi-LLM Agent Framework for Disruption-Aware Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ALAS decomposes each plan into role-specialized agents, equips them with automatic state tracking, and coordinates them through a lightweight protocol.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0197#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0198-09dd90744f", "paper_id": "P0198", "bibkey": "Papadakis2025Atlas", "title": "ATLAS: Adaptive Trading with LLM AgentS Through Dynamic Prompt Optimization and Multi-Agent Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present ATLAS (Adaptive Trading with LLM AgentS), a unified multi-agent framework that integrates structured information from markets, news, and corporate fundamentals to support robust trading decisions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0198-0fa94ce9e7", "paper_id": "P0198", "bibkey": "Papadakis2025Atlas", "title": "ATLAS: Adaptive Trading with LLM AgentS Through Dynamic Prompt Optimization and Multi-Agent Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Across regime-specific equity studies and multiple LLM families, Adaptive-OPRO consistently outperforms fixed prompts, while reflection-based feedback fails to provide systematic gains.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0198-a89dbf51a8", "paper_id": "P0198", "bibkey": "Papadakis2025Atlas", "title": "ATLAS: Adaptive Trading with LLM AgentS Through Dynamic Prompt Optimization and Multi-Agent Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models show promise for financial decision-making, yet deploying them as autonomous trading agents raises fundamental challenges: how to adapt instructions when rewards arrive late and obscured by market noise, how to synthesize heterogeneous information streams into coherent decisions, and how to bridge the gap between model outputs and executable market actions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0198-5a23b5a9bf", "paper_id": "P0198", "bibkey": "Papadakis2025Atlas", "title": "ATLAS: Adaptive Trading with LLM AgentS Through Dynamic Prompt Optimization and Multi-Agent Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present ATLAS (Adaptive Trading with LLM AgentS), a unified multi-agent framework that integrates structured information from markets, news, and corporate fundamentals to support robust trading decisions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0198-2de81eb230", "paper_id": "P0198", "bibkey": "Papadakis2025Atlas", "title": "ATLAS: Adaptive Trading with LLM AgentS Through Dynamic Prompt Optimization and Multi-Agent Coordination", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Within ATLAS, the central trading agent operates in an order-aware action space, ensuring that outputs correspond to executable market orders rather than abstract signals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0198#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0199-aa40d7e98d", "paper_id": "P0199", "bibkey": "Zhao2025Achieving", "title": "Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To further accelerate learning, we introduce Complexity-Boosting Reinforcement Learning (CBRL), which gradually increases the complexity of synthesized problems across training stages.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0199-1063eee7ce", "paper_id": "P0199", "bibkey": "Zhao2025Achieving", "title": "Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0199-5f246d0ca8", "paper_id": "P0199", "bibkey": "Zhao2025Achieving", "title": "Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Built on InternThinker-32B, InternGeometry solves 44 of 50 IMO geometry problems (2000-2024), exceeding the average gold medalist score (40.9), using only 13K training examples, just 0.004% of the data used by AlphaGeometry 2, demonstrating the potential of LLM agents on expert-level geometry tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#key_results[1]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0199-ff3c076fa9", "paper_id": "P0199", "bibkey": "Zhao2025Achieving", "title": "Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents exhibit strong mathematical problem-solving abilities and can even solve International Mathematical Olympiad (IMO) level problems with the assistance of formal proof systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0199-1c82b6f221", "paper_id": "P0199", "bibkey": "Zhao2025Achieving", "title": "Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0199-261bcbe260", "paper_id": "P0199", "bibkey": "Zhao2025Achieving", "title": "Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we make the first attempt to build a medalist-level LLM agent for geometry and present InternGeometry.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0199-5d444f55d8", "paper_id": "P0199", "bibkey": "Zhao2025Achieving", "title": "Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "InternGeometry overcomes the heuristic limitations in geometry by iteratively proposing propositions and auxiliary constructions, verifying them with a symbolic engine, and reflecting on the engine's feedback to guide subsequent proposals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0199#limitations[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0200-ae5dc83229", "paper_id": "P0200", "bibkey": "Wang2025Adversarial", "title": "Adversarial Reinforcement Learning for Large Language Model Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this limitation, we propose Adversarial Reinforcement Learning for Agent Safety (ARLAS), a novel framework that leverages adversarial reinforcement learning (RL) by formulating the problem as a two-player zero-sum game.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0200-8512d7eecf", "paper_id": "P0200", "bibkey": "Wang2025Adversarial", "title": "Adversarial Reinforcement Learning for Large Language Model Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Current defense strategies typically rely on fine-tuning LLM agents on datasets of known attacks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "security"]}
{"evidence_id": "E-P0200-ee6f97d5e5", "paper_id": "P0200", "bibkey": "Wang2025Adversarial", "title": "Adversarial Reinforcement Learning for Large Language Model Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "However, the generation of these datasets relies on manually crafted attack patterns, which limits their diversity and leaves agents vulnerable to novel prompt injections.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "security"]}
{"evidence_id": "E-P0200-be292bbd5d", "paper_id": "P0200", "bibkey": "Wang2025Adversarial", "title": "Adversarial Reinforcement Learning for Large Language Model Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Model (LLM) agents can leverage tools such as Google Search to complete complex tasks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0200-4d5c0a16df", "paper_id": "P0200", "bibkey": "Wang2025Adversarial", "title": "Adversarial Reinforcement Learning for Large Language Model Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, this tool usage introduces the risk of indirect prompt injections, where malicious instructions hidden in tool outputs can manipulate the agent, posing security risks like data leakage.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#summary_bullets[1]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0200-1020ba50c5", "paper_id": "P0200", "bibkey": "Wang2025Adversarial", "title": "Adversarial Reinforcement Learning for Large Language Model Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current defense strategies typically rely on fine-tuning LLM agents on datasets of known attacks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "security"]}
{"evidence_id": "E-P0200-63d993dc7c", "paper_id": "P0200", "bibkey": "Wang2025Adversarial", "title": "Adversarial Reinforcement Learning for Large Language Model Agent Safety", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "To address this limitation, we propose Adversarial Reinforcement Learning for Agent Safety (ARLAS), a novel framework that leverages adversarial reinforcement learning (RL) by formulating the problem as a two-player zero-sum game.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0200#limitations[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0201-64407d3670", "paper_id": "P0201", "bibkey": "Cheng2025Agent", "title": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Secondly, we introduce Agent-R1, a modular, flexible, and user-friendly training framework for RL-based LLM Agents, designed for straightforward adaptation across diverse task scenarios and interactive environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0201-459806f5ee", "paper_id": "P0201", "bibkey": "Cheng2025Agent", "title": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We conducted experiments on Multihop QA benchmark tasks, providing initial validation for the effectiveness of our proposed methods and framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0201-7ef16b36af", "paper_id": "P0201", "bibkey": "Cheng2025Agent", "title": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large Language Models (LLMs) are increasingly being explored for building Agents capable of active environmental interaction (e.g., via tool use) to solve complex problems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0201-20d62d78d4", "paper_id": "P0201", "bibkey": "Cheng2025Agent", "title": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Reinforcement Learning (RL) is considered a key technology with significant potential for training such Agents; however, the effective application of RL to LLM Agents is still in its nascent stages and faces considerable challenges.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0201-d1e6d786e3", "paper_id": "P0201", "bibkey": "Cheng2025Agent", "title": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Currently, this emerging field lacks in-depth exploration into RL approaches specifically tailored for the LLM Agent context, alongside a scarcity of flexible and easily extensible training frameworks designed for this purpose.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0201#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0202-7f1fe7766c", "paper_id": "P0202", "bibkey": "Xi2025Agentprm", "title": "AgentPRM: Process Reward Models for LLM Agents via Step-Wise Promise and Progress", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Building on this insight, we propose a re-defined PRM for agent tasks, named AgentPRM, to capture both the interdependence between sequential decisions and their contribution to the final goal.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0202-08d94a4353", "paper_id": "P0202", "bibkey": "Xi2025Agentprm", "title": "AgentPRM: Process Reward Models for LLM Agents via Step-Wise Promise and Progress", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments across different agentic tasks show that AgentPRM is over $8\\times$ more compute-efficient than baselines, and it demonstrates robust improvement when scaling up test-time compute.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0202-96cc8b3161", "paper_id": "P0202", "bibkey": "Xi2025Agentprm", "title": "AgentPRM: Process Reward Models for LLM Agents via Step-Wise Promise and Progress", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite rapid development, large language models (LLMs) still encounter challenges in multi-turn decision-making tasks (i.e., agent tasks) like web shopping and browser navigation, which require making a sequence of intelligent decisions based on environmental feedback.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0202-2d59c63db3", "paper_id": "P0202", "bibkey": "Xi2025Agentprm", "title": "AgentPRM: Process Reward Models for LLM Agents via Step-Wise Promise and Progress", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Previous work for LLM agents typically relies on elaborate prompt engineering or fine-tuning with expert trajectories to improve performance.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0202-083fec1c29", "paper_id": "P0202", "bibkey": "Xi2025Agentprm", "title": "AgentPRM: Process Reward Models for LLM Agents via Step-Wise Promise and Progress", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we take a different perspective: we explore constructing process reward models (PRMs) to evaluate each decision and guide the agent's decision-making process.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0202#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0203-1355c1ade0", "paper_id": "P0203", "bibkey": "Horovicz2025Agentshap", "title": "AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We introduce AgentSHAP, the first framework for explaining tool importance in LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0203-e9686e9095", "paper_id": "P0203", "bibkey": "Horovicz2025Agentshap", "title": "AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our contributions are: (1) the first explainability method for agent tool attribution, grounded in Shapley values from game theory; (2) Monte Carlo sampling that reduces cost from O(2n) to practical levels; and (3) comprehensive experiments on API-Bank showing that AgentSHAP produces consistent scores across runs, correctly identifies which tools matter, and distinguishes relevant from irrelevant tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "tooling"]}
{"evidence_id": "E-P0203-666cd64891", "paper_id": "P0203", "bibkey": "Horovicz2025Agentshap", "title": "AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "LLM agents that use external tools can solve complex tasks, but understanding which tools actually contributed to a response remains a blind spot.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0203-fb83d2e00f", "paper_id": "P0203", "bibkey": "Horovicz2025Agentshap", "title": "AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "No existing XAI methods address tool-level explanations.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#summary_bullets[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0203-ab8125783d", "paper_id": "P0203", "bibkey": "Horovicz2025Agentshap", "title": "AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We introduce AgentSHAP, the first framework for explaining tool importance in LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0203#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0204-7a4b1d1117", "paper_id": "P0204", "bibkey": "Wang2025Agentvigil", "title": "AgentVigil: Generic Black-Box Red-teaming for Indirect Prompt Injection against LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this work, we propose a generic black-box fuzzing framework, AgentVigil, designed to automatically discover and exploit indirect prompt injection vulnerabilities across diverse LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0204-03ed8e82d6", "paper_id": "P0204", "bibkey": "Wang2025Agentvigil", "title": "AgentVigil: Generic Black-Box Red-teaming for Indirect Prompt Injection against LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We evaluate AgentVigil on two public benchmarks, AgentDojo and VWA-adv, where it achieves 71% and 70% success rates against agents based on o3-mini and GPT-4o, respectively, nearly doubling the performance of baseline attacks.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers", "security"]}
{"evidence_id": "E-P0204-f4f37d874a", "paper_id": "P0204", "bibkey": "Wang2025Agentvigil", "title": "AgentVigil: Generic Black-Box Red-teaming for Indirect Prompt Injection against LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Beyond benchmark evaluations, we apply our attacks in real-world environments, successfully misleading agents to navigate to arbitrary URLs, including malicious sites.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "security"]}
{"evidence_id": "E-P0204-1e6424e090", "paper_id": "P0204", "bibkey": "Wang2025Agentvigil", "title": "AgentVigil: Generic Black-Box Red-teaming for Indirect Prompt Injection against LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "The strong planning and reasoning capabilities of Large Language Models (LLMs) have fostered the development of agent-based systems capable of leveraging external tools and interacting with increasingly complex environments.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0204-ba2c8b6097", "paper_id": "P0204", "bibkey": "Wang2025Agentvigil", "title": "AgentVigil: Generic Black-Box Red-teaming for Indirect Prompt Injection against LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, these powerful features also introduce a critical security risk: indirect prompt injection, a sophisticated attack vector that compromises the core of these agents, the LLM, by manipulating contextual information rather than direct user prompts.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0204-1740a8e576", "paper_id": "P0204", "bibkey": "Wang2025Agentvigil", "title": "AgentVigil: Generic Black-Box Red-teaming for Indirect Prompt Injection against LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this work, we propose a generic black-box fuzzing framework, AgentVigil, designed to automatically discover and exploit indirect prompt injection vulnerabilities across diverse LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0204#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0205-003a387b7d", "paper_id": "P0205", "bibkey": "Liu2025Aligning", "title": "Aligning LLM agents with human learning and adjustment behavior: a dual agent approach", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Building on this, we introduce a novel dual-agent framework that enables continuous learning and alignment between LLM agents and human travelers on learning and adaptation behavior from online data streams.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0205-17093ccc31", "paper_id": "P0205", "bibkey": "Liu2025Aligning", "title": "Aligning LLM agents with human learning and adjustment behavior: a dual agent approach", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Effective modeling of how human travelers learn and adjust their travel behavior from interacting with transportation systems is critical for system assessment and planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0205-96cf9ff5bf", "paper_id": "P0205", "bibkey": "Liu2025Aligning", "title": "Aligning LLM agents with human learning and adjustment behavior: a dual agent approach", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Building on this, we introduce a novel dual-agent framework that enables continuous learning and alignment between LLM agents and human travelers on learning and adaptation behavior from online data streams.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0205-b3a6043ca0", "paper_id": "P0205", "bibkey": "Liu2025Aligning", "title": "Aligning LLM agents with human learning and adjustment behavior: a dual agent approach", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Effective modeling of how human travelers learn and adjust their travel behavior from interacting with transportation systems is critical for system assessment and planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0205-24355878fd", "paper_id": "P0205", "bibkey": "Liu2025Aligning", "title": "Aligning LLM agents with human learning and adjustment behavior: a dual agent approach", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, this task is also difficult due to the complex cognition and decision-making involved in such behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0205-5a2846c2f9", "paper_id": "P0205", "bibkey": "Liu2025Aligning", "title": "Aligning LLM agents with human learning and adjustment behavior: a dual agent approach", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent research has begun to leverage Large Language Model (LLM) agents for this task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0205#summary_bullets[2]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0206-a40f113c0a", "paper_id": "P0206", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To demonstrate and exploit this vulnerability, we propose the Attractive Metadata Attack (AMA), a black-box in-context learning framework that generates highly attractive but syntactically and semantically valid tool metadata through iterative optimization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#method"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0206-a0b404d928", "paper_id": "P0206", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Extensive experiments across ten realistic, simulated tool-use scenarios and a range of popular LLM agents demonstrate consistently high attack success rates (81\\%-95\\%) and significant privacy leakage, with negligible impact on primary task execution.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#key_results[0]"}, "confidence": "medium", "tags": ["numbers", "security", "tooling"]}
{"evidence_id": "E-P0206-00dc8ff622", "paper_id": "P0206", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language model (LLM) agents have demonstrated remarkable capabilities in complex reasoning and decision-making by leveraging external tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0206-38b7cc5d37", "paper_id": "P0206", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, this tool-centric paradigm introduces a previously underexplored attack surface, where adversaries can manipulate tool metadata -- such as names, descriptions, and parameter schemas -- to influence agent behavior.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#summary_bullets[1]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0206-b47df2ba00", "paper_id": "P0206", "bibkey": "Mo2025Attractive", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We identify this as a new and stealthy threat surface that allows malicious tools to be preferentially selected by LLM agents, without requiring prompt injection or access to model internals.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0206#summary_bullets[2]"}, "confidence": "medium", "tags": ["security", "tooling"]}
{"evidence_id": "E-P0207-a8851cf04f", "paper_id": "P0207", "bibkey": "Lan2025Autoqual", "title": "AutoQual: An LLM Agent for Automated Discovery of Interpretable Features for Review Quality Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address these challenges, we propose AutoQual, an LLM-based agent framework that automates the discovery of interpretable features.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0207-eee04db801", "paper_id": "P0207", "bibkey": "Lan2025Autoqual", "title": "AutoQual: An LLM Agent for Automated Discovery of Interpretable Features for Review Quality Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Large-scale A/B testing confirms its effectiveness, increasing average reviews viewed per user by 0.79% and the conversion rate of review readers by 0.27%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0207-b0e3db9547", "paper_id": "P0207", "bibkey": "Lan2025Autoqual", "title": "AutoQual: An LLM Agent for Automated Discovery of Interpretable Features for Review Quality Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "It mimics a human research process, iteratively generating feature hypotheses through reflection, operationalizing them via autonomous tool implementation, and accumulating experience in a persistent memory.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#key_results[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0207-03df73518b", "paper_id": "P0207", "bibkey": "Lan2025Autoqual", "title": "AutoQual: An LLM Agent for Automated Discovery of Interpretable Features for Review Quality Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Ranking online reviews by their intrinsic quality is a critical task for e-commerce platforms and information services, impacting user experience and business outcomes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0207-d5d6a63ed3", "paper_id": "P0207", "bibkey": "Lan2025Autoqual", "title": "AutoQual: An LLM Agent for Automated Discovery of Interpretable Features for Review Quality Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "However, quality is a domain-dependent and dynamic concept, making its assessment a formidable challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0207-c050ca017e", "paper_id": "P0207", "bibkey": "Lan2025Autoqual", "title": "AutoQual: An LLM Agent for Automated Discovery of Interpretable Features for Review Quality Assessment", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Traditional methods relying on hand-crafted features are unscalable across domains and fail to adapt to evolving content patterns, while modern deep learning approaches often produce black-box models that lack interpretability and may prioritize semantics over quality.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0207#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0208-f91113514e", "paper_id": "P0208", "bibkey": "Wang2025Automated", "title": "Automated Penetration Testing with LLM Agents and Classical Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we introduce the \"Planner-Executor-Perceptor (PEP)\" design paradigm and use it to systematically review existing work and identify the key challenges in this area.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0208-32aec6c669", "paper_id": "P0208", "bibkey": "Wang2025Automated", "title": "Automated Penetration Testing with LLM Agents and Classical Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation shows that CHECKMATE outperforms the state-of-the-art system (Claude Code) in penetration capability, improving benchmark success rates by over 20%.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0208-fe9d3fbb2c", "paper_id": "P0208", "bibkey": "Wang2025Automated", "title": "Automated Penetration Testing with LLM Agents and Classical Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The results show that the out-of-the-box Claude Code and Sonnet 4.5 exhibit superior penetration capabilities observed to date, substantially outperforming all prior systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0208-d75f33bc1c", "paper_id": "P0208", "bibkey": "Wang2025Automated", "title": "Automated Penetration Testing with LLM Agents and Classical Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While penetration testing plays a vital role in cybersecurity, achieving fully automated, hands-off-the-keyboard execution remains a significant research challenge.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0208-b67604206c", "paper_id": "P0208", "bibkey": "Wang2025Automated", "title": "Automated Penetration Testing with LLM Agents and Classical Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In this paper, we introduce the \"Planner-Executor-Perceptor (PEP)\" design paradigm and use it to systematically review existing work and identify the key challenges in this area.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0208-b0076c372a", "paper_id": "P0208", "bibkey": "Wang2025Automated", "title": "Automated Penetration Testing with LLM Agents and Classical Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We also evaluate existing penetration testing systems, with a particular focus on the use of Large Language Model (LLM) agents for this task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0208-4a55873ef2", "paper_id": "P0208", "bibkey": "Wang2025Automated", "title": "Automated Penetration Testing with LLM Agents and Classical Planning", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "However, a detailed analysis of their testing processes reveals specific strengths and limitations; notably, LLM agents struggle with maintaining coherent long-horizon plans, performing complex reasoning, and effectively utilizing specialized tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0208#limitations[1]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0209-09f2e56422", "paper_id": "P0209", "bibkey": "Nusrat2025Automated", "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#method"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0209-c6c63e4ab5", "paper_id": "P0209", "bibkey": "Nusrat2025Automated", "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) while reducing cochlear dose below human baselines (p = 0.022).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#key_results[0]"}, "confidence": "medium", "tags": ["memory", "numbers"]}
{"evidence_id": "E-P0209-71f2629f1b", "paper_id": "P0209", "bibkey": "Nusrat2025Automated", "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#key_results[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0209-a1ae33c16c", "paper_id": "P0209", "bibkey": "Nusrat2025Automated", "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0209-98affd04d7", "paper_id": "P0209", "bibkey": "Nusrat2025Automated", "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#summary_bullets[1]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0209-0f1a9aa069", "paper_id": "P0209", "bibkey": "Nusrat2025Automated", "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0209#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0210-bfdc4b5d5b", "paper_id": "P0210", "bibkey": "Li2025Biasinspector", "title": "BIASINSPECTOR: Detecting Bias in Structured Data through LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To address this gap, we introduce the first end-to-end, multi-agent synergy framework, BIASINSPECTOR, designed for automatic bias detection in structured data based on specific user requirements.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0210-81e4cb17fb", "paper_id": "P0210", "bibkey": "Li2025Biasinspector", "title": "BIASINSPECTOR: Detecting Bias in Structured Data through LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Existing automated techniques are limited in diversity of data types and heavily reliant on human case-by-case handling, resulting in a lack of generalizability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0210-762ca88517", "paper_id": "P0210", "bibkey": "Li2025Biasinspector", "title": "BIASINSPECTOR: Detecting Bias in Structured Data through LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To address the lack of a standardized framework for evaluating the capability of LLM agents to detect biases in data, we further propose a comprehensive benchmark that includes multiple evaluation metrics and a large set of test cases.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0210-28a14d2214", "paper_id": "P0210", "bibkey": "Li2025Biasinspector", "title": "BIASINSPECTOR: Detecting Bias in Structured Data through LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Detecting biases in structured data is a complex and time-consuming task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0210-87449f09d2", "paper_id": "P0210", "bibkey": "Li2025Biasinspector", "title": "BIASINSPECTOR: Detecting Bias in Structured Data through LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing automated techniques are limited in diversity of data types and heavily reliant on human case-by-case handling, resulting in a lack of generalizability.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0210-30f2c4c6b2", "paper_id": "P0210", "bibkey": "Li2025Biasinspector", "title": "BIASINSPECTOR: Detecting Bias in Structured Data through LLM Agents", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Currently, large language model (LLM)-based agents have made significant progress in data science, but their ability to detect data biases is still insufficiently explored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0210#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0211-05a5339ecb", "paper_id": "P0211", "bibkey": "Zhang2025Buildbench", "title": "BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose a more challenging and realistic benchmark, BUILD-BENCH, comprising OSS that are more diverse in quality, scale, and characteristics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0211-f78c5a452b", "paper_id": "P0211", "bibkey": "Zhang2025Buildbench", "title": "BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Recent attempts using Large Language Models (LLMs) used selective evaluation on a subset of highly rated OSS, a practice that underestimates the realistic challenges of OSS compilation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0211-be78d66353", "paper_id": "P0211", "bibkey": "Zhang2025Buildbench", "title": "BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We propose a more challenging and realistic benchmark, BUILD-BENCH, comprising OSS that are more diverse in quality, scale, and characteristics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0211-a00c8d6c19", "paper_id": "P0211", "bibkey": "Zhang2025Buildbench", "title": "BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Automatically compiling open-source software (OSS) projects is a vital, labor-intensive, and complex task, which makes it a good challenge for LLM Agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0211-bb8146a552", "paper_id": "P0211", "bibkey": "Zhang2025Buildbench", "title": "BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing methods rely on manually curated rules and workflows, which cannot adapt to OSS that requires customized configuration or environment setup.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0211-85e19d2e85", "paper_id": "P0211", "bibkey": "Zhang2025Buildbench", "title": "BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recent attempts using Large Language Models (LLMs) used selective evaluation on a subset of highly rated OSS, a practice that underestimates the realistic challenges of OSS compilation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0211#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0212-5e1cd49574", "paper_id": "P0212", "bibkey": "Yoo2025Capturing", "title": "Capturing Semantic Flow of ML-based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose semantic flow, a concept designed to capture the internal behaviour of ML-based system and to provide a platform for traditional dynamic analysis techniques to be adapted to.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0212-c0043b7144", "paper_id": "P0212", "bibkey": "Yoo2025Capturing", "title": "Capturing Semantic Flow of ML-based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We propose the idea of semantic flow, introduce two examples using a DNN and an LLM agent, and finally sketch its properties and how it can be used to adapt existing dynamic analysis techniques for use in ML-based software systems.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0212-4940733e42", "paper_id": "P0212", "bibkey": "Yoo2025Capturing", "title": "Capturing Semantic Flow of ML-based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ML-based systems are software systems that incorporates machine learning components such as Deep Neural Networks (DNNs) or Large Language Models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0212-381fa970d9", "paper_id": "P0212", "bibkey": "Yoo2025Capturing", "title": "Capturing Semantic Flow of ML-based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While such systems enable advanced features such as high performance computer vision, natural language processing, and code generation, their internal behaviour remain largely opaque to traditional dynamic analysis such as testing: existing analysis typically concern only what is observable from the outside, such as input similarity or class label changes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0212-49a7fa1424", "paper_id": "P0212", "bibkey": "Yoo2025Capturing", "title": "Capturing Semantic Flow of ML-based Systems", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We propose semantic flow, a concept designed to capture the internal behaviour of ML-based system and to provide a platform for traditional dynamic analysis techniques to be adapted to.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0212#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0213-959fb538d9", "paper_id": "P0213", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present an LLM assistant, ChatVis, that aids the LLM to generate Python code for ParaView scientific visualization tasks, without the need for retraining or fine-tuning the LLM.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0213-4af4bd8bf3", "paper_id": "P0213", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "An integral part of our approach is a benchmark suite of canonical visualization tasks, ParaView regression tests, and scientific use cases that includes comprehensive evaluation metrics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#key_results[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0213-825bc530a5", "paper_id": "P0213", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We find that all the metrics are significantly improved with ChatVis.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0213-fa0414ceff", "paper_id": "P0213", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Large language models (LLMs) are rapidly increasing in capability, but they still struggle with highly specialized programming tasks such as scientific visualization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#summary_bullets[0]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0213-6af97a93b1", "paper_id": "P0213", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present an LLM assistant, ChatVis, that aids the LLM to generate Python code for ParaView scientific visualization tasks, without the need for retraining or fine-tuning the LLM.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0213-38ab24096b", "paper_id": "P0213", "bibkey": "Peterka2025Chatvis", "title": "ChatVis: Large Language Model Agent for Generating Scientific Visualizations", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "ChatVis employs chain-of-thought prompt simplification, retrieval-augmented prompt generation using a vector database of documentation and code examples, and error checking with iterative prompt feedback to correct errors until a visualization is produced.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0213#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory"]}
{"evidence_id": "E-P0214-2a002cd515", "paper_id": "P0214", "bibkey": "Ning2025Cheatagent", "title": "CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "Therefore, in this paper, we propose a novel attack framework called CheatAgent by harnessing the human-like capabilities of LLMs, where an LLM-based agent is developed to attack LLM-Empowered RecSys.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0214-89171fa2fa", "paper_id": "P0214", "bibkey": "Ning2025Cheatagent", "title": "CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "On the other hand, LLMs provide unprecedented opportunities to serve as attack agents to attack RecSys because of their impressive capability in simulating human-like decision-making processes.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#key_results[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0214-7b5d2479c7", "paper_id": "P0214", "bibkey": "Ning2025Cheatagent", "title": "CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Therefore, in this paper, we propose a novel attack framework called CheatAgent by harnessing the human-like capabilities of LLMs, where an LLM-based agent is developed to attack LLM-Empowered RecSys.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#key_results[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0214-174c20649a", "paper_id": "P0214", "bibkey": "Ning2025Cheatagent", "title": "CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Recently, Large Language Model (LLM)-empowered recommender systems (RecSys) have brought significant advances in personalized user experience and have attracted considerable attention.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0214-6ad3aeec30", "paper_id": "P0214", "bibkey": "Ning2025Cheatagent", "title": "CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Despite the impressive progress, the research question regarding the safety vulnerability of LLM-empowered RecSys still remains largely under-investigated.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0214-7db0c4c3b5", "paper_id": "P0214", "bibkey": "Ning2025Cheatagent", "title": "CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Given the security and privacy concerns, it is more practical to focus on attacking the black-box RecSys, where attackers can only observe the system's inputs and outputs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0214#summary_bullets[2]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0215-d068c35c6d", "paper_id": "P0215", "bibkey": "Wei2025Codearc", "title": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We propose CodeARC, the Code Abstraction and Reasoning Challenge, a new evaluation framework where agents interact with a hidden target function by querying it with new inputs, synthesizing candidate functions, and iteratively refining their solutions using a differential testing oracle.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0215-b133f8881c", "paper_id": "P0215", "bibkey": "Wei2025Codearc", "title": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "We construct the first large-scale benchmark for general-purpose inductive program synthesis, featuring 1114 functions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0215-e2f2890ba6", "paper_id": "P0215", "bibkey": "Wei2025Codearc", "title": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Among 18 models evaluated, o3-mini performs best with a success rate of 52.7%, highlighting the difficulty of this task.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#key_results[1]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0215-032f96e7f0", "paper_id": "P0215", "bibkey": "Wei2025Codearc", "title": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Inductive program synthesis, or programming by example, requires synthesizing functions from input-output examples that generalize to unseen inputs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0215-b404566b23", "paper_id": "P0215", "bibkey": "Wei2025Codearc", "title": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While large language model agents have shown promise in programming tasks guided by natural language, their ability to perform inductive program synthesis is underexplored.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0215-7330408131", "paper_id": "P0215", "bibkey": "Wei2025Codearc", "title": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Existing evaluation protocols rely on static sets of examples and held-out tests, offering no feedback when synthesized functions are incorrect and failing to reflect real-world scenarios such as reverse engineering.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0215#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0216-3ff75eaec6", "paper_id": "P0216", "bibkey": "Li2025Commercial", "title": "Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "In this paper, we analyze security and privacy vulnerabilities that are unique to LLM agents.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#method"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0216-5655415369", "paper_id": "P0216", "bibkey": "Li2025Commercial", "title": "Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Notably, our attacks are trivial to implement and require no understanding of machine learning.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#key_results[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0216-cde53205c2", "paper_id": "P0216", "bibkey": "Li2025Commercial", "title": "Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "A high volume of recent ML security literature focuses on attacks against aligned large language models (LLMs).", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#summary_bullets[0]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0216-90e0dffc35", "paper_id": "P0216", "bibkey": "Li2025Commercial", "title": "Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "These attacks may extract private information or coerce the model into producing harmful outputs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#summary_bullets[1]"}, "confidence": "medium", "tags": ["security"]}
{"evidence_id": "E-P0216-387afdab3b", "paper_id": "P0216", "bibkey": "Li2025Commercial", "title": "Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "In real-world deployments, LLMs are often part of a larger agentic pipeline including memory systems, retrieval, web access, and API calling.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0216#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation", "memory", "tooling"]}
{"evidence_id": "E-P0217-579c4d840d", "paper_id": "P0217", "bibkey": "Gao2025Comp", "title": "Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present Comp-X, the first intelligently interactive image compression paradigm empowered by the impressive reasoning capability of large language model (LLM) agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#method"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0217-4aa8210dce", "paper_id": "P0217", "bibkey": "Gao2025Comp", "title": "Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To overcome this, we advance the evolution of image coding paradigm by introducing three key innovations: (i) multi-functional coding framework, which unifies different coding modes of various objective/requirements, including human-machine perception, variable coding, and spatial bit allocation, into one framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#key_results[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0217-a849dc1b66", "paper_id": "P0217", "bibkey": "Gao2025Comp", "title": "Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "(iii) IIC-bench, the first dedicated benchmark comprising diverse user requests and the corresponding annotations from coding experts, which is systematically designed for intelligently interactive image compression evaluation.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0217-4cd5281f65", "paper_id": "P0217", "bibkey": "Gao2025Comp", "title": "Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "We present Comp-X, the first intelligently interactive image compression paradigm empowered by the impressive reasoning capability of large language model (LLM) agent.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0217-5eb34df4be", "paper_id": "P0217", "bibkey": "Gao2025Comp", "title": "Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Notably, commonly used image codecs usually suffer from limited coding modes and rely on manual mode selection by engineers, making them unfriendly for unprofessional users.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0217-ebaa00e677", "paper_id": "P0217", "bibkey": "Gao2025Comp", "title": "Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To overcome this, we advance the evolution of image coding paradigm by introducing three key innovations: (i) multi-functional coding framework, which unifies different coding modes of various objective/requirements, including human-machine perception, variable coding, and spatial bit allocation, into one framework.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0217#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0218-dd70f12024", "paper_id": "P0218", "bibkey": "Li2025Continuum", "title": "Continuum: Efficient and Robust Multi-Turn LLM Agent Scheduling with KV Cache Time-to-Live", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "We present Continuum, a serving system to optimize job completion time for multi-turn agent workloads by introducing time-to-live mechanism for KV cache retaining.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#method"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0218-a5937728f7", "paper_id": "P0218", "bibkey": "Li2025Continuum", "title": "Continuum: Efficient and Robust Multi-Turn LLM Agent Scheduling with KV Cache Time-to-Live", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Our evaluation on real-world agentic workloads (SWE-Bench and BFCL) with Llama-3.1 8B/70B shows that Continuum significantly improves the average job completion times and its improvement scales with turn number increase.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "memory", "numbers"]}
{"evidence_id": "E-P0218-7f83a4ebcb", "paper_id": "P0218", "bibkey": "Li2025Continuum", "title": "Continuum: Efficient and Robust Multi-Turn LLM Agent Scheduling with KV Cache Time-to-Live", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "Since some tool calls have much shorter durations than human response multi-turn chatbot, it would be promising to retain the KV cache in during these tools.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#key_results[1]"}, "confidence": "medium", "tags": ["memory", "tooling"]}
{"evidence_id": "E-P0218-5cbdd13532", "paper_id": "P0218", "bibkey": "Li2025Continuum", "title": "Continuum: Efficient and Robust Multi-Turn LLM Agent Scheduling with KV Cache Time-to-Live", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "KV cache management is essential for efficient LLM inference.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#summary_bullets[0]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0218-4f1f4d12d1", "paper_id": "P0218", "bibkey": "Li2025Continuum", "title": "Continuum: Efficient and Robust Multi-Turn LLM Agent Scheduling with KV Cache Time-to-Live", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "To maximize utilization, existing inference engines evict finished requests' KV cache if new requests are waiting.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#summary_bullets[1]"}, "confidence": "medium", "tags": ["memory"]}
{"evidence_id": "E-P0218-e1b7b44482", "paper_id": "P0218", "bibkey": "Li2025Continuum", "title": "Continuum: Efficient and Robust Multi-Turn LLM Agent Scheduling with KV Cache Time-to-Live", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This policy breaks for agentic workloads, which interleave LLM calls with tools, introducing pauses that prevent effective KV reuse across turns.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0218#summary_bullets[2]"}, "confidence": "medium", "tags": ["tooling"]}
{"evidence_id": "E-P0219-c6dd354c6b", "paper_id": "P0219", "bibkey": "Guo2025Cryptobench", "title": "CryptoBench: A Dynamic Benchmark for Expert-Level Evaluation of LLM Agents in Cryptocurrency", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "This paper introduces CryptoBench, the first expert-curated, dynamic benchmark designed to rigorously evaluate the real-world capabilities of Large Language Model (LLM) agents in the uniquely demanding and fast-paced cryptocurrency domain.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0219-031aeedf1f", "paper_id": "P0219", "bibkey": "Guo2025Cryptobench", "title": "CryptoBench: A Dynamic Benchmark for Expert-Level Evaluation of LLM Agents in Cryptocurrency", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "To address these challenges, we constructed a live, dynamic benchmark featuring 50 questions per month, expertly designed by crypto-native professionals to mirror actual analyst workflows.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#key_results[0]"}, "confidence": "medium", "tags": ["evaluation", "numbers"]}
{"evidence_id": "E-P0219-487418b7ec", "paper_id": "P0219", "bibkey": "Guo2025Cryptobench", "title": "CryptoBench: A Dynamic Benchmark for Expert-Level Evaluation of LLM Agents in Cryptocurrency", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "This paper introduces CryptoBench, the first expert-curated, dynamic benchmark designed to rigorously evaluate the real-world capabilities of Large Language Model (LLM) agents in the uniquely demanding and fast-paced cryptocurrency domain.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#key_results[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0219-2ee1ddb0ee", "paper_id": "P0219", "bibkey": "Guo2025Cryptobench", "title": "CryptoBench: A Dynamic Benchmark for Expert-Level Evaluation of LLM Agents in Cryptocurrency", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "This paper introduces CryptoBench, the first expert-curated, dynamic benchmark designed to rigorously evaluate the real-world capabilities of Large Language Model (LLM) agents in the uniquely demanding and fast-paced cryptocurrency domain.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#summary_bullets[0]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0219-2d506b2813", "paper_id": "P0219", "bibkey": "Guo2025Cryptobench", "title": "CryptoBench: A Dynamic Benchmark for Expert-Level Evaluation of LLM Agents in Cryptocurrency", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Unlike general-purpose agent benchmarks for search and prediction, professional crypto analysis presents specific challenges: \\emph{extreme time-sensitivity}, \\emph{a highly adversarial information environment}, and the critical need to synthesize data from \\emph{diverse, specialized sources}, such as on-chain intelligence platforms and real-time Decentralized Finance (DeFi) dashboards.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#summary_bullets[1]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0219-38879c2d02", "paper_id": "P0219", "bibkey": "Guo2025Cryptobench", "title": "CryptoBench: A Dynamic Benchmark for Expert-Level Evaluation of LLM Agents in Cryptocurrency", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "CryptoBench thus serves as a much more challenging and valuable scenario for LLM agent assessment.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0219#summary_bullets[2]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0220-e372fc0508", "paper_id": "P0220", "bibkey": "Chuang2025Debate", "title": "DEBATE: A Large-Scale Benchmark for Role-Playing LLM Agents in Multi-Agent, Long-Form Debates", "year": 2025, "evidence_level": "abstract", "claim_type": "method", "snippet": "To bridge this gap, we introduce DEBATE, the first large-scale empirical benchmark explicitly designed to evaluate the authenticity of the interaction between multi-agent role-playing LLMs.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#method"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0220-3acffd03b4", "paper_id": "P0220", "bibkey": "Chuang2025Debate", "title": "DEBATE: A Large-Scale Benchmark for Role-Playing LLM Agents in Multi-Agent, Long-Form Debates", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "DEBATE contains 29,417 messages from multi-round debate conversations among over 2,792 U.S.-based participants discussing 107 controversial topics, capturing both publicly-expressed messages and privately-reported opinions.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#key_results[0]"}, "confidence": "medium", "tags": ["numbers"]}
{"evidence_id": "E-P0220-854e81c644", "paper_id": "P0220", "bibkey": "Chuang2025Debate", "title": "DEBATE: A Large-Scale Benchmark for Role-Playing LLM Agents in Multi-Agent, Long-Form Debates", "year": 2025, "evidence_level": "abstract", "claim_type": "result", "snippet": "While role-playing large language models (LLMs) offer a promising way to simulate human-like interactions, existing research shows that single-agent alignment does not guarantee authentic multi-agent group dynamics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#key_results[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0220-76955a584d", "paper_id": "P0220", "bibkey": "Chuang2025Debate", "title": "DEBATE: A Large-Scale Benchmark for Role-Playing LLM Agents in Multi-Agent, Long-Form Debates", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Accurately modeling opinion change through social interactions is crucial for addressing issues like misinformation and polarization.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#summary_bullets[0]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0220-05f5d07036", "paper_id": "P0220", "bibkey": "Chuang2025Debate", "title": "DEBATE: A Large-Scale Benchmark for Role-Playing LLM Agents in Multi-Agent, Long-Form Debates", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "While role-playing large language models (LLMs) offer a promising way to simulate human-like interactions, existing research shows that single-agent alignment does not guarantee authentic multi-agent group dynamics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#summary_bullets[1]"}, "confidence": "medium", "tags": []}
{"evidence_id": "E-P0220-bb21c0d432", "paper_id": "P0220", "bibkey": "Chuang2025Debate", "title": "DEBATE: A Large-Scale Benchmark for Role-Playing LLM Agents in Multi-Agent, Long-Form Debates", "year": 2025, "evidence_level": "abstract", "claim_type": "summary", "snippet": "Current LLM role-play setups often produce unnatural dynamics (e.g., premature convergence), without an empirical benchmark to measure authentic human opinion trajectories.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#summary_bullets[2]"}, "confidence": "medium", "tags": ["evaluation"]}
{"evidence_id": "E-P0220-e917db5f9d", "paper_id": "P0220", "bibkey": "Chuang2025Debate", "title": "DEBATE: A Large-Scale Benchmark for Role-Playing LLM Agents in Multi-Agent, Long-Form Debates", "year": 2025, "evidence_level": "abstract", "claim_type": "limitation", "snippet": "While role-playing large language models (LLMs) offer a promising way to simulate human-like interactions, existing research shows that single-agent alignment does not guarantee authentic multi-agent group dynamics.", "locator": {"source": "paper_notes", "pointer": "papers/paper_notes.jsonl:paper_id=P0220#limitations[1]"}, "confidence": "medium", "tags": []}
