Once an interface fixes what actions are executable, the next bottleneck is how agents choose actions over time under uncertainty and budget constraints. Deliberate search and verification can improve correctness on long-horizon tasks, but they also increase cost and can introduce new failure modes, making success rates hard to interpret without explicit budget models [@Yao2023Tree; @Liu2025Costbench].

This chapter contrasts planning loops that search, decompose, or verify action sequences with memory mechanisms that determine what evidence the policy can condition on and how that evidence persists across steps. Keeping the evaluation protocol in view is essential: planners and memories that look strong under one cost model, tool catalog, or retrieval noise profile may not transfer under another, and methodology work increasingly treats these assumptions as part of the reported result rather than background detail [@Mudur2025Feabench; @Mohammadi2025Evaluation].
