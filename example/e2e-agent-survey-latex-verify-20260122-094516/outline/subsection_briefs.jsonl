{"sub_id": "3.1", "title": "Agent loop and action spaces", "section_id": "3", "section_title": "Foundations & Interfaces", "rq": "Which design choices in Agent loop and action spaces drive the major trade-offs, and how are those trade-offs measured?", "thesis": "For Agent loop and action spaces, evaluation protocol (datasets and metrics is a recurring axis of variation, and results are easiest to interpret when protocols and failure assumptions are explicit.", "scope_rule": {"include": ["Core topics directly relevant to 'Agent loop and action spaces'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["evaluation protocol (datasets", "metrics", "human evaluation)", "compute and latency constraints", "and failure modes and limitations"], "bridge_terms": ["benchmarks/metrics", "compute"], "contrast_hook": "evaluation", "tension_statement": "In Agent loop and action spaces, a key tension is capability versus safety: stronger agent actions increase utility but widen the attack surface and raise containment requirements.", "evaluation_anchor_minimal": {"task": "agent benchmark tasks", "metric": "success rate", "constraint": "budget/cost model"}, "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "compute / cost (train/infer)", "training signal / supervision", "failure modes and limitations"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0032", "P0091", "P0092", "P0187", "P0014", "P0016", "P0041", "P0119"], "bibkeys": ["Xi2026Toolgym", "Song2026Envscaler", "Zhang2026Evoroute", "Lin2026Froav", "Li2025Agentswift", "Kim2025Bridging", "Gasmi2025Bridging", "Fumero2025Cybersleuth"]}, {"label": "Planning / reasoning loops", "rationale": "Grouped by keyword tag `planning` from titles (bootstrap).", "paper_ids": ["P0187", "P0014", "P0016", "P0209", "P0078", "P0001"], "bibkeys": ["Lin2026Froav", "Li2025Agentswift", "Kim2025Bridging", "Nusrat2025Automated", "Shang2024Agentsquare", "Yao2022React"]}, {"label": "Tool-use and function calling", "rationale": "Grouped by keyword tag `tool-use` from titles (bootstrap).", "paper_ids": ["P0032", "P0091", "P0140", "P0027"], "bibkeys": ["Xi2026Toolgym", "Song2026Envscaler", "Ghose2025Orfs", "Shen2024Small"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Agent loop and action spaces drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism and system architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "core mechanism and system architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "baseline route (Agent frameworks / architectures)", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: training and data signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "training and data setup", "interface contract", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "elaboration", "connector_phrase": "implementation assumptions (interface + training)", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "evaluation anchor (task/metric/constraint) + failure modes", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism and system architecture and what it optimizes for.", "focus": ["cluster: Planning / reasoning loops", "contrast with Agent frameworks / architectures", "core mechanism and system architecture"], "connector_to_prev": "contrast", "connector_phrase": "contrast route (Planning / reasoning loops vs Agent frameworks / architectures)", "use_clusters": ["Planning / reasoning loops"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: training and data and interface assumptions (mirror A for comparability).", "focus": ["cluster: Planning / reasoning loops", "training and data setup", "interface contract", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "elaboration", "connector_phrase": "contrast implementation assumptions (B)", "use_clusters": ["Planning / reasoning loops"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Planning / reasoning loops", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "contrast evaluation anchor + trade-offs (B)", "use_clusters": ["Planning / reasoning loops"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Planning / reasoning loops", "multiple citations in one paragraph", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "synthesis", "connector_phrase": "cross-paper synthesis (Agent frameworks / architectures vs Planning / reasoning loops)", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Tool-use and function calling"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "decision guidance / criteria", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Tool-use and function calling"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "limitations + verification targets", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Tool-use and function calling"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-22T09:47:05"}
{"sub_id": "3.2", "title": "Tool interfaces and orchestration", "section_id": "3", "section_title": "Foundations & Interfaces", "rq": "Which design choices in Tool interfaces and orchestration drive the major trade-offs, and how are those trade-offs measured?", "thesis": "In Tool interfaces and orchestration, differences in evaluation protocol (datasets and metrics frequently imply different evaluation setups, so the key is to compare under consistent protocols where possible.", "scope_rule": {"include": ["Core topics directly relevant to 'Tool interfaces and orchestration'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["evaluation protocol (datasets", "metrics", "human evaluation)", "compute and latency constraints", "and failure modes and limitations"], "bridge_terms": ["function calling", "tool schema", "routing", "sandbox", "observability", "benchmarks/metrics"], "contrast_hook": "tool interfaces", "tension_statement": "In Tool interfaces and orchestration, a key tension is capability versus safety: stronger agent actions increase utility but widen the attack surface and raise containment requirements.", "evaluation_anchor_minimal": {"task": "agent benchmark tasks", "metric": "success rate", "constraint": "budget/cost model"}, "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "compute / cost (train/infer)", "training signal / supervision", "failure modes and limitations"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0033", "P0093", "P0098", "P0035", "P0047", "P0054", "P0056", "P0058"], "bibkeys": ["Li2026Toolprmbench", "Hao2026From", "Xuan2026Confidence", "Chen2025Agentguard", "Mohammadi2025Evaluation", "Li2025Dissonances", "Liu2025Mcpagentbench", "Lumer2025Memtool"]}, {"label": "Tool-use and function calling", "rationale": "Grouped by keyword tag `tool-use` from titles (bootstrap).", "paper_ids": ["P0033", "P0093", "P0098", "P0017", "P0035", "P0054", "P0056", "P0058"], "bibkeys": ["Li2026Toolprmbench", "Hao2026From", "Xuan2026Confidence", "Dong2025Etom", "Chen2025Agentguard", "Li2025Dissonances", "Liu2025Mcpagentbench", "Lumer2025Memtool"]}, {"label": "Evaluation / benchmark-focused works", "rationale": "Grouped by keyword tag `evaluation` from titles (bootstrap).", "paper_ids": ["P0017", "P0035", "P0047", "P0056"], "bibkeys": ["Dong2025Etom", "Chen2025Agentguard", "Mohammadi2025Evaluation", "Liu2025Mcpagentbench"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Tool interfaces and orchestration drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism and system architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "core mechanism and system architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "baseline route (Agent frameworks / architectures)", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: training and data signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "training and data setup", "interface contract", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "elaboration", "connector_phrase": "implementation assumptions (interface + training)", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "evaluation anchor (task/metric/constraint) + failure modes", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism and system architecture and what it optimizes for.", "focus": ["cluster: Tool-use and function calling", "contrast with Agent frameworks / architectures", "core mechanism and system architecture"], "connector_to_prev": "contrast", "connector_phrase": "contrast route (Tool-use and function calling vs Agent frameworks / architectures)", "use_clusters": ["Tool-use and function calling"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: training and data and interface assumptions (mirror A for comparability).", "focus": ["cluster: Tool-use and function calling", "training and data setup", "interface contract", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "elaboration", "connector_phrase": "contrast implementation assumptions (B)", "use_clusters": ["Tool-use and function calling"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Tool-use and function calling", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "contrast evaluation anchor + trade-offs (B)", "use_clusters": ["Tool-use and function calling"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Tool-use and function calling", "multiple citations in one paragraph", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "synthesis", "connector_phrase": "cross-paper synthesis (Agent frameworks / architectures vs Tool-use and function calling)", "use_clusters": ["Agent frameworks / architectures", "Tool-use and function calling", "Evaluation / benchmark-focused works"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "decision guidance / criteria", "use_clusters": ["Agent frameworks / architectures", "Tool-use and function calling", "Evaluation / benchmark-focused works"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "limitations + verification targets", "use_clusters": ["Agent frameworks / architectures", "Tool-use and function calling", "Evaluation / benchmark-focused works"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-22T09:47:05"}
{"sub_id": "4.1", "title": "Planning and reasoning loops", "section_id": "4", "section_title": "Core Components (Planning + Memory)", "rq": "Which design choices in Planning and reasoning loops drive the major trade-offs, and how are those trade-offs measured?", "thesis": "For Planning and reasoning loops, evaluation protocol (datasets and metrics is a recurring axis of variation, and results are easiest to interpret when protocols and failure assumptions are explicit.", "scope_rule": {"include": ["Core topics directly relevant to 'Planning and reasoning loops'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["evaluation protocol (datasets", "metrics", "human evaluation)", "compute and latency constraints", "and failure modes and limitations"], "bridge_terms": ["planner/executor", "search", "deliberation", "action grounding", "benchmarks/metrics", "compute"], "contrast_hook": "planning/control loop", "tension_statement": "In Planning and reasoning loops, a key tension is capability versus safety: stronger agent actions increase utility but widen the attack surface and raise containment requirements.", "evaluation_anchor_minimal": {"task": "agent benchmark tasks", "metric": "success rate", "constraint": "budget/cost model"}, "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "compute / cost (train/infer)", "training signal / supervision", "failure modes and limitations"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0016", "P0021", "P0024", "P0043", "P0061", "P0064", "P0072", "P0099"], "bibkeys": ["Kim2025Bridging", "Zhou2025Reasoning", "Hu2025Training", "Silva2025Agents", "Hatalis2025Review", "Zhou2025Siraj", "Zhu2025Where", "Kiruluta2025Novel"]}, {"label": "Planning / reasoning loops", "rationale": "Grouped by keyword tag `planning` from titles (bootstrap).", "paper_ids": ["P0016", "P0021", "P0024", "P0043", "P0059", "P0061", "P0064", "P0099"], "bibkeys": ["Kim2025Bridging", "Zhou2025Reasoning", "Hu2025Training", "Silva2025Agents", "Hong2025Planning", "Hatalis2025Review", "Zhou2025Siraj", "Kiruluta2025Novel"]}, {"label": "Control / conditioning interfaces", "rationale": "Grouped by keyword tag `control` from titles (bootstrap).", "paper_ids": ["P0016", "P0146"], "bibkeys": ["Kim2025Bridging", "Choi2025Reactree"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Planning and reasoning loops drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism and system architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "core mechanism and system architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "baseline route (Agent frameworks / architectures)", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: training and data signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "training and data setup", "interface contract", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "elaboration", "connector_phrase": "implementation assumptions (interface + training)", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "evaluation anchor (task/metric/constraint) + failure modes", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism and system architecture and what it optimizes for.", "focus": ["cluster: Planning / reasoning loops", "contrast with Agent frameworks / architectures", "core mechanism and system architecture"], "connector_to_prev": "contrast", "connector_phrase": "contrast route (Planning / reasoning loops vs Agent frameworks / architectures)", "use_clusters": ["Planning / reasoning loops"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: training and data and interface assumptions (mirror A for comparability).", "focus": ["cluster: Planning / reasoning loops", "training and data setup", "interface contract", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "elaboration", "connector_phrase": "contrast implementation assumptions (B)", "use_clusters": ["Planning / reasoning loops"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Planning / reasoning loops", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "contrast evaluation anchor + trade-offs (B)", "use_clusters": ["Planning / reasoning loops"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Planning / reasoning loops", "multiple citations in one paragraph", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "synthesis", "connector_phrase": "cross-paper synthesis (Agent frameworks / architectures vs Planning / reasoning loops)", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Control / conditioning interfaces"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "decision guidance / criteria", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Control / conditioning interfaces"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "limitations + verification targets", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Control / conditioning interfaces"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-22T09:47:05"}
{"sub_id": "4.2", "title": "Memory and retrieval (RAG)", "section_id": "4", "section_title": "Core Components (Planning + Memory)", "rq": "Which design choices in Memory and retrieval (RAG) drive the major trade-offs, and how are those trade-offs measured?", "thesis": "For Memory and retrieval (RAG), evaluation protocol (datasets and metrics is a recurring axis of variation, and results are easiest to interpret when protocols and failure assumptions are explicit.", "scope_rule": {"include": ["Core topics directly relevant to 'Memory and retrieval (RAG)'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["evaluation protocol (datasets", "metrics", "human evaluation)", "compute and latency constraints", "and failure modes and limitations"], "bridge_terms": ["retrieval", "index", "write policy", "long-term memory", "benchmarks/metrics", "compute"], "contrast_hook": "memory/retrieval", "tension_statement": "In Memory and retrieval (RAG), a key tension is capability versus safety: stronger agent actions increase utility but widen the attack surface and raise containment requirements.", "evaluation_anchor_minimal": {"task": "agent benchmark tasks", "metric": "success rate", "constraint": "budget/cost model"}, "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "compute / cost (train/infer)", "training signal / supervision", "failure modes and limitations"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0184", "P0185", "P0187", "P0014", "P0051", "P0055", "P0060", "P0067"], "bibkeys": ["Verma2026Active", "Yu2026Agentic", "Lin2026Froav", "Li2025Agentswift", "Chen2025Grounded", "Zhang2025Security", "Shi2025Progent", "Ye2025Task"]}, {"label": "Memory / retrieval augmentation", "rationale": "Grouped by keyword tag `memory` from titles (bootstrap).", "paper_ids": ["P0184", "P0185", "P0187", "P0019", "P0067", "P0135", "P0139", "P0153"], "bibkeys": ["Verma2026Active", "Yu2026Agentic", "Lin2026Froav", "Tawosi2025Meta", "Ye2025Task", "Zhang2025Large", "Wu2025Meta", "Ye2025Taska"]}, {"label": "Planning / reasoning loops", "rationale": "Grouped by keyword tag `planning` from titles (bootstrap).", "paper_ids": ["P0187", "P0014", "P0001"], "bibkeys": ["Lin2026Froav", "Li2025Agentswift", "Yao2022React"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Memory and retrieval (RAG) drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism and system architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "core mechanism and system architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "baseline route (Agent frameworks / architectures)", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: training and data signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "training and data setup", "interface contract", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "elaboration", "connector_phrase": "implementation assumptions (interface + training)", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "evaluation anchor (task/metric/constraint) + failure modes", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism and system architecture and what it optimizes for.", "focus": ["cluster: Memory / retrieval augmentation", "contrast with Agent frameworks / architectures", "core mechanism and system architecture"], "connector_to_prev": "contrast", "connector_phrase": "contrast route (Memory / retrieval augmentation vs Agent frameworks / architectures)", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: training and data and interface assumptions (mirror A for comparability).", "focus": ["cluster: Memory / retrieval augmentation", "training and data setup", "interface contract", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "elaboration", "connector_phrase": "contrast implementation assumptions (B)", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Memory / retrieval augmentation", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "contrast evaluation anchor + trade-offs (B)", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Memory / retrieval augmentation", "multiple citations in one paragraph", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "synthesis", "connector_phrase": "cross-paper synthesis (Agent frameworks / architectures vs Memory / retrieval augmentation)", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Planning / reasoning loops"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "decision guidance / criteria", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Planning / reasoning loops"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "limitations + verification targets", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Planning / reasoning loops"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-22T09:47:05"}
{"sub_id": "5.1", "title": "Self-improvement and adaptation", "section_id": "5", "section_title": "Learning, Adaptation & Coordination", "rq": "Which design choices in Self-improvement and adaptation drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Self-improvement and adaptation methods emphasize evaluation protocol (datasets and metrics trade-offs, but synthesis is clearest when claims are tied to explicit evaluation settings and reporting conventions.", "scope_rule": {"include": ["Core topics directly relevant to 'Self-improvement and adaptation'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["evaluation protocol (datasets", "metrics", "human evaluation)", "compute and latency constraints", "and failure modes and limitations"], "bridge_terms": ["preference", "reward", "feedback", "self-improvement", "benchmarks/metrics", "compute"], "contrast_hook": "learning/feedback", "tension_statement": "In Self-improvement and adaptation, a key tension is capability versus safety: stronger agent actions increase utility but widen the attack surface and raise containment requirements.", "evaluation_anchor_minimal": {"task": "agent benchmark tasks", "metric": "success rate", "constraint": "budget/cost model"}, "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "compute / cost (train/infer)", "training signal / supervision", "failure modes and limitations"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0028", "P0092", "P0008", "P0022", "P0036", "P0048", "P0049", "P0051"], "bibkeys": ["Li2026Autonomous", "Zhang2026Evoroute", "Van2025Survey", "Zhou2025Self", "Belle2025Agents", "Wu2025Evolver", "Nitin2025Faultline", "Chen2025Grounded"]}, {"label": "Planning / reasoning loops", "rationale": "Grouped by keyword tag `planning` from titles (bootstrap).", "paper_ids": ["P0036", "P0001"], "bibkeys": ["Belle2025Agents", "Yao2022React"]}, {"label": "Tool-use and function calling", "rationale": "Grouped by keyword tag `tool-use` from titles (bootstrap).", "paper_ids": ["P0008", "P0080"], "bibkeys": ["Van2025Survey", "Du2024Anytool"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Self-improvement and adaptation drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism and system architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "core mechanism and system architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "baseline route (Agent frameworks / architectures)", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: training and data signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "training and data setup", "interface contract", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "elaboration", "connector_phrase": "implementation assumptions (interface + training)", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "evaluation anchor (task/metric/constraint) + failure modes", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism and system architecture and what it optimizes for.", "focus": ["cluster: Planning / reasoning loops", "contrast with Agent frameworks / architectures", "core mechanism and system architecture"], "connector_to_prev": "contrast", "connector_phrase": "contrast route (Planning / reasoning loops vs Agent frameworks / architectures)", "use_clusters": ["Planning / reasoning loops"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: training and data and interface assumptions (mirror A for comparability).", "focus": ["cluster: Planning / reasoning loops", "training and data setup", "interface contract", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "elaboration", "connector_phrase": "contrast implementation assumptions (B)", "use_clusters": ["Planning / reasoning loops"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Planning / reasoning loops", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "contrast evaluation anchor + trade-offs (B)", "use_clusters": ["Planning / reasoning loops"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Planning / reasoning loops", "multiple citations in one paragraph", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "synthesis", "connector_phrase": "cross-paper synthesis (Agent frameworks / architectures vs Planning / reasoning loops)", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Tool-use and function calling"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "decision guidance / criteria", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Tool-use and function calling"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "limitations + verification targets", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Tool-use and function calling"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-22T09:47:05"}
{"sub_id": "5.2", "title": "Multi-agent coordination", "section_id": "5", "section_title": "Learning, Adaptation & Coordination", "rq": "Which design choices in Multi-agent coordination drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Multi-agent coordination highlights a tension around evaluation protocol (datasets and metrics, motivating a protocol-aware synthesis rather than per-paper summaries.", "scope_rule": {"include": ["Core topics directly relevant to 'Multi-agent coordination'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["evaluation protocol (datasets", "metrics", "human evaluation)", "compute and latency constraints", "and failure modes and limitations"], "bridge_terms": ["roles", "communication", "debate", "aggregation", "stability", "benchmarks/metrics"], "contrast_hook": "coordination", "tension_statement": "In Multi-agent coordination, a key tension is capability versus safety: stronger agent actions increase utility but widen the attack surface and raise containment requirements.", "evaluation_anchor_minimal": {"task": "agent benchmark tasks", "metric": "success rate", "constraint": "budget/cost model"}, "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "compute / cost (train/infer)", "training signal / supervision", "failure modes and limitations"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0010", "P0023", "P0042", "P0043", "P0045", "P0058", "P0114", "P0132"], "bibkeys": ["Sarkar2025Survey", "Cao2025Skyrl", "Shao2025Craken", "Silva2025Agents", "Lichkovski2025Agent", "Lumer2025Memtool", "Wu2025Agents", "Sun2025Agent"]}, {"label": "Multi-agent coordination", "rationale": "Grouped by keyword tag `multi-agent` from titles (bootstrap).", "paper_ids": ["P0043", "P0114", "P0198", "P0220"], "bibkeys": ["Silva2025Agents", "Wu2025Agents", "Papadakis2025Atlas", "Chuang2025Debate"]}, {"label": "Planning / reasoning loops", "rationale": "Grouped by keyword tag `planning` from titles (bootstrap).", "paper_ids": ["P0043", "P0114", "P0197"], "bibkeys": ["Silva2025Agents", "Wu2025Agents", "Chang2025Alas"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Multi-agent coordination drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism and system architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "core mechanism and system architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "baseline route (Agent frameworks / architectures)", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: training and data signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "training and data setup", "interface contract", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "elaboration", "connector_phrase": "implementation assumptions (interface + training)", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "evaluation anchor (task/metric/constraint) + failure modes", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism and system architecture and what it optimizes for.", "focus": ["cluster: Multi-agent coordination", "contrast with Agent frameworks / architectures", "core mechanism and system architecture"], "connector_to_prev": "contrast", "connector_phrase": "contrast route (Multi-agent coordination vs Agent frameworks / architectures)", "use_clusters": ["Multi-agent coordination"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: training and data and interface assumptions (mirror A for comparability).", "focus": ["cluster: Multi-agent coordination", "training and data setup", "interface contract", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "elaboration", "connector_phrase": "contrast implementation assumptions (B)", "use_clusters": ["Multi-agent coordination"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Multi-agent coordination", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "contrast evaluation anchor + trade-offs (B)", "use_clusters": ["Multi-agent coordination"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Multi-agent coordination", "multiple citations in one paragraph", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "synthesis", "connector_phrase": "cross-paper synthesis (Agent frameworks / architectures vs Multi-agent coordination)", "use_clusters": ["Agent frameworks / architectures", "Multi-agent coordination", "Planning / reasoning loops"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "decision guidance / criteria", "use_clusters": ["Agent frameworks / architectures", "Multi-agent coordination", "Planning / reasoning loops"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "limitations + verification targets", "use_clusters": ["Agent frameworks / architectures", "Multi-agent coordination", "Planning / reasoning loops"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-22T09:47:05"}
{"sub_id": "6.1", "title": "Benchmarks and evaluation protocols", "section_id": "6", "section_title": "Evaluation & Risks", "rq": "Which design choices in Benchmarks and evaluation protocols drive the major trade-offs, and how are those trade-offs measured?", "thesis": "For Benchmarks and evaluation protocols, evaluation protocol (datasets and metrics is a recurring axis of variation, and results are easiest to interpret when protocols and failure assumptions are explicit.", "scope_rule": {"include": ["Core topics directly relevant to 'Benchmarks and evaluation protocols'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["evaluation protocol (datasets", "metrics", "human evaluation)", "compute and latency constraints", "and failure modes and limitations"], "bridge_terms": ["function calling", "tool schema", "routing", "sandbox", "observability", "benchmarks"], "contrast_hook": "tool interfaces", "tension_statement": "In Benchmarks and evaluation protocols, a key tension is capability versus safety: stronger agent actions increase utility but widen the attack surface and raise containment requirements.", "evaluation_anchor_minimal": {"task": "agent benchmark tasks", "metric": "success rate", "constraint": "budget/cost model"}, "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "compute / cost (train/infer)", "training signal / supervision", "failure modes and limitations"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0029", "P0030", "P0008", "P0047", "P0063", "P0065", "P0068", "P0069"], "bibkeys": ["Kim2026Beyond", "Liu2026Agents", "Van2025Survey", "Mohammadi2025Evaluation", "Zhan2025Sentinel", "Liu2025Secure", "Ji2025Taxonomy", "Chen2025Towards"]}, {"label": "Evaluation / benchmark-focused works", "rationale": "Grouped by keyword tag `evaluation` from titles (bootstrap).", "paper_ids": ["P0029", "P0047", "P0063", "P0068", "P0069", "P0144", "P0151", "P0211"], "bibkeys": ["Kim2026Beyond", "Mohammadi2025Evaluation", "Zhan2025Sentinel", "Ji2025Taxonomy", "Chen2025Towards", "Fu2025Eval", "Seo2025Simuhome", "Zhang2025Buildbench"]}, {"label": "Safety / security / guardrails", "rationale": "Grouped by keyword tag `security` from titles (bootstrap).", "paper_ids": ["P0063", "P0065", "P0113", "P0144"], "bibkeys": ["Zhan2025Sentinel", "Liu2025Secure", "Das2025Beyond", "Fu2025Eval"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Benchmarks and evaluation protocols drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism and system architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "core mechanism and system architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "baseline route (Agent frameworks / architectures)", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: training and data signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "training and data setup", "interface contract", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "elaboration", "connector_phrase": "implementation assumptions (interface + training)", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "evaluation anchor (task/metric/constraint) + failure modes", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism and system architecture and what it optimizes for.", "focus": ["cluster: Evaluation / benchmark-focused works", "contrast with Agent frameworks / architectures", "core mechanism and system architecture"], "connector_to_prev": "contrast", "connector_phrase": "contrast route (Evaluation / benchmark-focused works vs Agent frameworks / architectures)", "use_clusters": ["Evaluation / benchmark-focused works"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: training and data and interface assumptions (mirror A for comparability).", "focus": ["cluster: Evaluation / benchmark-focused works", "training and data setup", "interface contract", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "elaboration", "connector_phrase": "contrast implementation assumptions (B)", "use_clusters": ["Evaluation / benchmark-focused works"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Evaluation / benchmark-focused works", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "contrast evaluation anchor + trade-offs (B)", "use_clusters": ["Evaluation / benchmark-focused works"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Evaluation / benchmark-focused works", "multiple citations in one paragraph", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "synthesis", "connector_phrase": "cross-paper synthesis (Agent frameworks / architectures vs Evaluation / benchmark-focused works)", "use_clusters": ["Agent frameworks / architectures", "Evaluation / benchmark-focused works", "Safety / security / guardrails"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "decision guidance / criteria", "use_clusters": ["Agent frameworks / architectures", "Evaluation / benchmark-focused works", "Safety / security / guardrails"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "limitations + verification targets", "use_clusters": ["Agent frameworks / architectures", "Evaluation / benchmark-focused works", "Safety / security / guardrails"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-22T09:47:05"}
{"sub_id": "6.2", "title": "Safety, security, and governance", "section_id": "6", "section_title": "Evaluation & Risks", "rq": "Which design choices in Safety, security, and governance drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Safety, security, and governance methods emphasize evaluation protocol (datasets and metrics trade-offs, but synthesis is clearest when claims are tied to explicit evaluation settings and reporting conventions.", "scope_rule": {"include": ["Core topics directly relevant to 'Safety, security, and governance'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["evaluation protocol (datasets", "metrics", "human evaluation)", "compute and latency constraints", "and failure modes and limitations"], "bridge_terms": ["threat model", "prompt/tool injection", "monitoring", "guardrails", "benchmarks/metrics", "compute"], "contrast_hook": "security", "tension_statement": "In Safety, security, and governance, a key tension is capability versus safety: stronger agent actions increase utility but widen the attack surface and raise containment requirements.", "evaluation_anchor_minimal": {"task": "attack/defense evaluation", "metric": "attack success rate", "constraint": "policy/sandbox setting"}, "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "compute / cost (train/infer)", "training signal / supervision", "failure modes and limitations", "threat model", "defense surface"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0012", "P0013", "P0041", "P0055", "P0060", "P0071", "P0102", "P0104"], "bibkeys": ["Hadeliya2025When", "Bonagiri2025Check", "Gasmi2025Bridging", "Zhang2025Security", "Shi2025Progent", "Fang2025Should", "Luo2025Agrail", "Sha2025Agent"]}, {"label": "Safety / security / guardrails", "rationale": "Grouped by keyword tag `security` from titles (bootstrap).", "paper_ids": ["P0012", "P0013", "P0041", "P0055", "P0071", "P0102", "P0104", "P0128"], "bibkeys": ["Hadeliya2025When", "Bonagiri2025Check", "Gasmi2025Bridging", "Zhang2025Security", "Fang2025Should", "Luo2025Agrail", "Sha2025Agent", "An2025Ipiguard"]}, {"label": "Evaluation / benchmark-focused works", "rationale": "Grouped by keyword tag `evaluation` from titles (bootstrap).", "paper_ids": ["P0055", "P0144", "P0157", "P0174"], "bibkeys": ["Zhang2025Security", "Fu2025Eval", "Shao2025Towards", "Yuan2024Judge"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Safety, security, and governance drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism and system architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "core mechanism and system architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "baseline route (Agent frameworks / architectures)", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: training and data signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "training and data setup", "interface contract", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "elaboration", "connector_phrase": "implementation assumptions (interface + training)", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "evaluation anchor (task/metric/constraint) + failure modes", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism and system architecture and what it optimizes for.", "focus": ["cluster: Safety / security / guardrails", "contrast with Agent frameworks / architectures", "core mechanism and system architecture"], "connector_to_prev": "contrast", "connector_phrase": "contrast route (Safety / security / guardrails vs Agent frameworks / architectures)", "use_clusters": ["Safety / security / guardrails"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: training and data and interface assumptions (mirror A for comparability).", "focus": ["cluster: Safety / security / guardrails", "training and data setup", "interface contract", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "elaboration", "connector_phrase": "contrast implementation assumptions (B)", "use_clusters": ["Safety / security / guardrails"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Safety / security / guardrails", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "contrast evaluation anchor + trade-offs (B)", "use_clusters": ["Safety / security / guardrails"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Safety / security / guardrails", "multiple citations in one paragraph", "axes: evaluation protocol (datasets, metrics, human evaluation), compute and latency constraints, and failure modes and limitations"], "connector_to_prev": "synthesis", "connector_phrase": "cross-paper synthesis (Agent frameworks / architectures vs Safety / security / guardrails)", "use_clusters": ["Agent frameworks / architectures", "Safety / security / guardrails", "Evaluation / benchmark-focused works"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "decision guidance / criteria", "use_clusters": ["Agent frameworks / architectures", "Safety / security / guardrails", "Evaluation / benchmark-focused works"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "limitations + verification targets", "use_clusters": ["Agent frameworks / architectures", "Safety / security / guardrails", "Evaluation / benchmark-focused works"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-22T09:47:05"}
