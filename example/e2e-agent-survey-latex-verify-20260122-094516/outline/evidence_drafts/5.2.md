# Evidence draft: 5.2 Multi-agent coordination

## Evidence snippets (with provenance)
- (E-P0199-1063eee7ce) However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. Zhao2025Achieving (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0199#key_results[0])
- (E-P0023-32b2c8cf19) We introduce SkyRL-Agent, a framework for efficient, multi-turn, long-horizon agent training and evaluation. Cao2025Skyrl (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0023#method)
- (E-P0045-a256400826) We encourage future work extending agentic safety benchmarks to different legal jurisdictions and to multi-turn and multilingual interactions. Lichkovski2025Agent (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0045#limitations[1])
- (E-P0042-9d48d99db0) On evaluation of MITRE ATT&CK techniques, CRAKEN solves 25-30% more techniques than prior work, demonstrating improved cybersecurity capabilities via knowledge-based execution. Shao2025Craken (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0042#key_results[1])
- (E-P0218-a5937728f7) Our evaluation on real-world agentic workloads (SWE-Bench and BFCL) with Llama-3.1 8B/70B shows that Continuum significantly improves the average job completion times and its improvement scales with turn number increase. Li2025Continuum (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0218#key_results[0])
- (E-P0058-35271418ac) Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy. Lumer2025Memtool (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
- (E-P0023-3af1ce8090) Using SkyRL-Agent, we train SA-SWE-32B, a software engineering agent trained from Qwen3-32B (24.4% Pass@1) purely with reinforcement learning. Cao2025Skyrl (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0023#key_results[0])
- (E-P0043-baa622fa7f) This study offers new insights into the strengths and failure modes of LLMs in physically grounded multi-agent collaboration tasks, contributing to future benchmarks and architectural improvements. Silva2025Agents (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0043#key_results[1])
- (E-P0114-e31a1bbba7) We address this question through a controlled study using the Knight--Knave--Spy logic puzzle, which enables precise, step-wise evaluation of debate outcomes and processes under verifiable ground truth. Wu2025Agents (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0114#key_results[0])
- (E-P0132-027093d5f5) Evaluating these systems is challenging, as their rapid evolution outpaces traditional human evaluation. Sun2025Agent (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0132#key_results[1])

## Definitions / setup

- Setup: Which design choices in Multi-agent coordination drive the major trade-offs, and how are those trade-offs measured? Scope: in-scope: Core topics directly relevant to 'Multi-agent coordination'.. Axes: evaluation protocol (datasets; metrics; human evaluation); compute and latency constraints; and failure modes and limitations. Sarkar2025Survey Cao2025Skyrl Shao2025Craken

## Claim candidates

- However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. Zhao2025Achieving
- We introduce SkyRL-Agent, a framework for efficient, multi-turn, long-horizon agent training and evaluation. Cao2025Skyrl
- We encourage future work extending agentic safety benchmarks to different legal jurisdictions and to multi-turn and multilingual interactions. Lichkovski2025Agent
- On evaluation of MITRE ATT&CK techniques, CRAKEN solves 25-30% more techniques than prior work, demonstrating improved cybersecurity capabilities via knowledge-based execution. Shao2025Craken
- Our evaluation on real-world agentic workloads (SWE-Bench and BFCL) with Llama-3.1 8B/70B shows that Continuum significantly improves the average job completion times and its improvement scales with turn number increase. Li2025Continuum

## Concrete comparisons

- Axis: evaluation protocol (datasets; A: Agent frameworks / architectures: `P0010`, `P0023`, `P0042`; B: Multi-agent coordination: `P0043`, `P0114`, `P0198`. Lumer2025Memtool Silva2025Agents Wu2025Agents
  - A highlight: (E-P0058-35271418ac) Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy. Lumer2025Memtool (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - A highlight: (E-P0043-baa622fa7f) This study offers new insights into the strengths and failure modes of LLMs in physically grounded multi-agent collaboration tasks, contributing to future benchmarks and architectural improvements. Silva2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0043#key_results[1])
  - B highlight: (E-P0043-baa622fa7f) This study offers new insights into the strengths and failure modes of LLMs in physically grounded multi-agent collaboration tasks, contributing to future benchmarks and architectural improvements. Silva2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0043#key_results[1])
  - B highlight: (E-P0114-e31a1bbba7) We address this question through a controlled study using the Knight--Knave--Spy logic puzzle, which enables precise, step-wise evaluation of debate outcomes and processes under verifiable ground truth. Wu2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0114#key_results[0])
- Axis: metrics; A: Agent frameworks / architectures: `P0010`, `P0023`, `P0042`; B: Multi-agent coordination: `P0043`, `P0114`, `P0198`. Lumer2025Memtool Shao2025Craken Wu2025Agents Silva2025Agents
  - A highlight: (E-P0058-35271418ac) Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy. Lumer2025Memtool (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - A highlight: (E-P0042-9d48d99db0) On evaluation of MITRE ATT&CK techniques, CRAKEN solves 25-30% more techniques than prior work, demonstrating improved cybersecurity capabilities via knowledge-based execution. Shao2025Craken (pointer: papers/paper_notes.jsonl:paper_id=P0042#key_results[1])
  - B highlight: (E-P0114-e31a1bbba7) We address this question through a controlled study using the Knight--Knave--Spy logic puzzle, which enables precise, step-wise evaluation of debate outcomes and processes under verifiable ground truth. Wu2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0114#key_results[0])
  - B highlight: (E-P0043-baa622fa7f) This study offers new insights into the strengths and failure modes of LLMs in physically grounded multi-agent collaboration tasks, contributing to future benchmarks and architectural improvements. Silva2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0043#key_results[1])
- Axis: human evaluation); A: Agent frameworks / architectures: `P0010`, `P0023`, `P0042`; B: Multi-agent coordination: `P0043`, `P0114`, `P0198`. Lumer2025Memtool Shao2025Craken Wu2025Agents Silva2025Agents
  - A highlight: (E-P0058-35271418ac) Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy. Lumer2025Memtool (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - A highlight: (E-P0042-9d48d99db0) On evaluation of MITRE ATT&CK techniques, CRAKEN solves 25-30% more techniques than prior work, demonstrating improved cybersecurity capabilities via knowledge-based execution. Shao2025Craken (pointer: papers/paper_notes.jsonl:paper_id=P0042#key_results[1])
  - B highlight: (E-P0114-e31a1bbba7) We address this question through a controlled study using the Knight--Knave--Spy logic puzzle, which enables precise, step-wise evaluation of debate outcomes and processes under verifiable ground truth. Wu2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0114#key_results[0])
  - B highlight: (E-P0043-baa622fa7f) This study offers new insights into the strengths and failure modes of LLMs in physically grounded multi-agent collaboration tasks, contributing to future benchmarks and architectural improvements. Silva2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0043#key_results[1])
- Axis: compute and latency constraints; A: Agent frameworks / architectures: `P0010`, `P0023`, `P0042`; B: Multi-agent coordination: `P0043`, `P0114`, `P0198`. Cao2025Skyrl Wu2025Agents Silva2025Agents
  - A highlight: (E-P0023-32b2c8cf19) We introduce SkyRL-Agent, a framework for efficient, multi-turn, long-horizon agent training and evaluation. Cao2025Skyrl (pointer: papers/paper_notes.jsonl:paper_id=P0023#method)
  - A highlight: (E-P0023-3af1ce8090) Using SkyRL-Agent, we train SA-SWE-32B, a software engineering agent trained from Qwen3-32B (24.4% Pass@1) purely with reinforcement learning. Cao2025Skyrl (pointer: papers/paper_notes.jsonl:paper_id=P0023#key_results[0])
  - B highlight: (E-P0114-e31a1bbba7) We address this question through a controlled study using the Knight--Knave--Spy logic puzzle, which enables precise, step-wise evaluation of debate outcomes and processes under verifiable ground truth. Wu2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0114#key_results[0])
  - B highlight: (E-P0043-baa622fa7f) This study offers new insights into the strengths and failure modes of LLMs in physically grounded multi-agent collaboration tasks, contributing to future benchmarks and architectural improvements. Silva2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0043#key_results[1])
- Axis: and failure modes and limitations; A: Agent frameworks / architectures: `P0010`, `P0023`, `P0042`; B: Multi-agent coordination: `P0043`, `P0114`, `P0198`. Lumer2025Memtool Shao2025Craken Wu2025Agents Silva2025Agents
  - A highlight: (E-P0058-35271418ac) Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy. Lumer2025Memtool (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - A highlight: (E-P0042-9d48d99db0) On evaluation of MITRE ATT&CK techniques, CRAKEN solves 25-30% more techniques than prior work, demonstrating improved cybersecurity capabilities via knowledge-based execution. Shao2025Craken (pointer: papers/paper_notes.jsonl:paper_id=P0042#key_results[1])
  - B highlight: (E-P0114-e31a1bbba7) We address this question through a controlled study using the Knight--Knave--Spy logic puzzle, which enables precise, step-wise evaluation of debate outcomes and processes under verifiable ground truth. Wu2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0114#key_results[0])
  - B highlight: (E-P0043-baa622fa7f) This study offers new insights into the strengths and failure modes of LLMs in physically grounded multi-agent collaboration tasks, contributing to future benchmarks and architectural improvements. Silva2025Agents (pointer: papers/paper_notes.jsonl:paper_id=P0043#key_results[1])

## Evaluation protocol

- Evaluation tokens mentioned in mapped evidence: MCP; LLM-based; MCP-compliant; SA-SWE-32B; AST-based; SWE-Bench; SWE; SkyRL-Agent; SkyRL-train; VeRL. Sarkar2025Survey Cao2025Skyrl Shao2025Craken Silva2025Agents

## Failures / limitations

- The article concludes by outlining open challenges, potential security risks, and promising directions for advancing robust, interoperable, and scalable multi-agent LLM ecosystems. Sarkar2025Survey
- While LLM agents have demonstrated cybersecurity capabilities on Capture-The-Flag (CTF) competitions, they have two key limitations: accessing latest cybersecurity expertise beyond training data, and integrating new knowledge into complex task planning. Shao2025Craken
- Knowledge-based approaches that incorporate technical understanding into the task-solving automation can tackle these limitations. Shao2025Craken
- We present CRAKEN, a knowledge-based LLM agent framework that improves cybersecurity capability through three core mechanisms: contextual decomposition of task-critical information, iterative self-reflected knowledge retrieval, and knowledge-hint injection that transforms insights into adaptive attack strategies. Shao2025Craken

## Verify fields (non-blocking)

- named benchmarks/datasets used
- metrics/human-eval protocol
- compute/training/inference cost
- training data and supervision signal
- failure modes / known limitations
- baseline choices and ablation evidence
