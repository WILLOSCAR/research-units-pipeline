# Evidence draft: 3.2 Tool interfaces and orchestration

## Evidence snippets (with provenance)
- (E-P0047-37f9ea924c) This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and (2) evaluation process -- how to evaluate, including interaction modes, datasets and benchmarks, metric computation methods, and tooling. Mohammadi2025Evaluation (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0047#key_results[0])
- (E-P0017-192e78b614) We introduce ETOM, a five-level benchmark for evaluating multi-hop, end-to-end tool orchestration by LLM agents within a hierarchical Model-Context Protocol (MCP) ecosystem. Dong2025Etom (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0017#method)
- (E-P0056-f7a14123f9) To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents. Liu2025Mcpagentbench (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0056#limitations[1])
- (E-P0054-fae121f81b) Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat. Li2025Dissonances (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
- (E-P0080-d5c234444e) Experiments across various datasets demonstrate the superiority of our AnyTool over strong baselines such as ToolLLM and a GPT-4 variant tailored for tool utilization. Du2024Anytool (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0080#key_results[0])
- (E-P0058-35271418ac) Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy. Lumer2025Memtool (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
- (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- (E-P0017-55ce44af76) Existing benchmarks often assess tools in isolation, overlooking challenges such as functional overlap and cross-server orchestration, which can lead to overly optimistic evaluations. Dong2025Etom (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0017#key_results[1])
- (E-P0017-6ee6d5b951) We introduce ETOM, a five-level benchmark for evaluating multi-hop, end-to-end tool orchestration by LLM agents within a hierarchical Model-Context Protocol (MCP) ecosystem. Dong2025Etom (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0017#key_results[0])
- (E-P0027-9640816b42) Evaluation across various tool-use benchmarks illustrates that our proposed multi-LLM framework surpasses the traditional single-LLM approach, highlighting its efficacy and advantages in tool learning. Shen2024Small (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0027#key_results[1])

## Definitions / setup

- Setup: Which design choices in Tool interfaces and orchestration drive the major trade-offs, and how are those trade-offs measured? Scope: in-scope: Core topics directly relevant to 'Tool interfaces and orchestration'.. Axes: evaluation protocol (datasets; metrics; human evaluation); compute and latency constraints; and failure modes and limitations. Li2026Toolprmbench Hao2026From Xuan2026Confidence

## Claim candidates

- This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and (2) evaluation process -- how to evaluate, including interaction modes, datasets and benchmarks, metric computation Mohammadi2025Evaluation
- We introduce ETOM, a five-level benchmark for evaluating multi-hop, end-to-end tool orchestration by LLM agents within a hierarchical Model-Context Protocol (MCP) ecosystem. Dong2025Etom
- To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents. Liu2025Mcpagentbench
- Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat. Li2025Dissonances
- Experiments across various datasets demonstrate the superiority of our AnyTool over strong baselines such as ToolLLM and a GPT-4 variant tailored for tool utilization. Du2024Anytool

## Concrete comparisons

- Axis: evaluation protocol (datasets; A: Agent frameworks / architectures: `P0033`, `P0093`, `P0098`; B: Tool-use and function calling: `P0033`, `P0093`, `P0098`. Mohammadi2025Evaluation Lumer2025Memtool Dong2025Etom
  - A highlight: (E-P0047-37f9ea924c) This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and Mohammadi2025Evaluation (pointer: papers/paper_notes.jsonl:paper_id=P0047#key_results[0])
  - A highlight: (E-P0058-35271418ac) Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy. Lumer2025Memtool (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - B highlight: (E-P0058-35271418ac) Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy. Lumer2025Memtool (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - B highlight: (E-P0017-192e78b614) We introduce ETOM, a five-level benchmark for evaluating multi-hop, end-to-end tool orchestration by LLM agents within a hierarchical Model-Context Protocol (MCP) ecosystem. Dong2025Etom (pointer: papers/paper_notes.jsonl:paper_id=P0017#method)
- Axis: metrics; A: Agent frameworks / architectures: `P0033`, `P0093`, `P0098`; B: Tool-use and function calling: `P0033`, `P0093`, `P0098`. Mohammadi2025Evaluation Li2025Dissonances Lumer2025Memtool
  - A highlight: (E-P0047-37f9ea924c) This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and Mohammadi2025Evaluation (pointer: papers/paper_notes.jsonl:paper_id=P0047#key_results[0])
  - A highlight: (E-P0054-fae121f81b) Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat. Li2025Dissonances (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - B highlight: (E-P0054-fae121f81b) Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat. Li2025Dissonances (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - B highlight: (E-P0058-35271418ac) Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy. Lumer2025Memtool (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
- Axis: human evaluation); A: Agent frameworks / architectures: `P0033`, `P0093`, `P0098`; B: Tool-use and function calling: `P0033`, `P0093`, `P0098`. Mohammadi2025Evaluation Li2025Dissonances Lumer2025Memtool
  - A highlight: (E-P0047-37f9ea924c) This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and Mohammadi2025Evaluation (pointer: papers/paper_notes.jsonl:paper_id=P0047#key_results[0])
  - A highlight: (E-P0054-fae121f81b) Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat. Li2025Dissonances (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - B highlight: (E-P0054-fae121f81b) Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat. Li2025Dissonances (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - B highlight: (E-P0058-35271418ac) Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy. Lumer2025Memtool (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
- Axis: compute and latency constraints; A: Agent frameworks / architectures: `P0033`, `P0093`, `P0098`; B: Tool-use and function calling: `P0033`, `P0093`, `P0098`. Li2025Dissonances Mohammadi2025Evaluation Lumer2025Memtool
  - A highlight: (E-P0054-fae121f81b) Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat. Li2025Dissonances (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - A highlight: (E-P0047-37f9ea924c) This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and Mohammadi2025Evaluation (pointer: papers/paper_notes.jsonl:paper_id=P0047#key_results[0])
  - B highlight: (E-P0054-fae121f81b) Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat. Li2025Dissonances (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - B highlight: (E-P0058-35271418ac) Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy. Lumer2025Memtool (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
- Axis: and failure modes and limitations; A: Agent frameworks / architectures: `P0033`, `P0093`, `P0098`; B: Tool-use and function calling: `P0033`, `P0093`, `P0098`. Mohammadi2025Evaluation Li2025Dissonances Lumer2025Memtool
  - A highlight: (E-P0047-37f9ea924c) This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and Mohammadi2025Evaluation (pointer: papers/paper_notes.jsonl:paper_id=P0047#key_results[0])
  - A highlight: (E-P0054-fae121f81b) Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat. Li2025Dissonances (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - B highlight: (E-P0054-fae121f81b) Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat. Li2025Dissonances (pointer: papers/paper_notes.jsonl:paper_id=P0054#key_results[0])
  - B highlight: (E-P0058-35271418ac) Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy. Lumer2025Memtool (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])

## Evaluation protocol

- Evaluation tokens mentioned in mapped evidence: PRMs; PRM; ToolPRMBench; API; GPT-5; HardGen; LLMs; AgentGuard; LLM-based; XTHP. Li2026Toolprmbench Hao2026From Xuan2026Confidence Chen2025Agentguard

## Failures / limitations

- Firstly, HardGen establishes a dynamic API Graph built upon agent failure cases, from which it samples to synthesize hard traces. Hao2026From
- Autonomous agents based on large language models (LLMs) are rapidly evolving to handle multi-turn tasks, but ensuring their trustworthiness remains a critical challenge. Xuan2026Confidence
- We propose AgentGuard, a framework to autonomously discover and validate unsafe tool-use workflows, followed by generating safety constraints to confine the behaviors of agents, achieving the baseline of safety guarantee at deployment. Chen2025Agentguard
- The framework operates through four phases: identifying unsafe workflows, validating them in real-world execution, generating safety constraints, and validating constraint efficacy. Chen2025Agentguard

## Verify fields (non-blocking)

- named benchmarks/datasets used
- metrics/human-eval protocol
- compute/training/inference cost
- training data and supervision signal
- failure modes / known limitations
- baseline choices and ablation evidence
