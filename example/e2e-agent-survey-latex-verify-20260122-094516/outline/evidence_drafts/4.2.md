# Evidence draft: 4.2 Memory and retrieval (RAG)

## Evidence snippets (with provenance)
- (E-P0019-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0019#key_results[1])
- (E-P0055-8bcb673a7d) We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling. Zhang2025Security (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0055#method)
- (E-P0158-c9781caf3b) SAFE demonstrates robust improvements in long-form COVID-19 fact-checking by addressing LLM limitations in consistency and explainability. Huang2025Retrieval (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0158#limitations[1])
- (E-P0055-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed attacks; (2) an evaluation harness that executes attacks by running real tools (both benign and malicious) via MCP rather than simulation; and (3) a robustness metric that quantifies the trade-off between security and performance: Net Resilient Performance (NRP). Zhang2025Security (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0055#key_results[0])
- (E-P0060-68db58914f) Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed. Shi2025Progent (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0060#key_results[0])
- (E-P0158-4af0cf3c02) This study presents SAFE (system for accurate fact extraction and evaluation), an agent system that combines large language models with retrieval-augmented generation (RAG) to improve automated fact-checking of long-form COVID-19 misinformation. Huang2025Retrieval (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0158#key_results[1])
- (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- (E-P0014-904ba35500) Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\% over both existing automated agent search methods and manually designed agents. Li2025Agentswift (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0014#key_results[0])
- (E-P0055-7a6ec4daed) We evaluate nine popular LLM agents across 10 domains and 400+ tools, producing 2,000 attack instances. Zhang2025Security (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0055#key_results[1])
- (E-P0184-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0184#key_results[1])

## Definitions / setup

- Setup: Which design choices in Memory and retrieval (RAG) drive the major trade-offs, and how are those trade-offs measured? Scope: in-scope: Core topics directly relevant to 'Memory and retrieval (RAG)'.. Axes: evaluation protocol (datasets; metrics; human evaluation); compute and latency constraints; and failure modes and limitations. Verma2026Active Yu2026Agentic Lin2026Froav

## Claim candidates

- Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta
- We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling. Zhang2025Security
- SAFE demonstrates robust improvements in long-form COVID-19 fact-checking by addressing LLM limitations in consistency and explainability. Huang2025Retrieval
- MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed attacks; (2) an evaluation harness that executes attacks by running real tools (both benign and malicious) via MCP Zhang2025Security
- Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed. Shi2025Progent

## Concrete comparisons

- Axis: evaluation protocol (datasets; A: Agent frameworks / architectures: `P0184`, `P0185`, `P0187`; B: Memory / retrieval augmentation: `P0184`, `P0185`, `P0187`. Zhang2025Security Li2025Agentswift Tawosi2025Meta Verma2026Active
  - A highlight: (E-P0055-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0055#key_results[0])
  - A highlight: (E-P0014-904ba35500) Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\% over both existing automated agent search methods and manually designed agents. Li2025Agentswift (pointer: papers/paper_notes.jsonl:paper_id=P0014#key_results[0])
  - B highlight: (E-P0019-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta (pointer: papers/paper_notes.jsonl:paper_id=P0019#key_results[1])
  - B highlight: (E-P0184-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (pointer: papers/paper_notes.jsonl:paper_id=P0184#key_results[1])
- Axis: metrics; A: Agent frameworks / architectures: `P0184`, `P0185`, `P0187`; B: Memory / retrieval augmentation: `P0184`, `P0185`, `P0187`. Zhang2025Security Shi2025Progent Tawosi2025Meta Verma2026Active
  - A highlight: (E-P0055-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0055#key_results[0])
  - A highlight: (E-P0060-68db58914f) Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed. Shi2025Progent (pointer: papers/paper_notes.jsonl:paper_id=P0060#key_results[0])
  - B highlight: (E-P0019-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta (pointer: papers/paper_notes.jsonl:paper_id=P0019#key_results[1])
  - B highlight: (E-P0184-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (pointer: papers/paper_notes.jsonl:paper_id=P0184#key_results[1])
- Axis: human evaluation); A: Agent frameworks / architectures: `P0184`, `P0185`, `P0187`; B: Memory / retrieval augmentation: `P0184`, `P0185`, `P0187`. Zhang2025Security Shi2025Progent Tawosi2025Meta Verma2026Active
  - A highlight: (E-P0055-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0055#key_results[0])
  - A highlight: (E-P0060-68db58914f) Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed. Shi2025Progent (pointer: papers/paper_notes.jsonl:paper_id=P0060#key_results[0])
  - B highlight: (E-P0019-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta (pointer: papers/paper_notes.jsonl:paper_id=P0019#key_results[1])
  - B highlight: (E-P0184-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (pointer: papers/paper_notes.jsonl:paper_id=P0184#key_results[1])
- Axis: compute and latency constraints; A: Agent frameworks / architectures: `P0184`, `P0185`, `P0187`; B: Memory / retrieval augmentation: `P0184`, `P0185`, `P0187`. Zhang2025Security Shi2025Progent Tawosi2025Meta Verma2026Active
  - A highlight: (E-P0055-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0055#key_results[0])
  - A highlight: (E-P0060-68db58914f) Our extensive evaluation across various agent use cases, using benchmarks like AgentDojo, ASB, and AgentPoison, demonstrates that Progent reduces attack success rates to 0%, while preserving agent utility and speed. Shi2025Progent (pointer: papers/paper_notes.jsonl:paper_id=P0060#key_results[0])
  - B highlight: (E-P0019-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta (pointer: papers/paper_notes.jsonl:paper_id=P0019#key_results[1])
  - B highlight: (E-P0184-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (pointer: papers/paper_notes.jsonl:paper_id=P0184#key_results[1])
- Axis: and failure modes and limitations; A: Agent frameworks / architectures: `P0184`, `P0185`, `P0187`; B: Memory / retrieval augmentation: `P0184`, `P0185`, `P0187`. Zhang2025Security Li2025Agentswift Tawosi2025Meta Verma2026Active
  - A highlight: (E-P0055-d6095e10e9) MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed Zhang2025Security (pointer: papers/paper_notes.jsonl:paper_id=P0055#key_results[0])
  - A highlight: (E-P0014-904ba35500) Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\% over both existing automated agent search methods and manually designed agents. Li2025Agentswift (pointer: papers/paper_notes.jsonl:paper_id=P0014#key_results[0])
  - B highlight: (E-P0019-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta (pointer: papers/paper_notes.jsonl:paper_id=P0019#key_results[1])
  - B highlight: (E-P0184-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (pointer: papers/paper_notes.jsonl:paper_id=P0184#key_results[1])

## Evaluation protocol

- Evaluation tokens mentioned in mapped evidence: SWE-bench; LTM; STM; GRPO; AgeMem; LLMs; LLM-based; FROAV; RAG; LLM-as-a-Judge. Verma2026Active Yu2026Agentic Lin2026Froav Li2025Agentswift

## Failures / limitations

- Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical. Yu2026Agentic
- Large language model (LLM) agents have demonstrated strong capabilities across diverse domains, yet automated agent design remains a significant challenge. Li2025Agentswift
- This challenge stems from two distinct failure modes: a syntactic misunderstanding of environment-specific components like observation formats, and a semantic misunderstanding of state-transition dynamics, which are only revealed at test time. Chen2025Grounded
- While MCP unlocks broad interoperability, it also enlarges the attack surface by making tools first-class, composable objects with natural-language metadata, and standardized I/O. Zhang2025Security

## Verify fields (non-blocking)

- named benchmarks/datasets used
- metrics/human-eval protocol
- compute/training/inference cost
- training data and supervision signal
- failure modes / known limitations
- baseline choices and ablation evidence
